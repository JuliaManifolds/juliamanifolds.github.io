[{"id":3,"pagetitle":"Home","title":"ManifoldsBase.jl","ref":"/manifoldsbase/stable/#ManifoldsBase.jl","content":" ManifoldsBase.jl ManifoldsBase.jl  is a lightweight interface for manifolds. This packages has two main purposes. You can add it as a dependency if you plan to work on manifolds (generically) or if you plan to define own manifolds in a package. For a package that (only) depends on  ManifoldsBase.jl , see  Manopt.jl , which implements optimization algorithms on manifolds using this interface. These optimisation algorithms can hence be used with any manifold implemented based on  ManifoldsBase.jl . For a library of manifolds implemented using this interface  Manifolds.jl . Your package is using  ManifoldsBase ? We would like to add that here as well. Either  write an issue  or add yourself by forking, editing this file and  opening a PR ."},{"id":4,"pagetitle":"Home","title":"Citation","ref":"/manifoldsbase/stable/#Citation","content":" Citation If you use  ManifoldsBase.jl  in your work, please cite the following paper, which covers both the basic interface as well as the performance for  Manifolds.jl . @article{AxenBaranBergmannRzecki:2023,\n    AUTHOR    = {Axen, Seth D. and Baran, Mateusz and Bergmann, Ronny and Rzecki, Krzysztof},\n    ARTICLENO = {33},\n    DOI       = {10.1145/3618296},\n    JOURNAL   = {ACM Transactions on Mathematical Software},\n    MONTH     = {dec},\n    NUMBER    = {4},\n    TITLE     = {Manifolds.Jl: An Extensible Julia Framework for Data Analysis on Manifolds},\n    VOLUME    = {49},\n    YEAR      = {2023}\n} Note that the citation is in  BibLaTeX  format."},{"id":7,"pagetitle":"Bases for tangent spaces","title":"Bases for tangent spaces","ref":"/manifoldsbase/stable/bases/#bases","content":" Bases for tangent spaces The following functions and types provide support for bases of the tangent space of different manifolds. Moreover, bases of the cotangent space are also supported, though this description focuses on the tangent space. An orthonormal basis of the tangent space  $T_p \\mathcal M$  of (real) dimension  $n$  has a real-coefficient basis  $e_1, e_2, ‚Ä¶, e_n$  if  $\\mathrm{Re}(g_p(e_i, e_j)) = Œ¥_{ij}$  for each  $i,j ‚àà \\{1, 2, ‚Ä¶, n\\}$  where  $g_p$  is the Riemannian metric at point  $p$ . A vector  $X$  from the tangent space  $T_p \\mathcal M$  can be expressed in Einstein notation as a sum  $X = X^i e_i$ , where (real) coefficients  $X^i$  are calculated as  $X^i = \\mathrm{Re}(g_p(X, e_i))$ . The main types are: DefaultOrthonormalBasis , which is designed to work when no special properties of the tangent space basis are required.  It is designed to make  get_coordinates  and  get_vector  fast. DiagonalizingOrthonormalBasis , which diagonalizes the curvature tensor and makes the curvature in the selected direction equal to 0. ProjectedOrthonormalBasis , which projects a basis of the ambient space and orthonormalizes projections to obtain a basis in a generic way. CachedBasis , which stores (explicitly or implicitly) a precomputed basis at a certain point. The main functions are: get_basis  precomputes a basis at a certain point. get_coordinates  returns coordinates of a tangent vector. get_vector  returns a vector for the specified coordinates. get_vectors  returns a vector of basis vectors. Calling it should be avoided for high-dimensional manifolds."},{"id":8,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.AbstractBasis","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.AbstractBasis","content":" ManifoldsBase.AbstractBasis  ‚Äî  Type AbstractBasis{ùîΩ,VST<:VectorSpaceType} Abstract type that represents a basis of vector space of type  VST  on a manifold or a subset of it. The type parameter  ùîΩ  denotes the  AbstractNumbers  that will be used for the vectors elements. See also VectorSpaceType source"},{"id":9,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.AbstractOrthogonalBasis","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.AbstractOrthogonalBasis","content":" ManifoldsBase.AbstractOrthogonalBasis  ‚Äî  Type AbstractOrthogonalBasis{ùîΩ,VST<:VectorSpaceType} Abstract type that represents an orthonormal basis of vector space of type  VST  on a manifold or a subset of it. The type parameter  ùîΩ  denotes the  AbstractNumbers  that will be used for the vectors elements. See also VectorSpaceType source"},{"id":10,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.AbstractOrthonormalBasis","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.AbstractOrthonormalBasis","content":" ManifoldsBase.AbstractOrthonormalBasis  ‚Äî  Type AbstractOrthonormalBasis{ùîΩ,VST<:VectorSpaceType} Abstract type that represents an orthonormal basis of vector space of type  VST  on a manifold or a subset of it. The type parameter  ùîΩ  denotes the  AbstractNumbers  that will be used for the vectors elements. See also VectorSpaceType source"},{"id":11,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.CachedBasis","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.CachedBasis","content":" ManifoldsBase.CachedBasis  ‚Äî  Type CachedBasis{ùîΩ,V,<:AbstractBasis{ùîΩ}} <: AbstractBasis{ùîΩ} A cached version of the given  basis  with precomputed basis vectors. The basis vectors are stored in  data , either explicitly (like in cached variants of  ProjectedOrthonormalBasis ) or implicitly. Constructor CachedBasis(basis::AbstractBasis, data) source"},{"id":12,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.CotangentSpaceType","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.CotangentSpaceType","content":" ManifoldsBase.CotangentSpaceType  ‚Äî  Type struct CotangentSpaceType <: VectorSpaceType end A type that indicates that a  Fiber  is a  CotangentSpace . source"},{"id":13,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.DefaultBasis","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.DefaultBasis","content":" ManifoldsBase.DefaultBasis  ‚Äî  Type DefaultBasis{ùîΩ,VST<:VectorSpaceType} An arbitrary basis of vector space of type  VST  on a manifold. This will usually be the fastest basis available for a manifold. The type parameter  ùîΩ  denotes the  AbstractNumbers  that will be used for the vectors elements. See also VectorSpaceType source"},{"id":14,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.DefaultOrthogonalBasis","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.DefaultOrthogonalBasis","content":" ManifoldsBase.DefaultOrthogonalBasis  ‚Äî  Type DefaultOrthogonalBasis{ùîΩ,VST<:VectorSpaceType} An arbitrary orthogonal basis of vector space of type  VST  on a manifold. This will usually be the fastest orthogonal basis available for a manifold. The type parameter  ùîΩ  denotes the  AbstractNumbers  that will be used for the vectors elements. See also VectorSpaceType source"},{"id":15,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.DefaultOrthonormalBasis","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.DefaultOrthonormalBasis","content":" ManifoldsBase.DefaultOrthonormalBasis  ‚Äî  Type DefaultOrthonormalBasis(ùîΩ::AbstractNumbers = ‚Ñù, vs::VectorSpaceType = TangentSpaceType()) An arbitrary orthonormal basis of vector space of type  VST  on a manifold. This will usually be the fastest orthonormal basis available for a manifold. The type parameter  ùîΩ  denotes the  AbstractNumbers  that will be used for the vectors elements. See also VectorSpaceType source"},{"id":16,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.DiagonalizingOrthonormalBasis","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.DiagonalizingOrthonormalBasis","content":" ManifoldsBase.DiagonalizingOrthonormalBasis  ‚Äî  Type DiagonalizingOrthonormalBasis{ùîΩ,TV} <: AbstractOrthonormalBasis{ùîΩ,TangentSpaceType} An orthonormal basis  Œû  as a vector of tangent vectors (of length determined by  manifold_dimension ) in the tangent space that diagonalizes the curvature tensor  $R(u,v)w$  and where the direction  frame_direction $v$  has curvature  0 . The type parameter  ùîΩ  denotes the  AbstractNumbers  that will be used for the vectors elements. Constructor DiagonalizingOrthonormalBasis(frame_direction, ùîΩ::AbstractNumbers = ‚Ñù) source"},{"id":17,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.GramSchmidtOrthonormalBasis","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.GramSchmidtOrthonormalBasis","content":" ManifoldsBase.GramSchmidtOrthonormalBasis  ‚Äî  Type GramSchmidtOrthonormalBasis{ùîΩ} <: AbstractOrthonormalBasis{ùîΩ} An orthonormal basis obtained from a basis. Constructor GramSchmidtOrthonormalBasis(ùîΩ::AbstractNumbers = ‚Ñù) source"},{"id":18,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.ProjectedOrthonormalBasis","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.ProjectedOrthonormalBasis","content":" ManifoldsBase.ProjectedOrthonormalBasis  ‚Äî  Type ProjectedOrthonormalBasis(method::Symbol, ùîΩ::AbstractNumbers = ‚Ñù) An orthonormal basis that comes from orthonormalization of basis vectors of the ambient space projected onto the subspace representing the tangent space at a given point. The type parameter  ùîΩ  denotes the  AbstractNumbers  that will be used for the vectors elements. Available methods: :gram_schmidt  uses a modified Gram-Schmidt orthonormalization. :svd  uses SVD decomposition to orthogonalize projected vectors. The SVD-based method should be more numerically stable at the cost of an additional assumption (local metric tensor at a point where the basis is calculated has to be diagonal). source"},{"id":19,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.TangentSpaceType","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.TangentSpaceType","content":" ManifoldsBase.TangentSpaceType  ‚Äî  Type struct TangentSpaceType <: VectorSpaceType end A type that indicates that a  Fiber  is a  TangentSpace . source"},{"id":20,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.VectorSpaceType","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.VectorSpaceType","content":" ManifoldsBase.VectorSpaceType  ‚Äî  Type VectorSpaceType Abstract type for tangent spaces, cotangent spaces, their tensor products, exterior products, etc. Every vector space  fiber  is supposed to provide: a method of constructing vectors, basic operations: addition, subtraction, multiplication by a scalar and negation (unary minus), zero_vector(fiber, p)  to construct zero vectors at point  p , allocate(X)  and  allocate(X, T)  for vector  X  and type  T , copyto!(X, Y)  for vectors  X  and  Y , number_eltype(v)  for vector  v , vector_space_dimension . Optionally: inner product via  inner  (used to provide Riemannian metric on vector bundles), flat  and  sharp , norm  (by default uses  inner ), project  (for embedded vector spaces), representation_size , broadcasting for basic operations. source"},{"id":21,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.allocate_coordinates","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.allocate_coordinates-Tuple{AbstractManifold, Any, Any, Int64}","content":" ManifoldsBase.allocate_coordinates  ‚Äî  Method allocate_coordinates(M::AbstractManifold, p, T, n::Int) Allocate vector of coordinates of length  n  of type  T  of a vector at point  p  on manifold  M . source"},{"id":22,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.allocation_promotion_function","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.allocation_promotion_function-Tuple{AbstractManifold, Any, Tuple}","content":" ManifoldsBase.allocation_promotion_function  ‚Äî  Method allocation_promotion_function(M::AbstractManifold, f, args::Tuple) Determine the function that must be used to ensure that the allocated representation is of the right type. This is needed for  get_vector  when a point on a complex manifold is represented by a real-valued vectors with a real-coefficient basis, so that a complex-valued vector representation is allocated. source"},{"id":23,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.change_basis","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.change_basis-Tuple{AbstractManifold, Any, Any, ManifoldsBase.AbstractBasis, ManifoldsBase.AbstractBasis}","content":" ManifoldsBase.change_basis  ‚Äî  Method change_basis(M::AbstractManifold, p, c, B_in::AbstractBasis, B_out::AbstractBasis) Given a vector with coordinates  c  at point  p  from manifold  M  in basis  B_in , compute coordinates of the same vector in basis  B_out . source"},{"id":24,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.coordinate_eltype","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.coordinate_eltype-Union{Tuple{MùîΩ}, Tuple{AbstractManifold{MùîΩ}, Any, ManifoldsBase.AbstractNumbers}} where MùîΩ","content":" ManifoldsBase.coordinate_eltype  ‚Äî  Method coordinate_eltype(M::AbstractManifold{MùîΩ}, p, ùîΩ::AbstractNumbers) where {MùîΩ} Get the element type for ùîΩ-field coordinates of the tangent space at a point  p  from manifold  M . This default assumes that usually complex bases of complex manifolds have real coordinates but it can be overridden by a more specific method. source"},{"id":25,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.dual_basis","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.dual_basis-Tuple{AbstractManifold, Any, ManifoldsBase.AbstractBasis}","content":" ManifoldsBase.dual_basis  ‚Äî  Method dual_basis(M::AbstractManifold, p, B::AbstractBasis) Get the dual basis to  B , a basis of a vector space at point  p  from manifold  M . The dual to the  $i$ th vector  $v_i$  from basis  B  is a vector  $v^i$  from the dual space such that  $v^i(v_j) = Œ¥^i_j$ , where  $Œ¥^i_j$  is the Kronecker delta symbol: \\[Œ¥^i_j = \\begin{cases}\n1 & \\text{ if } i=j, \\\\\n0 & \\text{ otherwise.}\n\\end{cases}\\] source"},{"id":26,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.get_basis","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.get_basis-Tuple{AbstractManifold, Any, ManifoldsBase.AbstractBasis}","content":" ManifoldsBase.get_basis  ‚Äî  Method get_basis(M::AbstractManifold, p, B::AbstractBasis; kwargs...) -> CachedBasis Compute the basis vectors of the tangent space at a point on manifold  M  represented by  p . Returned object derives from  AbstractBasis  and may have a field  .vectors  that stores tangent vectors or it may store them implicitly, in which case the function  get_vectors  needs to be used to retrieve the basis vectors. See also:  get_coordinates ,  get_vector source"},{"id":27,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.get_coordinates","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.get_coordinates-Tuple{AbstractManifold, Any, Any, ManifoldsBase.AbstractBasis}","content":" ManifoldsBase.get_coordinates  ‚Äî  Method get_coordinates(M::AbstractManifold, p, X, B::AbstractBasis)\nget_coordinates(M::AbstractManifold, p, X, B::CachedBasis) Compute a one-dimensional vector of coefficients of the tangent vector  X  at point denoted by  p  on manifold  M  in basis  B . Depending on the basis,  p  may not directly represent a point on the manifold. For example if a basis transported along a curve is used,  p  may be the coordinate along the curve. If a  CachedBasis  is provided, their stored vectors are used, otherwise the user has to provide a method to compute the coordinates. For the  CachedBasis  keep in mind that the reconstruction with  get_vector  requires either a dual basis or the cached basis to be selfdual, for example orthonormal See also:  get_vector ,  get_basis source"},{"id":28,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.get_vector","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.get_vector-Tuple{AbstractManifold, Any, Any, ManifoldsBase.AbstractBasis}","content":" ManifoldsBase.get_vector  ‚Äî  Method X = get_vector(M::AbstractManifold, p, c, B::AbstractBasis) Convert a one-dimensional vector of coefficients in a basis  B  of the tangent space at  p  on manifold  M  to a tangent vector  X  at  p . Depending on the basis,  p  may not directly represent a point on the manifold. For example if a basis transported along a curve is used,  p  may be the coordinate along the curve. For the  CachedBasis  keep in mind that the reconstruction from  get_coordinates  requires either a dual basis or the cached basis to be selfdual, for example orthonormal See also:  get_coordinates ,  get_basis source"},{"id":29,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.get_vectors","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.get_vectors-Tuple{AbstractManifold, Any, ManifoldsBase.AbstractBasis}","content":" ManifoldsBase.get_vectors  ‚Äî  Method get_vectors(M::AbstractManifold, p, B::AbstractBasis) Get the basis vectors of basis  B  of the tangent space at point  p . source"},{"id":30,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.gram_schmidt","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.gram_schmidt-Union{Tuple{ùîΩ}, Tuple{AbstractManifold{ùîΩ}, Any, ManifoldsBase.AbstractBasis{ùîΩ}}} where ùîΩ","content":" ManifoldsBase.gram_schmidt  ‚Äî  Method gram_schmidt(M::AbstractManifold{ùîΩ}, p, B::AbstractBasis{ùîΩ}) where {ùîΩ}\ngram_schmidt(M::AbstractManifold, p, V::AbstractVector) Compute an ONB in the tangent space at  p  on the [ AbstractManifold ](@ref}  M  from either an  AbstractBasis  basis ¬¥B¬¥ or a set of (at most)  manifold_dimension (M)  many vectors. Note that this method requires the manifold and basis to work on the same  AbstractNumbers ùîΩ , i.e. with real coefficients. The method always returns a basis, i.e. linearly dependent vectors are removed. Keyword arguments warn_linearly_dependent  ( false ) ‚Äì warn if the basis vectors are not linearly independent skip_linearly_dependent  ( false ) ‚Äì whether to just skip ( true ) a vector that is linearly dependent to the previous ones or to stop ( false , default) at that point return_incomplete_set  ( false ) ‚Äì throw an error if the resulting set of vectors is not a basis but contains less vectors further keyword arguments can be passed to set the accuracy of the independence test. Especially  atol  is raised slightly by default to  atol = 5*1e-16 . Return value When a set of vectors is orthonormalized a set of vectors is returned. When an  AbstractBasis  is orthonormalized, a  CachedBasis  is returned. source"},{"id":31,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.hat","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.hat-Tuple{AbstractManifold, Any, Any}","content":" ManifoldsBase.hat  ‚Äî  Method hat(M::AbstractManifold, p, X‚Å±) Given a basis  $e_i$  on the tangent space at a point  p  and tangent component vector  $X^i ‚àà ‚Ñù$ , compute the equivalent vector representation  $X=X^i e_i$ , where Einstein summation notation is used: \\[‚àß : X^i ‚Ü¶ X^i e_i\\] For array manifolds, this converts a vector representation of the tangent vector to an array representation. The  vee  map is the  hat  map's inverse. source"},{"id":32,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.number_of_coordinates","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.number_of_coordinates-Union{Tuple{ùîæ}, Tuple{ùîΩ}, Tuple{AbstractManifold{ùîΩ}, ManifoldsBase.AbstractBasis{ùîæ}}} where {ùîΩ, ùîæ}","content":" ManifoldsBase.number_of_coordinates  ‚Äî  Method number_of_coordinates(M::AbstractManifold{ùîΩ}, B::AbstractBasis)\nnumber_of_coordinates(M::AbstractManifold{ùîΩ}, ::ùîæ) Compute the number of coordinates in basis of field type  ùîæ  on a manifold  M . This also corresponds to the number of vectors represented by  B , or stored within  B  in case of a  CachedBasis . source"},{"id":33,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.number_system","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.number_system-Union{Tuple{ManifoldsBase.AbstractBasis{ùîΩ}}, Tuple{ùîΩ}} where ùîΩ","content":" ManifoldsBase.number_system  ‚Äî  Method number_system(::AbstractBasis) The number system for the vectors of the given basis. source"},{"id":34,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.requires_caching","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.requires_caching-Tuple{ManifoldsBase.AbstractBasis}","content":" ManifoldsBase.requires_caching  ‚Äî  Method requires_caching(B::AbstractBasis) Return whether basis  B  can be used in  get_vector  and  get_coordinates  without calling  get_basis  first. source"},{"id":35,"pagetitle":"Bases for tangent spaces","title":"ManifoldsBase.vee","ref":"/manifoldsbase/stable/bases/#ManifoldsBase.vee-Tuple{AbstractManifold, Any, Any}","content":" ManifoldsBase.vee  ‚Äî  Method vee(M::AbstractManifold, p, X) Given a basis  $e_i$  on the tangent space at a point  p  and tangent vector  X , compute the vector components  $X^i ‚àà ‚Ñù$ , such that  $X = X^i e_i$ , where Einstein summation notation is used: \\[\\vee : X^i e_i ‚Ü¶ X^i\\] For array manifolds, this converts an array representation of the tangent vector to a vector representation. The  hat  map is the  vee  map's inverse. source"},{"id":38,"pagetitle":"Decorating/Extending a Manifold","title":"A Decorator for manifolds","ref":"/manifoldsbase/stable/decorator/#A-Decorator-for-manifolds","content":" A Decorator for manifolds Several properties of a manifold are often implicitly assumed, for example the choice of the (Riemannian) metric, the group structure or the embedding. The latter shall serve as an example how to either implicitly or explicitly specify the embedding to avoid re-implementations and/or distinguish different embeddings."},{"id":39,"pagetitle":"Decorating/Extending a Manifold","title":"The abstract decorator","ref":"/manifoldsbase/stable/decorator/#The-abstract-decorator","content":" The abstract decorator When first implementing a manifold, it might be beneficial to dispatch certain computations to already existing manifolds. For an embedded manifold that is isometrically embedded this might be the  inner  the manifold inherits in each tangent space from its embedding. This means we would like to dispatch the default implementation of a function to some other manifold. We refer to this as implicit decoration, since one can not ‚Äúsee‚Äù explicitly that a certain manifold inherits this property. As an example consider the  Sphere . At each point the tangent space can be identified with a subspace of the tangent space in the embedding, the  Euclidean  manifold which the unit vectors of the sphere belong to. Thus every tangent space inherits its metric from the embedding. Since in the default implementation in  Manifolds.jl  points are represented by unit vectors and tangent vectors at a point as vectors orthogonal to that point, we can just dispatch the inner product to the embedding without having to re-implement this. The manifold using such an implicit dispatch just has to be a subtype of  AbstractDecoratorManifold ."},{"id":40,"pagetitle":"Decorating/Extending a Manifold","title":"Traits with an inheritance hierarchy","ref":"/manifoldsbase/stable/decorator/#Traits-with-an-inheritance-hierarchy","content":" Traits with an inheritance hierarchy The properties mentioned above might form a hierarchy. For embedded manifolds, again, we might have just a manifold whose points are represented in some embedding. If the manifold is even isometrically embedded, it is embedded but also inherits the Riemannian metric by restricting the metric from the embedding to the corresponding tangent space under consideration. But it also inherits the functions defined for the plain embedding, for example checking some conditions for the validity of points and vectors. If it is even a submanifold, also further functions are inherited like the  shortest_geodesic . We use a variation of  Tim Holy's Traits Trick  (THTT) which takes into account this nestedness of traits."},{"id":41,"pagetitle":"Decorating/Extending a Manifold","title":"ManifoldsBase.AbstractDecoratorManifold","ref":"/manifoldsbase/stable/decorator/#ManifoldsBase.AbstractDecoratorManifold","content":" ManifoldsBase.AbstractDecoratorManifold  ‚Äî  Type AbstractDecoratorManifold{ùîΩ} <: AbstractManifold{ùîΩ} Declare a manifold to be an abstract decorator. A manifold which is a subtype of is a  decorated manifold , i.e. has certain additional properties or delegates certain properties to other manifolds. Most prominently, a manifold might be an embedded manifold, i.e. points on a manifold  $\\mathcal M$  are represented by (some, maybe not all) points on another manifold  $\\mathcal N$ . Depending on the type of embedding, several functions are dedicated to the embedding. For example if the embedding is isometric, then the  inner  does not have to be implemented for  $\\mathcal M$  but can be automatically implemented by deligation to  $\\mathcal N$ . This is modelled by the  AbstractDecoratorManifold  and traits. These are mapped to functions, which determine the types of transparencies. source"},{"id":42,"pagetitle":"Decorating/Extending a Manifold","title":"ManifoldsBase.AbstractTrait","ref":"/manifoldsbase/stable/decorator/#ManifoldsBase.AbstractTrait","content":" ManifoldsBase.AbstractTrait  ‚Äî  Type AbstractTrait An abstract trait type to build a sequence of traits source"},{"id":43,"pagetitle":"Decorating/Extending a Manifold","title":"ManifoldsBase.EmptyTrait","ref":"/manifoldsbase/stable/decorator/#ManifoldsBase.EmptyTrait","content":" ManifoldsBase.EmptyTrait  ‚Äî  Type EmptyTrait <: AbstractTrait A Trait indicating that no feature is present. source"},{"id":44,"pagetitle":"Decorating/Extending a Manifold","title":"ManifoldsBase.IsExplicitDecorator","ref":"/manifoldsbase/stable/decorator/#ManifoldsBase.IsExplicitDecorator","content":" ManifoldsBase.IsExplicitDecorator  ‚Äî  Type IsExplicitDecorator <: AbstractTrait Specify that a certain type should dispatch per default to its  decorated_manifold . Note Any decorator  behind  this decorator might not have any effect, since the function dispatch is moved to its field at this point. Therefore this decorator should always be  last  in the  TraitList . source"},{"id":45,"pagetitle":"Decorating/Extending a Manifold","title":"ManifoldsBase.TraitList","ref":"/manifoldsbase/stable/decorator/#ManifoldsBase.TraitList","content":" ManifoldsBase.TraitList  ‚Äî  Type TraitList <: AbstractTrait Combine two traits into a combined trait.  Note that this introduces a preceedence. the first of the traits takes preceedence if a trait is implemented for both functions. Constructor TraitList(head::AbstractTrait, tail::AbstractTrait) source"},{"id":46,"pagetitle":"Decorating/Extending a Manifold","title":"ManifoldsBase.@next_trait_function","ref":"/manifoldsbase/stable/decorator/#ManifoldsBase.@next_trait_function-Tuple{Any, Any}","content":" ManifoldsBase.@next_trait_function  ‚Äî  Macro next_trait_function(trait_type, sig) Define a special trait-handling method for function indicated by  sig . It does not change the result but the presence of such additional methods may prevent method recursion limits in Julia's inference from being triggered. Some functions may work faster after adding methods generated by  next_trait_function . See the \"Trait recursion breaking\" section at the bottom of  src/decorator_trait.jl  file for an example of intended usage. source"},{"id":47,"pagetitle":"Decorating/Extending a Manifold","title":"ManifoldsBase.active_traits","ref":"/manifoldsbase/stable/decorator/#ManifoldsBase.active_traits-Tuple{Any, Vararg{Any}}","content":" ManifoldsBase.active_traits  ‚Äî  Method active_traits(f, args...) Return the list of traits applicable to the given call of function  f `. This function should be overloaded for specific function calls. source"},{"id":48,"pagetitle":"Decorating/Extending a Manifold","title":"ManifoldsBase.expand_trait","ref":"/manifoldsbase/stable/decorator/#ManifoldsBase.expand_trait-Tuple{AbstractTrait}","content":" ManifoldsBase.expand_trait  ‚Äî  Method expand_trait(t::AbstractTrait) Expand given trait into an ordered  TraitList  list of traits with their parent traits obtained using  parent_trait . source"},{"id":49,"pagetitle":"Decorating/Extending a Manifold","title":"ManifoldsBase.merge_traits","ref":"/manifoldsbase/stable/decorator/#ManifoldsBase.merge_traits-Tuple{}","content":" ManifoldsBase.merge_traits  ‚Äî  Method merge_traits(t1, t2, trest...) Merge two traits into a nested list of traits. Note that this takes trait preceedence into account, i.e.  t1  takes preceedence over  t2  is any operations. It always returns either ab  EmptyTrait  or a  TraitList . This means that for one argument it just returns the trait itself if it is list-like, or wraps the trait in a   single-element list otherwise, two arguments that are list-like, it merges them, two arguments of which only the first one is list-like and the second one is not,   it appends the second argument to the list, two arguments of which only the second one is list-like, it prepends the first one to   the list, two arguments of which none is list-like, it creates a two-element list. more than two arguments it recursively performs a left-assiciative recursive reduction   on arguments, that is for example  merge_traits(t1, t2, t3)  is equivalent to    merge_traits(merge_traits(t1, t2), t3) source"},{"id":50,"pagetitle":"Decorating/Extending a Manifold","title":"ManifoldsBase.next_trait","ref":"/manifoldsbase/stable/decorator/#ManifoldsBase.next_trait-Tuple{AbstractTrait}","content":" ManifoldsBase.next_trait  ‚Äî  Method next_trait(t::AbstractTrait) Return the next trait to consider, which by default is no following trait (i.e.  EmptyTrait ). Expecially for a a  TraitList  this function returns the (remaining) tail of the remaining traits. source"},{"id":51,"pagetitle":"Decorating/Extending a Manifold","title":"ManifoldsBase.parent_trait","ref":"/manifoldsbase/stable/decorator/#ManifoldsBase.parent_trait-Tuple{AbstractTrait}","content":" ManifoldsBase.parent_trait  ‚Äî  Method parent_trait(t::AbstractTrait) Return the parent trait for trait  t , that is the more general trait whose behaviour it inherits as a fallback. source The key part of the trait system is that it forms a list of traits, from the most specific one to the least specific one, and tries to find a specific implementation of a function for a trait in the least. This ensures that there are, by design, no ambiguities (caused by traits) in the method selection process. Trait resolution is driven by Julia's method dispatch and the compiler is sufficiently clever to quite reliably constant-propagate traits and inline method calls. The list of traits is browsed from the most specific one for implementation of a given function for that trait. If one is found, the implementation is called and it may internally call completely different function, breaking the trait dispatch chain. When no implementation for a trait is found, the next trait on the list is checked, until  EmptyTrait  is reached, which is conventionally the last trait to be considered, expected to have the most generic default implementation of a function If you want to continue with the following traits afterwards, use  s = next_trait (t)  of a  TraitList t  to continue working on the next trait in the list by calling the function with  s  as first argument."},{"id":52,"pagetitle":"Decorating/Extending a Manifold","title":"The Manifold decorator","ref":"/manifoldsbase/stable/decorator/#The-Manifold-decorator","content":" The Manifold decorator Based on the generic  TraitList  the following types, functions, and macros introduce the decorator trait which allows to decorate an arbitrary  <: AbstractDecoratorManifold  with further features."},{"id":53,"pagetitle":"Decorating/Extending a Manifold","title":"ManifoldsBase.IsEmbeddedManifold","ref":"/manifoldsbase/stable/decorator/#ManifoldsBase.IsEmbeddedManifold","content":" ManifoldsBase.IsEmbeddedManifold  ‚Äî  Type IsEmbeddedManifold <: AbstractTrait A trait to declare an  AbstractManifold  as an embedded manifold. source"},{"id":54,"pagetitle":"Decorating/Extending a Manifold","title":"ManifoldsBase.IsEmbeddedSubmanifold","ref":"/manifoldsbase/stable/decorator/#ManifoldsBase.IsEmbeddedSubmanifold","content":" ManifoldsBase.IsEmbeddedSubmanifold  ‚Äî  Type IsEmbeddedSubmanifold <: AbstractTrait A trait to determine whether an  AbstractDecoratorManifold M  is an embedded submanifold. It is a special case of the  IsIsometricEmbeddedManifold  trait, i.e. it has all properties of this trait. In this trait, additionally to the isometric embedded manifold, all retractions, inverse retractions, and vectors transports, especially  exp ,  log , and  parallel_transport_to  are passed to the embedding. source"},{"id":55,"pagetitle":"Decorating/Extending a Manifold","title":"ManifoldsBase.IsIsometricEmbeddedManifold","ref":"/manifoldsbase/stable/decorator/#ManifoldsBase.IsIsometricEmbeddedManifold","content":" ManifoldsBase.IsIsometricEmbeddedManifold  ‚Äî  Type IsIsometricManifoldEmbeddedManifold <: AbstractTrait A Trait to determine whether an  AbstractDecoratorManifold M  is an isometrically embedded manifold. It is a special case of the  IsEmbeddedManifold  trait, i.e. it has all properties of this trait. Here, additionally, netric related functions like  inner  and  norm  are passed to the embedding source"},{"id":56,"pagetitle":"Decorating/Extending a Manifold","title":"ManifoldsBase.decorated_manifold","ref":"/manifoldsbase/stable/decorator/#ManifoldsBase.decorated_manifold-Tuple{AbstractDecoratorManifold}","content":" ManifoldsBase.decorated_manifold  ‚Äî  Method decorated_manifold(M::AbstractDecoratorManifold) For a manifold  M  that is decorated with some properties, this function returns the manifold without that manifold, i.e. the manifold that  was decorated . source"},{"id":57,"pagetitle":"Decorating/Extending a Manifold","title":"ManifoldsBase.get_embedding","ref":"/manifoldsbase/stable/decorator/#ManifoldsBase.get_embedding-Tuple{AbstractDecoratorManifold, Any}","content":" ManifoldsBase.get_embedding  ‚Äî  Method get_embedding(M::AbstractDecoratorManifold)\nget_embedding(M::AbstractDecoratorManifold, p) Specify the embedding of a manifold that has abstract decorators. the embedding might depend on a point representation, where different point representations are distinguished as subtypes of  AbstractManifoldPoint . A unique or default representation might also just be an  AbstractArray . source For an example see the  (implicit) embedded manifold ."},{"id":60,"pagetitle":"Design principles","title":"Main Design Principles","ref":"/manifoldsbase/stable/design/#Design","content":" Main Design Principles The interface for a manifold is defined to be as generic as possible, such that applications can be implemented as independently as possible from an actual manifold. This way, algorithms like those from  Manopt.jl  can be implemented on  arbitrary  manifolds. The main design criteria for the interface are: Aims to also provide  efficient global state-free , both  in-place  and  out-of-place  computations whenever possible. Provide a high level interface that is easy to use. Therefore this interface has 3 main features, that we will explain using two (related) concepts, the  exponential map  that maps a tangent vector  $X$  at a point  $p$  to a point  $q$  or mathematically  $\\exp_p:T_p\\mathcal M \\to \\mathcal M$  and its generalization, a  retract ion  $\\operatorname{retr}_p$  with the same domain and range. You do not need to know their exact definition at this point, just that there is  one  exponential map on a Riemannian manifold, and several retractions, where one of them is the exponential map (called  ExponentialRetraction  for completeness). Every retraction has its own subtype of the  AbstractRetractionMethod  that uniquely defines it. The following three design patterns aim to fulfil the criteria from above, while also avoiding ambiguities in multiple dispatch using the  dispatch on one argument at a time  approach."},{"id":61,"pagetitle":"Design principles","title":"General order of parameters","ref":"/manifoldsbase/stable/design/#General-order-of-parameters","content":" General order of parameters Since the central element for functions on a manifold is the manifold itself, it should always be the first parameter, even for in-place functions. Then the classical parameters of a function (for example a point and a tangent vector for the retraction) follow and the final part are parameters to further dispatch on, which usually have their defaults. Besides this order the functions follow the scheme ‚Äúallocate early‚Äù, i.e. to switch to the mutating variant when reasonable, cf.  Mutating and allocating functions ."},{"id":62,"pagetitle":"Design principles","title":"A 3-Layer architecture for dispatch","ref":"/manifoldsbase/stable/design/#A-3-Layer-architecture-for-dispatch","content":" A 3-Layer architecture for dispatch The general architecture consists of three layers The high level interface for ease of use ‚Äì and to dispatch on other manifolds. The intermediate layer to dispatch on different parameters in the last section, e.g. type of retraction or vector transport. The lowest layer for specific manifolds to dispatch on different types of points and tangent vectors. Usually this layer with a specific manifold and no optional parameters. These three layers are described in more detail in the following. The main motivation to introduce these layers is, that it reduces method ambiguities. It also provides a good structure where to implement extensions to this interface."},{"id":63,"pagetitle":"Design principles","title":"Layer I: The high level interface and ease of use","ref":"/manifoldsbase/stable/design/#design-layer1","content":" Layer I: The high level interface and ease of use The highest layer for convenience of decorators. A usual scheme is, that a manifold might assume several things implicitly, for example the default implementation of the sphere  $\\mathbb S^n$  using unit vectors in  $\\mathbb R^{n+1}$ . The embedding can be explicitly used to avoid re-implementations ‚Äì the inner product can be ‚Äúpassed on‚Äù to its embedding. To do so, we ‚Äúdecorate‚Äù the manifold by making it an  AbstractDecoratorManifold  and activating the right traits see the tutorial  How to Implement a Manifold . The explicit case of the  EmbeddedManifold  can be used to distinguish different embeddings of a manifold, but also their dispatch (onto the manifold or its embedding, depending on the type of embedding) happens here. Note that all other parameters of a function should be as least typed as possible for all parameters besides the manifold. With respect to the  dispatch on one argument at a time  paradigm, this layer dispatches the  manifold first . We also stay as abstract as possible, for example on the  AbstractManifold  level if possible. If a function has optional positional arguments, (like  retract ) their default values might be filled/provided on this layer. This layer ends usually in calling the same functions like  retract  but prefixed with a  _  to enter  Layer II . Note Usually only functions from this layer are exported from the interface, since these are the ones one should use for generic implementations. If you implement your own manifold,  import  the necessary lower layer functions as needed."},{"id":64,"pagetitle":"Design principles","title":"Layer II: An internal dispatch interface for parameters","ref":"/manifoldsbase/stable/design/#design-layer2","content":" Layer II: An internal dispatch interface for parameters This layer is an interims layer to dispatch on the (optional/default) parameters of a function. For example the last parameter of retraction:  retract  determines the type (variant) to be used. The last function in the previous layer calls  _retract , which is an internal function. These parameters are usually the last parameters of a function. On this layer, e.g. for  _retract  only these last parameters should be typed, the manifold should stay at the  AbstractManifold  level. The layer dispatches on different functions per existing parameter type (and might pass this one further on, if it has fields). Function definitions on this layer should only be extended when introducing new such parameter types, for example when introducing a new type of a retraction. The functions from this layer should never be called directly, are hence also not exported and carry the  _  prefix. They should only be called as the final step in the previous layer. If the default parameters are not dispatched per type, using  _  might be skipped. The same holds for functions that do not have these parameters. The following resolution might even be seen as a last step in layer I or the resolution here in layer II. exp(M::AbstractManifold, p, X, t::Real) = exp(M, p, t * X) When there is no dispatch for different types of the optional parameter (here  t ), the  _  might be skipped. One could hence see the last code line as a definition on Layer I that passes directly to Layer III, since there are not parameter to dispatch on. To close this section, let‚Äòs look at an example. The high level (or  Layer I ) definition of the retraction is given by retract!(M::AbstractManifold, q, p, X, m::AbstractRetractionMethod=default_retraction_method(M, typeof(p))) = _retract!(M, q, p, X, m) Note that the convenience function  retract(M, q, p, X, m)  first allocates a  q  before calling this function as well. This level now dispatches on different retraction types  m . It usually passes to specific functions implemented in  Layer III , here for example _retract!(M::AbstractManifold, q, p, X, m::Exponentialretraction) = exp(M, q, p, X)\n_retract!(M::AbstractManifold, q, p, X, m::PolarRetraction) = retract_polar(M, q, p, X) where the  ExponentialRetraction  is resolved by again calling a function on  Layer I  (to fill futher default values if these exist). The  PolarRetraction  is dispatched to  retract_polar! , a function on  Layer III . For further details and dispatches, see  retractions and inverse retractions  for an overview. Note The documentation should be attached to the high level functions, since this again fosters ease of use. If you implement a polar retraction, you should write a method of function  retract_polar!  but the doc string should be attached to  retract(::M, ::P, ::V, ::PolarRetraction)  for your types  ::M, ::P, ::V  of the manifold, points and vectors, respectively. To summarize, with respect to the  dispatch on one argument at a time  paradigm, this layer dispatches the (optional)  parameters second ."},{"id":65,"pagetitle":"Design principles","title":"Layer III: The base layer with focus on implementations","ref":"/manifoldsbase/stable/design/#design-layer3","content":" Layer III: The base layer with focus on implementations This lower level aims for the actual implementation of the function avoiding ambiguities. It should have as few as possible optional parameters and as concrete as possible types for these. This means the function name should be similar to its high level parent (for example  retract!  and  retract_polar!   above) The manifold type in method signature should always be as narrow as possible. The points/vectors should either be untyped (for the default representation or if there is only one implementation) or provide all type bounds (for second representations or when using  AbstractManifoldPoint  and  TVector , respectively). The first step that often happens on this level is memory allocation and calling the in-place function. If faster, it might also implement the function at hand itself. Usually functions from this layer are not exported, when they have an analogue on the first layer. For example the function  retract_polar! (M, q, p, X)  is not exported, since when using the interface one would use the  PolarRetraction  or to be precise call  retract! (M, q, p, X, PolarRetraction()) . When implementing your own manifold, you have to import functions like these anyway. To summarize, with respect to the  dispatch on one argument at a time  paradigm, this layer dispatches the  concrete manifold and point/vector types last ."},{"id":66,"pagetitle":"Design principles","title":"Mutating and allocating functions","ref":"/manifoldsbase/stable/design/#inplace-and-noninplace","content":" Mutating and allocating functions Every function, where this is applicable, should provide an in-place and an allocating variant. For example for the exponential map  exp(M, p, X, t)  returns a  new  point  q  where the result is computed in. On the other hand  exp!(M, q, p, X, t)  computes the result in place of  q , where the design of the implementation should keep in mind that also  exp!(M, p, p, X, t)  should correctly overwrite  p . The interface provides a way to determine the allocation type and a result to compute/allocate the resulting memory, such that the default implementation allocating functions, like  exp  is to allocate the resulting memory and call  exp! . Note It might be useful to provide two distinct implementations, for example when using AD schemes. The default is meant for ease of use (concerning implementation), since then one has to just implement the in-place variants. Non-mutating functions in  ManifoldsBase.jl  are typically implemented using in-place variants after a suitable allocation of memory. Not that this allocation usually takes place only on  Layer III  when dispatching on points. Both  Layer I  and  Layer II  are usually implemented for both variants in parallel."},{"id":67,"pagetitle":"Design principles","title":"Allocation of new points and vectors","ref":"/manifoldsbase/stable/design/#Allocation-of-new-points-and-vectors","content":" Allocation of new points and vectors The  allocate  function behaves like  similar  for simple representations of points and vectors (for example  Array{Float64} ). For more complex types, such as nested representations of  PowerManifold  (see  NestedPowerRepresentation ), checked types like  ValidationMPoint  and more it operates differently. While  similar  only concerns itself with the higher level of nested structures,  allocate  maps itself through all levels of nesting until a simple array of numbers is reached and then calls  similar . The difference can be most easily seen in the following example: julia> x = similar([[1.0], [2.0]])\n2-element Array{Array{Float64,1},1}:\n #undef\n #undef\n\njulia> y = allocate([[1.0], [2.0]])\n2-element Array{Array{Float64,1},1}:\n [6.90031725726027e-310]\n [6.9003678131654e-310]\n\njulia> x[1]\nERROR: UndefRefError: access to undefined reference\nStacktrace:\n [1] getindex(::Array{Array{Float64,1},1}, ::Int64) at ./array.jl:744\n [2] top-level scope at REPL[12]:1\n\njulia> y[1]\n1-element Array{Float64,1}:\n 6.90031725726027e-310 The function  allocate_result  allocates a correct return value. It takes into account the possibility that different arguments may have different numeric  number_eltype  types thorough the  allocate_result_type  function. The most prominent example of the usage of this function is the logarithmic function  log  when used with typed points. Lets assume on a manifold  M  the have points of type  P  and corresponding tangent vector types  V . then the logarithmic map has the signature log(::M, ::P, ::P) but the return type would be  $V$ , whose internal sizes (fields/arrays) will depend on the concrete type of one of the points. This is accomplished by implementing a method  allocate_result(::M, ::typeof(log), ::P, ::P)  that returns the concrete variable for the result. This way, even with specific types, one just has to implement  log!  and the one line for the allocation. Note This dispatch from the allocating to the in-place variant happens in Layer I (which changed in ManifoldsBase.jl 0.15), that is, functions like  exp  or  retract  allocate their result and call the in-place variant  exp!  and  retract!  afterwards, where the ladder passes down to layer III to reach  retract_polar! ."},{"id":70,"pagetitle":"Basic functions","title":"Functions on manifolds","ref":"/manifoldsbase/stable/functions/#Functions-on-manifolds","content":" Functions on manifolds This page collects several basic functions on manifolds."},{"id":71,"pagetitle":"Basic functions","title":"The exponential map, the logarithmic map, and geodesics","ref":"/manifoldsbase/stable/functions/#exp-and-log","content":" The exponential map, the logarithmic map, and geodesics Geodesics are the generalizations of a straight line to manifolds, i.e. their intrinsic acceleration is zero. Together with geodesics one also obtains the exponential map and its inverse, the logarithmic map. Informally speaking, the exponential map takes a vector (think of a direction and a length) at one point and returns another point, which lies towards this direction at distance of the specified length. The logarithmic map does the inverse, i.e. given two points, it tells which vector ‚Äúpoints towards‚Äù the other point."},{"id":72,"pagetitle":"Basic functions","title":"Base.exp","ref":"/manifoldsbase/stable/functions/#Base.exp-Tuple{AbstractManifold, Any, Any}","content":" Base.exp  ‚Äî  Method exp(M::AbstractManifold, p, X)\nexp(M::AbstractManifold, p, X, t::Number = 1) Compute the exponential map of tangent vector  X , optionally scaled by  t ,  at point  p  from the manifold  AbstractManifold M , i.e. \\[\\exp_p X = Œ≥_{p,X}(1),\\] where  $Œ≥_{p,X}$  is the unique geodesic starting in  $Œ≥(0)=p$  such that  $\\dot Œ≥(0) = X$ . See also  shortest_geodesic ,  retract . source"},{"id":73,"pagetitle":"Basic functions","title":"Base.log","ref":"/manifoldsbase/stable/functions/#Base.log-Tuple{AbstractManifold, Any, Any}","content":" Base.log  ‚Äî  Method log(M::AbstractManifold, p, q) Compute the logarithmic map of point  q  at base point  p  on the  AbstractManifold M . The logarithmic map is the inverse of the  exp onential map. Note that the logarithmic map might not be globally defined. See also  inverse_retract . source"},{"id":74,"pagetitle":"Basic functions","title":"ManifoldsBase.exp!","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.exp!-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldsBase.exp!  ‚Äî  Method exp!(M::AbstractManifold, q, p, X)\nexp!(M::AbstractManifold, q, p, X, t::Number = 1) Compute the exponential map of tangent vector  X , optionally scaled by  t ,  at point  p  from the manifold  AbstractManifold M . The result is saved to  q . If you want to implement exponential map for your manifold, you should implement the method with  t , that is  exp!(M::MyManifold, q, p, X, t::Number) . See also  exp . source"},{"id":75,"pagetitle":"Basic functions","title":"ManifoldsBase.geodesic!","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.geodesic!-Tuple{AbstractManifold, Any, Any, Any, AbstractVector}","content":" ManifoldsBase.geodesic!  ‚Äî  Method geodesic!(M::AbstractManifold, Q, p, X, T::AbstractVector) -> AbstractVector Get the geodesic with initial point  p  and velocity  X  on the  AbstractManifold M . A geodesic is a curve of zero acceleration. That is for the curve  $Œ≥_{p,X}: I ‚Üí \\mathcal M$ , with  $Œ≥_{p,X}(0) = p$  and  $\\dot Œ≥_{p,X}(0) = X$  a geodesic further fulfills \\[‚àá_{\\dot Œ≥_{p,X}(t)} \\dot Œ≥_{p,X}(t) = 0,\\] i.e. the curve is acceleration free with respect to the Riemannian metric. This function evaluates the geodeic at time points  t  fom  T  in place of  Q . source"},{"id":76,"pagetitle":"Basic functions","title":"ManifoldsBase.geodesic!","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.geodesic!-Tuple{AbstractManifold, Any, Any, Any, Real}","content":" ManifoldsBase.geodesic!  ‚Äî  Method geodesic!(M::AbstractManifold, q, p, X, t::Real) Get the geodesic with initial point  p  and velocity  X  on the  AbstractManifold M . A geodesic is a curve of zero acceleration. That is for the curve  $Œ≥_{p,X}: I ‚Üí \\mathcal M$ , with  $Œ≥_{p,X}(0) = p$  and  $\\dot Œ≥_{p,X}(0) = X$  a geodesic further fulfills \\[‚àá_{\\dot Œ≥_{p,X}(t)} \\dot Œ≥_{p,X}(t) = 0,\\] i.e. the curve is acceleration free with respect to the Riemannian metric. This function evaluates the geodeic at  t  in place of  q . source"},{"id":77,"pagetitle":"Basic functions","title":"ManifoldsBase.geodesic!","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.geodesic!-Tuple{AbstractManifold, Any, Any}","content":" ManifoldsBase.geodesic!  ‚Äî  Method geodesic!(M::AbstractManifold, p, X) -> Function Get the geodesic with initial point  p  and velocity  X  on the  AbstractManifold M . A geodesic is a curve of zero acceleration. That is for the curve  $Œ≥_{p,X}: I ‚Üí \\mathcal M$ , with  $Œ≥_{p,X}(0) = p$  and  $\\dot Œ≥_{p,X}(0) = X$  a geodesic further fulfills \\[‚àá_{\\dot Œ≥_{p,X}(t)} \\dot Œ≥_{p,X}(t) = 0,\\] i.e. the curve is acceleration free with respect to the Riemannian metric. This yields that the curve has constant velocity and is locally distance-minimizing. This function returns a function  (q,t)  of (time)  t  that mutates  q `. source"},{"id":78,"pagetitle":"Basic functions","title":"ManifoldsBase.geodesic","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.geodesic-Tuple{AbstractManifold, Any, Any, AbstractVector}","content":" ManifoldsBase.geodesic  ‚Äî  Method geodesic(M::AbstractManifold, p, X, T::AbstractVector) -> AbstractVector Evaluate the geodesic  $Œ≥_{p,X}: I ‚Üí \\mathcal M$ , with  $Œ≥_{p,X}(0) = p$  and  $\\dot Œ≥_{p,X}(0) = X$  a geodesic further fulfills \\[‚àá_{\\dot Œ≥_{p,X}(t)} \\dot Œ≥_{p,X}(t) = 0,\\] at time points  t  from  T . source"},{"id":79,"pagetitle":"Basic functions","title":"ManifoldsBase.geodesic","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.geodesic-Tuple{AbstractManifold, Any, Any, Real}","content":" ManifoldsBase.geodesic  ‚Äî  Method geodesic(M::AbstractManifold, p, X, t::Real) Evaluate the geodesic  $Œ≥_{p,X}: I ‚Üí \\mathcal M$ , with  $Œ≥_{p,X}(0) = p$  and  $\\dot Œ≥_{p,X}(0) = X$  a geodesic further fulfills \\[‚àá_{\\dot Œ≥_{p,X}(t)} \\dot Œ≥_{p,X}(t) = 0,\\] at time  t . source"},{"id":80,"pagetitle":"Basic functions","title":"ManifoldsBase.geodesic","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.geodesic-Tuple{AbstractManifold, Any, Any}","content":" ManifoldsBase.geodesic  ‚Äî  Method geodesic(M::AbstractManifold, p, X) -> Function Get the geodesic with initial point  p  and velocity  X  on the  AbstractManifold M . A geodesic is a curve of zero acceleration. That is for the curve  $Œ≥_{p,X}: I ‚Üí \\mathcal M$ , with  $Œ≥_{p,X}(0) = p$  and  $\\dot Œ≥_{p,X}(0) = X$  a geodesic further fulfills \\[‚àá_{\\dot Œ≥_{p,X}(t)} \\dot Œ≥_{p,X}(t) = 0,\\] i.e. the curve is acceleration free with respect to the Riemannian metric. This yields, that the curve has constant velocity that is locally distance-minimizing. This function returns a function of (time)  t . source"},{"id":81,"pagetitle":"Basic functions","title":"ManifoldsBase.log!","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.log!-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldsBase.log!  ‚Äî  Method log!(M::AbstractManifold, X, p, q) Compute the logarithmic map of point  q  at base point  p  on the  AbstractManifold M . The result is saved to  X . The logarithmic map is the inverse of the  exp! onential map. Note that the logarithmic map might not be globally defined. see also  log  and  inverse_retract! , source"},{"id":82,"pagetitle":"Basic functions","title":"ManifoldsBase.shortest_geodesic!","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.shortest_geodesic!-Tuple{AbstractManifold, Any, Any, Any, AbstractVector}","content":" ManifoldsBase.shortest_geodesic!  ‚Äî  Method shortest_geodesic!(M::AbstractManifold, R, p, q, T::AbstractVector) -> AbstractVector Evaluate a  geodesic $Œ≥_{p,q}(t)$  whose length is the shortest path between the points  p and  q , where  $Œ≥_{p,q}(0)=p$  and  $Œ≥_{p,q}(1)=q$  at all  t  from  T  in place of  R . When there are multiple shortest geodesics, a deterministic choice will be taken. source"},{"id":83,"pagetitle":"Basic functions","title":"ManifoldsBase.shortest_geodesic!","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.shortest_geodesic!-Tuple{AbstractManifold, Any, Any, Any, Real}","content":" ManifoldsBase.shortest_geodesic!  ‚Äî  Method shortest_geodesic!(M::AabstractManifold, r, p, q, t::Real) Evaluate a  geodesic $Œ≥_{p,q}(t)$  whose length is the shortest path between the points  p and  q , where  $Œ≥_{p,q}(0)=p$  and  $Œ≥_{p,q}(1)=q$  at  t  in place of  r . When there are multiple shortest geodesics, a deterministic choice will be taken. source"},{"id":84,"pagetitle":"Basic functions","title":"ManifoldsBase.shortest_geodesic!","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.shortest_geodesic!-Tuple{AbstractManifold, Any, Any}","content":" ManifoldsBase.shortest_geodesic!  ‚Äî  Method shortest_geodesic!(M::AbstractManifold, p, q) -> Function Get a  geodesic $Œ≥_{p,q}(t)$  whose length is the shortest path between the points  p and  q , where  $Œ≥_{p,q}(0)=p$  and  $Œ≥_{p,q}(1)=q$ . When there are multiple shortest geodesics, a deterministic choice will be returned. This function returns a function  (r,t) -> ...  of time  t  which works in place of  r . Further variants shortest_geodesic!(M::AabstractManifold, r, p, q, t::Real)\nshortest_geodesic!(M::AbstractManifold, R, p, q, T::AbstractVector) -> AbstractVector mutate (and return) the point  r  and the vector of points  R , respectively, returning the point at time  t  or points at times  t  in  T  along the shortest  geodesic . source"},{"id":85,"pagetitle":"Basic functions","title":"ManifoldsBase.shortest_geodesic","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.shortest_geodesic-Tuple{AbstractManifold, Any, Any, AbstractVector}","content":" ManifoldsBase.shortest_geodesic  ‚Äî  Method shortest_geodesic(M::AbstractManifold, p, q, T::AbstractVector) -> AbstractVector Evaluate a  geodesic $Œ≥_{p,q}(t)$  whose length is the shortest path between the points  p and  q , where  $Œ≥_{p,q}(0)=p$  and  $Œ≥_{p,q}(1)=q$  at time points  T . When there are multiple shortest geodesics, a deterministic choice will be returned. source"},{"id":86,"pagetitle":"Basic functions","title":"ManifoldsBase.shortest_geodesic","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.shortest_geodesic-Tuple{AbstractManifold, Any, Any, Real}","content":" ManifoldsBase.shortest_geodesic  ‚Äî  Method shortest_geodesic(M::AabstractManifold, p, q, t::Real) Evaluate a  geodesic $Œ≥_{p,q}(t)$  whose length is the shortest path between the points  p and  q , where  $Œ≥_{p,q}(0)=p$  and  $Œ≥_{p,q}(1)=q$  at time  t . When there are multiple shortest geodesics, a deterministic choice will be returned. source"},{"id":87,"pagetitle":"Basic functions","title":"ManifoldsBase.shortest_geodesic","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.shortest_geodesic-Tuple{AbstractManifold, Any, Any}","content":" ManifoldsBase.shortest_geodesic  ‚Äî  Method shortest_geodesic(M::AbstractManifold, p, q) -> Function Get a  geodesic $Œ≥_{p,q}(t)$  whose length is the shortest path between the points  p and  q , where  $Œ≥_{p,q}(0)=p$  and  $Œ≥_{p,q}(1)=q$ . When there are multiple shortest geodesics, a deterministic choice will be returned. This function returns a function of time, which may be a  Real  or an  AbstractVector . source"},{"id":88,"pagetitle":"Basic functions","title":"Parallel transport","ref":"/manifoldsbase/stable/functions/#subsec-parallel-transport","content":" Parallel transport While moving vectors from one base point to another is the identity in the Euclidean space ‚Äì¬†or in other words all tangent spaces (directions one can ‚Äúwalk‚Äù into) are the same. This is different on a manifold. If we have two points  $p,q ‚àà \\mathcal M$ , we take a  $c: [0,1] ‚Üí \\mathcal M$  connecting the two points, i.e.  $c(0) = p$  and  $c(1) = q$ . this could be a (or the) geodesic. If we further consider a vector field  $X: [0,1] ‚Üí T\\mathcal M$ , i.e. where  $X(t) ‚àà T_{c(t)}\\mathcal M$ . Then the vector field is called  parallel  if its covariant derivative  $\\frac{\\mathrm{D}}{\\mathrm{d}t}X(t) = 0$  for all  $t‚àà |0,1]$ . If we now impose a value for  $X=X(0) ‚àà T_p\\mathcal M$ , we obtain an ODE with an initial condition. The resulting value  $X(1) ‚àà T_q\\mathcal M$  is called the  parallel transport  of  X  along  $c$  or in case of a geodesic the _parallel transport of  X  from  p  to  q ."},{"id":89,"pagetitle":"Basic functions","title":"ManifoldsBase.parallel_transport_along","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.parallel_transport_along-Tuple{AbstractManifold, Any, Any, AbstractVector}","content":" ManifoldsBase.parallel_transport_along  ‚Äî  Method Y = parallel_transport_along(M::AbstractManifold, p, X, c) Compute the parallel transport of the vector  X  from the tangent space at  p  along the curve  c . To be precise let  $c(t)$  be a curve  $c(0)=p$  for  vector_transport_along $\\mathcal P^cY$ THen In the result  $Y\\in T_p\\mathcal M$  is the vector  $X$  from the tangent space at  $p=c(0)$  to the tangent space at  $c(1)$ . Let  $Z\\colon [0,1] \\to T\\mathcal M$ ,  $Z(t)\\in T_{c(t)}\\mathcal M$  be a smooth vector field along the curve  $c$  with  $Z(0) = Y$ , such that  $Z$  is  parallel , i.e. its covariant derivative  $\\frac{\\mathrm{D}}{\\mathrm{d}t}Z$  is zero. Note that such a  $Z$  always exists and is unique. Then the parallel transport is given by  $Z(1)$ . source"},{"id":90,"pagetitle":"Basic functions","title":"ManifoldsBase.parallel_transport_direction","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.parallel_transport_direction-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldsBase.parallel_transport_direction  ‚Äî  Method parallel_transport_direction(M::AbstractManifold, p, X, d) Compute the  parallel_transport_along  the curve  $c(t) = Œ≥_{p,q}(t)$ , i.e. the * the unique geodesic  $c(t)=Œ≥_{p,X}(t)$  from  $Œ≥_{p,d}(0)=p$  into direction  $\\dot Œ≥_{p,d}(0)=d$ , of the tangent vector  X . By default this function calls  parallel_transport_to (M, p, X, q) , where  $q=\\exp_pX$ . source"},{"id":91,"pagetitle":"Basic functions","title":"ManifoldsBase.parallel_transport_to","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.parallel_transport_to-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldsBase.parallel_transport_to  ‚Äî  Method parallel_transport_to(M::AbstractManifold, p, X, q) Compute the  parallel_transport_along  the curve  $c(t) = Œ≥_{p,q}(t)$ , i.e. the (assumed to be unique)  geodesic  connecting  p  and  q , of the tangent vector  X . source"},{"id":92,"pagetitle":"Basic functions","title":"Further functions on manifolds","ref":"/manifoldsbase/stable/functions/#Further-functions-on-manifolds","content":" Further functions on manifolds"},{"id":93,"pagetitle":"Basic functions","title":"General functions provided by the interface","ref":"/manifoldsbase/stable/functions/#General-functions-provided-by-the-interface","content":" General functions provided by the interface"},{"id":94,"pagetitle":"Basic functions","title":"Base.angle","ref":"/manifoldsbase/stable/functions/#Base.angle-Tuple{AbstractManifold, Any, Any, Any}","content":" Base.angle  ‚Äî  Method angle(M::AbstractManifold, p, X, Y) Compute the angle between tangent vectors  X  and  Y  at point  p  from the  AbstractManifold M  with respect to the inner product from  inner . source"},{"id":95,"pagetitle":"Basic functions","title":"Base.copy","ref":"/manifoldsbase/stable/functions/#Base.copy-Tuple{AbstractManifold, Any, Any}","content":" Base.copy  ‚Äî  Method copy(M::AbstractManifold, p, X) Copy the value(s) from the tangent vector  X  at a point  p  on the  AbstractManifold M  into a new tangent vector. See  allocate_result  for the allocation of new point memory and  copyto!  for the copying. source"},{"id":96,"pagetitle":"Basic functions","title":"Base.copy","ref":"/manifoldsbase/stable/functions/#Base.copy-Tuple{AbstractManifold, Any}","content":" Base.copy  ‚Äî  Method copy(M::AbstractManifold, p) Copy the value(s) from the point  p  on the  AbstractManifold M  into a new point. See  allocate_result  for the allocation of new point memory and  copyto!  for the copying. source"},{"id":97,"pagetitle":"Basic functions","title":"Base.copyto!","ref":"/manifoldsbase/stable/functions/#Base.copyto!-Tuple{AbstractManifold, Any, Any, Any}","content":" Base.copyto!  ‚Äî  Method copyto!(M::AbstractManifold, Y, p, X) Copy the value(s) from  X  to  Y , where both are tangent vectors from the tangent space at  p  on the  AbstractManifold M . This function defaults to calling  copyto!(Y, X) , but it might be useful to overwrite the function at the level, where also information from  p  and  M  can be accessed. source"},{"id":98,"pagetitle":"Basic functions","title":"Base.copyto!","ref":"/manifoldsbase/stable/functions/#Base.copyto!-Tuple{AbstractManifold, Any, Any}","content":" Base.copyto!  ‚Äî  Method copyto!(M::AbstractManifold, q, p) Copy the value(s) from  p  to  q , where both are points on the  AbstractManifold M . This function defaults to calling  copyto!(q, p) , but it might be useful to overwrite the function at the level, where also information from  M  can be accessed. source"},{"id":99,"pagetitle":"Basic functions","title":"Base.isapprox","ref":"/manifoldsbase/stable/functions/#Base.isapprox-Tuple{AbstractManifold, Any, Any, Any}","content":" Base.isapprox  ‚Äî  Method isapprox(M::AbstractManifold, p, X, Y; error:Symbol=:none; kwargs...) Check if vectors  X  and  Y  tangent at  p  from  AbstractManifold M  are approximately equal. The optional positional argument can be used to get more information for the case that the result is false, if the concrete manifold provides such information. Currently the following are supported :error  - throws an error if  isapprox  evaluates to false, providing possibly a more detailed error. Note that this turns  isapprox  basically to an  @assert . :info  ‚Äì prints the information in an  @info :warn  ‚Äì prints the information in an  @warn :none  (default) ‚Äì the function just returns  true / false By default these informations are collected by calling  check_approx . Keyword arguments can be used to specify tolerances. source"},{"id":100,"pagetitle":"Basic functions","title":"Base.isapprox","ref":"/manifoldsbase/stable/functions/#Base.isapprox-Tuple{AbstractManifold, Any, Any}","content":" Base.isapprox  ‚Äî  Method isapprox(M::AbstractManifold, p, q; error::Symbol=:none, kwargs...) Check if points  p  and  q  from  AbstractManifold M  are approximately equal. The keyword argument can be used to get more information for the case that the result is false, if the concrete manifold provides such information. Currently the following are supported :error  - throws an error if  isapprox  evaluates to false, providing possibly a more detailed error. Note that this turns  isapprox  basically to an  @assert . :info  ‚Äì prints the information in an  @info :warn  ‚Äì prints the information in an  @warn :none  (default) ‚Äì the function just returns  true / false Keyword arguments can be used to specify tolerances. source"},{"id":101,"pagetitle":"Basic functions","title":"Base.rand","ref":"/manifoldsbase/stable/functions/#Base.rand-Tuple{AbstractManifold}","content":" Base.rand  ‚Äî  Method Random.rand(M::AbstractManifold, [d::Integer]; vector_at=nothing)\nRandom.rand(rng::AbstractRNG, M::AbstractManifold, [d::Integer]; vector_at=nothing) Generate a random point on manifold  M  (when  vector_at  is  nothing ) or a tangent vector at point  vector_at  (when it is not  nothing ). Optionally a random number generator  rng  to be used can be specified. An optional integer  d  indicates that a vector of  d  points or tangent vectors is to be generated. Note Usually a uniform distribution should be expected for compact manifolds and a Gaussian-like distribution for non-compact manifolds and tangent vectors, although it is not guaranteed. The distribution may change between releases. rand  methods for specific manifolds may take additional keyword arguments. source"},{"id":102,"pagetitle":"Basic functions","title":"LinearAlgebra.norm","ref":"/manifoldsbase/stable/functions/#LinearAlgebra.norm-Tuple{AbstractManifold, Any, Any}","content":" LinearAlgebra.norm  ‚Äî  Method norm(M::AbstractManifold, p, X) Compute the norm of tangent vector  X  at point  p  from a  AbstractManifold M . By default this is computed using  inner . source"},{"id":103,"pagetitle":"Basic functions","title":"ManifoldsBase.Weingarten!","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.Weingarten!-Tuple{AbstractManifold, Vararg{Any, 4}}","content":" ManifoldsBase.Weingarten!  ‚Äî  Method Weingarten!(M, Y, p, X, V) Compute the Weingarten map  $\\mathcal W_p\\colon T_p\\mathcal M √ó N_p\\mathcal M \\to T_p\\mathcal M$  in place of  Y , see  Weingarten . source"},{"id":104,"pagetitle":"Basic functions","title":"ManifoldsBase.Weingarten","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.Weingarten-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldsBase.Weingarten  ‚Äî  Method Weingarten(M, p, X, V) Compute the Weingarten map  $\\mathcal W_p\\colon T_p\\mathcal M √ó N_p\\mathcal M \\to T_p\\mathcal M$ , where  $N_p\\mathcal M$  is the orthogonal complement of the tangent space  $T_p\\mathcal M$  of the embedded submanifold  $\\mathcal M$ , where we denote the embedding by  $\\mathcal E$ . The Weingarten map can be defined by restricting the differential of the orthogonal  project ion  $\\operatorname{proj}_{T_p\\mathcal M}\\colon T_p \\mathcal E \\to T_p\\mathcal M$  with respect to the base point  $p$ , i.e. defining \\[\\mathcal P_X := D_p\\operatorname{proj}_{T_p\\mathcal M}(Y)[X],\n\\qquad Y \\in T_p \\mathcal E, X \\in T_p\\mathcal M,\\] the Weingarten map can be written as  $\\mathcal W_p(X,V) = \\mathcal P_X(V)$ . The Weingarten map is named after  Julius Weingarten  (1836‚Äì1910). source"},{"id":105,"pagetitle":"Basic functions","title":"ManifoldsBase.allocate","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.allocate-Tuple{Any, Vararg{Any}}","content":" ManifoldsBase.allocate  ‚Äî  Method allocate(a)\nallocate(a, dims::Integer...)\nallocate(a, dims::Tuple)\nallocate(a, T::Type)\nallocate(a, T::Type, dims::Integer...)\nallocate(a, T::Type, dims::Tuple)\nallocate(M::AbstractManifold, a)\nallocate(M::AbstractManifold, a, dims::Integer...)\nallocate(M::AbstractManifold, a, dims::Tuple)\nallocate(M::AbstractManifold, a, T::Type)\nallocate(M::AbstractManifold, a, T::Type, dims::Integer...)\nallocate(M::AbstractManifold, a, T::Type, dims::Tuple) Allocate an object similar to  a . It is similar to function  similar , although instead of working only on the outermost layer of a nested structure, it maps recursively through outer layers and calls  similar  on the innermost array-like object only. Type  T  is the new number element type  number_eltype , if it is not given the element type of  a  is retained. The  dims  argument can be given for non-nested allocation and is forwarded to the function  similar . It's behavior can be overriden by a specific manifold, for example power manifold with nested replacing representation can decide that  allocate  for  Array{<:SArray}  returns another  Array{<:SArray}  instead of  Array{<:MArray} , as would be done by default. source"},{"id":106,"pagetitle":"Basic functions","title":"ManifoldsBase.base_manifold","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.base_manifold","content":" ManifoldsBase.base_manifold  ‚Äî  Function base_manifold(M::AbstractManifold, depth = Val(-1)) Return the internally stored  AbstractManifold  for decorated manifold  M  and the base manifold for vector bundles or power manifolds. The optional parameter  depth  can be used to remove only the first  depth  many decorators and return the  AbstractManifold  from that level, whether its decorated or not. Any negative value deactivates this depth limit. source"},{"id":107,"pagetitle":"Basic functions","title":"ManifoldsBase.distance","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.distance-Tuple{AbstractManifold, Any, Any, AbstractInverseRetractionMethod}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::AbstractManifold, p, q, m::AbstractInverseRetractionMethod) Approximate distance between points  p  and  q  on manifold  M  using  AbstractInverseRetractionMethod m . source"},{"id":108,"pagetitle":"Basic functions","title":"ManifoldsBase.distance","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.distance-Tuple{AbstractManifold, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::AbstractManifold, p, q) Shortest distance between the points  p  and  q  on the  AbstractManifold M , i.e. \\[d(p,q) = \\inf_{Œ≥} L(Œ≥),\\] where the infimum is over all piecewise smooth curves  $Œ≥: [a,b] \\to \\mathcal M$  connecting  $Œ≥(a)=p$  and  $Œ≥(b)=q$  and \\[L(Œ≥) = \\displaystyle\\int_{a}^{b} \\lVert \\dotŒ≥(t)\\rVert_{Œ≥(t)} \\mathrm{d}t\\] is the length of the curve  $Œ≥$ . If  $\\mathcal M$  is not connected, i.e. consists of several disjoint components, the distance between two points from different components should be  $‚àû$ . source"},{"id":109,"pagetitle":"Basic functions","title":"ManifoldsBase.embed!","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.embed!-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldsBase.embed!  ‚Äî  Method embed!(M::AbstractManifold, Y, p, X) Embed a tangent vector  X  at a point  p  on the  AbstractManifold M  into the ambient space and return the result in  Y . This method is only available for manifolds where implicitly an embedding or ambient space is given. Additionally,  embed!  includes changing data representation, if applicable, i.e. if the tangents on  M  are not represented in the same way as tangents on the embedding, the representation is changed accordingly. This is the case for example for Lie groups, when tangent vectors are represented in the Lie algebra. The embedded tangents are then in the tangent spaces of the embedded base points. The default is set in such a way that it assumes that the points on  M  are represented in their embedding (for example like the unit vectors in a space to represent the sphere) and hence embedding also for tangent vectors is the identity by default. See also:  EmbeddedManifold ,  project! source"},{"id":110,"pagetitle":"Basic functions","title":"ManifoldsBase.embed!","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.embed!-Tuple{AbstractManifold, Any, Any}","content":" ManifoldsBase.embed!  ‚Äî  Method embed!(M::AbstractManifold, q, p) Embed point  p  from the  AbstractManifold M  into an ambient space. This method is only available for manifolds where implicitly an embedding or ambient space is given. Not implementing this function means, there is no proper embedding for your manifold. Additionally,  embed  might include changing data representation, if applicable, i.e. if points on  M  are not represented in the same way as their counterparts in the embedding, the representation is changed accordingly. The default is set in such a way that it assumes that the points on  M  are represented in their embedding (for example like the unit vectors in a space to represent the sphere) and hence embedding in the identity by default. If you have more than one embedding, see  EmbeddedManifold  for defining a second embedding. If your point  p  is already represented in some embedding, see  AbstractDecoratorManifold  how you can avoid reimplementing code from the embedded manifold See also:  EmbeddedManifold ,  project! source"},{"id":111,"pagetitle":"Basic functions","title":"ManifoldsBase.embed","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.embed-Tuple{AbstractManifold, Any, Any}","content":" ManifoldsBase.embed  ‚Äî  Method embed(M::AbstractManifold, p, X) Embed a tangent vector  X  at a point  p  on the  AbstractManifold M  into an ambient space. This method is only available for manifolds where implicitly an embedding or ambient space is given. Not implementing this function means, there is no proper embedding for your tangent space(s). Additionally,  embed  might include changing data representation, if applicable, i.e. if tangent vectors on  M  are not represented in the same way as their counterparts in the embedding, the representation is changed accordingly. The default is set in such a way that memory is allocated and  embed!(M, Y, p. X)  is called. If you have more than one embedding, see  EmbeddedManifold  for defining a second embedding. If your tangent vector  X  is already represented in some embedding, see  AbstractDecoratorManifold  how you can avoid reimplementing code from the embedded manifold See also:  EmbeddedManifold ,  project source"},{"id":112,"pagetitle":"Basic functions","title":"ManifoldsBase.embed","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.embed-Tuple{AbstractManifold, Any}","content":" ManifoldsBase.embed  ‚Äî  Method embed(M::AbstractManifold, p) Embed point  p  from the  AbstractManifold M  into the ambient space. This method is only available for manifolds where implicitly an embedding or ambient space is given. Additionally,  embed  includes changing data representation, if applicable, i.e. if the points on  M  are not represented in the same way as points on the embedding, the representation is changed accordingly. The default is set in such a way that memory is allocated and  embed!(M, q, p)  is called. See also:  EmbeddedManifold ,  project source"},{"id":113,"pagetitle":"Basic functions","title":"ManifoldsBase.embed_project","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.embed_project-Tuple{AbstractManifold, Any, Any}","content":" ManifoldsBase.embed_project  ‚Äî  Method embed_project(M::AbstractManifold, p, X) Embed vector  X  tangent at  p  from manifold  M  an project it back to tangent space at  p . For points from that tangent space this is identity but in case embedding is defined for tagent vectors from outside of it, this can serve as a way to for example remove numerical innacuracies caused by some algorithms. source"},{"id":114,"pagetitle":"Basic functions","title":"ManifoldsBase.embed_project","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.embed_project-Tuple{AbstractManifold, Any}","content":" ManifoldsBase.embed_project  ‚Äî  Method embed_project(M::AbstractManifold, p) Embed  p  from manifold  M  an project it back to  M . For points from  M  this is identity but in case embedding is defined for points outside of  M , this can serve as a way to for example remove numerical innacuracies caused by some algorithms. source"},{"id":115,"pagetitle":"Basic functions","title":"ManifoldsBase.injectivity_radius","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.injectivity_radius-Tuple{AbstractManifold}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(M::AbstractManifold) Infimum of the injectivity radii  injectivity_radius(M,p)  of all points  p  on the  AbstractManifold . injectivity_radius(M::AbstractManifold, p) Return the distance  $d$  such that  exp(M, p, X)  is injective for all tangent vectors shorter than  $d$  (i.e. has an inverse). injectivity_radius(M::AbstractManifold[, x], method::AbstractRetractionMethod)\ninjectivity_radius(M::AbstractManifold, x, method::AbstractRetractionMethod) Distance  $d$  such that  retract(M, p, X, method)  is injective for all tangent vectors shorter than  $d$  (i.e. has an inverse) for point  p  if provided or all manifold points otherwise. In order to dispatch on different retraction methods, please either implement  _injectivity_radius(M[, p], m::T)  for your retraction  R  or specifically  injectivity_radius_exp(M[, p])  for the exponential map. By default the variant with a point  p  assumes that the default (without  p ) can ve called as a lower bound. source"},{"id":116,"pagetitle":"Basic functions","title":"ManifoldsBase.inner","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.inner-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::AbstractManifold, p, X, Y) Compute the inner product of tangent vectors  X  and  Y  at point  p  from the  AbstractManifold M . source"},{"id":117,"pagetitle":"Basic functions","title":"ManifoldsBase.is_flat","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.is_flat-Tuple{AbstractManifold}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(M::AbstractManifold) Return true if the  AbstractManifold M  is flat, i.e. if its Riemann curvature tensor is everywhere zero. source"},{"id":118,"pagetitle":"Basic functions","title":"ManifoldsBase.is_point","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.is_point-Tuple{AbstractManifold, Any, Bool}","content":" ManifoldsBase.is_point  ‚Äî  Method is_point(M::AbstractManifold, p; error::Symbol = :none, kwargs...)\nis_point(M::AbstractManifold, p, throw_error::Bool; kwargs...) Return whether  p  is a valid point on the  AbstractManifold M . By default the function calls  check_point , which returns an  ErrorException  or  nothing . How to report a potential error can be set using the  error=  keyword :error           - throws an error if  p  is not a point :info            - displays the error message as an  @info :warn            - displays the error message as a  @warning :none  (default) ‚Äì the function just returns  true / false all other symbols are equivalent to  error=:none . The second signature is a shorthand, where the boolean is used for  error=:error  ( true ) and  error=:none  (default,  false ). This case ignores the  error=  keyword source"},{"id":119,"pagetitle":"Basic functions","title":"ManifoldsBase.is_vector","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.is_vector-Tuple{AbstractManifold, Any, Any, Bool, Bool}","content":" ManifoldsBase.is_vector  ‚Äî  Method is_vector(M::AbstractManifold, p, X, check_base_point::Bool=true; error::Symbol=:none, kwargs...)\nis_vector(M::AbstractManifold, p, X, check_base_point::Bool=true, throw_error::Boolean; kwargs...) Return whether  X  is a valid tangent vector at point  p  on the  AbstractManifold M . Returns either  true  or  false . If  check_base_point  is set to true, this function also (first) calls  is_point  on  p . Then, the function calls  check_vector  and checks whether the returned value is  nothing  or an error. How to report a potential error can be set using the  error=  keyword :error           - throws an error if  X  is not a tangent vector and/or  p  is not point ^  :info            - displays the error message as an  @info :warn            - displays the error message as a  @warn ing. :none            - (default) the function just returns  true / false all other symbols are equivalent to  error=:none The second signature is a shorthand, where  throw_error  is used for  error=:error  ( true ) and  error=:none  (default,  false ). This case ignores the  error=  keyword. source"},{"id":120,"pagetitle":"Basic functions","title":"ManifoldsBase.manifold_dimension","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.manifold_dimension-Tuple{AbstractManifold}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::AbstractManifold) The dimension  $n=\\dim_{\\mathcal M}$  of real space  $\\mathbb R^n$  to which the neighborhood of each point of the  AbstractManifold M  is homeomorphic. source"},{"id":121,"pagetitle":"Basic functions","title":"ManifoldsBase.mid_point!","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.mid_point!-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldsBase.mid_point!  ‚Äî  Method mid_point!(M::AbstractManifold, q, p1, p2) Calculate the middle between the two point  p1  and  p2  from manifold  M . By default uses  log , divides the vector by 2 and uses  exp! . Saves the result in  q . source"},{"id":122,"pagetitle":"Basic functions","title":"ManifoldsBase.mid_point","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.mid_point-Tuple{AbstractManifold, Any, Any}","content":" ManifoldsBase.mid_point  ‚Äî  Method mid_point(M::AbstractManifold, p1, p2) Calculate the middle between the two point  p1  and  p2  from manifold  M . By default uses  log , divides the vector by 2 and uses  exp . source"},{"id":123,"pagetitle":"Basic functions","title":"ManifoldsBase.number_eltype","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.number_eltype-Tuple{Any}","content":" ManifoldsBase.number_eltype  ‚Äî  Method number_eltype(x) Numeric element type of the a nested representation of a point or a vector. To be used in conjuntion with  allocate  or  allocate_result . source"},{"id":124,"pagetitle":"Basic functions","title":"ManifoldsBase.representation_size","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.representation_size-Tuple{AbstractManifold}","content":" ManifoldsBase.representation_size  ‚Äî  Method representation_size(M::AbstractManifold) The size of an array representing a point on  AbstractManifold M . Returns  nothing  by default indicating that points are not represented using an  AbstractArray . source"},{"id":125,"pagetitle":"Basic functions","title":"ManifoldsBase.riemann_tensor","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.riemann_tensor-Tuple{AbstractManifold, Vararg{Any, 4}}","content":" ManifoldsBase.riemann_tensor  ‚Äî  Method riemann_tensor(M::AbstractManifold, p, X, Y, Z) Compute the value of the Riemann tensor  $R(X_f,Y_f)Z_f$  at point  p , where  $X_f$ ,  $Y_f$  and  $Z_f$  are vector fields defined by parallel transport of, respectively,  X ,  Y  and  Z  to the desired point. All computations are performed using the connection associated to manifold  M . The formula reads  $R(X_f,Y_f)Z_f = \\nabla_X\\nabla_Y Z - \\nabla_Y\\nabla_X Z - \\nabla_{[X, Y]}Z$ , where  $[X, Y]$  is the Lie bracket of vector fields. Note that some authors define this quantity with inverse sign. source"},{"id":126,"pagetitle":"Basic functions","title":"ManifoldsBase.sectional_curvature","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.sectional_curvature-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldsBase.sectional_curvature  ‚Äî  Method sectional_curvature(M::AbstractManifold, p, X, Y) Compute the sectional curvature of a manifold  $\\mathcal M$  at a point  $p \\in \\mathcal M$  on two linearly independent tangent vectors at  $p$ . The formula reads \\[\n    \\kappa_p(X, Y) = \\frac{‚ü®R(X, Y, Y), X‚ü©_p}{\\lVert X \\rVert^2_p \\lVert Y \\rVert^2_p - ‚ü®X, Y‚ü©^2_p}\n\\] where  $R(X, Y, Y)$  is the  riemann_tensor  on  $\\mathcal M$ . Input M :   a manifold  $\\mathcal M$ p :   a point  $p \\in \\mathcal M$ X :   a tangent vector  $X \\in T_p \\mathcal M$ Y :   a tangent vector  $Y \\in T_p \\mathcal M$ source"},{"id":127,"pagetitle":"Basic functions","title":"ManifoldsBase.sectional_curvature_max","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.sectional_curvature_max-Tuple{AbstractManifold}","content":" ManifoldsBase.sectional_curvature_max  ‚Äî  Method sectional_curvature_max(M::AbstractManifold) Upper bound on sectional curvature of manifold  M . The formula reads \\[\\omega = \\operatorname{sup}_{p\\in\\mathcal M, X\\in T_p\\mathcal M, Y\\in T_p\\mathcal M, ‚ü®X, Y‚ü© ‚â† 0} \\kappa_p(X, Y)\\] source"},{"id":128,"pagetitle":"Basic functions","title":"ManifoldsBase.sectional_curvature_min","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.sectional_curvature_min-Tuple{AbstractManifold}","content":" ManifoldsBase.sectional_curvature_min  ‚Äî  Method sectional_curvature_min(M::AbstractManifold) Lower bound on sectional curvature of manifold  M . The formula reads \\[\\omega = \\operatorname{inf}_{p\\in\\mathcal M, X\\in T_p\\mathcal M, Y\\in T_p\\mathcal M, ‚ü®X, Y‚ü© ‚â† 0} \\kappa_p(X, Y)\\] source"},{"id":129,"pagetitle":"Basic functions","title":"ManifoldsBase.zero_vector!","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.zero_vector!-Tuple{AbstractManifold, Any, Any}","content":" ManifoldsBase.zero_vector!  ‚Äî  Method zero_vector!(M::AbstractManifold, X, p) Save to  X  the tangent vector from the tangent space  $T_p\\mathcal M$  at  p  that represents the zero vector, i.e. such that retracting  X  to the  AbstractManifold M  at  p  produces  p . source"},{"id":130,"pagetitle":"Basic functions","title":"ManifoldsBase.zero_vector","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.zero_vector-Tuple{AbstractManifold, Any}","content":" ManifoldsBase.zero_vector  ‚Äî  Method zero_vector(M::AbstractManifold, p) Return the tangent vector from the tangent space  $T_p\\mathcal M$  at  p  on the  AbstractManifold M , that represents the zero vector, i.e. such that a retraction at  p  produces  p . source"},{"id":131,"pagetitle":"Basic functions","title":"Internal functions","ref":"/manifoldsbase/stable/functions/#Internal-functions","content":" Internal functions While you should always add your documentation to functions from the last section, some of the functions dispatch onto functions on  layer III . These are the ones you usually implement for your manifold ‚Äì unless there is no lower level function called, like for the  manifold_dimension ."},{"id":132,"pagetitle":"Basic functions","title":"Base.convert","ref":"/manifoldsbase/stable/functions/#Base.convert-Tuple{Type, AbstractManifold, Any, Any}","content":" Base.convert  ‚Äî  Method convert(T::Type, M::AbstractManifold, p, X) Convert vector  X  tangent at point  p  from manifold  M  to type  T . source"},{"id":133,"pagetitle":"Basic functions","title":"Base.convert","ref":"/manifoldsbase/stable/functions/#Base.convert-Tuple{Type, AbstractManifold, Any}","content":" Base.convert  ‚Äî  Method convert(T::Type, M::AbstractManifold, p) Convert point  p  from manifold  M  to type  T . source"},{"id":134,"pagetitle":"Basic functions","title":"ManifoldsBase._isapprox","ref":"/manifoldsbase/stable/functions/#ManifoldsBase._isapprox-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldsBase._isapprox  ‚Äî  Method _isapprox(M::AbstractManifold, p, X, Y; kwargs...) An internal function for testing whether tangent vectors  X  and  Y  from tangent space at point  p  from manifold  M  are approximately equal. Returns either  true  or  false  and does not support errors like  isapprox . For more details see documentation of  check_approx . source"},{"id":135,"pagetitle":"Basic functions","title":"ManifoldsBase._isapprox","ref":"/manifoldsbase/stable/functions/#ManifoldsBase._isapprox-Tuple{AbstractManifold, Any, Any}","content":" ManifoldsBase._isapprox  ‚Äî  Method _isapprox(M::AbstractManifold, p, q; kwargs...) An internal function for testing whether points  p  and  q  from manifold  M  are approximately equal. Returns either  true  or  false  and does not support errors like  isapprox . For more details see documentation of  check_approx . source"},{"id":136,"pagetitle":"Basic functions","title":"ManifoldsBase._pick_basic_allocation_argument","ref":"/manifoldsbase/stable/functions/#ManifoldsBase._pick_basic_allocation_argument-Tuple{AbstractManifold, Any, Vararg{Any}}","content":" ManifoldsBase._pick_basic_allocation_argument  ‚Äî  Method _pick_basic_allocation_argument(::AbstractManifold, f, x...) Pick which one of elements of  x  should be used as a basis for allocation in the  allocate_result(M::AbstractManifold, f, x...)  method. This can be specialized to, for example, skip  Identity  arguments in Manifolds.jl group-related functions. source"},{"id":137,"pagetitle":"Basic functions","title":"ManifoldsBase.allocate_result","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.allocate_result-Tuple{AbstractManifold, Any, Vararg{Any}}","content":" ManifoldsBase.allocate_result  ‚Äî  Method allocate_result(M::AbstractManifold, f, x...) Allocate an array for the result of function  f  on  AbstractManifold M  and arguments  x...  for implementing the non-modifying operation using the modifying operation. Usefulness of passing a function is demonstrated by methods that allocate results of musical isomorphisms. source"},{"id":138,"pagetitle":"Basic functions","title":"ManifoldsBase.allocate_result_type","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.allocate_result_type-Union{Tuple{TF}, Tuple{N}, Tuple{AbstractManifold, TF, Tuple{Vararg{Any, N}}}} where {N, TF}","content":" ManifoldsBase.allocate_result_type  ‚Äî  Method allocate_result_type(M::AbstractManifold, f, args::NTuple{N,Any}) where N Return type of element of the array that will represent the result of function  f  and the  AbstractManifold M  on given arguments  args  (passed as a tuple). source"},{"id":139,"pagetitle":"Basic functions","title":"ManifoldsBase.are_linearly_independent","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.are_linearly_independent-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldsBase.are_linearly_independent  ‚Äî  Method are_linearly_independent(M::AbstractManifold, p, X, Y) Check is vectors  X ,  Y  tangent at  p  to  M  are linearly independent. source"},{"id":140,"pagetitle":"Basic functions","title":"ManifoldsBase.check_approx","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.check_approx-Tuple{AbstractManifold, Any, Any}","content":" ManifoldsBase.check_approx  ‚Äî  Method check_approx(M::AbstractManifold, p, q; kwargs...)\ncheck_approx(M::AbstractManifold, p, X, Y; kwargs...) Check whether two elements are approximately equal, either  p ,  q  on the  AbstractManifold  or the two tangent vectors  X ,  Y  in the tangent space at  p  are approximately the same. The keyword arguments  kwargs  can be used to set tolerances, similar to Julia's  isapprox . This function might use  isapprox  from Julia internally and is similar to  isapprox , with the difference that is returns an  ApproximatelyError  if the two elements are not approximately equal, containting a more detailed description/reason. If the two elements are approximalely equal, this method returns  nothing . This method is an internal function and is called by  isapprox  whenever the user specifies an  error=  keyword therein.  _isapprox  is another related internal function. It is supposed to provide a fast true/false decision whether points or vectors are equal or not, while  check_approx  also provides a textual explanation. If no additional explanation is needed, a manifold may just implement a method of  _isapprox , while it should also implement  check_approx  if a more detailed explanation could be helpful. source"},{"id":141,"pagetitle":"Basic functions","title":"ManifoldsBase.check_point","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.check_point-Tuple{AbstractManifold, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::AbstractManifold, p; kwargs...) -> Union{Nothing,String} Return  nothing  when  p  is a point on the  AbstractManifold M . Otherwise, return an error with description why the point does not belong to manifold  M . By default,  check_point  returns  nothing , i.e. if no checks are implemented, the assumption is to be optimistic for a point not deriving from the  AbstractManifoldPoint  type. source"},{"id":142,"pagetitle":"Basic functions","title":"ManifoldsBase.check_size","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.check_size-Tuple{AbstractManifold, Any}","content":" ManifoldsBase.check_size  ‚Äî  Method check_size(M::AbstractManifold, p)\ncheck_size(M::AbstractManifold, p, X) Check whether  p  has the right  representation_size  for a  AbstractManifold M . Additionally if a tangent vector is given, both  p  and  X  are checked to be of corresponding correct representation sizes for points and tangent vectors on  M . By default,  check_size  returns  nothing , i.e. if no checks are implemented, the assumption is to be optimistic. source"},{"id":143,"pagetitle":"Basic functions","title":"ManifoldsBase.check_vector","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.check_vector-Tuple{AbstractManifold, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::AbstractManifold, p, X; kwargs...) -> Union{Nothing,String} Check whether  X  is a valid tangent vector in the tangent space of  p  on the  AbstractManifold M . An implementation does not have to validate the point  p . If it is not a tangent vector, an error string should be returned. By default,  check_vector  returns  nothing , i.e. if no checks are implemented, the assumption is to be optimistic for tangent vectors not deriving from the  TVector  type. source"},{"id":144,"pagetitle":"Basic functions","title":"ManifoldsBase.size_to_tuple","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.size_to_tuple-Union{Tuple{Type{S}}, Tuple{S}} where S<:Tuple","content":" ManifoldsBase.size_to_tuple  ‚Äî  Method size_to_tuple(::Type{S}) where S<:Tuple Converts a size given by  Tuple{N, M, ...}  into a tuple  (N, M, ...) . source"},{"id":145,"pagetitle":"Basic functions","title":"Approximation Methods","ref":"/manifoldsbase/stable/functions/#Approximation-Methods","content":" Approximation Methods"},{"id":146,"pagetitle":"Basic functions","title":"ManifoldsBase.AbstractApproximationMethod","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.AbstractApproximationMethod","content":" ManifoldsBase.AbstractApproximationMethod  ‚Äî  Type AbstractApproximationMethod Abstract type for defining estimation methods on manifolds. source"},{"id":147,"pagetitle":"Basic functions","title":"ManifoldsBase.CyclicProximalPointEstimation","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.CyclicProximalPointEstimation","content":" ManifoldsBase.CyclicProximalPointEstimation  ‚Äî  Type CyclicProximalPointEstimation <: AbstractApproximationMethod Method for estimation using the cyclic proximal point technique, which is based on  üìñ proximal maps . source"},{"id":148,"pagetitle":"Basic functions","title":"ManifoldsBase.EfficientEstimator","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.EfficientEstimator","content":" ManifoldsBase.EfficientEstimator  ‚Äî  Type EfficientEstimator <: AbstractApproximationMethod Method for estimation in the best possible sense, see  üìñ Efficiency (Statictsics)  for more details. This can for example be used when computing the usual mean on an Euclidean space, which is the best estimator. source"},{"id":149,"pagetitle":"Basic functions","title":"ManifoldsBase.ExtrinsicEstimation","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.ExtrinsicEstimation","content":" ManifoldsBase.ExtrinsicEstimation  ‚Äî  Type ExtrinsicEstimation{T} <: AbstractApproximationMethod Method for estimation in the ambient space with a method of type  T  and projecting the result back to the manifold. source"},{"id":150,"pagetitle":"Basic functions","title":"ManifoldsBase.GeodesicInterpolation","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.GeodesicInterpolation","content":" ManifoldsBase.GeodesicInterpolation  ‚Äî  Type GeodesicInterpolation <: AbstractApproximationMethod Method for estimation based on geodesic interpolation. source"},{"id":151,"pagetitle":"Basic functions","title":"ManifoldsBase.GeodesicInterpolationWithinRadius","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.GeodesicInterpolationWithinRadius","content":" ManifoldsBase.GeodesicInterpolationWithinRadius  ‚Äî  Type GeodesicInterpolationWithinRadius{T} <: AbstractApproximationMethod Method for estimation based on geodesic interpolation that is restricted to some  radius Constructor GeodesicInterpolationWithinRadius(radius::Real) source"},{"id":152,"pagetitle":"Basic functions","title":"ManifoldsBase.GradientDescentEstimation","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.GradientDescentEstimation","content":" ManifoldsBase.GradientDescentEstimation  ‚Äî  Type GradientDescentEstimation <: AbstractApproximationMethod Method for estimation using  üìñ gradient descent . source"},{"id":153,"pagetitle":"Basic functions","title":"ManifoldsBase.WeiszfeldEstimation","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.WeiszfeldEstimation","content":" ManifoldsBase.WeiszfeldEstimation  ‚Äî  Type WeiszfeldEstimation <: AbstractApproximationMethod Method for estimation using the Weiszfeld algorithm, compare for example the computation of the  üìñ Geometric median . source"},{"id":154,"pagetitle":"Basic functions","title":"ManifoldsBase.default_approximation_method","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.default_approximation_method-Tuple{AbstractManifold, Any}","content":" ManifoldsBase.default_approximation_method  ‚Äî  Method default_approximation_method(M::AbstractManifold, f)\ndefault_approximation_method(M::AbtractManifold, f, T) Specify a default estimation method for an  AbstractManifold  and a specific function  f  and optionally as well a type  T  to distinguish different (point or vector) representations on  M . By default, all functions  f  call the signature for just a manifold. The exceptional functions are: retract  and  retract!  which fall back to  default_retraction_method inverse_retract  and  inverse_retract!  which fall back to  default_inverse_retraction_method any of the vector transport mehods fall back to  default_vector_transport_method source"},{"id":155,"pagetitle":"Basic functions","title":"Error Messages","ref":"/manifoldsbase/stable/functions/#Error-Messages","content":" Error Messages This interface introduces a small set of own error messages."},{"id":156,"pagetitle":"Basic functions","title":"ManifoldsBase.AbstractManifoldDomainError","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.AbstractManifoldDomainError","content":" ManifoldsBase.AbstractManifoldDomainError  ‚Äî  Type AbstractManifoldDomainError <: Exception An absytract Case for Errors when checking validity of points/vectors on mainfolds source"},{"id":157,"pagetitle":"Basic functions","title":"ManifoldsBase.ApproximatelyError","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.ApproximatelyError","content":" ManifoldsBase.ApproximatelyError  ‚Äî  Type ApproximatelyError{V,S} <: Exception Store an error that occurs when two data structures, e.g. points or tangent vectors. Fields val  amount the two approximate elements are apart ‚Äì is set to  NaN  if this is not known msg  a message providing more detail about the performed test and why it failed. Constructors ApproximatelyError(val::V, msg::S) where {V,S} Generate an Error with value  val  and message  msg . ApproximatelyError(msg::S) where {S} Generate a message without a value (using  val=NaN  internally) and message  msg . source"},{"id":158,"pagetitle":"Basic functions","title":"ManifoldsBase.ComponentManifoldError","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.ComponentManifoldError","content":" ManifoldsBase.ComponentManifoldError  ‚Äî  Type CompnentError{I,E} <: Exception Store an error that occured in a component, where the additional  index  is stored. Fields index::I  index where the error occured` error::E  error that occured. source"},{"id":159,"pagetitle":"Basic functions","title":"ManifoldsBase.CompositeManifoldError","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.CompositeManifoldError","content":" ManifoldsBase.CompositeManifoldError  ‚Äî  Type CompositeManifoldError{T} <: Exception A composite type to collect a set of errors that occured. Mainly used in conjunction with  ComponentManifoldError  to store a set of errors that occured. Fields errors  a  Vector  of  <:Exceptions . source"},{"id":160,"pagetitle":"Basic functions","title":"ManifoldsBase.ManifoldDomainError","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.ManifoldDomainError","content":" ManifoldsBase.ManifoldDomainError  ‚Äî  Type ManifoldDomainError{<:Exception} <: Exception An error to represent a nested (Domain) error on a manifold, for example if a point or tangent vector is invalid because its representation in some embedding is already invalid. source"},{"id":161,"pagetitle":"Basic functions","title":"ManifoldsBase.OutOfInjectivityRadiusError","ref":"/manifoldsbase/stable/functions/#ManifoldsBase.OutOfInjectivityRadiusError","content":" ManifoldsBase.OutOfInjectivityRadiusError  ‚Äî  Type OutOfInjectivityRadiusError An error thrown when a function (for example  log arithmic map or  inverse_retract ) is given arguments outside of its  injectivity_radius . source"},{"id":164,"pagetitle":"Manifolds","title":"Manifolds","ref":"/manifoldsbase/stable/manifolds/#Manifolds","content":" Manifolds While the interface  ManifoldsBase.jl  does not cover concrete manifolds, it provides a few helpers to build or create manifolds based on existing manifolds"},{"id":165,"pagetitle":"Manifolds","title":"A default manifold","ref":"/manifoldsbase/stable/manifolds/#A-default-manifold","content":" A default manifold DefaultManifold  is a simplified version of  Euclidean  and demonstrates a basic interface implementation. It can be used to perform simple tests. Since when using  Manifolds.jl  the  Euclidean  is available, the  DefaultManifold  itself is not exported."},{"id":166,"pagetitle":"Manifolds","title":"ManifoldsBase.DefaultManifold","ref":"/manifoldsbase/stable/manifolds/#ManifoldsBase.DefaultManifold","content":" ManifoldsBase.DefaultManifold  ‚Äî  Type DefaultManifold <: AbstractManifold This default manifold illustrates the main features of the interface and provides a skeleton to build one's own manifold. It is a simplified/shortened variant of  Euclidean  from  Manifolds.jl . This manifold further illustrates how to type your manifold points and tangent vectors. Note that the interface does not require this, but it might be handy in debugging and educative situations to verify correctness of involved variables. Constructor DefaultManifold(n::Int...; field = ‚Ñù, parameter::Symbol = :field) Arguments: n : shape of array representing points on the manifold. field : field over which the manifold is defined. Either  ‚Ñù ,  ‚ÑÇ  or  ‚Ñç . parameter : whether a type parameter should be used to store  n . By default size is stored in a field. Value can either be  :field  or  :type . source"},{"id":167,"pagetitle":"Manifolds","title":"Embedded manifold","ref":"/manifoldsbase/stable/manifolds/#sec-embedded-manifold","content":" Embedded manifold The embedded manifold is a manifold  $\\mathcal M$  which is modelled  explicitly  specifying its embedding  $\\mathcal N$  in which the points and tangent vectors are represented. Most prominently  is_point  and  is_vector  of an embedded manifold are implemented to check whether the point is a valid point in the embedding. This can of course still be extended by further tests.  ManifoldsBase.jl  provides two possibilities of easily introducing this in order to dispatch some functions to the embedding."},{"id":168,"pagetitle":"Manifolds","title":"Implicit case: the  IsEmbeddedManifold  Trait","ref":"/manifoldsbase/stable/manifolds/#subsec-implicit-embedded","content":" Implicit case: the  IsEmbeddedManifold  Trait For the implicit case, your manifold has to be a subtype of the  AbstractDecoratorManifold . Adding a method to the  active_traits  function for a manifold that returns an  AbstractTrait IsEmbeddedManifold , makes that manifold an embedded manifold. You just have to also define  get_embedding  so that appropriate functions are passed on to that embedding. This is the implicit case, since the manifold type itself does not carry any information about the embedding, just the trait and the function definition do."},{"id":169,"pagetitle":"Manifolds","title":"Explicit case: the  EmbeddedManifold","ref":"/manifoldsbase/stable/manifolds/#subsec-explicit-embedded","content":" Explicit case: the  EmbeddedManifold The  EmbeddedManifold  itself is an  AbstractDecoratorManifold  so it is a case of the implicit embedding itself, but internally stores both the original manifold and the embedding. They are also parameters of the type. This way, an additional embedding of one manifold in another can be modelled. That is, if the manifold is implemented using the implicit embedding approach from before but can also be implemented using a  different  embedding, then this method should be chosen, since you can dispatch functions that you want to implement in this embedding then on the type which explicitly has the manifold and its embedding as parameters. Hence this case should be used for any further embedding after the first or if the default implementation works without an embedding and the alternative needs one."},{"id":170,"pagetitle":"Manifolds","title":"ManifoldsBase.EmbeddedManifold","ref":"/manifoldsbase/stable/manifolds/#ManifoldsBase.EmbeddedManifold","content":" ManifoldsBase.EmbeddedManifold  ‚Äî  Type EmbeddedManifold{ùîΩ, MT <: AbstractManifold, NT <: AbstractManifold} <: AbstractDecoratorManifold{ùîΩ} A type to represent an explicit embedding of a  AbstractManifold M  of type  MT  embedded into a manifold  N  of type  NT . By default, an embedded manifold is set to be embedded, but neither isometrically embedded nor a submanifold. Note This type is not required if a manifold  M  is to be embedded in one specific manifold  N .  One can then just implement  embed!  and  project! . You can further pass functions to the embedding, for example, when it is an isometric embedding, by using an  AbstractDecoratorManifold . Only for a second ‚Äìmaybe considered non-default‚Äì embedding, this type should be considered in order to dispatch on different embed and project methods for different embeddings  N . Fields manifold  the manifold that is an embedded manifold embedding  a second manifold, the first one is embedded into Constructor EmbeddedManifold(M, N) Generate the  EmbeddedManifold  of the  AbstractManifold M  into the  AbstractManifold N . source"},{"id":171,"pagetitle":"Manifolds","title":"ManifoldsBase.decorated_manifold","ref":"/manifoldsbase/stable/manifolds/#ManifoldsBase.decorated_manifold-Tuple{EmbeddedManifold}","content":" ManifoldsBase.decorated_manifold  ‚Äî  Method decorated_manifold(M::EmbeddedManifold, d::Val{N} = Val(-1)) Return the manifold of  M  that is decorated with its embedding. For this specific type the internally stored enhanced manifold  M.manifold  is returned. See also  base_manifold , where this is used to (potentially) completely undecorate the manifold. source"},{"id":172,"pagetitle":"Manifolds","title":"ManifoldsBase.get_embedding","ref":"/manifoldsbase/stable/manifolds/#ManifoldsBase.get_embedding-Tuple{EmbeddedManifold}","content":" ManifoldsBase.get_embedding  ‚Äî  Method get_embedding(M::EmbeddedManifold) Return the embedding  AbstractManifold N  of  M , if it exists. source"},{"id":173,"pagetitle":"Manifolds","title":"Metrics","ref":"/manifoldsbase/stable/manifolds/#Metrics","content":" Metrics Most metric-related functionality is currently defined in  Manifolds.jl  but a few basic types are defined here."},{"id":174,"pagetitle":"Manifolds","title":"ManifoldsBase.AbstractMetric","ref":"/manifoldsbase/stable/manifolds/#ManifoldsBase.AbstractMetric","content":" ManifoldsBase.AbstractMetric  ‚Äî  Type AbstractMetric Abstract type for the pseudo-Riemannian metric tensor  $g$ , a family of smoothly varying inner products on the tangent space. See  inner . Functor (metric::Metric)(M::AbstractManifold)\n(metric::Metric)(M::MetricManifold) Generate the  MetricManifold  that wraps the manifold  M  with given  metric . This works for both a variable containing the metric as well as a subtype  T<:AbstractMetric , where a zero parameter constructor  T()  is availabe. If  M  is already a metric manifold, the inner manifold with the new  metric  is returned. source"},{"id":175,"pagetitle":"Manifolds","title":"ManifoldsBase.EuclideanMetric","ref":"/manifoldsbase/stable/manifolds/#ManifoldsBase.EuclideanMetric","content":" ManifoldsBase.EuclideanMetric  ‚Äî  Type EuclideanMetric <: RiemannianMetric A general type for any manifold that employs the Euclidean Metric, for example the  Euclidean  manifold itself, or the  Sphere , where every tangent space (as a plane in the embedding) uses this metric (in the embedding). Since the metric is independent of the field type, this metric is also used for the Hermitian metrics, i.e. metrics that are analogous to the  EuclideanMetric  but where the field type of the manifold is  ‚ÑÇ . This metric is the default metric for example for the  Euclidean  manifold. source"},{"id":176,"pagetitle":"Manifolds","title":"ManifoldsBase.RiemannianMetric","ref":"/manifoldsbase/stable/manifolds/#ManifoldsBase.RiemannianMetric","content":" ManifoldsBase.RiemannianMetric  ‚Äî  Type RiemannianMetric <: AbstractMetric Abstract type for Riemannian metrics, a family of positive definite inner products. The positive definite property means that for  $X  ‚àà T_p \\mathcal M$ , the inner product  $g(X, X) > 0$  whenever  $X$  is not the zero vector. source"},{"id":177,"pagetitle":"Manifolds","title":"ManifoldsBase.change_metric!","ref":"/manifoldsbase/stable/manifolds/#ManifoldsBase.change_metric!-Tuple{AbstractManifold, Any, ManifoldsBase.AbstractMetric, Any, Any}","content":" ManifoldsBase.change_metric!  ‚Äî  Method change_metric!(M::AbstractcManifold, Y, G2::AbstractMetric, p, X) Compute the  change_metric  in place of  Y . source"},{"id":178,"pagetitle":"Manifolds","title":"ManifoldsBase.change_metric","ref":"/manifoldsbase/stable/manifolds/#ManifoldsBase.change_metric-Tuple{AbstractManifold, ManifoldsBase.AbstractMetric, Any, Any}","content":" ManifoldsBase.change_metric  ‚Äî  Method change_metric(M::AbstractcManifold, G2::AbstractMetric, p, X) On the  AbstractManifold M  with implicitly given metric  $g_1$  and a second  AbstractMetric $g_2$  this function performs a change of metric in the sense that it returns the tangent vector  $Z=BX$  such that the linear map  $B$  fulfills \\[g_2(Y_1,Y_2) = g_1(BY_1,BY_2) \\quad \\text{for all } Y_1, Y_2 ‚àà T_p\\mathcal M.\\] source"},{"id":179,"pagetitle":"Manifolds","title":"ManifoldsBase.change_representer!","ref":"/manifoldsbase/stable/manifolds/#ManifoldsBase.change_representer!-Tuple{AbstractManifold, Any, ManifoldsBase.AbstractMetric, Any, Any}","content":" ManifoldsBase.change_representer!  ‚Äî  Method change_representer!(M::AbstractcManifold, Y, G2::AbstractMetric, p, X) Compute the  change_metric  in place of  Y . source"},{"id":180,"pagetitle":"Manifolds","title":"ManifoldsBase.change_representer","ref":"/manifoldsbase/stable/manifolds/#ManifoldsBase.change_representer-Tuple{AbstractManifold, ManifoldsBase.AbstractMetric, Any, Any}","content":" ManifoldsBase.change_representer  ‚Äî  Method change_representer(M::AbstractManifold, G2::AbstractMetric, p, X) Convert the representer  X  of a linear function (in other words a cotangent vector at  p ) in the tangent space at  p  on the  AbstractManifold M  given with respect to the  AbstractMetric G2  into the representer with respect to the (implicit) metric of  M . In order to convert  X  into the representer with respect to the (implicitly given) metric  $g_1$  of  M , we have to find the conversion function  $c: T_p\\mathcal M \\to T_p\\mathcal M$  such that \\[    g_2(X,Y) = g_1(c(X),Y)\\] source"},{"id":181,"pagetitle":"Manifolds","title":"A manifold for validation","ref":"/manifoldsbase/stable/manifolds/#A-manifold-for-validation","content":" A manifold for validation ValidationManifold  is a simple decorator using the  AbstractDecoratorManifold  that ‚Äúdecorates‚Äù a manifold with tests that all involved points and vectors are valid for the wrapped manifold. For example involved input and output paratemers are checked before and after running a function, repectively. This is done by calling  is_point  or  is_vector  whenever applicable."},{"id":182,"pagetitle":"Manifolds","title":"ManifoldsBase.ValidationCoTVector","ref":"/manifoldsbase/stable/manifolds/#ManifoldsBase.ValidationCoTVector","content":" ManifoldsBase.ValidationCoTVector  ‚Äî  Type ValidationCoTVector = ValidationFibreVector{CotangentSpaceType} Represent a cotangent vector to a point on an  ValidationManifold , i.e. on a manifold where data can be represented by arrays. The array is stored internally and semantically. This distinguished the value from  ValidationMPoint s vectors of other types. source"},{"id":183,"pagetitle":"Manifolds","title":"ManifoldsBase.ValidationFibreVector","ref":"/manifoldsbase/stable/manifolds/#ManifoldsBase.ValidationFibreVector","content":" ManifoldsBase.ValidationFibreVector  ‚Äî  Type ValidationFibreVector{TType<:VectorSpaceType} <: AbstractFibreVector{TType} Represent a tangent vector to a point on an  ValidationManifold , i.e. on a manifold where data can be represented by arrays. The array is stored internally and semantically. This distinguished the value from  ValidationMPoint s vectors of other types. source"},{"id":184,"pagetitle":"Manifolds","title":"ManifoldsBase.ValidationMPoint","ref":"/manifoldsbase/stable/manifolds/#ManifoldsBase.ValidationMPoint","content":" ManifoldsBase.ValidationMPoint  ‚Äî  Type ValidationMPoint <: AbstractManifoldPoint Represent a point on an  ValidationManifold , i.e. on a manifold where data can be represented by arrays. The array is stored internally and semantically. This distinguished the value from  ValidationTVector s and  ValidationCoTVector s. source"},{"id":185,"pagetitle":"Manifolds","title":"ManifoldsBase.ValidationManifold","ref":"/manifoldsbase/stable/manifolds/#ManifoldsBase.ValidationManifold","content":" ManifoldsBase.ValidationManifold  ‚Äî  Type ValidationManifold{ùîΩ,M<:AbstractManifold{ùîΩ}} <: AbstractDecoratorManifold{ùîΩ} A manifold to encapsulate manifolds working on array representations of  AbstractManifoldPoint s and  TVector s in a transparent way, such that for these manifolds it's not necessary to introduce explicit types for the points and tangent vectors, but they are encapsulated/stripped automatically when needed. This manifold is a decorator for a manifold, i.e. it decorates a  AbstractManifold M  with types points, vectors, and covectors. Constructor ValidationManifold(M::AbstractManifold; error::Symbol = :error) Generate the Validation manifold, where  error  is used as the symbol passed to all checks. This  :error s by default but could also be set to  :warn  for example source"},{"id":186,"pagetitle":"Manifolds","title":"ManifoldsBase.ValidationTVector","ref":"/manifoldsbase/stable/manifolds/#ManifoldsBase.ValidationTVector","content":" ManifoldsBase.ValidationTVector  ‚Äî  Type ValidationTVector = ValidationFibreVector{TangentSpaceType} Represent a tangent vector to a point on an  ValidationManifold , i.e. on a manifold where data can be represented by arrays. The array is stored internally and semantically. This distinguished the value from  ValidationMPoint s vectors of other types. source"},{"id":187,"pagetitle":"Manifolds","title":"ManifoldsBase.array_value","ref":"/manifoldsbase/stable/manifolds/#ManifoldsBase.array_value-Tuple{AbstractArray}","content":" ManifoldsBase.array_value  ‚Äî  Method array_value(p) Return the internal array value of an  ValidationMPoint ,  ValidationTVector , or  ValidationCoTVector  if the value  p  is encapsulated as such. Return  p  if it is already an array. source"},{"id":190,"pagetitle":"Meta-Manifolds","title":"Meta Manifolds","ref":"/manifoldsbase/stable/metamanifolds/#Meta-Manifolds","content":" Meta Manifolds While the interface does not provide concrete manifolds itself, it does provide several manifolds that can be build based on a given  AbstractManifold  instance."},{"id":191,"pagetitle":"Meta-Manifolds","title":"(Abstract) power manifold","ref":"/manifoldsbase/stable/metamanifolds/#sec-power-manifold","content":" (Abstract) power manifold A power manifold is constructed like higher dimensional vector spaces are formed from the real line, just that for every point  $p = (p_1,\\ldots,p_n) ‚àà \\mathcal M^n$  on the power manifold  $\\mathcal M^n$  the entries of  $p$  are points  $p_1,\\ldots,p_n ‚àà \\mathcal M$  on some manifold  $\\mathcal M$ . Note that  $n$  can also be replaced by multiple values, such that  $p$  is not a vector but a matrix or a multi-index array of points."},{"id":192,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.AbstractPowerManifold","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.AbstractPowerManifold","content":" ManifoldsBase.AbstractPowerManifold  ‚Äî  Type AbstractPowerManifold{ùîΩ,M,TPR} <: AbstractManifold{ùîΩ} An abstract  AbstractManifold  to represent manifolds that are build as powers of another  AbstractManifold M  with representation type  TPR , a subtype of  AbstractPowerRepresentation . source"},{"id":193,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.AbstractPowerRepresentation","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.AbstractPowerRepresentation","content":" ManifoldsBase.AbstractPowerRepresentation  ‚Äî  Type AbstractPowerRepresentation An abstract representation type of points and tangent vectors on a power manifold. source"},{"id":194,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.NestedPowerRepresentation","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.NestedPowerRepresentation","content":" ManifoldsBase.NestedPowerRepresentation  ‚Äî  Type NestedPowerRepresentation Representation of points and tangent vectors on a power manifold using arrays of size equal to  TSize  of a  PowerManifold . Each element of such array stores a single point or tangent vector. For modifying operations, each element of the outer array is modified in-place, differently than in  NestedReplacingPowerRepresentation . source"},{"id":195,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.NestedReplacingPowerRepresentation","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.NestedReplacingPowerRepresentation","content":" ManifoldsBase.NestedReplacingPowerRepresentation  ‚Äî  Type NestedReplacingPowerRepresentation Representation of points and tangent vectors on a power manifold using arrays of size equal to  TSize  of a  PowerManifold . Each element of such array stores a single point or tangent vector. For modifying operations, each element of the outer array is replaced using non-modifying operations, differently than for  NestedReplacingPowerRepresentation . source"},{"id":196,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.PowerBasisData","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.PowerBasisData","content":" ManifoldsBase.PowerBasisData  ‚Äî  Type PowerBasisData{TB<:AbstractArray} Data storage for an array of basis data. source"},{"id":197,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.PowerManifold","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.PowerManifold","content":" ManifoldsBase.PowerManifold  ‚Äî  Type PowerManifold{ùîΩ,TM<:AbstractManifold,TSize,TPR<:AbstractPowerRepresentation} <: AbstractPowerManifold{ùîΩ,TM} The power manifold  $\\mathcal M^{n_1√ó n_2 √ó ‚Ä¶ √ó n_d}$  with power geometry.   TSize  defines the number of elements along each axis, either statically using   TypeParameter  or storing it in a field. For example, a manifold-valued time series would be represented by a power manifold with  $d$  equal to 1 and  $n_1$  equal to the number of samples. A manifold-valued image (for example in diffusion tensor imaging) would be represented by a two-axis power manifold ( $d=2$ ) with  $n_1$  and  $n_2$  equal to width and height of the image. While the size of the manifold is static, points on the power manifold would not be represented by statically-sized arrays. Constructor PowerManifold(M::PowerManifold, N_1, N_2, ..., N_d; parameter::Symbol=:field)\nPowerManifold(M::AbstractManifold, NestedPowerRepresentation(), N_1, N_2, ..., N_d; parameter::Symbol=:field)\nM^(N_1, N_2, ..., N_d) Generate the power manifold  $M^{N_1 √ó N_2 √ó ‚Ä¶ √ó N_d}$ . By default, a  PowerManifold  is expanded further, i.e. for  M=PowerManifold(N, 3) PowerManifold(M, 2)  is equivalent to  PowerManifold(N, 3, 2) . Points are then 3√ó2 matrices of points on  N . Providing a  NestedPowerRepresentation  as the second argument to the constructor can be used to nest manifold, i.e.  PowerManifold(M, NestedPowerRepresentation(), 2)  represents vectors of length 2 whose elements are vectors of length 3 of points on N in a nested array representation. Since there is no default  AbstractPowerRepresentation  within this interface, the  ^  operator is only available for  PowerManifold s and concatenates dimensions. parameter : whether a type parameter should be used to store  n . By default size is stored in a field. Value can either be  :field  or  :type . source"},{"id":198,"pagetitle":"Meta-Manifolds","title":"Base.copyto!","ref":"/manifoldsbase/stable/metamanifolds/#Base.copyto!-Tuple{AbstractPowerManifold{ùîΩ, <:AbstractManifold{ùîΩ}, NestedPowerRepresentation} where ùîΩ, Any, Any, Any}","content":" Base.copyto!  ‚Äî  Method copyto!(M::PowerManifoldNested, Y, p, X) Copy the values elementwise, i.e. call  copyto!(M.manifold, B, a, A)  for all elements  A ,  a  and  B  of  X ,  p , and  Y , respectively. source"},{"id":199,"pagetitle":"Meta-Manifolds","title":"Base.copyto!","ref":"/manifoldsbase/stable/metamanifolds/#Base.copyto!-Tuple{AbstractPowerManifold{ùîΩ, <:AbstractManifold{ùîΩ}, NestedPowerRepresentation} where ùîΩ, Any, Any}","content":" Base.copyto!  ‚Äî  Method copyto!(M::PowerManifoldNested, q, p) Copy the values elementwise, i.e. call  copyto!(M.manifold, b, a)  for all elements  a  and  b  of  p  and  q , respectively. source"},{"id":200,"pagetitle":"Meta-Manifolds","title":"Base.exp","ref":"/manifoldsbase/stable/metamanifolds/#Base.exp-Tuple{AbstractPowerManifold, Vararg{Any}}","content":" Base.exp  ‚Äî  Method exp(M::AbstractPowerManifold, p, X) Compute the exponential map from  p  in direction  X  on the  AbstractPowerManifold M , which can be computed using the base manifolds exponential map elementwise. source"},{"id":201,"pagetitle":"Meta-Manifolds","title":"Base.getindex","ref":"/manifoldsbase/stable/metamanifolds/#Base.getindex-Tuple{AbstractArray, AbstractPowerManifold, Vararg{Union{Colon, Integer, AbstractVector}}}","content":" Base.getindex  ‚Äî  Method getindex(p, M::AbstractPowerManifold, i::Union{Integer,Colon,AbstractVector}...)\np[M::AbstractPowerManifold, i...] Access the element(s) at index  [i...]  of a point  p  on an  AbstractPowerManifold M  by linear or multidimensional indexing. See also  Array Indexing  in Julia. source"},{"id":202,"pagetitle":"Meta-Manifolds","title":"Base.log","ref":"/manifoldsbase/stable/metamanifolds/#Base.log-Tuple{AbstractPowerManifold, Vararg{Any}}","content":" Base.log  ‚Äî  Method log(M::AbstractPowerManifold, p, q) Compute the logarithmic map from  p  to  q  on the  AbstractPowerManifold M , which can be computed using the base manifolds logarithmic map elementwise. source"},{"id":203,"pagetitle":"Meta-Manifolds","title":"Base.setindex!","ref":"/manifoldsbase/stable/metamanifolds/#Base.setindex!-Tuple{AbstractArray, Any, AbstractPowerManifold, Vararg{Union{Colon, Integer, AbstractVector}}}","content":" Base.setindex!  ‚Äî  Method setindex!(q, p, M::AbstractPowerManifold, i::Union{Integer,Colon,AbstractVector}...)\nq[M::AbstractPowerManifold, i...] = p Set the element(s) at index  [i...]  of a point  q  on an  AbstractPowerManifold M  by linear or multidimensional indexing to  q . See also  Array Indexing  in Julia. source"},{"id":204,"pagetitle":"Meta-Manifolds","title":"Base.view","ref":"/manifoldsbase/stable/metamanifolds/#Base.view-Tuple{AbstractArray, AbstractPowerManifold{ùîΩ, <:AbstractManifold{ùîΩ}, NestedPowerRepresentation} where ùîΩ, Vararg{Union{Colon, Integer, AbstractVector}}}","content":" Base.view  ‚Äî  Method view(p, M::PowerManifoldNested, i::Union{Integer,Colon,AbstractVector}...) Get the view of the element(s) at index  [i...]  of a point  p  on an  AbstractPowerManifold M  by linear or multidimensional indexing. source"},{"id":205,"pagetitle":"Meta-Manifolds","title":"LinearAlgebra.norm","ref":"/manifoldsbase/stable/metamanifolds/#LinearAlgebra.norm-Tuple{AbstractPowerManifold, Any, Any}","content":" LinearAlgebra.norm  ‚Äî  Method norm(M::AbstractPowerManifold, p, X) Compute the norm of  X  from the tangent space of  p  on an  AbstractPowerManifold M , i.e. from the element wise norms the Frobenius norm is computed. source"},{"id":206,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.Weingarten","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.Weingarten-Tuple{AbstractPowerManifold, Any, Any, Any}","content":" ManifoldsBase.Weingarten  ‚Äî  Method Y = Weingarten(M::AbstractPowerManifold, p, X, V)\nWeingarten!(M::AbstractPowerManifold, Y, p, X, V) Since the metric decouples, also the computation of the Weingarten map  $\\mathcal W_p$  can be computed elementwise on the single elements of the  PowerManifold M . source"},{"id":207,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase._allocate_access_nested","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase._allocate_access_nested-Tuple{AbstractPowerManifold{ùîΩ, <:AbstractManifold{ùîΩ}, NestedPowerRepresentation} where ùîΩ, Any, Any}","content":" ManifoldsBase._allocate_access_nested  ‚Äî  Method _allocate_access_nested(M::PowerManifoldNested, y, i) Helper function for  allocate_result  on  PowerManifoldNested . In allocation  y  can be a number in which case  _access_nested  wouldn't work. source"},{"id":208,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase._parameter_symbol","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase._parameter_symbol-Tuple{PowerManifold}","content":" ManifoldsBase._parameter_symbol  ‚Äî  Method _parameter_symbol(M::PowerManifold) Return  :field  if size of  PowerManifold M  is stored in a field and  :type  if in a  TypeParameter . source"},{"id":209,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.change_metric","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.change_metric-Tuple{AbstractPowerManifold, ManifoldsBase.AbstractMetric, Any, Any}","content":" ManifoldsBase.change_metric  ‚Äî  Method change_metric(M::AbstractPowerManifold, ::AbstractMetric, p, X) Since the metric on a power manifold decouples, the change of metric can be done elementwise. source"},{"id":210,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.change_representer","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.change_representer-Tuple{AbstractPowerManifold, ManifoldsBase.AbstractMetric, Any, Any}","content":" ManifoldsBase.change_representer  ‚Äî  Method change_representer(M::AbstractPowerManifold, ::AbstractMetric, p, X) Since the metric on a power manifold decouples, the change of a representer can be done elementwise source"},{"id":211,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.check_point","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.check_point-Tuple{AbstractPowerManifold, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::AbstractPowerManifold, p; kwargs...) Check whether  p  is a valid point on an  AbstractPowerManifold M , i.e. each element of  p  has to be a valid point on the base manifold. If  p  is not a point on  M  a  CompositeManifoldError  consisting of all error messages of the components, for which the tests fail is returned. The tolerance for the last test can be set using the  kwargs... . source"},{"id":212,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.check_power_size","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.check_power_size-Tuple{AbstractPowerManifold, Any}","content":" ManifoldsBase.check_power_size  ‚Äî  Method check_power_size(M, p)\ncheck_power_size(M, p, X) Check whether  p has the right size to represent points on M`` generically, i.e. just checking the overall sizes, not the individual ones per manifold. source"},{"id":213,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.check_vector","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.check_vector-Tuple{AbstractPowerManifold, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::AbstractPowerManifold, p, X; kwargs... ) Check whether  X  is a tangent vector to  p  an the  AbstractPowerManifold M , i.e. atfer  check_point (M, p) , and all projections to base manifolds must be respective tangent vectors. If  X  is not a tangent vector to  p  on  M  a  CompositeManifoldError  consisting of all error messages of the components, for which the tests fail is returned. The tolerance for the last test can be set using the  kwargs... . source"},{"id":214,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.default_inverse_retraction_method","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.default_inverse_retraction_method-Tuple{PowerManifold}","content":" ManifoldsBase.default_inverse_retraction_method  ‚Äî  Method default_inverse_retraction_method(M::PowerManifold) Use the default inverse retraction method of the internal  M.manifold  also in defaults of functions defined for the power manifold, meaning that this is used elementwise. source"},{"id":215,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.default_retraction_method","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.default_retraction_method-Tuple{PowerManifold}","content":" ManifoldsBase.default_retraction_method  ‚Äî  Method default_retraction_method(M::PowerManifold) Use the default retraction method of the internal  M.manifold  also in defaults of functions defined for the power manifold, meaning that this is used elementwise. source"},{"id":216,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.default_vector_transport_method","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.default_vector_transport_method-Tuple{PowerManifold}","content":" ManifoldsBase.default_vector_transport_method  ‚Äî  Method default_vector_transport_method(M::PowerManifold) Use the default vector transport method of the internal  M.manifold  also in defaults of functions defined for the power manifold, meaning that this is used elementwise. source"},{"id":217,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.distance","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.distance-Tuple{AbstractPowerManifold, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::AbstractPowerManifold, p, q) Compute the distance between  q  and  p  on an  AbstractPowerManifold , i.e. from the element wise distances the Forbenius norm is computed. source"},{"id":218,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.get_component","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.get_component-Tuple{AbstractPowerManifold, Any, Vararg{Any}}","content":" ManifoldsBase.get_component  ‚Äî  Method get_component(M::AbstractPowerManifold, p, idx...) Get the component of a point  p  on an  AbstractPowerManifold M  at index  idx . source"},{"id":219,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.injectivity_radius","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.injectivity_radius-Tuple{AbstractPowerManifold, Any}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(M::AbstractPowerManifold[, p]) the injectivity radius on an  AbstractPowerManifold  is for the global case equal to the one of its base manifold. For a given point  p  it's equal to the minimum of all radii in the array entries. source"},{"id":220,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.inner","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.inner-Tuple{AbstractPowerManifold, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::AbstractPowerManifold, p, X, Y) Compute the inner product of  X  and  Y  from the tangent space at  p  on an  AbstractPowerManifold M , i.e. for each arrays entry the tangent vector entries from  X  and  Y  are in the tangent space of the corresponding element from  p . The inner product is then the sum of the elementwise inner products. source"},{"id":221,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.inverse_retract","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.inverse_retract-Tuple{AbstractPowerManifold, Vararg{Any}}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(M::AbstractPowerManifold, p, q, m::AbstractInverseRetractionMethod) Compute the inverse retraction from  p  with respect to  q  on an  AbstractPowerManifold M  using an  AbstractInverseRetractionMethod . Then this method is performed elementwise, so the inverse retraction method has to be one that is available on the base  AbstractManifold . source"},{"id":222,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.is_flat","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.is_flat-Tuple{AbstractPowerManifold}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(M::AbstractPowerManifold) Return true if  AbstractPowerManifold  is flat. It is flat if and only if the wrapped manifold is flat. source"},{"id":223,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.manifold_dimension","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.manifold_dimension-Tuple{PowerManifold}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::PowerManifold) Returns the manifold-dimension of an  PowerManifold M $=\\mathcal N = (\\mathcal M)^{n_1,‚Ä¶,n_d}$ , i.e. with  $n=(n_1,‚Ä¶,n_d)$  the array size of the power manifold and  $d_{\\mathcal M}$  the dimension of the base manifold  $\\mathcal M$ , the manifold is of dimension \\[\\dim(\\mathcal N) = \\dim(\\mathcal M)\\prod_{i=1}^d n_i = n_1n_2‚ãÖ‚Ä¶‚ãÖ n_d \\dim(\\mathcal M).\\] source"},{"id":224,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.power_dimensions","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.power_dimensions-Tuple{PowerManifold}","content":" ManifoldsBase.power_dimensions  ‚Äî  Method power_dimensions(M::PowerManifold) return the power of  M , source"},{"id":225,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.project","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.project-Tuple{AbstractPowerManifold, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::AbstractPowerManifold, p, X) Project the point  X  onto the tangent space at  p  on the  AbstractPowerManifold M  by projecting all components. source"},{"id":226,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.project","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.project-Tuple{AbstractPowerManifold, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::AbstractPowerManifold, p) Project the point  p  from the embedding onto the  AbstractPowerManifold M  by projecting all components. source"},{"id":227,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.retract","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.retract-Tuple{AbstractPowerManifold, Vararg{Any}}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::AbstractPowerManifold, p, X, method::AbstractRetractionMethod) Compute the retraction from  p  with tangent vector  X  on an  AbstractPowerManifold M  using a  AbstractRetractionMethod . Then this method is performed elementwise, so the retraction method has to be one that is available on the base  AbstractManifold . source"},{"id":228,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.riemann_tensor","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.riemann_tensor-Tuple{AbstractPowerManifold, Vararg{Any, 4}}","content":" ManifoldsBase.riemann_tensor  ‚Äî  Method riemann_tensor(M::AbstractPowerManifold, p, X, Y, Z) Compute the Riemann tensor at point from  p  with tangent vectors  X ,  Y  and  Z  on the  AbstractPowerManifold M . source"},{"id":229,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.sectional_curvature","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.sectional_curvature-Tuple{AbstractPowerManifold, Any, Any, Any}","content":" ManifoldsBase.sectional_curvature  ‚Äî  Method sectional_curvature(M::AbstractPowerManifold, p, X, Y) Compute the sectional curvature of a power manifold manifold  $\\mathcal M$  at a point  $p \\in \\mathcal M$  on two linearly independent tangent vectors at  $p$ . It may be 0 for  if projections of  X  and  Y  on subspaces corresponding to component manifolds are not linearly independent. source"},{"id":230,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.sectional_curvature_max","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.sectional_curvature_max-Tuple{AbstractPowerManifold}","content":" ManifoldsBase.sectional_curvature_max  ‚Äî  Method sectional_curvature_max(M::AbstractPowerManifold) Upper bound on sectional curvature of  AbstractPowerManifold M . It is the maximum of sectional curvature of the wrapped manifold and 0 in case there are two or more component manifolds, as the sectional curvature corresponding to the plane spanned by vectors  (X_1, 0, ... 0)  and  (0, X_2, 0, ..., 0)  is 0. source"},{"id":231,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.sectional_curvature_min","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.sectional_curvature_min-Tuple{AbstractPowerManifold}","content":" ManifoldsBase.sectional_curvature_min  ‚Äî  Method sectional_curvature_min(M::AbstractPowerManifold) Lower bound on sectional curvature of  AbstractPowerManifold M . It is the minimum of sectional curvature of the wrapped manifold and 0 in case there are two or more component manifolds, as the sectional curvature corresponding to the plane spanned by vectors  (X_1, 0, ... 0)  and  (0, X_2, 0, ..., 0)  is 0. source"},{"id":232,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.set_component!","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.set_component!-Tuple{AbstractPowerManifold, Any, Any, Vararg{Any}}","content":" ManifoldsBase.set_component!  ‚Äî  Method set_component!(M::AbstractPowerManifold, q, p, idx...) Set the component of a point  q  on an  AbstractPowerManifold M  at index  idx  to  p , which itself is a point on the  AbstractManifold  the power manifold is build on. source"},{"id":233,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.vector_transport_to","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.vector_transport_to-Tuple{AbstractPowerManifold, Any, Any, Any, AbstractVectorTransportMethod}","content":" ManifoldsBase.vector_transport_to  ‚Äî  Method vector_transport_to(M::AbstractPowerManifold, p, X, q, method::AbstractVectorTransportMethod) Compute the vector transport the tangent vector  X at  p  to  q  on the  PowerManifold M  using an  AbstractVectorTransportMethod m . This method is performed elementwise, i.e. the method  m  has to be implemented on the base manifold. source"},{"id":234,"pagetitle":"Meta-Manifolds","title":"Product Manifold","ref":"/manifoldsbase/stable/metamanifolds/#ProductManifold","content":" Product Manifold"},{"id":235,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.InverseProductRetraction","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.InverseProductRetraction","content":" ManifoldsBase.InverseProductRetraction  ‚Äî  Type InverseProductRetraction(retractions::AbstractInverseRetractionMethod...) Product inverse retraction of  inverse retractions . Works on  ProductManifold . source"},{"id":236,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.ProductBasisData","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.ProductBasisData","content":" ManifoldsBase.ProductBasisData  ‚Äî  Type ProductBasisData A typed tuple to store tuples of data of stored/precomputed bases for a  ProductManifold . source"},{"id":237,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.ProductManifold","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.ProductManifold","content":" ManifoldsBase.ProductManifold  ‚Äî  Type ProductManifold{ùîΩ,TM<:Tuple} <: AbstractManifold{ùîΩ} Product manifold  $M_1 √ó M_2 √ó ‚Ä¶  √ó M_n$  with product geometry. Constructor ProductManifold(M_1, M_2, ..., M_n) generates the product manifold  $M_1 √ó M_2 √ó ‚Ä¶ √ó M_n$ . Alternatively, the same manifold can be contructed using the  √ó  operator:  M_1 √ó M_2 √ó M_3 . source"},{"id":238,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.ProductMetric","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.ProductMetric","content":" ManifoldsBase.ProductMetric  ‚Äî  Type ProductMetric <: AbstractMetric A type to represent the product of metrics for a  ProductManifold . source"},{"id":239,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.ProductRetraction","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.ProductRetraction","content":" ManifoldsBase.ProductRetraction  ‚Äî  Type ProductRetraction(retractions::AbstractRetractionMethod...) Product retraction of  retractions . Works on  ProductManifold . source"},{"id":240,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.ProductVectorTransport","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.ProductVectorTransport","content":" ManifoldsBase.ProductVectorTransport  ‚Äî  Type ProductVectorTransport(methods::AbstractVectorTransportMethod...) Product vector transport type of  methods . Works on  ProductManifold . source"},{"id":241,"pagetitle":"Meta-Manifolds","title":"Base.exp","ref":"/manifoldsbase/stable/metamanifolds/#Base.exp-Tuple{ProductManifold, Vararg{Any}}","content":" Base.exp  ‚Äî  Method exp(M::ProductManifold, p, X) compute the exponential map from  p  in the direction of  X  on the  ProductManifold M , which is the elementwise exponential map on the internal manifolds that build  M . source"},{"id":242,"pagetitle":"Meta-Manifolds","title":"Base.getindex","ref":"/manifoldsbase/stable/metamanifolds/#Base.getindex-Tuple{ProductManifold, Integer}","content":" Base.getindex  ‚Äî  Method getindex(M::ProductManifold, i)\nM[i] access the  i th manifold component from the  ProductManifold M . source"},{"id":243,"pagetitle":"Meta-Manifolds","title":"Base.log","ref":"/manifoldsbase/stable/metamanifolds/#Base.log-Tuple{ProductManifold, Vararg{Any}}","content":" Base.log  ‚Äî  Method log(M::ProductManifold, p, q) Compute the logarithmic map from  p  to  q  on the  ProductManifold M , which can be computed using the logarithmic maps of the manifolds elementwise. source"},{"id":244,"pagetitle":"Meta-Manifolds","title":"LinearAlgebra.cross","ref":"/manifoldsbase/stable/metamanifolds/#LinearAlgebra.cross-Tuple{Vararg{AbstractInverseRetractionMethod}}","content":" LinearAlgebra.cross  ‚Äî  Method √ó(m, n)\ncross(m, n)\ncross(m1, m2, m3,...) Return the  InverseProductRetraction  For two or more  AbstractInverseRetractionMethod s, where for the case that one of them is a  InverseProductRetraction  itself, the other is either prepended (if  r  is a product) or appenden (if  s ) is. If both  InverseProductRetraction s, they are combined into one keeping the order. source"},{"id":245,"pagetitle":"Meta-Manifolds","title":"LinearAlgebra.cross","ref":"/manifoldsbase/stable/metamanifolds/#LinearAlgebra.cross-Tuple{Vararg{AbstractManifold}}","content":" LinearAlgebra.cross  ‚Äî  Method √ó(M, N)\ncross(M, N)\ncross(M1, M2, M3,...) Return the  ProductManifold  For two  AbstractManifold s  M  and  N , where for the case that one of them is a  ProductManifold  itself, the other is either prepended (if  N  is a product) or appenden (if  M ) is. If both are product manifold, they are combined into one product manifold, keeping the order. For the case that more than one is a product manifold of these is build with the same approach as above source"},{"id":246,"pagetitle":"Meta-Manifolds","title":"LinearAlgebra.cross","ref":"/manifoldsbase/stable/metamanifolds/#LinearAlgebra.cross-Tuple{Vararg{AbstractRetractionMethod}}","content":" LinearAlgebra.cross  ‚Äî  Method √ó(m, n)\ncross(m, n)\ncross(m1, m2, m3,...) Return the  ProductRetraction  For two or more  AbstractRetractionMethod s, where for the case that one of them is a  ProductRetraction  itself, the other is either prepended (if  m  is a product) or appenden (if  n ) is. If both  ProductRetraction s, they are combined into one keeping the order. source"},{"id":247,"pagetitle":"Meta-Manifolds","title":"LinearAlgebra.cross","ref":"/manifoldsbase/stable/metamanifolds/#LinearAlgebra.cross-Tuple{Vararg{AbstractVectorTransportMethod}}","content":" LinearAlgebra.cross  ‚Äî  Method √ó(m, n)\ncross(m, n)\ncross(m1, m2, m3,...) Return the  ProductVectorTransport  For two or more  AbstractVectorTransportMethod s, where for the case that one of them is a  ProductVectorTransport  itself, the other is either prepended (if  r  is a product) or appenden (if  s ) is. If both  ProductVectorTransport s, they are combined into one keeping the order. source"},{"id":248,"pagetitle":"Meta-Manifolds","title":"LinearAlgebra.norm","ref":"/manifoldsbase/stable/metamanifolds/#LinearAlgebra.norm-Tuple{ProductManifold, Any, Any}","content":" LinearAlgebra.norm  ‚Äî  Method norm(M::ProductManifold, p, X) Compute the norm of  X  from the tangent space of  p  on the  ProductManifold , i.e. from the element wise norms the 2-norm is computed. source"},{"id":249,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.Weingarten","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.Weingarten-Tuple{ProductManifold, Any, Any, Any}","content":" ManifoldsBase.Weingarten  ‚Äî  Method Y = Weingarten(M::ProductManifold, p, X, V)\nWeingarten!(M::ProductManifold, Y, p, X, V) Since the metric decouples, also the computation of the Weingarten map  $\\mathcal W_p$  can be computed elementwise on the single elements of the  ProductManifold M . source"},{"id":250,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.change_metric","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.change_metric-Tuple{ProductManifold, ManifoldsBase.AbstractMetric, Any, Any}","content":" ManifoldsBase.change_metric  ‚Äî  Method change_metric(M::ProductManifold, ::AbstractMetric, p, X) Since the metric on a product manifold decouples, the change of metric can be done elementwise. source"},{"id":251,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.change_representer","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.change_representer-Tuple{ProductManifold, ManifoldsBase.AbstractMetric, Any, Any}","content":" ManifoldsBase.change_representer  ‚Äî  Method change_representer(M::ProductManifold, ::AbstractMetric, p, X) Since the metric on a product manifold decouples, the change of a representer can be done elementwise source"},{"id":252,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.check_point","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.check_point-Tuple{ProductManifold, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::ProductManifold, p; kwargs...) Check whether  p  is a valid point on the  ProductManifold M . If  p  is not a point on  M  a  CompositeManifoldError .consisting of all error messages of the components, for which the tests fail is returned. The tolerance for the last test can be set using the  kwargs... . source"},{"id":253,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.check_size","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.check_size-Tuple{ProductManifold, Any}","content":" ManifoldsBase.check_size  ‚Äî  Method check_size(M::ProductManifold, p; kwargs...) Check whether  p  is of valid size on the  ProductManifold M . If  p  has components of wrong size a  CompositeManifoldError .consisting of all error messages of the components, for which the tests fail is returned. The tolerance for the last test can be set using the  kwargs... . source"},{"id":254,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.check_vector","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.check_vector-Tuple{ProductManifold, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::ProductManifold, p, X; kwargs... ) Check whether  X  is a tangent vector to  p  on the  ProductManifold M , i.e. all projections to base manifolds must be respective tangent vectors. If  X  is not a tangent vector to  p  on  M  a  CompositeManifoldError .consisting of all error messages of the components, for which the tests fail is returned. The tolerance for the last test can be set using the  kwargs... . source"},{"id":255,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.distance","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.distance-Tuple{ProductManifold, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::ProductManifold, p, q) Compute the distance between two points  p  and  q  on the  ProductManifold M , which is the 2-norm of the elementwise distances on the internal manifolds that build  M . source"},{"id":256,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.get_component","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.get_component-Tuple{ProductManifold, Any, Any}","content":" ManifoldsBase.get_component  ‚Äî  Method get_component(M::ProductManifold, p, i) Get the  i th component of a point  p  on a  ProductManifold M . source"},{"id":257,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.injectivity_radius","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.injectivity_radius-Tuple{ProductManifold, Vararg{Any}}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(M::ProductManifold)\ninjectivity_radius(M::ProductManifold, x) Compute the injectivity radius on the  ProductManifold , which is the minimum of the factor manifolds. source"},{"id":258,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.inner","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.inner-Tuple{ProductManifold, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::ProductManifold, p, X, Y) compute the inner product of two tangent vectors  X ,  Y  from the tangent space at  p  on the  ProductManifold M , which is just the sum of the internal manifolds that build  M . source"},{"id":259,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.inverse_retract","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.inverse_retract-Tuple{ProductManifold, Any, Any, Any, AbstractInverseRetractionMethod}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(M::ProductManifold, p, q, m::AbstractInverseRetractionMethod) Compute the inverse retraction from  p  with respect to  q  on the  ProductManifold M  using an  AbstractInverseRetractionMethod , which is used on each manifold of the product. source"},{"id":260,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.inverse_retract","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.inverse_retract-Tuple{ProductManifold, Any, Any, Any, InverseProductRetraction}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(M::ProductManifold, p, q, m::InverseProductRetraction) Compute the inverse retraction from  p  with respect to  q  on the  ProductManifold M  using an  InverseProductRetraction , which by default encapsulates a inverse retraction for each manifold of the product. Then this method is performed elementwise, so the encapsulated inverse retraction methods have to be available per factor. source"},{"id":261,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.is_flat","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.is_flat-Tuple{ProductManifold}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::ProductManifold) Return true if and only if all component manifolds of  ProductManifold M  are flat. source"},{"id":262,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.manifold_dimension","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.manifold_dimension-Tuple{ProductManifold}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::ProductManifold) Return the manifold dimension of the  ProductManifold , which is the sum of the manifold dimensions the product is made of. source"},{"id":263,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.number_of_components","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.number_of_components-Union{Tuple{ProductManifold{ùîΩ, <:Tuple{Vararg{Any, N}}}}, Tuple{N}, Tuple{ùîΩ}} where {ùîΩ, N}","content":" ManifoldsBase.number_of_components  ‚Äî  Method number_of_components(M::ProductManifold{<:NTuple{N,Any}}) where {N} Calculate the number of manifolds multiplied in the given  ProductManifold M . source"},{"id":264,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.retract","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.retract-Tuple{ProductManifold, Any, Any, AbstractRetractionMethod}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::ProductManifold, p, X, m::AbstractRetractionMethod) Compute the retraction from  p  with tangent vector  X  on the  ProductManifold M  using the  AbstractRetractionMethod m  on every manifold. source"},{"id":265,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.retract","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.retract-Tuple{ProductManifold, Any, Any, ProductRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::ProductManifold, p, X, m::ProductRetraction) Compute the retraction from  p  with tangent vector  X  on the  ProductManifold M  using an  ProductRetraction , which by default encapsulates retractions of the base manifolds. Then this method is performed elementwise, so the encapsulated retractions method has to be one that is available on the manifolds. source"},{"id":266,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.riemann_tensor","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.riemann_tensor-Tuple{ProductManifold, Vararg{Any, 4}}","content":" ManifoldsBase.riemann_tensor  ‚Äî  Method riemann_tensor(M::ProductManifold, p, X, Y, Z) Compute the Riemann tensor at point from  p  with tangent vectors  X ,  Y  and  Z  on the  ProductManifold M . source"},{"id":267,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.sectional_curvature","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.sectional_curvature-Tuple{ProductManifold, Any, Any, Any}","content":" ManifoldsBase.sectional_curvature  ‚Äî  Method sectional_curvature(M::ProductManifold, p, X, Y) Compute the sectional curvature of a manifold  $\\mathcal M$  at a point  $p \\in \\mathcal M$  on two linearly independent tangent vectors at  $p$ . It may be 0 for a product of non-flat manifolds if projections of  X  and  Y  on subspaces corresponding to component manifolds are not linearly independent. source"},{"id":268,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.sectional_curvature_max","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.sectional_curvature_max-Tuple{ProductManifold}","content":" ManifoldsBase.sectional_curvature_max  ‚Äî  Method sectional_curvature_max(M::ProductManifold) Upper bound on sectional curvature of  ProductManifold M . It is the maximum of sectional curvatures of component manifolds and 0 in case there are two or more component manifolds, as the sectional curvature corresponding to the plane spanned by vectors  (X_1, 0)  and  (0, X_2)  is 0. source"},{"id":269,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.sectional_curvature_min","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.sectional_curvature_min-Tuple{ProductManifold}","content":" ManifoldsBase.sectional_curvature_min  ‚Äî  Method sectional_curvature_min(M::ProductManifold) Lower bound on sectional curvature of  ProductManifold M . It is the minimum of sectional curvatures of component manifolds and 0 in case there are two or more component manifolds, as the sectional curvature corresponding to the plane spanned by vectors  (X_1, 0)  and  (0, X_2)  is 0. source"},{"id":270,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.select_from_tuple","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.select_from_tuple-Union{Tuple{P}, Tuple{N}, Tuple{Tuple{Vararg{Any, N}}, Val{P}}} where {N, P}","content":" ManifoldsBase.select_from_tuple  ‚Äî  Method select_from_tuple(t::NTuple{N, Any}, positions::Val{P}) Selects elements of tuple  t  at positions specified by the second argument. For example  select_from_tuple((\"a\", \"b\", \"c\"), Val((3, 1, 1)))  returns  (\"c\", \"a\", \"a\") . source"},{"id":271,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.set_component!","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.set_component!-Tuple{ProductManifold, Any, Any, Any}","content":" ManifoldsBase.set_component!  ‚Äî  Method set_component!(M::ProductManifold, q, p, i) Set the  i th component of a point  q  on a  ProductManifold M  to  p , where  p  is a point on the  AbstractManifold   this factor of the product manifold consists of. source"},{"id":272,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.submanifold","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.submanifold-Tuple{ProductManifold, Integer}","content":" ManifoldsBase.submanifold  ‚Äî  Method submanifold(M::ProductManifold, i::Integer) Extract the  i th factor of the product manifold  M . source"},{"id":273,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.submanifold","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.submanifold-Tuple{ProductManifold, Val}","content":" ManifoldsBase.submanifold  ‚Äî  Method submanifold(M::ProductManifold, i::Val)\nsubmanifold(M::ProductManifold, i::AbstractVector) Extract the factor of the product manifold  M  indicated by indices in  i . For example, for  i  equal to  Val((1, 3))  the product manifold constructed from the first and the third factor is returned. The version with  AbstractVector  is not type-stable, for better preformance use  Val . source"},{"id":274,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.submanifold_component","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.submanifold_component-Tuple","content":" ManifoldsBase.submanifold_component  ‚Äî  Method submanifold_component(M::AbstractManifold, p, i::Integer)\nsubmanifold_component(M::AbstractManifold, p, ::Val{i}) where {i}\nsubmanifold_component(p, i::Integer)\nsubmanifold_component(p, ::Val{i}) where {i} Project the product array  p  on  M  to its  i th component. A new array is returned. source"},{"id":275,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.submanifold_components","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.submanifold_components-Tuple","content":" ManifoldsBase.submanifold_components  ‚Äî  Method submanifold_components(M::AbstractManifold, p)\nsubmanifold_components(p) Get the projected components of  p  on the submanifolds of  M . The components are returned in a Tuple. source"},{"id":276,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.vector_transport_to","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.vector_transport_to-Tuple{ProductManifold, Any, Any, Any, AbstractVectorTransportMethod}","content":" ManifoldsBase.vector_transport_to  ‚Äî  Method vector_transport_to(M::ProductManifold, p, X, q, m::AbstractVectorTransportMethod) Compute the vector transport the tangent vector  X  at  p  to  q  on the  ProductManifold M  using an  AbstractVectorTransportMethod m  on each manifold. source"},{"id":277,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.vector_transport_to","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.vector_transport_to-Tuple{ProductManifold, Any, Any, Any, ProductVectorTransport}","content":" ManifoldsBase.vector_transport_to  ‚Äî  Method vector_transport_to(M::ProductManifold, p, X, q, m::ProductVectorTransport) Compute the vector transport the tangent vector  X  at  p  to  q  on the  ProductManifold M  using a  ProductVectorTransport m . source"},{"id":278,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.ziptuples","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.ziptuples-Union{Tuple{M}, Tuple{N}, Tuple{Tuple{Vararg{Any, N}}, Tuple{Vararg{Any, M}}}} where {N, M}","content":" ManifoldsBase.ziptuples  ‚Äî  Method ziptuples(a, b[, c[, d[, e]]]) Zips tuples  a ,  b , and remaining in a fast, type-stable way. If they have different lengths, the result is trimmed to the length of the shorter tuple. source"},{"id":279,"pagetitle":"Meta-Manifolds","title":"Fiber","ref":"/manifoldsbase/stable/metamanifolds/#Fiber","content":" Fiber"},{"id":280,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.Fiber","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.Fiber","content":" ManifoldsBase.Fiber  ‚Äî  Type Fiber{ùîΩ,TFiber<:FiberType,TM<:AbstractManifold{ùîΩ},TX} <: AbstractManifold{ùîΩ} A fiber of a fiber bundle at a point  p  on the manifold. This fiber itself is also a  manifold . For vector fibers it's by default flat and hence isometric to the  Euclidean  manifold. Fields manifold     ‚Äì base space of the fiber bundle point        ‚Äì a point  $p$  from the base space; the fiber corresponds to the preimage                 by bundle projection  $\\pi^{-1}(\\{p\\})$ . Constructor Fiber(M::AbstractManifold, p, fiber_type::FiberType) A fiber of type  fiber_type  at point  p  from the manifold  manifold . source"},{"id":281,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.FiberType","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.FiberType","content":" ManifoldsBase.FiberType  ‚Äî  Type abstract type FiberType end An abstract type for fiber types that can be used within  Fiber . source"},{"id":282,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.VectorSpaceFiber","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.VectorSpaceFiber","content":" ManifoldsBase.VectorSpaceFiber  ‚Äî  Type VectorSpaceFiber{ùîΩ,M,TSpaceType} = Fiber{ùîΩ,TSpaceType,M}\n    where {ùîΩ,M<:AbstractManifold{ùîΩ},TSpaceType<:VectorSpaceType} Alias for a  Fiber  when the fiber is a vector space. source"},{"id":283,"pagetitle":"Meta-Manifolds","title":"Tangent Space","ref":"/manifoldsbase/stable/metamanifolds/#Tangent-Space","content":" Tangent Space"},{"id":284,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.CotangentSpace","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.CotangentSpace","content":" ManifoldsBase.CotangentSpace  ‚Äî  Type CotangentSpace{ùîΩ,M} = Fiber{ùîΩ,CotangentSpaceType,M} where {ùîΩ,M<:AbstractManifold{ùîΩ}} A manifold for the Cotangent space  $T^*_p\\mathcal M$  at a point  $p\\in\\mathcal M$ . This is modelled as an alias for  VectorSpaceFiber  corresponding to  CotangentSpaceType . Constructor CotangentSpace(M::AbstractManifold, p) Return the manifold (vector space) representing the cotangent space  $T^*_p\\mathcal M$  at point  p ,  $p\\in\\mathcal M$ . source"},{"id":285,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.TangentSpace","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.TangentSpace","content":" ManifoldsBase.TangentSpace  ‚Äî  Type TangentSpace{ùîΩ,M} = Fiber{ùîΩ,TangentSpaceType,M} where {ùîΩ,M<:AbstractManifold{ùîΩ}} A manifold for the tangent space  $T_p\\mathcal M$  at a point  $p\\in\\mathcal M$ . This is modelled as an alias for  VectorSpaceFiber  corresponding to  TangentSpaceType . Constructor TangentSpace(M::AbstractManifold, p) Return the manifold (vector space) representing the tangent space  $T_p\\mathcal M$  at point  p ,  $p\\in\\mathcal M$ . source"},{"id":286,"pagetitle":"Meta-Manifolds","title":"Base.exp","ref":"/manifoldsbase/stable/metamanifolds/#Base.exp-Tuple{ManifoldsBase.Fiber{ùîΩ, TangentSpaceType, M} where {ùîΩ, M<:AbstractManifold{ùîΩ}}, Any, Any}","content":" Base.exp  ‚Äî  Method exp(TpM::TangentSpace, X, V) Exponential map of tangent vectors  X  from  TpM  and a direction  V , which is also from the  TangentSpace TpM  since we identify the tangent space of  TpM  with  TpM . The exponential map then simplifies to the sum  X+V . source"},{"id":287,"pagetitle":"Meta-Manifolds","title":"Base.log","ref":"/manifoldsbase/stable/metamanifolds/#Base.log-Tuple{ManifoldsBase.Fiber{ùîΩ, TangentSpaceType, M} where {ùîΩ, M<:AbstractManifold{ùîΩ}}, Vararg{Any}}","content":" Base.log  ‚Äî  Method log(TpM::TangentSpace, X, Y) Logarithmic map on the  TangentSpace TpM , calculated as the difference of tangent vectors  q  and  p  from  TpM . source"},{"id":288,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.Weingarten","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.Weingarten-Tuple{ManifoldsBase.Fiber{ùîΩ, TangentSpaceType, M} where {ùîΩ, M<:AbstractManifold{ùîΩ}}, Any, Any, Any}","content":" ManifoldsBase.Weingarten  ‚Äî  Method Y = Weingarten(TpM::TangentSpace, X, V, A)\nWeingarten!(TpM::TangentSpace, Y, p, X, V) Compute the Weingarten map  $\\mathcal W_X$  at  X  on the  TangentSpace TpM  with respect to the tangent vector  $V \\in T_p\\mathcal M$  and the normal vector  $A \\in N_p\\mathcal M$ . Since this a flat space by itself, the result is always the zero tangent vector. source"},{"id":289,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.distance","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.distance-Tuple{ManifoldsBase.Fiber{ùîΩ, TangentSpaceType, M} where {ùîΩ, M<:AbstractManifold{ùîΩ}}, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::TangentSpace, X, Y) Distance between vectors  X  and  Y  from the  TangentSpace TpM . It is calculated as the  norm  (induced by the metric on  TpM ) of their difference. source"},{"id":290,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.injectivity_radius","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.injectivity_radius-Tuple{ManifoldsBase.Fiber{ùîΩ, TangentSpaceType, M} where {ùîΩ, M<:AbstractManifold{ùîΩ}}}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(TpM::TangentSpace) Return the injectivity radius on the  TangentSpace TpM , which is  $‚àû$ . source"},{"id":291,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.inner","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.inner-Tuple{ManifoldsBase.Fiber{ùîΩ, TangentSpaceType, M} where {ùîΩ, M<:AbstractManifold{ùîΩ}}, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::TangentSpace, X, V, W) For any  $X ‚àà T_p\\mathcal M$  we identify the tangent space  $T_X(T_p\\mathcal M)$  with  $T_p\\mathcal M$  again. Hence an inner product of  $V,W$  is just the inner product of the tangent space itself.  $‚ü®V,W‚ü©_X = ‚ü®V,W‚ü©_p$ . source"},{"id":292,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.is_flat","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.is_flat-Tuple{ManifoldsBase.Fiber{ùîΩ, TangentSpaceType, M} where {ùîΩ, M<:AbstractManifold{ùîΩ}}}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::TangentSpace) The  TangentSpace  is a flat manifold, so this returns  true . source"},{"id":293,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.manifold_dimension","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.manifold_dimension-Tuple{ManifoldsBase.Fiber{ùîΩ, TangentSpaceType, M} where {ùîΩ, M<:AbstractManifold{ùîΩ}}}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(TpM::TangentSpace) Return the dimension of the  TangentSpace $T_p\\mathcal M$  at  $p‚àà\\mathcal M$ , which is the same as the dimension of the manifold  $\\mathcal M$ . source"},{"id":294,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.parallel_transport_to","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.parallel_transport_to-Tuple{ManifoldsBase.Fiber{ùîΩ, TangentSpaceType, M} where {ùîΩ, M<:AbstractManifold{ùîΩ}}, Any, Any, Any}","content":" ManifoldsBase.parallel_transport_to  ‚Äî  Method parallel_transport_to(::TangentSpace, X, V, Y) Transport the tangent vector  $Z ‚àà T_X(T_p\\mathcal M)$  from  X  to  Y . Since we identify  $T_X(T_p\\mathcal M) = T_p\\mathcal M$  and the tangent space is a vector space, parallel transport simplifies to the identity, so this function yields  $V$  as a result. source"},{"id":295,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.project","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.project-Tuple{ManifoldsBase.Fiber{ùîΩ, TangentSpaceType, M} where {ùîΩ, M<:AbstractManifold{ùîΩ}}, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(TpM::TangentSpace, X, V) Project the vector  V  from the embedding of the tangent space  TpM  (identified with  $T_X(T_p\\mathcal M)$ ), that is project the vector  V  onto the tangent space at  TpM.point . source"},{"id":296,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.project","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.project-Tuple{ManifoldsBase.Fiber{ùîΩ, TangentSpaceType, M} where {ùîΩ, M<:AbstractManifold{ùîΩ}}, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(TpM::TangentSpace, X) Project the point  X  from embedding of the  TangentSpace TpM  onto  TpM . source"},{"id":297,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.zero_vector","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.zero_vector-Tuple{ManifoldsBase.Fiber{ùîΩ, TangentSpaceType, M} where {ùîΩ, M<:AbstractManifold{ùîΩ}}, Vararg{Any}}","content":" ManifoldsBase.zero_vector  ‚Äî  Method zero_vector(TpM::TangentSpace, X) Zero tangent vector at point  X  from the  TangentSpace TpM , that is the zero tangent vector at point  TpM.point , since we identify the tangent space  $T_X(T_p\\mathcal M)$  with  $T_p\\mathcal M$ . source"},{"id":298,"pagetitle":"Meta-Manifolds","title":"ManifoldsBase.zero_vector","ref":"/manifoldsbase/stable/metamanifolds/#ManifoldsBase.zero_vector-Tuple{ManifoldsBase.Fiber{ùîΩ, TangentSpaceType, M} where {ùîΩ, M<:AbstractManifold{ùîΩ}}}","content":" ManifoldsBase.zero_vector  ‚Äî  Method zero_vector(TpM::TangentSpace) Zero tangent vector in the  TangentSpace TpM , that is the zero tangent vector at point  TpM.point . source"},{"id":301,"pagetitle":"Projections","title":"Projections","ref":"/manifoldsbase/stable/projections/#Projections","content":" Projections A manifold might be embedded in some space. Often this is implicitly assumed, for example the complex  Circle  is embedded in the complex plane. Let‚Äòs keep the circle in mind in the following as a simple example. For the general case of explicitly stating an embedding and/or to distinguish several, different embeddings, see  Embedded Manifolds  below. To make this a little more concrete, let‚Äòs assume we have a manifold  $\\mathcal M$  which is embedded in some manifold  $\\mathcal N$  and the image  $i(\\mathcal M)$  of the embedding function  $i$  is a closed set (with respect to the topology on  $\\mathcal N$ ). Then we can do two kinds of projections. To make this concrete in an example for the Circle  $\\mathcal M=\\mathcal C := \\{ p ‚àà ‚ÑÇ¬†| |p| = 1\\}$  the embedding can be chosen to be the manifold  $\\mathcal N = ‚ÑÇ$  and due to our representation of  $\\mathcal C$  as complex numbers already, we have  $i(p) = p$ , that is the identity as the embedding function. The first projection we can consider is for a given a point  $p‚àà\\mathcal N$  in the embedding we can look for the closest point on the manifold  $\\mathcal M$ , i.e. \\[  \\operatorname*{arg\\,min}_{q‚àà \\mathcal M}\\ d_{\\mathcal N}(i(q),p)\\] And this resulting  $q$  we call the projection of  $p$  onto the manifold  $\\mathcal M$ . The second projection we can look at is for a given a point  $p‚àà\\mathcal M$  and a vector in  $X‚àà T_{i(p)}\\mathcal N$  in the embedding, where we can similarly look for the closest tangent vector  $Y‚àà T_p\\mathcal M$ , which we have to embed itself before itself. Embedding a tangent vector is usually the same as using the pushforward  $\\mathrm{d}i_p$  of the embedding (at  $p$ ). We obtain \\[  \\operatorname*{arg\\,min}_{Y‚àà T_p\\mathcal M}\\ \\bigl\\lVert \\mathrm{d}i(p)[Y] - X \\bigr\\rVert_{i(p)}\\] And we call the resulting  $Y$  the projection of  $X$  onto the tangent space  $T_p\\mathcal M$  at  $p$ . Let‚Äòs look at the little more concrete example of the complex circle again. Here, the closest point of  $p ‚àà ‚ÑÇ$  is just the projection onto the circle, or in other words  $q = \\frac{p}{\\lvert p \\rvert}$ , as long as  $p\\neq 0$ . For  $p=0$  the projection is not defined. A tangent space  $T_p\\mathcal C$  in the embedding is the line through the origin that is orthogonal to a point  $p‚àà\\mathcal C$ . This can be better visualized by looking at  $p+T_p\\mathcal C$  which is actually the line tangent to  $p$  on the unit circle. Note that this shift does not change the resulting projection relative to the origin of the tangent space. Here the projection can be computed as the classical projection onto the line, i.e.   $Y = X - ‚ü®X,p‚ü©X$ . Both projections onto  $\\mathcal C$  and onto  $T_p\\mathcal C$  are illustrated in the following figure. The functions provided in this interface are the following."},{"id":302,"pagetitle":"Projections","title":"ManifoldsBase.project!","ref":"/manifoldsbase/stable/projections/#ManifoldsBase.project!-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldsBase.project!  ‚Äî  Method project!(M::AbstractManifold, Y, p, X) Project ambient space representation of a vector  X  to a tangent vector at point  p  on the  AbstractManifold M . The result is saved in vector  Y . This method is only available for manifolds where implicitly an embedding or ambient space is given. Additionally,  project!  includes changing data representation, if applicable, i.e. if the tangents on  M  are not represented in the same way as points on the embedding, the representation is changed accordingly. This is the case for example for Lie groups, when tangent vectors are represented in the Lie algebra. after projection the change to the Lie algebra is perfomed, too. See also:  EmbeddedManifold ,  embed! source"},{"id":303,"pagetitle":"Projections","title":"ManifoldsBase.project!","ref":"/manifoldsbase/stable/projections/#ManifoldsBase.project!-Tuple{AbstractManifold, Any, Any}","content":" ManifoldsBase.project!  ‚Äî  Method project!(M::AbstractManifold, q, p) Project point  p  from the ambient space onto the  AbstractManifold M . The result is storedin  q . This method is only available for manifolds where implicitly an embedding or ambient space is given. Additionally, the projection includes changing data representation, if applicable, i.e. if the points on  M  are not represented in the same array data, the data is changed accordingly. See also:  EmbeddedManifold ,  embed! source"},{"id":304,"pagetitle":"Projections","title":"ManifoldsBase.project","ref":"/manifoldsbase/stable/projections/#ManifoldsBase.project-Tuple{AbstractManifold, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::AbstractManifold, p, X) Project ambient space representation of a vector  X  to a tangent vector at point  p  on the  AbstractManifold M . This method is only available for manifolds where implicitly an embedding or ambient space is given. Additionally,  project  includes changing data representation, if applicable, i.e. if the tangents on  M  are not represented in the same way as points on the embedding, the representation is changed accordingly. This is the case for example for Lie groups, when tangent vectors are represented in the Lie algebra. after projection the change to the Lie algebra is perfomed, too. See also:  EmbeddedManifold ,  embed source"},{"id":305,"pagetitle":"Projections","title":"ManifoldsBase.project","ref":"/manifoldsbase/stable/projections/#ManifoldsBase.project-Tuple{AbstractManifold, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::AbstractManifold, p) Project point  p  from the ambient space of the  AbstractManifold M  to  M . This method is only available for manifolds where implicitly an embedding or ambient space is given. Additionally, the projection includes changing data representation, if applicable, i.e. if the points on  M  are not represented in the same array data, the data is changed accordingly. See also:  EmbeddedManifold ,  embed source"},{"id":308,"pagetitle":"References","title":"Literature","ref":"/manifoldsbase/stable/references/#Literature","content":" Literature [AMS08] P.-A.¬†Absil, R.¬†Mahony and R.¬†Sepulchre.  Optimization Algorithms on Matrix Manifolds  (Princeton University Press, 2008), available online at  press.princeton.edu/chapters/absil/ . [EPS72] J.¬†Ehlers, F.¬†A.¬†Pirani and A.¬†Schild.  Republication of: The geometry of free fall and light propagation .  General¬†Relativity¬†and¬†Gravitation  44 , 1587‚Äì1609  (1972). [LP13] M.¬†Lorenzi and X.¬†Pennec.  Efficient Parallel Transport of Deformations in Time Series of Images: From Schild's to Pole Ladder .  Journal¬†of¬†Mathematical¬†Imaging¬†and¬†Vision  50 , 5‚Äì17  (2013),  arXiv:00870489 . [MF12] P.¬†Muralidharan and P.¬†T.¬†Fletcher.  Sasaki metrics for analysis of longitudinal data on manifolds . In:  2012 IEEE Conference on Computer Vision and Pattern Recognition  (2012). [Pen18] X.¬†Pennec.  Parallel Transport with Pole Ladder: a Third Order Scheme in Affine Connection Spaces which is Exact in Affine Symmetric Spaces.  arXiv¬†Preprint (2018),  arXiv:1805.11436 . [SI13] H.¬†Sato and T.¬†Iwai.  A new,  globally convergent Riemannian conjugate gradient method .  Optimization  64 , 1011‚Äì1031  (2013),  arXiv:1302.0125 ."},{"id":311,"pagetitle":"Retractions","title":"Retractions and inverse Retractions","ref":"/manifoldsbase/stable/retractions/#sec-retractions","content":" Retractions and inverse Retractions The  exponential and logarithmic map  might be too expensive to evaluate or not be available in a very stable numerical way on certain manifolds  $\\mathcal M$ . Retractions provide a possibly cheap, fast and stable alternative. A  retraction $\\operatorname{retr}_p: T_p\\mathcal M ‚Üí \\mathcal M$  is a smooth map that fulfils (for all  $p‚àà\\mathcal M$ ) that $\\operatorname{retr}_p(0) = p$ $D\\operatorname{retr}_p(0): T_p\\mathcal M \\to T_p\\mathcal M$  is the identity map, i.e.  $D\\operatorname{retr}_p(0)[X]=X$  holds for all  $X‚àà T_p\\mathcal M$ , where  $D\\operatorname{retr}_p$  denotes the differential of the retraction. A retraction  $\\operatorname{retr}_p$  can be interpreted as a first order approximation to the exponential map  $\\exp_p$ . The retraction is called of second order if for all  $X$  the curves  $c(t) = R_p(tX)$  have a zero acceleration at  $t=0$ , i.e.  $c''(0) = 0$ . The following figure compares the exponential map  exp (M, p, X)  on the  Circle (‚ÑÇ)  (or  Sphere (1)  embedded in  $‚Ñù^2$  with one possible retraction, the one based on projections. Note especially that  $\\operatorname{dist}(p,q)=\\lVert X\\rVert_p$  while this is not the case for the result  $\\operatorname{retr}_p(X) = q'$ . Similar to the  exp onential map the  retract ion might not be globally invertible, but locally it is. So locally one can define the inverse retraction  $\\operatorname{retr}_p^{-1}\\colon \\mathcal M \\to T_p\\mathcal M$ , which can be seen as a first order approximation to the  log arithmic map. Within the  ManifoldsBase.jl  interface the inverse retraction is called  inverse_retract . The general interface looks as follows."},{"id":312,"pagetitle":"Retractions","title":"ManifoldsBase.default_inverse_retraction_method","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.default_inverse_retraction_method-Tuple{AbstractManifold}","content":" ManifoldsBase.default_inverse_retraction_method  ‚Äî  Method default_inverse_retraction_method(M::AbstractManifold)\ndefault_inverse_retraction_method(M::AbstractManifold, ::Type{T}) where {T} The  AbstractInverseRetractionMethod  that is used when calling  inverse_retract  without specifying the inverse retraction method. By default, this is the  LogarithmicInverseRetraction . This method can also be specified more precisely with a point type  T , for the case that on a  M  there are two different representations of points, which provide different inverse retraction methods. source"},{"id":313,"pagetitle":"Retractions","title":"ManifoldsBase.default_retraction_method","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.default_retraction_method-Tuple{AbstractManifold}","content":" ManifoldsBase.default_retraction_method  ‚Äî  Method default_retraction_method(M::AbstractManifold)\ndefault_retraction_method(M::AbstractManifold, ::Type{T}) where {T} The  AbstractRetractionMethod  that is used when calling  retract  without specifying the retraction method. By default, this is the  ExponentialRetraction . This method can also be specified more precisely with a point type  T , for the case that on a  M  there are two different representations of points, which provide different retraction methods. source"},{"id":314,"pagetitle":"Retractions","title":"ManifoldsBase.inverse_retract","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.inverse_retract","content":" ManifoldsBase.inverse_retract  ‚Äî  Function inverse_retract(M::AbstractManifold, p, q)\ninverse_retract(M::AbstractManifold, p, q, method::AbstractInverseRetractionMethod Compute the inverse retraction, a cheaper, approximate version of the  log arithmic map), of points  p  and  q  on the  AbstractManifold M . Inverse retraction method can be specified by the last argument, defaulting to  default_inverse_retraction_method (M) . For available inverse retractions on certain manifolds see the documentation on the corresponding manifold. See also  retract . source"},{"id":315,"pagetitle":"Retractions","title":"ManifoldsBase.inverse_retract!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.inverse_retract!","content":" ManifoldsBase.inverse_retract!  ‚Äî  Function inverse_retract!(M::AbstractManifold, X, p, q[, method::AbstractInverseRetractionMethod]) Compute the inverse retraction, a cheaper, approximate version of the  log arithmic map), of points  p  and  q  on the  AbstractManifold M . Result is saved to  X . Inverse retraction method can be specified by the last argument, defaulting to  default_inverse_retraction_method (M) . See the documentation of respective manifolds for available methods. See also  retract! . source"},{"id":316,"pagetitle":"Retractions","title":"ManifoldsBase.retract","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.retract","content":" ManifoldsBase.retract  ‚Äî  Function retract(M::AbstractManifold, p, X, method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)))\nretract(M::AbstractManifold, p, X, t::Number=1, method::AbstractRetractionMethod=default_retraction_method(M, typeof(p))) Compute a retraction, a cheaper, approximate version of the  exp onential map, from  p  into direction  X , scaled by  t , on the  AbstractManifold M . A retraction  $\\operatorname{retr}_p: T_p\\mathcal M ‚Üí \\mathcal M$  is a smooth map that fulfils $\\operatorname{retr}_p(0) = p$ $D\\operatorname{retr}_p(0): T_p\\mathcal M \\to T_p\\mathcal M$  is the identity map, i.e.  $D\\operatorname{retr}_p(0)[X]=X$  holds for all  $X\\in T_p\\mathcal M$ , where  $D\\operatorname{retr}_p$  denotes the differential of the retraction The retraction is called of second order if for all  $X$  the curves  $c(t) = R_p(tX)$  have a zero acceleration at  $t=0$ , i.e.  $c''(0) = 0$ . Retraction method can be specified by the last argument, defaulting to  default_retraction_method (M) . For further available retractions see the documentation of respective manifolds. Locally, the retraction is invertible. For the inverse operation, see  inverse_retract . source"},{"id":317,"pagetitle":"Retractions","title":"ManifoldsBase.retract!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.retract!","content":" ManifoldsBase.retract!  ‚Äî  Function retract!(M::AbstractManifold, q, p, X)\nretract!(M::AbstractManifold, q, p, X, t::Real=1)\nretract!(M::AbstractManifold, q, p, X, method::AbstractRetractionMethod)\nretract!(M::AbstractManifold, q, p, X, t::Real=1, method::AbstractRetractionMethod) Compute a retraction, a cheaper, approximate version of the  exp onential map, from  p  into direction  X , scaled by  t , on the  AbstractManifold  manifold  M . Result is saved to  q . Retraction method can be specified by the last argument, defaulting to  default_retraction_method (M) . See the documentation of respective manifolds for available methods. See  retract  for more details. source"},{"id":318,"pagetitle":"Retractions","title":"Types of Retractions","ref":"/manifoldsbase/stable/retractions/#Types-of-Retractions","content":" Types of Retractions To distinguish different types of retractions, the last argument of the retraction as well as its inverse specifies a type. The following ones are available."},{"id":319,"pagetitle":"Retractions","title":"ManifoldsBase.AbstractInverseRetractionMethod","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.AbstractInverseRetractionMethod","content":" ManifoldsBase.AbstractInverseRetractionMethod  ‚Äî  Type AbstractInverseRetractionMethod <: AbstractApproximationMethod Abstract type for methods for inverting a retraction (see  inverse_retract ). source"},{"id":320,"pagetitle":"Retractions","title":"ManifoldsBase.AbstractRetractionMethod","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.AbstractRetractionMethod","content":" ManifoldsBase.AbstractRetractionMethod  ‚Äî  Type AbstractRetractionMethod <: AbstractApproximationMethod Abstract type for methods for  retract ing a tangent vector to a manifold. source"},{"id":321,"pagetitle":"Retractions","title":"ManifoldsBase.ApproximateInverseRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.ApproximateInverseRetraction","content":" ManifoldsBase.ApproximateInverseRetraction  ‚Äî  Type ApproximateInverseRetraction <: AbstractInverseRetractionMethod An abstract type for representing approximate inverse retraction methods. source"},{"id":322,"pagetitle":"Retractions","title":"ManifoldsBase.ApproximateRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.ApproximateRetraction","content":" ManifoldsBase.ApproximateRetraction  ‚Äî  Type ApproximateRetraction <: AbstractRetractionMethod An abstract type for representing approximate retraction methods. source"},{"id":323,"pagetitle":"Retractions","title":"ManifoldsBase.CayleyInverseRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.CayleyInverseRetraction","content":" ManifoldsBase.CayleyInverseRetraction  ‚Äî  Type CayleyInverseRetraction <: AbstractInverseRetractionMethod A retraction based on the Cayley transform, which is realized by using the  PadeRetraction {1} . Technical Note Though you would call e.g.  inverse_retract (M, p, q, CayleyInverseRetraction()) , to implement an inverse caley retraction, define  inverse_retract_cayley! (M, X, p, q)  for your manifold  M . By default both these functions fall back to calling a  PadeInverseRetraction (1) . source"},{"id":324,"pagetitle":"Retractions","title":"ManifoldsBase.CayleyRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.CayleyRetraction","content":" ManifoldsBase.CayleyRetraction  ‚Äî  Type CayleyRetraction <: AbstractRetractionMethod A retraction based on the Cayley transform, which is realized by using the  PadeRetraction {1} . Technical Note Though you would call e.g.  retract (M, p, X, CayleyRetraction()) , to implement a caley retraction, define  retract_cayley! (M, q, p, X, t)  for your manifold  M . By default both these functions fall back to calling a  PadeRetraction (1) . source"},{"id":325,"pagetitle":"Retractions","title":"ManifoldsBase.EmbeddedInverseRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.EmbeddedInverseRetraction","content":" ManifoldsBase.EmbeddedInverseRetraction  ‚Äî  Type EmbeddedInverseRetraction{T<:AbstractInverseRetractionMethod} <: AbstractInverseRetractionMethod Compute an inverse retraction by using the inverse retraction of type  T  in the embedding and projecting the result Constructor EmbeddedInverseRetraction(r::AbstractInverseRetractionMethod) Generate the inverse retraction with inverse retraction  r  to use in the embedding. source"},{"id":326,"pagetitle":"Retractions","title":"ManifoldsBase.EmbeddedRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.EmbeddedRetraction","content":" ManifoldsBase.EmbeddedRetraction  ‚Äî  Type EmbeddedRetraction{T<:AbstractRetractionMethod} <: AbstractRetractionMethod Compute a retraction by using the retraction of type  T  in the embedding and projecting the result. Constructor EmbeddedRetraction(r::AbstractRetractionMethod) Generate the retraction with retraction  r  to use in the embedding. source"},{"id":327,"pagetitle":"Retractions","title":"ManifoldsBase.ExponentialRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.ExponentialRetraction","content":" ManifoldsBase.ExponentialRetraction  ‚Äî  Type ExponentialRetraction <: AbstractRetractionMethod Retraction using the exponential map. source"},{"id":328,"pagetitle":"Retractions","title":"ManifoldsBase.InverseRetractionWithKeywords","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.InverseRetractionWithKeywords","content":" ManifoldsBase.InverseRetractionWithKeywords  ‚Äî  Type InverseRetractionWithKeywords{R<:AbstractRetractionMethod,K} <: AbstractInverseRetractionMethod Since inverse retractions might have keywords, this type is a way to set them as an own type to be used as a specific inverse retraction. Another reason for this type is that we dispatch on the inverse retraction first and only the last layer would be implemented with keywords, so this way they can be passed down. Fields inverse_retraction  the inverse retraction that is decorated with keywords kwargs  the keyword arguments Note that you can nest this type. Then the most outer specification of a keyword is used. Constructor InverseRetractionWithKeywords(m::T; kwargs...) where {T <: AbstractInverseRetractionMethod} Specify the subtype  T <: AbstractInverseRetractionMethod  to have keywords  kwargs... . source"},{"id":329,"pagetitle":"Retractions","title":"ManifoldsBase.LogarithmicInverseRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.LogarithmicInverseRetraction","content":" ManifoldsBase.LogarithmicInverseRetraction  ‚Äî  Type LogarithmicInverseRetraction <: AbstractInverseRetractionMethod Inverse retraction using the  log arithmic map. source"},{"id":330,"pagetitle":"Retractions","title":"ManifoldsBase.NLSolveInverseRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.NLSolveInverseRetraction","content":" ManifoldsBase.NLSolveInverseRetraction  ‚Äî  Type NLSolveInverseRetraction{T<:AbstractRetractionMethod,TV,TK} <:\n    ApproximateInverseRetraction An inverse retraction method for approximating the inverse of a retraction using  NLsolve . Constructor NLSolveInverseRetraction(\n    method::AbstractRetractionMethod[, X0];\n    project_tangent=false,\n    project_point=false,\n    nlsolve_kwargs...,\n) Constructs an approximate inverse retraction for the retraction  method  with initial guess  X0 , defaulting to the zero vector. If  project_tangent  is  true , then the tangent vector is projected before the retraction using  project . If  project_point  is  true , then the resulting point is projected after the retraction.  nlsolve_kwargs  are keyword arguments passed to  NLsolve.nlsolve . source"},{"id":331,"pagetitle":"Retractions","title":"ManifoldsBase.ODEExponentialRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.ODEExponentialRetraction","content":" ManifoldsBase.ODEExponentialRetraction  ‚Äî  Type ODEExponentialRetraction{T<:AbstractRetractionMethod, B<:AbstractBasis} <: AbstractRetractionMethod Approximate the exponential map on the manifold by evaluating the ODE descripting the geodesic at 1, assuming the default connection of the given manifold by solving the ordinary differential equation \\[\\frac{d^2}{dt^2} p^k + Œì^k_{ij} \\frac{d}{dt} p_i \\frac{d}{dt} p_j = 0,\\] where  $Œì^k_{ij}$  are the Christoffel symbols of the second kind, and the Einstein summation convention is assumed. Constructor ODEExponentialRetraction(\n    r::AbstractRetractionMethod,\n    b::AbstractBasis=DefaultOrthogonalBasis(),\n) Generate the retraction with a retraction to use internally (for some approaches) and a basis for the tangent space(s). source"},{"id":332,"pagetitle":"Retractions","title":"ManifoldsBase.PadeInverseRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.PadeInverseRetraction","content":" ManifoldsBase.PadeInverseRetraction  ‚Äî  Type PadeInverseRetraction{m} <: AbstractInverseRetractionMethod An inverse retraction based on the Pad√© approximation of order  $m$  for the retraction. Technical Note Though you would call e.g.  inverse_retract (M, p, q, PadeInverseRetraction(m)) , to implement an inverse Pad√© retraction, define  inverse_retract_pade! (M, X, p, q, m)  for your manifold  M . source"},{"id":333,"pagetitle":"Retractions","title":"ManifoldsBase.PadeRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.PadeRetraction","content":" ManifoldsBase.PadeRetraction  ‚Äî  Type PadeRetraction{m} <: AbstractRetractionMethod A retraction based on the Pad√© approximation of order  $m$ Constructor PadeRetraction(m::Int) Technical Note Though you would call e.g.  retract (M, p, X, PadeRetraction(m)) , to implement a Pad√© retraction, define  retract_pade! (M, q, p, X, t, m)  for your manifold  M . source"},{"id":334,"pagetitle":"Retractions","title":"ManifoldsBase.PolarInverseRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.PolarInverseRetraction","content":" ManifoldsBase.PolarInverseRetraction  ‚Äî  Type PolarInverseRetraction <: AbstractInverseRetractionMethod Inverse retractions that are based on a singular value decomposition of the matrix / matrices for point and tangent vector on a  AbstractManifold Technical Note Though you would call e.g.  inverse_retract (M, p, q, PolarInverseRetraction()) , to implement an inverse polar retraction, define  inverse_retract_polar! (M, X, p, q)  for your manifold  M . source"},{"id":335,"pagetitle":"Retractions","title":"ManifoldsBase.PolarRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.PolarRetraction","content":" ManifoldsBase.PolarRetraction  ‚Äî  Type PolarRetraction <: AbstractRetractionMethod Retractions that are based on singular value decompositions of the matrix / matrices for point and tangent vectors. Technical Note Though you would call e.g.  retract (M, p, X, PolarRetraction()) , to implement a polar retraction, define  retract_polar! (M, q, p, X, t)  for your manifold  M . source"},{"id":336,"pagetitle":"Retractions","title":"ManifoldsBase.ProjectionInverseRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.ProjectionInverseRetraction","content":" ManifoldsBase.ProjectionInverseRetraction  ‚Äî  Type ProjectionInverseRetraction <: AbstractInverseRetractionMethod Inverse retractions that are based on a projection (or its inversion). Technical Note Though you would call e.g.  inverse_retract (M, p, q, ProjectionInverseRetraction()) , to implement an inverse projection retraction, define  inverse_retract_project! (M, X, p, q)  for your manifold  M . source"},{"id":337,"pagetitle":"Retractions","title":"ManifoldsBase.ProjectionRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.ProjectionRetraction","content":" ManifoldsBase.ProjectionRetraction  ‚Äî  Type ProjectionRetraction <: AbstractRetractionMethod Retractions that are based on projection and usually addition in the embedding. Technical Note Though you would call e.g.  retract (M, p, X, ProjectionRetraction()) , to implement a projection retraction, define  retract_project! (M, q, p, X, t)  for your manifold  M . source"},{"id":338,"pagetitle":"Retractions","title":"ManifoldsBase.QRInverseRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.QRInverseRetraction","content":" ManifoldsBase.QRInverseRetraction  ‚Äî  Type QRInverseRetraction <: AbstractInverseRetractionMethod Inverse retractions that are based on a QR decomposition of the matrix / matrices for point and tangent vector on a  AbstractManifold Technical Note Though you would call e.g.  inverse_retract (M, p, q, QRInverseRetraction()) , to implement an inverse QR retraction, define  inverse_retract_qr! (M, X, p, q)  for your manifold  M . source"},{"id":339,"pagetitle":"Retractions","title":"ManifoldsBase.QRRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.QRRetraction","content":" ManifoldsBase.QRRetraction  ‚Äî  Type QRRetraction <: AbstractRetractionMethod Retractions that are based on a QR decomposition of the matrix / matrices for point and tangent vector on a  AbstractManifold Technical Note Though you would call e.g.  retract (M, p, X, QRRetraction()) , to implement a QR retraction, define  retract_qr! (M, q, p, X, t)  for your manifold  M . source"},{"id":340,"pagetitle":"Retractions","title":"ManifoldsBase.RetractionWithKeywords","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.RetractionWithKeywords","content":" ManifoldsBase.RetractionWithKeywords  ‚Äî  Type RetractionWithKeywords{R<:AbstractRetractionMethod,K} <: AbstractRetractionMethod Since retractions might have keywords, this type is a way to set them as an own type to be used as a specific retraction. Another reason for this type is that we dispatch on the retraction first and only the last layer would be implemented with keywords, so this way they can be passed down. Fields retraction  the retraction that is decorated with keywords kwargs  the keyword arguments Note that you can nest this type. Then the most outer specification of a keyword is used. Constructor RetractionWithKeywords(m::T; kwargs...) where {T <: AbstractRetractionMethod} Specify the subtype  T <: AbstractRetractionMethod  to have keywords  kwargs... . source"},{"id":341,"pagetitle":"Retractions","title":"ManifoldsBase.SasakiRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.SasakiRetraction","content":" ManifoldsBase.SasakiRetraction  ‚Äî  Type struct SasakiRetraction <: AbstractRetractionMethod end Exponential map on  TangentBundle  computed via Euler integration as described in [ MF12 ]. The system of equations for  $\\gamma : ‚Ñù \\to T\\mathcal M$  such that  $\\gamma(1) = \\exp_{p,X}(X_M, X_F)$  and  $\\gamma(0)=(p, X)$  reads \\[\\dot{\\gamma}(t) = (\\dot{p}(t), \\dot{X}(t)) = (R(X(t), \\dot{X}(t))\\dot{p}(t), 0)\\] where  $R$  is the Riemann curvature tensor (see  riemann_tensor ). Constructor SasakiRetraction(L::Int) In this constructor  L  is the number of integration steps. source"},{"id":342,"pagetitle":"Retractions","title":"ManifoldsBase.SoftmaxInverseRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.SoftmaxInverseRetraction","content":" ManifoldsBase.SoftmaxInverseRetraction  ‚Äî  Type SoftmaxInverseRetraction <: AbstractInverseRetractionMethod Describes an inverse retraction that is based on the softmax function. Technical Note Though you would call e.g.  inverse_retract (M, p, q, SoftmaxInverseRetraction()) , to implement an inverse softmax retraction, define  inverse_retract_softmax! (M, X, p, q)  for your manifold  M . source"},{"id":343,"pagetitle":"Retractions","title":"ManifoldsBase.SoftmaxRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.SoftmaxRetraction","content":" ManifoldsBase.SoftmaxRetraction  ‚Äî  Type SoftmaxRetraction <: AbstractRetractionMethod Describes a retraction that is based on the softmax function. Technical Note Though you would call e.g.  retract (M, p, X, SoftmaxRetraction()) , to implement a softmax retraction, define  retract_softmax! (M, q, p, X, t)  for your manifold  M . source"},{"id":344,"pagetitle":"Retractions","title":"ManifoldsBase.ShootingInverseRetraction","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.ShootingInverseRetraction","content":" ManifoldsBase.ShootingInverseRetraction  ‚Äî  Type ShootingInverseRetraction <: ApproximateInverseRetraction Approximating the inverse of a retraction using the shooting method. This implementation of the shooting method works by using another inverse retraction to form the first guess of the vector. This guess is updated by shooting the vector, guessing the vector pointing from the shooting result to the target point, and transporting this vector update back to the initial point on a discretized grid. This process is repeated until the norm of the vector update falls below a specified tolerance or the maximum number of iterations is reached. Fields retraction::AbstractRetractionMethod : The retraction whose inverse is approximated. initial_inverse_retraction::AbstractInverseRetractionMethod : The inverse retraction used   to form the initial guess of the vector. vector_transport::AbstractVectorTransportMethod : The vector transport used to transport   the initial guess of the vector. num_transport_points::Int : The number of discretization points used for vector   transport in the shooting method. 2 is the minimum number of points, including just the   endpoints. tolerance::Real : The tolerance for the shooting method. max_iterations::Int : The maximum number of iterations for the shooting method. source"},{"id":345,"pagetitle":"Retractions","title":"The functions on layer 3","ref":"/manifoldsbase/stable/retractions/#The-functions-on-layer-3","content":" The functions on layer 3 While you should always add your documentation to  retract  or  retract!  when implementing new manifolds, the actual implementation happens on the following functions on  layer III ."},{"id":346,"pagetitle":"Retractions","title":"ManifoldsBase.inverse_retract_cayley!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.inverse_retract_cayley!-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldsBase.inverse_retract_cayley!  ‚Äî  Method inverse_retract_cayley!(M::AbstractManifold, X, p, q) Compute the in-place variant of the  CayleyInverseRetraction , which by default calls the first order [ PadeInverseRetraction ¬ß(@ref). source"},{"id":347,"pagetitle":"Retractions","title":"ManifoldsBase.inverse_retract_embedded!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.inverse_retract_embedded!-Tuple{AbstractManifold, Any, Any, Any, AbstractInverseRetractionMethod}","content":" ManifoldsBase.inverse_retract_embedded!  ‚Äî  Method inverse_retract_embedded!(M::AbstractManifold, X, p, q, m::AbstractInverseRetractionMethod) Compute the in-place variant of the  EmbeddedInverseRetraction  using the  AbstractInverseRetractionMethod m  in the embedding (see  get_embedding ) and projecting the result back. source"},{"id":348,"pagetitle":"Retractions","title":"ManifoldsBase.inverse_retract_nlsolve!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.inverse_retract_nlsolve!-Tuple{AbstractManifold, Any, Any, Any, NLSolveInverseRetraction}","content":" ManifoldsBase.inverse_retract_nlsolve!  ‚Äî  Method inverse_retract_nlsolve!(M::AbstractManifold, X, p, q, m::NLSolveInverseRetraction) Compute the in-place variant of the  NLSolveInverseRetraction m . source"},{"id":349,"pagetitle":"Retractions","title":"ManifoldsBase.inverse_retract_pade!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.inverse_retract_pade!-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldsBase.inverse_retract_pade!  ‚Äî  Method inverse_retract_pade!(M::AbstractManifold, p, q, n) Compute the in-place variant of the  PadeInverseRetraction (n) , source"},{"id":350,"pagetitle":"Retractions","title":"ManifoldsBase.inverse_retract_polar!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.inverse_retract_polar!-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldsBase.inverse_retract_polar!  ‚Äî  Method inverse_retract_polar!(M::AbstractManifold, X, p, q) Compute the in-place variant of the  PolarInverseRetraction . source"},{"id":351,"pagetitle":"Retractions","title":"ManifoldsBase.inverse_retract_project!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.inverse_retract_project!-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldsBase.inverse_retract_project!  ‚Äî  Method inverse_retract_project!(M::AbstractManifold, X, p, q) Compute the in-place variant of the  ProjectionInverseRetraction . source"},{"id":352,"pagetitle":"Retractions","title":"ManifoldsBase.inverse_retract_qr!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.inverse_retract_qr!-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldsBase.inverse_retract_qr!  ‚Äî  Method inverse_retract_qr!(M::AbstractManifold, X, p, q) Compute the in-place variant of the  QRInverseRetraction . source"},{"id":353,"pagetitle":"Retractions","title":"ManifoldsBase.inverse_retract_softmax!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.inverse_retract_softmax!-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldsBase.inverse_retract_softmax!  ‚Äî  Method inverse_retract_softmax!(M::AbstractManifold, X, p, q) Compute the in-place variant of the  SoftmaxInverseRetraction . source"},{"id":354,"pagetitle":"Retractions","title":"ManifoldsBase.retract_cayley!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.retract_cayley!-Tuple{AbstractManifold, Vararg{Any, 4}}","content":" ManifoldsBase.retract_cayley!  ‚Äî  Method retract_cayley!(M::AbstractManifold, q, p, X, t) Compute the in-place variant of the  CayleyRetraction , which by default falls back to calling the first order  PadeRetraction . source"},{"id":355,"pagetitle":"Retractions","title":"ManifoldsBase.retract_embedded!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.retract_embedded!-Tuple{AbstractManifold, Any, Any, Any, Any, AbstractRetractionMethod}","content":" ManifoldsBase.retract_embedded!  ‚Äî  Method retract_embedded!(M::AbstractManifold, q, p, X, t, m::AbstractRetractionMethod) Compute the in-place variant of the  EmbeddedRetraction  using the  AbstractRetractionMethod m  in the embedding (see  get_embedding ) and projecting the result back. source"},{"id":356,"pagetitle":"Retractions","title":"ManifoldsBase.retract_exp_ode!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.retract_exp_ode!-Tuple{AbstractManifold, Any, Any, Any, Any, AbstractRetractionMethod, ManifoldsBase.AbstractBasis}","content":" ManifoldsBase.retract_exp_ode!  ‚Äî  Method retract_exp_ode!(M::AbstractManifold, q, p, X, t, m::AbstractRetractionMethod, B::AbstractBasis) Compute the in-place variant of the  ODEExponentialRetraction (m, B) . source"},{"id":357,"pagetitle":"Retractions","title":"ManifoldsBase.retract_pade!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.retract_pade!-Tuple{AbstractManifold, Any, Any, Any, Any, PadeRetraction}","content":" ManifoldsBase.retract_pade!  ‚Äî  Method retract_pade!(M::AbstractManifold, q, p, X, t, m::PadeRetraction) Compute the in-place variant of the  PadeRetraction m . source"},{"id":358,"pagetitle":"Retractions","title":"ManifoldsBase.retract_polar!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.retract_polar!-Tuple{AbstractManifold, Vararg{Any, 4}}","content":" ManifoldsBase.retract_polar!  ‚Äî  Method retract_polar!(M::AbstractManifold, q, p, X, t) Compute the in-place variant of the  PolarRetraction . source"},{"id":359,"pagetitle":"Retractions","title":"ManifoldsBase.retract_project!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.retract_project!-Tuple{AbstractManifold, Vararg{Any, 4}}","content":" ManifoldsBase.retract_project!  ‚Äî  Method retract_project!(M::AbstractManifold, q, p, X, t) Compute the in-place variant of the  ProjectionRetraction . source"},{"id":360,"pagetitle":"Retractions","title":"ManifoldsBase.retract_qr!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.retract_qr!-Tuple{AbstractManifold, Vararg{Any, 4}}","content":" ManifoldsBase.retract_qr!  ‚Äî  Method retract_qr!(M::AbstractManifold, q, p, X, t) Compute the in-place variant of the  QRRetraction . source"},{"id":361,"pagetitle":"Retractions","title":"ManifoldsBase.retract_sasaki!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.retract_sasaki!-Tuple{AbstractManifold, Any, Any, Any, Number, SasakiRetraction}","content":" ManifoldsBase.retract_sasaki!  ‚Äî  Method retract_sasaki!(M::AbstractManifold, q, p, X, t::Number, m::SasakiRetraction) Compute the in-place variant of the  SasakiRetraction m . source"},{"id":362,"pagetitle":"Retractions","title":"ManifoldsBase.retract_softmax!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.retract_softmax!-Tuple{AbstractManifold, Any, Any, Any, Number}","content":" ManifoldsBase.retract_softmax!  ‚Äî  Method retract_softmax!(M::AbstractManifold, q, p, X, t) Compute the in-place variant of the  SoftmaxRetraction . source"},{"id":363,"pagetitle":"Retractions","title":"ManifoldsBase.inverse_retract_shooting!","ref":"/manifoldsbase/stable/retractions/#ManifoldsBase.inverse_retract_shooting!-Tuple{AbstractManifold, Any, Any, Any, ShootingInverseRetraction}","content":" ManifoldsBase.inverse_retract_shooting!  ‚Äî  Method inverse_retract_shooting!(M::AbstractManifold, X, p, q, m::ShootingInverseRetraction) Approximate the inverse of a retraction using the shooting method. source"},{"id":366,"pagetitle":"How to define a manifold","title":"How to Implement a Manifold","ref":"/manifoldsbase/stable/tutorials/implement-a-manifold/#How-to-Implement-a-Manifold","content":" How to Implement a Manifold This tutorial illustrates, how to implement your very first manifold. We start from the very beginning and cover the basic ideas of the interface provided by  ManifoldsBase.jl  interface."},{"id":367,"pagetitle":"How to define a manifold","title":"Preliminaries","ref":"/manifoldsbase/stable/tutorials/implement-a-manifold/#Preliminaries","content":" Preliminaries We will use a simple example in this tutorial, since the main focus here is to illustrate how to define a manifold. We will use the sphere of radius  $r$  embedded in  $\\mathbb R^{d+1}$ , i.e.¬†all vectors of length  $r$ . Formally we define \\[\\mathbb S_r^d :=\n\\bigl\\{\n    p \\in \\mathbb R^{d+1}\n    \\big|\n    \\lVert p \\rVert = r\n\\bigr\\}\\] When defining a Riemannian manifold mathematically, there is several things to keep in mind, for example the metric imposed on the tangent spaces. For this interface we assume these things to be given implicitly for a first implementation, but they can be made more precise when necessary. The only thing we have to be aware of for now is the  number_system , i.e.¬†whether our manifold is a real-valued or a complex-valued manifold. The abstract type all manifolds inherit from, the  AbstractManifold {ùîΩ}  has this number system as a parameter. The usual parameter we will use are the  RealNumbers () , which have a short hand in  ManifoldsBase.jl , namely  ‚Ñù . The second one are the  ComplexNumbers () , or  ‚ÑÇ  for short. using LinearAlgebra, ManifoldsBase\nusing ManifoldsBase: ‚Ñù"},{"id":368,"pagetitle":"How to define a manifold","title":"Defining a manifold","ref":"/manifoldsbase/stable/tutorials/implement-a-manifold/#Defining-a-manifold","content":" Defining a manifold A manifold itself is a  struct  that is a subtype of  AbstractManifold  and should contain. We usually recommend to also document your new manifold. Since the  Sphere  is already a name used within  Manifolds.jl , let‚Äôs use a slightly more specific name. We define \"\"\"\n    ScaledSphere <: AbstractManifold{‚Ñù}\n\nDefine a sphere of fixed radius\n\n# Fields\n\n* `dimension` dimension of the sphere\n* `radius` the radius of the sphere\n\n# Constructor\n\n    ScaledSphere(dimension,radius=1.0)\n\nInitialize the manifold to a certain `dimension` and `radius`,\nwhich by default is set to `1.0`\n\"\"\"\nstruct ScaledSphere <: AbstractManifold{‚Ñù}\n    dimension::Int\n    radius::Float64\nend And we can directly use this manifold and set M = ScaledSphere(2,1.5) ScaledSphere(2, 1.5)"},{"id":369,"pagetitle":"How to define a manifold","title":"Functions I: Manifold properties","ref":"/manifoldsbase/stable/tutorials/implement-a-manifold/#Functions-I:-Manifold-properties","content":" Functions I: Manifold properties While the interface provides a lot of possible functions to define for your manifold, you only need to define those that are necessary for your implementation. If you are using other packages depending on  ManifoldsBase.jl  you will often just get a ‚ÄúMethod not defined‚Äù and sometimes an ambiguity error indicating that a function is missing that is required for a certain task. We can first start with a technical function which internally ist often used. Any of our points or tangent vectors is represented as a  $(d+1)$ -dimensional vector. This is internally often used when allocating memory, see  representation_size . It returns a tuple representing the size of arrays for valid points. We define import ManifoldsBase: representation_size\nrepresentation_size(M::ScaledSphere) = (M.dimension+1,) Similarly, we can implement the function returning the dimension of the manifold, cf.¬† manifold_dimension  as import ManifoldsBase: manifold_dimension\nmanifold_dimension(M::ScaledSphere) = M.dimension and we can now easily use them to access the dimension of the manifold manifold_dimension(M) 2"},{"id":370,"pagetitle":"How to define a manifold","title":"Functions II: Verifying Points and tangent vectors","ref":"/manifoldsbase/stable/tutorials/implement-a-manifold/#Functions-II:-Verifying-Points-and-tangent-vectors","content":" Functions II: Verifying Points and tangent vectors The first two functions we want to define are those to check points and tangent vectors for our manifold. Let‚Äôs first clarify what the tangent space looks like. The directions ‚Äúwe can walk into‚Äù from a point  $p\\in \\mathbb S_r^d$  are all  $X$  that are orthogonal to  $p$ , which is the plane/vector space tangent to the sphere. Formally \\[T_p\\mathbb S_r^d :=\n\\bigl\\{\n    X \\in \\mathbb R^{d+1}\n    \\big|\n    \\langle p, X \\rangle = 0\n\\bigr\\}, \\qquad p \\in \\mathbb S_r^d\\] to verify either  p  or  X  one uses  is_point (M,p)  and  is_vector (M, p, X)  respectively. Since both involve some automatic options and possibililities, for example whether to throw an error or just return false, both mention that the actual functions to implement are  check_point  and  check_vector , which both do not throw but  return  an error if something is wrong. In principle we would have to check two properties, namely that the size of  p  is of correct size  M.dimension+1  and that its norm is  M.radius . Luckily, by defining  representation_size  the first check is automatically done already ‚Äì¬†actually for both points and vectors. We define import ManifoldsBase: check_point\nfunction check_point(M::ScaledSphere, p; kwargs...)\n    if !isapprox(norm(p), M.radius; kwargs...)\n        return DomainError(norm(p), \"The norm of $p is not $(M.radius).\")\n    end\n    return nothing\nend And we can directly test the function. To see all 3 failing ones, we switch from errors to warnings in the check is_point(M, [1.5, 0.0], error=:warn) # wrong size\nis_point(M, [1.0, 0.0, 0.0], error=:warn) # wrong norm\nis_point(M, [1.5, 0.0, 0.0], error=:warn) # on the manifold, returns true ‚îå Warning: DomainError with (2,):\n‚îÇ The point [1.5, 0.0] can not belong to the manifold ScaledSphere(2, 1.5), since its size (2,) is not equal to the manifolds representation size ((3,)).\n‚îî @ ManifoldsBase ~/work/ManifoldsBase.jl/ManifoldsBase.jl/src/ManifoldsBase.jl:703\n‚îå Warning: DomainError with 1.0:\n‚îÇ The norm of [1.0, 0.0, 0.0] is not 1.5.\n‚îî @ ManifoldsBase ~/work/ManifoldsBase.jl/ManifoldsBase.jl/src/ManifoldsBase.jl:716\n\ntrue similarly for vectors, we just have to implement the orthogonality check. import ManifoldsBase: check_vector\nfunction check_vector(M::ScaledSphere, p, X; kwargs...)\n    if !isapprox(dot(p,X), 0.0; kwargs...)\n        return DomainError(\n            dot(p,X),\n            \"The tangent vector $X is not orthogonal to $p.\"\n        )\n    end\n    return nothing\nend and again, the high level interface can be used to display warning for vectors not fulfilling the criterion, but we can also activate a check for the point using the last positional argument is_vector(M, [1.5, 0.0, 0.0], [0.0, 1.0]; error=:warn) # wrong size\nis_vector(M, [1.5, 0.0, 0.0], [1.0, 1.0, 0.0]; error=:warn) # not orthogonal norm\nis_vector(M, [1.0, 0.0, 0.0], [0.0, 1.0, 0.0], true; error=:warn) # point not valid\nis_vector(M, [1.5, 0.0, 0.0], [0.0, 1.0, 0.0], true; error=:warn) # returns true ‚îå Warning: DomainError with (2,):\n‚îÇ The tangent vector [0.0, 1.0] can not belong to the manifold ScaledSphere(2, 1.5), since its size (2,) is not equal to the manifodls representation size ((3,)).\n‚îî @ ManifoldsBase ~/work/ManifoldsBase.jl/ManifoldsBase.jl/src/ManifoldsBase.jl:787\n‚îå Warning: DomainError with 1.5:\n‚îÇ The tangent vector [1.0, 1.0, 0.0] is not orthogonal to [1.5, 0.0, 0.0].\n‚îî @ ManifoldsBase ~/work/ManifoldsBase.jl/ManifoldsBase.jl/src/ManifoldsBase.jl:800\n‚îå Warning: DomainError with 1.0:\n‚îÇ The norm of [1.0, 0.0, 0.0] is not 1.5.\n‚îî @ ManifoldsBase ~/work/ManifoldsBase.jl/ManifoldsBase.jl/src/ManifoldsBase.jl:716\n\ntrue"},{"id":371,"pagetitle":"How to define a manifold","title":"Functions on Manifolds III: The exponential map and a retraction.","ref":"/manifoldsbase/stable/tutorials/implement-a-manifold/#Functions-on-Manifolds-III:-The-exponential-map-and-a-retraction.","content":" Functions on Manifolds III: The exponential map and a retraction. For the final group of functions, we want to implement the  exp onential map and a  retract ion. Both are ways to ‚Äúmove around‚Äù on the manifold, that is, given a point  $p$  and a tangent vector indicating a ‚Äúwalking direction‚Äù, the two functions we define will return a new point  $q$  on the manifold. For functions that compute a new point or tangent vector,  ManifoldsBase.jl  always provides two varinats: One that allocates new memory and one, that allows to provide the memory, the result should be returned in ‚Äì¬†to spare memory allocations. Let‚Äôs first take a look at what the exponential map is defined like. We follow the shortest curves, that is great arcs, on the sphere. Formally we have \\[\\exp_p X =\n\\cos\\Bigl(\\frac{1}{r}\\lVert X \\rVert\\Bigr)p +\n\\sin\\Bigl(\\frac{1}{r}\\lVert X \\rVert\\Bigr)\\frac{X}{\\lVert X \\rVert}.\\] In fact, from the two functions above,  exp (M, p, X)  and  exp! (M, q, p, X) , that works in place of  q , we only have to implement the second. The first one,  exp  by default falls back to allocating memory and calling the secnod. Sp  exp  should only be defined, if there is a special reason for. Furthermore, we usually do not verify/check inputs to spare time. If a user feels insecure, they could for example use the  ValidationManifold  wrapper which adds explicitly checks of inputs and outputs. We define import ManifoldsBase: exp!\nfunction exp!(M::ScaledSphere, q, p, X)\n    nX = norm(X)\n    if nX == 0\n        q .= p\n    else\n        q .= cos(nX/M.radius)*p + M.radius*sin(nX/M.radius) .* (1/nX) .* X\n    end\n    return q\nend and we can directly test our function starting in the north pole and ‚Äúwaling down‚Äù to the equator q = exp(M, [0.0, 0.0, 1.5], [0.75œÄ, 0.0, 0.0]) 3-element Vector{Float64}:\n 1.5\n 0.0\n 9.184850993605148e-17 but we also get the other variants for free, for example q2 = zero(q)\nexp!(M, q2, [0.0, 0.0, 1.5], [0.75œÄ, 0.0, 0.0])\nq2 3-element Vector{Float64}:\n 1.5\n 0.0\n 9.184850993605148e-17 or the one that shortens or enlongates the path by a factor, for example, if we walk twice the distance, we reach the opposite point exp!(M, q2, [0.0, 0.0, 1.5], [0.75œÄ, 0.0, 0.0], 2.0)\nq2 3-element Vector{Float64}:\n  1.8369701987210297e-16\n  0.0\n -1.5 Of course we can easliy check that both points we computed still lie on the sphere all([is_point(M, q), is_point(M, q2)]) true Since the exponential map might in general be expensive, we can do a similar implementation with the  ProjectionRetraction . Here, we really have to take into account, that the interface is  designed with 3 levels  in mind: While the actual function we would call in the end is  retract(M, p, X, ProjectionRetraction())  (or its  !  variant), we actually have to implement  retract_project!(M, q, p, X, t)  for technical details, that are a bit beyond this introductionary tutorial. In short this split avoids ambiguity errors for decorators of the manifolds. We define import ManifoldsBase: retract_project!\nfunction retract_project!(M::ScaledSphere, q, p, X, t)\n    q .= (p + t*X) .* (M.radius/norm(p + t*X))\n    return q\nend retract_project! (generic function with 2 methods) And to test also this function, and avoiding allocations at the same time, we call retract!(M, q, [0.0, 0.0, 1.5], [0.75œÄ, 0.0, 0.0], ProjectionRetraction()) 3-element Vector{Float64}:\n 1.2653454121031529\n 0.0\n 0.8055439082194726 Finally, there is  default_retraction_method  to specify which is the default retraction to use. By default this is default_retraction_method(M) ExponentialRetraction() But we can easily specify this for our manifold as well, for example defining import ManifoldsBase: default_retraction_method\ndefault_retraction_method(::ScaledSphere) = ProjectionRetraction() default_retraction_method (generic function with 6 methods) Then default_retraction_method(M) ProjectionRetraction() and retract without a method specified would always fall back to using the projection retraction instead of the exponential map. Note that for compatibilty there is the  AbstractRetractionMethod  called  ExponentialRetraction  which makes  retract  fall back to calling  exp ."},{"id":372,"pagetitle":"How to define a manifold","title":"Technical Details","ref":"/manifoldsbase/stable/tutorials/implement-a-manifold/#Technical-Details","content":" Technical Details This notebook was rendered with the following environment Pkg.status() Status `~/work/ManifoldsBase.jl/ManifoldsBase.jl/tutorials/Project.toml`\n  [7073ff75] IJulia v1.24.2\n  [3362f125] ManifoldsBase v0.15.8 `~/work/ManifoldsBase.jl/ManifoldsBase.jl`\n‚åÖ [91a5bcdd] Plots v1.39.0\nInfo Packages marked with ‚åÖ have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated`"},{"id":375,"pagetitle":"An abstract manifold","title":"The Manifold interface","ref":"/manifoldsbase/stable/types/#The-Manifold-interface","content":" The Manifold interface"},{"id":376,"pagetitle":"An abstract manifold","title":"The  AbstractManifold","ref":"/manifoldsbase/stable/types/#The-AbstractManifold","content":" The  AbstractManifold The main type is the  AbstractManifold . It represents the manifold per se. Throughout the documentation of  ManifoldsBase.jl  we might use the  Euclidean Space  and the  Sphere  (both implemented in  Manifolds.jl ) as easy examples to illustrate properties and features of this interface on concrete examples."},{"id":377,"pagetitle":"An abstract manifold","title":"ManifoldsBase.AbstractManifold","ref":"/manifoldsbase/stable/types/#ManifoldsBase.AbstractManifold","content":" ManifoldsBase.AbstractManifold  ‚Äî  Type AbstractManifold{ùîΩ} A type to represent a (Riemannian) manifold. The  AbstractManifold  is a central type of this interface. It allows to distinguish different implementations of functions like the  exp onential and  log arithmic map for different manifolds. Usually, the manifold is the first parameter in any of these functions within  ManifoldsBase.jl . Based on these, say ‚Äúelementary‚Äù functions, as the two mentioned above, more general functions are built, for example the  shortest_geodesic  and the  geodesic . These should only be overwritten (reimplemented) if for a certain manifold specific, more efficient implementations are possible, that do not just call the elementary functions. The [ AbstractManifold ] is parametrized by  AbstractNumbers  to distinguish for example real (‚Ñù) and complex (‚ÑÇ) manifolds. For subtypes the preferred order of parameters is: size and simple value parameters, followed by the  AbstractNumbers field , followed by data type parameters, which might depend on the abstract number field type. source which should store information about the manifold, for example parameters inherent to the manifold."},{"id":378,"pagetitle":"An abstract manifold","title":"Points on a manifold","ref":"/manifoldsbase/stable/types/#Points-on-a-manifold","content":" Points on a manifold Points do not necessarily have to be typed. Usually one can just use any type. When a manifold has multiple representations, these should be distinguished by point and vector types."},{"id":379,"pagetitle":"An abstract manifold","title":"ManifoldsBase.AbstractManifoldPoint","ref":"/manifoldsbase/stable/types/#ManifoldsBase.AbstractManifoldPoint","content":" ManifoldsBase.AbstractManifoldPoint  ‚Äî  Type AbstractManifoldPoint Type for a point on a manifold. While an  AbstractManifold  does not necessarily require this type, for example when it is implemented for  Vector s or  Matrix  type elements, this type can be used either for more complicated representations, semantic verification, or when dispatching on different representations of points on a manifold. Since semantic verification and different representations usually might still only store a matrix internally, it is possible to use  @manifold_element_forwards  and  @default_manifold_fallbacks  to reduce implementation overhead. source Converting points between different representations can be performed using the  convert  function with either two or three arguments ( convert(T, M, p)  or  convert(T, p) ). For some manifolds providing  M  may be necessary. The first variant falls back to the second variant."},{"id":380,"pagetitle":"An abstract manifold","title":"Tangent and Cotangent spaces","ref":"/manifoldsbase/stable/types/#Tangent-and-Cotangent-spaces","content":" Tangent and Cotangent spaces"},{"id":381,"pagetitle":"An abstract manifold","title":"ManifoldsBase.AbstractFibreVector","ref":"/manifoldsbase/stable/types/#ManifoldsBase.AbstractFibreVector","content":" ManifoldsBase.AbstractFibreVector  ‚Äî  Type AbstractFibreVector{TType<:VectorSpaceType} Type for a vector from a vector space (fibre of a vector bundle) of type  TType  of a manifold. While a  AbstractManifold  does not necessarily require this type, for example when it is implemented for  Vector s or  Matrix  type elements, this type can be used for more complicated representations, semantic verification, or even dispatch for different representations of tangent vectors and their types on a manifold. You may use macro  @manifold_vector_forwards  to introduce commonly used method definitions for your subtype of  AbstractFibreVector . source"},{"id":382,"pagetitle":"An abstract manifold","title":"ManifoldsBase.CoTVector","ref":"/manifoldsbase/stable/types/#ManifoldsBase.CoTVector","content":" ManifoldsBase.CoTVector  ‚Äî  Type CoTVector = AbstractFibreVector{CotangentSpaceType} Type for a cotangent vector of a manifold. While a  AbstractManifold  does not necessarily require this type, for example when it is implemented for  Vector s or  Matrix  type elements, this type can be used for more complicated representations, semantic verification, or even dispatch for different representations of cotangent vectors and their types on a manifold. source"},{"id":383,"pagetitle":"An abstract manifold","title":"ManifoldsBase.FVector","ref":"/manifoldsbase/stable/types/#ManifoldsBase.FVector","content":" ManifoldsBase.FVector  ‚Äî  Type FVector(type::VectorSpaceType, data, basis::AbstractBasis) Decorator indicating that the vector  data  contains coordinates of a vector from a fiber of a vector bundle of type  type .  basis  is an object describing the basis of that space in which the coordinates are given. Conversion between  FVector  representation and the default representation of an object (for example a tangent vector) for a manifold should be done using  get_coordinates  and  get_vector . Examples julia> using Manifolds\n\njulia> M = Sphere(2)\nSphere(2, ‚Ñù)\n\njulia> p = [1.0, 0.0, 0.0]\n3-element Vector{Float64}:\n 1.0\n 0.0\n 0.0\n\njulia> X = [0.0, 2.0, -1.0]\n3-element Vector{Float64}:\n  0.0\n  2.0\n -1.0\n\njulia> B = DefaultOrthonormalBasis()\nDefaultOrthonormalBasis(‚Ñù)\n\njulia> fX = TFVector(get_coordinates(M, p, X, B), B)\nTFVector([2.0, -1.0], DefaultOrthonormalBasis(‚Ñù))\n\njulia> X_back = get_vector(M, p, fX.data, fX.basis)\n3-element Vector{Float64}:\n -0.0\n  2.0\n -1.0 source"},{"id":384,"pagetitle":"An abstract manifold","title":"ManifoldsBase.TVector","ref":"/manifoldsbase/stable/types/#ManifoldsBase.TVector","content":" ManifoldsBase.TVector  ‚Äî  Type TVector = AbstractFibreVector{TangentSpaceType} Type for a tangent vector of a manifold. While a  AbstractManifold  does not necessarily require this type, for example when it is implemented for  Vector s or  Matrix  type elements, this type can be used for more complicated representations, semantic verification, or even dispatch for different representations of tangent vectors and their types on a manifold. source"},{"id":385,"pagetitle":"An abstract manifold","title":"ManifoldsBase.vector_space_dimension","ref":"/manifoldsbase/stable/types/#ManifoldsBase.vector_space_dimension-Tuple{AbstractManifold, ManifoldsBase.VectorSpaceType}","content":" ManifoldsBase.vector_space_dimension  ‚Äî  Method vector_space_dimension(M::AbstractManifold, V::VectorSpaceType) Dimension of the vector space of type  V  on manifold  M . source This interface also covers a large variety how to  model bases in tangent spaces . Converting tangent vectors between different representations can be performed using the  convert  function with either three or four arguments ( convert(T, M, p, X)  or  convert(T, p, X) ). For some manifolds providing  M  may be necessary. The first variant falls back to the second variant."},{"id":386,"pagetitle":"An abstract manifold","title":"Macros for automatic forwards for simple points/tangent vectors","ref":"/manifoldsbase/stable/types/#Macros-for-automatic-forwards-for-simple-points/tangent-vectors","content":" Macros for automatic forwards for simple points/tangent vectors When distinguishing different representations of points or tangent vectors on one manifold, it might happen that both a subtype of  AbstractManifoldPoint  and a subtype of  TVector  are just encapsulating a value This is taken into account by the following macros, that forward several actions just to this field. Most prominently vector operations for the tangent vectors. If there is still a default case, a macro sets this type to be equivalent to calling the manifold functions just with the types field that carries the value."},{"id":387,"pagetitle":"An abstract manifold","title":"ManifoldsBase.@default_manifold_fallbacks","ref":"/manifoldsbase/stable/types/#ManifoldsBase.@default_manifold_fallbacks-Tuple{Any, Any, Any, Symbol, Symbol}","content":" ManifoldsBase.@default_manifold_fallbacks  ‚Äî  Macro default_manifold_fallbacks(TM, TP, TV, pfield::Symbol, vfield::Symbol) Introduce default fallbacks for all basic functions on manifolds, for manifold of type  TM , points of type  TP , tangent vectors of type  TV , with forwarding to fields  pfield  and  vfield  for point and tangent vector functions, respectively. source"},{"id":388,"pagetitle":"An abstract manifold","title":"ManifoldsBase.@manifold_element_forwards","ref":"/manifoldsbase/stable/types/#ManifoldsBase.@manifold_element_forwards-Tuple{Any, Symbol}","content":" ManifoldsBase.@manifold_element_forwards  ‚Äî  Macro manifold_element_forwards(T, field::Symbol)\nmanifold_element_forwards(T, Twhere, field::Symbol) Introduce basic fallbacks for type  T  (which can be a subtype of  Twhere ) that represents points or vectors for a manifold. Fallbacks will work by forwarding to the field passed in  field ` List of forwarded functions: allocate , copy , copyto! , number_eltype  (only for values, not the type itself), similar , size , == . source"},{"id":389,"pagetitle":"An abstract manifold","title":"ManifoldsBase.@manifold_vector_forwards","ref":"/manifoldsbase/stable/types/#ManifoldsBase.@manifold_vector_forwards-Tuple{Any, Symbol}","content":" ManifoldsBase.@manifold_vector_forwards  ‚Äî  Macro manifold_vector_forwards(T, field::Symbol)\nmanifold_vector_forwards(T, Twhere, field::Symbol) Introduce basic fallbacks for type  T  that represents vectors from a vector bundle for a manifold.  Twhere  is put into  where  clause of each method. Fallbacks work by forwarding to field passed as  field . List of forwarded functions: basic arithmetic ( * ,  / ,  \\ ,  + ,  - ), all things from  @manifold_element_forwards , broadcasting support. example @eval @manifold_vector_forwards ValidationFibreVector{TType} TType value source"},{"id":390,"pagetitle":"An abstract manifold","title":"Number Systems","ref":"/manifoldsbase/stable/types/#number-system","content":" Number Systems The  AbstractManifold  has one parameter to distinguish the number system a manifold is based on."},{"id":391,"pagetitle":"An abstract manifold","title":"ManifoldsBase.AbstractNumbers","ref":"/manifoldsbase/stable/types/#ManifoldsBase.AbstractNumbers","content":" ManifoldsBase.AbstractNumbers  ‚Äî  Type AbstractNumbers An abstract type to represent the number system on which a manifold is built. This provides concrete number types for dispatch. The two most common number types are the fields  RealNumbers  ( ‚Ñù  for short) and  ComplexNumbers  ( ‚ÑÇ ). source"},{"id":392,"pagetitle":"An abstract manifold","title":"ManifoldsBase.ComplexNumbers","ref":"/manifoldsbase/stable/types/#ManifoldsBase.ComplexNumbers","content":" ManifoldsBase.ComplexNumbers  ‚Äî  Type ComplexNumbers <: AbstractNumbers\n‚ÑÇ = ComplexNumbers() The field of complex numbers. source"},{"id":393,"pagetitle":"An abstract manifold","title":"ManifoldsBase.QuaternionNumbers","ref":"/manifoldsbase/stable/types/#ManifoldsBase.QuaternionNumbers","content":" ManifoldsBase.QuaternionNumbers  ‚Äî  Type QuaternionNumbers <: AbstractNumbers\n‚Ñç = QuaternionNumbers() The division algebra of quaternions. source"},{"id":394,"pagetitle":"An abstract manifold","title":"ManifoldsBase.RealNumbers","ref":"/manifoldsbase/stable/types/#ManifoldsBase.RealNumbers","content":" ManifoldsBase.RealNumbers  ‚Äî  Type RealNumbers <: AbstractNumbers\n‚Ñù = RealNumbers() The field of real numbers. source"},{"id":395,"pagetitle":"An abstract manifold","title":"ManifoldsBase._unify_number_systems","ref":"/manifoldsbase/stable/types/#ManifoldsBase._unify_number_systems-Tuple{ManifoldsBase.AbstractNumbers, Vararg{ManifoldsBase.AbstractNumbers}}","content":" ManifoldsBase._unify_number_systems  ‚Äî  Method _unify_number_systems(ùîΩs::AbstractNumbers...) Compute a number system that includes all given number systems (as sub-systems) and is closed under addition and multiplication. source"},{"id":396,"pagetitle":"An abstract manifold","title":"ManifoldsBase.number_system","ref":"/manifoldsbase/stable/types/#ManifoldsBase.number_system-Union{Tuple{AbstractManifold{ùîΩ}}, Tuple{ùîΩ}} where ùîΩ","content":" ManifoldsBase.number_system  ‚Äî  Method number_system(M::AbstractManifold{ùîΩ}) Return the number system the manifold  M  is based on, i.e. the parameter  ùîΩ . source"},{"id":397,"pagetitle":"An abstract manifold","title":"ManifoldsBase.real_dimension","ref":"/manifoldsbase/stable/types/#ManifoldsBase.real_dimension-Tuple{ManifoldsBase.AbstractNumbers}","content":" ManifoldsBase.real_dimension  ‚Äî  Method real_dimension(ùîΩ::AbstractNumbers) Return the real dimension  $\\dim_‚Ñù ùîΩ$  of the  AbstractNumbers  system  ùîΩ . The real dimension is the dimension of a real vector space with which a number in  ùîΩ  can be identified. For example,  ComplexNumbers  have a real dimension of 2, and  QuaternionNumbers  have a real dimension of 4. source"},{"id":398,"pagetitle":"An abstract manifold","title":"Type Parameter","ref":"/manifoldsbase/stable/types/#type-parameter","content":" Type Parameter Concrete  AbstractManifold s usually correspond to families of manifolds that are parameterized by some numbers, for example determining their  manifold_dimension . Those numbers can either be stored in a field or as a type parameter of the structure. The  TypeParameter  offers the flexibility to have this parameter either as type parameter or a field."},{"id":399,"pagetitle":"An abstract manifold","title":"ManifoldsBase.TypeParameter","ref":"/manifoldsbase/stable/types/#ManifoldsBase.TypeParameter","content":" ManifoldsBase.TypeParameter  ‚Äî  Type TypeParameter{T} Represents numeric parameters of a manifold type as type parameters, allowing for static specialization of methods. source"},{"id":400,"pagetitle":"An abstract manifold","title":"ManifoldsBase.wrap_type_parameter","ref":"/manifoldsbase/stable/types/#ManifoldsBase.wrap_type_parameter","content":" ManifoldsBase.wrap_type_parameter  ‚Äî  Function wrap_type_parameter(parameter::Symbol, data) Wrap  data  in  TypeParameter  if  parameter  is  :type  or return  data  unchanged if  parameter  is  :field . Intended for use in manifold constructors, see  DefaultManifold  for an example. source"},{"id":403,"pagetitle":"Vector transports","title":"Vector transport","ref":"/manifoldsbase/stable/vector_transports/#Vector-transport","content":" Vector transport Similar to the  exponential and logarithmic map  also the  parallel transport  might be costly to compute, especially when there is no closed form solution known and it has to be approximated with numerical methods. Similar to the  retraction and its inverse , the generalisation of the parallel transport can be phrased as follows A  vector transport  is a way to transport a vector between two tangent spaces. Let  $p,q ‚àà \\mathcal M$  be given,  $c$  the curve along which we want to transport (cf.  parallel transport , for example a geodesic or curve given by a retraction. We can specify the geodesic or curve a retraction realises for example by a direction  $d$ . More precisely using [ AMS08 ], Def. 8.1.1, a vector transport  $T_{p,d}: T_p\\mathcal M \\to T_q\\mathcal M$ ,  $p‚àà \\mathcal M$ ,  $Y‚àà T_p\\mathcal M$  is a smooth mapping associated to a retraction  $\\operatorname{retr}_p(Y) = q$  such that (associated retraction)  $\\mathcal T_{p,d}X ‚àà T_q\\mathcal M$  if and only if  $q = \\operatorname{retr}_p(d)$ , (consistency)  $\\mathcal T_{p,0_p}X = X$  for all  $X‚ààT_p\\mathcal M$ , (linearity)  $\\mathcal T_{p,d}(Œ±X+Œ≤Y) = \\mathcal Œ±T_{p,d}X + \\mathcal Œ≤T_{p,d}Y$  for all  $Œ±, Œ≤ ‚àà ùîΩ$ , hold. Currently the following methods for vector transport are defined in  ManifoldsBase.jl ."},{"id":404,"pagetitle":"Vector transports","title":"ManifoldsBase.default_vector_transport_method","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.default_vector_transport_method-Tuple{AbstractManifold}","content":" ManifoldsBase.default_vector_transport_method  ‚Äî  Method default_vector_transport_method(M::AbstractManifold)\ndefault_vector_transport_method(M::AbstractManifold, ::Type{T}) where {T} The  AbstractVectorTransportMethod  that is used when calling  vector_transport_along ,  vector_transport_to , or  vector_transport_direction  without specifying the vector transport method. By default, this is  ParallelTransport . This method can also be specified more precisely with a point type  T , for the case that on a  M  there are two different representations of points, which provide different vector transport methods. source"},{"id":405,"pagetitle":"Vector transports","title":"ManifoldsBase.vector_transport_along","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.vector_transport_along","content":" ManifoldsBase.vector_transport_along  ‚Äî  Function vector_transport_along(M::AbstractManifold, p, X, c)\nvector_transport_along(M::AbstractManifold, p, X, c, m::AbstractVectorTransportMethod) Transport a vector  X  from the tangent space at a point  p  on the  AbstractManifold M  along the curve represented by  c  using the  method , which defaults to  default_vector_transport_method (M) . source"},{"id":406,"pagetitle":"Vector transports","title":"ManifoldsBase.vector_transport_along!","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.vector_transport_along!","content":" ManifoldsBase.vector_transport_along!  ‚Äî  Function vector_transport_along!(M::AbstractManifold, Y, p, X, c::AbstractVector)\nvector_transport_along!(M::AbstractManifold, Y, p, X, c::AbstractVector, m::AbstractVectorTransportMethod) Transport a vector  X  from the tangent space at a point  p  on the  AbstractManifold M  along the curve represented by  c  using the  method , which defaults to  default_vector_transport_method (M) . The result is saved to  Y . source"},{"id":407,"pagetitle":"Vector transports","title":"ManifoldsBase.vector_transport_along","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.vector_transport_along-Tuple{AbstractManifold, Any, Any, AbstractVector, SchildsLadderTransport}","content":" ManifoldsBase.vector_transport_along  ‚Äî  Method vector_transport_along(\n    M::AbstractManifold,\n    p,\n    X,\n    c::AbstractVector,\n    m::SchildsLadderTransport\n) Compute the vector transport along a discretized curve using  SchildsLadderTransport  succesively along the sampled curve. This method is avoiding additional allocations as well as inner exp/log by performing all ladder steps on the manifold and only computing one tangent vector in the end. source"},{"id":408,"pagetitle":"Vector transports","title":"ManifoldsBase.vector_transport_along","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.vector_transport_along-Tuple{AbstractManifold, Any, Any, Any, AbstractVector, PoleLadderTransport}","content":" ManifoldsBase.vector_transport_along  ‚Äî  Method function vector_transport_along(\n    M::AbstractManifold,\n    p,\n    X,\n    c::AbstractVector,\n    m::PoleLadderTransport\n) Compute the vector transport along a discretized curve using  PoleLadderTransport  succesively along the sampled curve. This method is avoiding additional allocations as well as inner exp/log by performing all ladder steps on the manifold and only computing one tangent vector in the end. source"},{"id":409,"pagetitle":"Vector transports","title":"ManifoldsBase.vector_transport_direction","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.vector_transport_direction","content":" ManifoldsBase.vector_transport_direction  ‚Äî  Function vector_transport_direction(M::AbstractManifold, p, X, d)\nvector_transport_direction(M::AbstractManifold, p, X, d, m::AbstractVectorTransportMethod) Given an  AbstractManifold $\\mathcal M$  the vector transport is a generalization of the  parallel_transport_direction  that identifies vectors from different tangent spaces. More precisely using [ AMS08 ], Def. 8.1.1, a vector transport  $T_{p,d}: T_p\\mathcal M \\to T_q\\mathcal M$ ,  $p‚àà \\mathcal M$ ,  $Y‚àà T_p\\mathcal M$  is a smooth mapping associated to a retraction  $\\operatorname{retr}_p(Y) = q$  such that (associated retraction)  $\\mathcal T_{p,d}X ‚àà T_q\\mathcal M$  if and only if  $q = \\operatorname{retr}_p(d)$ . (consistency)  $\\mathcal T_{p,0_p}X = X$  for all  $X‚ààT_p\\mathcal M$ (linearity)  $\\mathcal T_{p,d}(Œ±X+Œ≤Y) = Œ±\\mathcal T_{p,d}X + Œ≤\\mathcal T_{p,d}Y$ For the  AbstractVectorTransportMethod  we might even omit the third point. The  AbstractLinearVectorTransportMethod s are linear. Input Parameters M  a manifold p  indicating the tangent space of X  the tangent vector to be transported d  indicating a transport direction (and distance through its length) m  an  AbstractVectorTransportMethod , by default  default_vector_transport_method , so usually  ParallelTransport Usually this method requires a  AbstractRetractionMethod  as well. By default this is assumed to be the  default_retraction_method  or implicitly given (and documented) for a vector transport. To explicitly distinguish different retractions for a vector transport, see  VectorTransportDirection . Instead of spcifying a start direction  d  one can equivalently also specify a target tanget space  $T_q\\mathcal M$ , see  vector_transport_to . By default  vector_transport_direction  falls back to using  vector_transport_to , using the  default_retraction_method  on  M . source"},{"id":410,"pagetitle":"Vector transports","title":"ManifoldsBase.vector_transport_direction!","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.vector_transport_direction!","content":" ManifoldsBase.vector_transport_direction!  ‚Äî  Function vector_transport_direction!(M::AbstractManifold, Y, p, X, d)\nvector_transport_direction!(M::AbstractManifold, Y, p, X, d, m::AbstractVectorTransportMethod) Transport a vector  X  from the tangent space at a point  p  on the  AbstractManifold M  in the direction indicated by the tangent vector  d  at  p . By default,  retract  and  vector_transport_to!  are used with the  m  and  r , which default to  default_vector_transport_method (M)  and  default_retraction_method (M) , respectively. The result is saved to  Y . See  vector_transport_direction  for more details. source"},{"id":411,"pagetitle":"Vector transports","title":"ManifoldsBase.vector_transport_to","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.vector_transport_to","content":" ManifoldsBase.vector_transport_to  ‚Äî  Function vector_transport_to(M::AbstractManifold, p, X, q)\nvector_transport_to(M::AbstractManifold, p, X, q, m::AbstractVectorTransportMethod)\nvector_transport_to(M::AbstractManifold, p, X, q, m::AbstractVectorTransportMethod) Transport a vector  X  from the tangent space at a point  p  on the  AbstractManifold M  along a curve implicitly given by an  AbstractRetractionMethod  associated to  m . By default  m  is the  default_vector_transport_method (M) . To explicitly specify a (different) retraction to the implicitly assumeed retraction, see  VectorTransportTo . Note that some vector transport methods might also carry their own retraction they are associated to, like the   DifferentiatedRetractionVectorTransport  and some are even independent of the retraction, for example the  ProjectionTransport . This method is equivalent to using  $d = \\operatorname{retr}^{-1}_p(q)$  in  vector_transport_direction (M, p, X, q, m, r) , where you can find the formal definition. This is the fallback for  VectorTransportTo . source"},{"id":412,"pagetitle":"Vector transports","title":"ManifoldsBase.vector_transport_to!","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.vector_transport_to!","content":" ManifoldsBase.vector_transport_to!  ‚Äî  Function vector_transport_to!(M::AbstractManifold, Y, p, X, q)\nvector_transport_to!(M::AbstractManifold, Y, p, X, q, m::AbstractVectorTransportMethod) Transport a vector  X  from the tangent space at a point  p  on the  AbstractManifold M  to  q  using the  AbstractVectorTransportMethod m  and the  AbstractRetractionMethod r . The result is computed in  Y . See  vector_transport_to  for more details. source"},{"id":413,"pagetitle":"Vector transports","title":"Types of vector transports","ref":"/manifoldsbase/stable/vector_transports/#Types-of-vector-transports","content":" Types of vector transports To distinguish different types of vector transport we introduce the  AbstractVectorTransportMethod . The following concrete types are available."},{"id":414,"pagetitle":"Vector transports","title":"ManifoldsBase.AbstractLinearVectorTransportMethod","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.AbstractLinearVectorTransportMethod","content":" ManifoldsBase.AbstractLinearVectorTransportMethod  ‚Äî  Type AbstractLinearVectorTransportMethod <: AbstractVectorTransportMethod Abstract type for linear methods for transporting vectors, that is transport of a linear combination of vectors is a linear combination of transported vectors. source"},{"id":415,"pagetitle":"Vector transports","title":"ManifoldsBase.AbstractVectorTransportMethod","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.AbstractVectorTransportMethod","content":" ManifoldsBase.AbstractVectorTransportMethod  ‚Äî  Type AbstractVectorTransportMethod <: AbstractApproximationMethod Abstract type for methods for transporting vectors. Such vector transports are not necessarily linear. See also AbstractLinearVectorTransportMethod source"},{"id":416,"pagetitle":"Vector transports","title":"ManifoldsBase.DifferentiatedRetractionVectorTransport","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.DifferentiatedRetractionVectorTransport","content":" ManifoldsBase.DifferentiatedRetractionVectorTransport  ‚Äî  Type DifferentiatedRetractionVectorTransport{R<:AbstractRetractionMethod} <:\n    AbstractVectorTransportMethod A type to specify a vector transport that is given by differentiating a retraction. This can be introduced in two ways. Let  $\\mathcal M$  be a Riemannian manifold,  $p‚àà\\mathcal M$  a point, and  $X,Y‚àà T_p\\mathcal M$  denote two tangent vectors at  $p$ . Given a retraction (cf.  AbstractRetractionMethod )  $\\operatorname{retr}$ , the vector transport of  X  in direction  Y  (cf.  vector_transport_direction ) by differentiation this retraction, is given by \\[\\mathcal T^{\\operatorname{retr}}_{p,Y}X\n= D_Y\\operatorname{retr}_p(Y)[X]\n= \\frac{\\mathrm{d}}{\\mathrm{d}t}\\operatorname{retr}_p(Y+tX)\\Bigr|_{t=0}.\\] see [ AMS08 ], Section 8.1.2 for more details. This can be phrased similarly as a  vector_transport_to  by introducing  $q=\\operatorname{retr}_pX$  and defining \\[\\mathcal T^{\\operatorname{retr}}_{q \\gets p}X = \\mathcal T^{\\operatorname{retr}}_{p,Y}X\\] which in practice usually requires the  inverse_retract  to exists in order to compute  $Y = \\operatorname{retr}_p^{-1}q$ . Constructor DifferentiatedRetractionVectorTransport(m::AbstractRetractionMethod) source"},{"id":417,"pagetitle":"Vector transports","title":"ManifoldsBase.EmbeddedVectorTransport","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.EmbeddedVectorTransport","content":" ManifoldsBase.EmbeddedVectorTransport  ‚Äî  Type EmbeddedVectorTransport{T<:AbstractVectorTransportMethod} <: AbstractVectorTransportMethod Compute a vector transport by using the vector transport of type  T  in the embedding and projecting the result. Constructor EmbeddedVectorTransport(vt::AbstractVectorTransportMethod) Generate the vector transport with vector transport  vt  to use in the embedding. source"},{"id":418,"pagetitle":"Vector transports","title":"ManifoldsBase.ParallelTransport","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.ParallelTransport","content":" ManifoldsBase.ParallelTransport  ‚Äî  Type ParallelTransport <: AbstractVectorTransportMethod Compute the vector transport by parallel transport, see  parallel_transport_to source"},{"id":419,"pagetitle":"Vector transports","title":"ManifoldsBase.PoleLadderTransport","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.PoleLadderTransport","content":" ManifoldsBase.PoleLadderTransport  ‚Äî  Type PoleLadderTransport <: AbstractVectorTransportMethod Specify to use  pole_ladder  as vector transport method within  vector_transport_to ,  vector_transport_direction , or  vector_transport_along , i.e. Let  $X‚àà T_p\\mathcal M$  be a tangent vector at  $p‚àà\\mathcal M$  and  $q‚àà\\mathcal M$  the point to transport to. Then  $x = \\exp_pX$  is used to call  y = pole_ladder (M, p, x, q)  and the resulting vector is obtained by computing  $Y = -\\log_qy$ . The  PoleLadderTransport  posesses two advantages compared to  SchildsLadderTransport : it is cheaper to evaluate, if you want to transport several vectors, since the mid point  $c$  then stays unchanged. while both methods are exact if the curvature is zero, pole ladder is even exact in symmetric Riemannian manifolds [ Pen18 ] The pole ladder was was proposed in [ LP13 ]. Its name stems from the fact that it resembles a pole ladder when applied to a sequence of points usccessively. Constructor PoleLadderTransport(\n    retraction = ExponentialRetraction(),\n    inverse_retraction = LogarithmicInverseRetraction(),\n) Construct the classical pole ladder that employs exp and log, i.e. as proposed in[ LP13 ]. For an even cheaper transport the inner operations can be changed to an  AbstractRetractionMethod retraction  and an  AbstractInverseRetractionMethod inverse_retraction , respectively. source"},{"id":420,"pagetitle":"Vector transports","title":"ManifoldsBase.ProjectionTransport","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.ProjectionTransport","content":" ManifoldsBase.ProjectionTransport  ‚Äî  Type ProjectionTransport <: AbstractVectorTransportMethod Specify to use projection onto tangent space as vector transport method within  vector_transport_to ,  vector_transport_direction , or  vector_transport_along . See  project  for details. source"},{"id":421,"pagetitle":"Vector transports","title":"ManifoldsBase.ScaledVectorTransport","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.ScaledVectorTransport","content":" ManifoldsBase.ScaledVectorTransport  ‚Äî  Type ScaledVectorTransport{T} <: AbstractVectorTransportMethod Introduce a scaled variant of any  AbstractVectorTransportMethod T , as introduced in [ SI13 ] for some  $X‚àà T_p\\mathcal M$  as \\[    \\mathcal T^{\\mathrm{S}}(X) = \\frac{\\lVert X\\rVert_p}{\\lVert \\mathcal T(X)\\rVert_q}\\mathcal T(X).\\] Note that the resulting point  q  has to be known, i.e. for  vector_transport_direction  the curve or more precisely its end point has to be known (via an exponential map or a retraction). Therefore a default implementation is only provided for the  vector_transport_to Constructor ScaledVectorTransport(m::AbstractVectorTransportMethod) source"},{"id":422,"pagetitle":"Vector transports","title":"ManifoldsBase.SchildsLadderTransport","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.SchildsLadderTransport","content":" ManifoldsBase.SchildsLadderTransport  ‚Äî  Type SchildsLadderTransport <: AbstractVectorTransportMethod Specify to use  schilds_ladder  as vector transport method within  vector_transport_to ,  vector_transport_direction , or  vector_transport_along , i.e. Let  $X‚àà T_p\\mathcal M$  be a tangent vector at  $p‚àà\\mathcal M$  and  $q‚àà\\mathcal M$  the point to transport to. Then \\[P^{\\mathrm{S}}_{q\\gets p}(X) =\n    \\log_q\\bigl( \\operatorname{retr}_p ( 2\\operatorname{retr}_p^{-1}c ) \\bigr),\\] where  $c$  is the mid point between  $q$  and  $d=\\exp_pX$ . This method employs the internal function  schilds_ladder (M, p, d, q)  that avoids leaving the manifold. The name stems from the image of this paralleltogram in a repeated application yielding the image of a ladder. The approximation was proposed in [ EPS72 ]. Constructor SchildsLadderTransport(\n    retraction = ExponentialRetraction(),\n    inverse_retraction = LogarithmicInverseRetraction(),\n) Construct the classical Schilds ladder that employs exp and log, i.e. as proposed in [ EPS72 ]. For an even cheaper transport these inner operations can be changed to an  AbstractRetractionMethod retraction  and an  AbstractInverseRetractionMethod inverse_retraction , respectively. source"},{"id":423,"pagetitle":"Vector transports","title":"ManifoldsBase.VectorTransportDirection","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.VectorTransportDirection","content":" ManifoldsBase.VectorTransportDirection  ‚Äî  Type VectorTransportDirection{VM<:AbstractVectorTransportMethod,RM<:AbstractRetractionMethod}\n    <: AbstractVectorTransportMethod Specify a  vector_transport_direction  using a  AbstractVectorTransportMethod  with explicitly using the  AbstractRetractionMethod  to determine the point in the specified direction where to transsport to. Note that you only need this for the non-default (non-implicit) second retraction method associated to a vector transport, i.e. when a first implementation assumed an implicit associated retraction. source"},{"id":424,"pagetitle":"Vector transports","title":"ManifoldsBase.VectorTransportTo","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.VectorTransportTo","content":" ManifoldsBase.VectorTransportTo  ‚Äî  Type VectorTransportTo{VM<:AbstractVectorTransportMethod,RM<:AbstractRetractionMethod}\n    <: AbstractVectorTransportMethod Specify a  vector_transport_to  using a  AbstractVectorTransportMethod  with explicitly using the  AbstractInverseRetractionMethod  to determine the direction that transports from  in  p to  q . Note that you only need this for the non-default (non-implicit) second retraction method associated to a vector transport, i.e. when a first implementation assumed an implicit associated retraction. source"},{"id":425,"pagetitle":"Vector transports","title":"ManifoldsBase.VectorTransportWithKeywords","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.VectorTransportWithKeywords","content":" ManifoldsBase.VectorTransportWithKeywords  ‚Äî  Type VectorTransportWithKeywords{V<:AbstractVectorTransportMethod, K} <: AbstractVectorTransportMethod Since vector transports might have keywords, this type is a way to set them as an own type to be used as a specific vector transport. Another reason for this type is that we dispatch on the vector transport first and only the last layer would be implemented with keywords, so this way they can be passed down. Fields vector_transport  the vector transport that is decorated with keywords kwargs  the keyword arguments Note that you can nest this type. Then the most outer specification of a keyword is used. Constructor VectorTransportWithKeywords(m::T; kwargs...) where {T <: AbstractVectorTransportMethod} Specify the subtype  T <: AbstractVectorTransportMethod  to have keywords  kwargs... . source"},{"id":426,"pagetitle":"Vector transports","title":"Functions to implement (on Layer III)","ref":"/manifoldsbase/stable/vector_transports/#Functions-to-implement-(on-Layer-III)","content":" Functions to implement (on Layer III) While you should always add your documentation to the first layer vector transport methods above when implementing new manifolds, the actual implementation happens on the following functions on  layer III ."},{"id":427,"pagetitle":"Vector transports","title":"ManifoldsBase.pole_ladder","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.pole_ladder","content":" ManifoldsBase.pole_ladder  ‚Äî  Function pole_ladder(\n    M,\n    p,\n    d,\n    q,\n    c = mid_point(M, p, q);\n    retraction=default_retraction_method(M, typeof(p)),\n    inverse_retraction=default_inverse_retraction_method(M, typeof(p))\n) Compute an inner step of the pole ladder, that can be used as a  vector_transport_to . Let  $c = \\gamma_{p,q}(\\frac{1}{2})$  mid point between  p  and  q , then the pole ladder is given by \\[    \\operatorname{Pl}(p,d,q) = \\operatorname{retr}_d (2\\operatorname{retr}_d^{-1}c)\\] Where the classical pole ladder employs  $\\operatorname{retr}_d=\\exp_d$  and  $\\operatorname{retr}_d^{-1}=\\log_d$  but for an even cheaper transport these can be set to different  AbstractRetractionMethod  and  AbstractInverseRetractionMethod . When you have  $X=log_pd$  and  $Y = -\\log_q \\operatorname{Pl}(p,d,q)$ , you will obtain the  PoleLadderTransport . When performing multiple steps, this method avoids the switching to the tangent space. Keep in mind that after  $n$  successive steps the tangent vector reads  $Y_n = (-1)^n\\log_q \\operatorname{Pl}(p_{n-1},d_{n-1},p_n)$ . It is cheaper to evaluate than  schilds_ladder , sinc if you want to form multiple ladder steps between  p  and  q , but with different  d , there is just one evaluation of a geodesic each., since the center  c  can be reused. source"},{"id":428,"pagetitle":"Vector transports","title":"ManifoldsBase.pole_ladder!","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.pole_ladder!","content":" ManifoldsBase.pole_ladder!  ‚Äî  Function pole_ladder(\n    M,\n    pl,\n    p,\n    d,\n    q,\n    c = mid_point(M, p, q),\n    X = allocate_result_type(M, log, d, c);\n    retraction = default_retraction_method(M, typeof(p)),\n    inverse_retraction = default_inverse_retraction_method(M, typeof(p)),\n) Compute the  pole_ladder , i.e. the result is saved in  pl .  X  is used for storing intermediate inverse retraction. source"},{"id":429,"pagetitle":"Vector transports","title":"ManifoldsBase.schilds_ladder","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.schilds_ladder","content":" ManifoldsBase.schilds_ladder  ‚Äî  Function schilds_ladder(\n    M,\n    p,\n    d,\n    q,\n    c = mid_point(M, q, d);\n    retraction = default_retraction_method(M, typeof(p)),\n    inverse_retraction = default_inverse_retraction_method(M, typeof(p)),\n) Perform an inner step of schilds ladder, which can be used as a  vector_transport_to , see  SchildsLadderTransport . Let  $c = \\gamma_{q,d}(\\frac{1}{2})$  denote the mid point on the shortest geodesic connecting  $q$  and the point  $d$ . Then Schild's ladder reads as \\[\\operatorname{Sl}(p,d,q) = \\operatorname{retr}_p( 2\\operatorname{retr}_p^{-1} c)\\] Where the classical Schilds ladder employs  $\\operatorname{retr}_d=\\exp_d$  and  $\\operatorname{retr}_d^{-1}=\\log_d$  but for an even cheaper transport these can be set to different  AbstractRetractionMethod  and  AbstractInverseRetractionMethod . In consistency with  pole_ladder  you can change the way the mid point is computed using the optional parameter  c , but note that here it's the mid point between  q  and  d . When you have  $X=log_pd$  and  $Y = \\log_q \\operatorname{Sl}(p,d,q)$ , you will obtain the  PoleLadderTransport . Then the approximation to the transported vector is given by  $\\log_q\\operatorname{Sl}(p,d,q)$ . When performing multiple steps, this method avoidsd the switching to the tangent space. Hence after  $n$  successive steps the tangent vector reads  $Y_n = \\log_q \\operatorname{Pl}(p_{n-1},d_{n-1},p_n)$ . source"},{"id":430,"pagetitle":"Vector transports","title":"ManifoldsBase.schilds_ladder!","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.schilds_ladder!","content":" ManifoldsBase.schilds_ladder!  ‚Äî  Function schilds_ladder!(\n    M,\n    sl\n    p,\n    d,\n    q,\n    c = mid_point(M, q, d),\n    X = allocate_result_type(M, log, d, c);\n    retraction = default_retraction_method(M, typeof(p)),\n    inverse_retraction = default_inverse_retraction_method(M, typeof(p)),\n) Compute  schilds_ladder  and return the value in the parameter  sl . If the required mid point  c  was computed before, it can be passed using  c , and the allocation of new memory can be avoided providing a tangent vector  X  for the interims result. source"},{"id":431,"pagetitle":"Vector transports","title":"ManifoldsBase.vector_transport_along_diff!","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.vector_transport_along_diff!-Tuple{AbstractManifold, Vararg{Any, 5}}","content":" ManifoldsBase.vector_transport_along_diff!  ‚Äî  Method vector_transport_along_diff!(M::AbstractManifold, Y, p, X, c, m::AbstractRetractionMethod) Compute the vector transport of  X  from  $T_p\\mathcal M$  along the curve  c  using the differential of the  AbstractRetractionMethod m  in place of  Y . source"},{"id":432,"pagetitle":"Vector transports","title":"ManifoldsBase.vector_transport_along_embedded!","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.vector_transport_along_embedded!-Tuple{AbstractManifold, Any, Any, Any, Any, AbstractVectorTransportMethod}","content":" ManifoldsBase.vector_transport_along_embedded!  ‚Äî  Method vector_transport_along_embedded!(M::AbstractManifold, Y, p, X, c, m::AbstractVectorTransportMethod; kwargs...) Compute the vector transport of  X  from  $T_p\\mathcal M$  along the curve  c  using the vector transport method  m  in the embedding and projecting the result back on the corresponding tangent space. The result is computed in place of  Y . source"},{"id":433,"pagetitle":"Vector transports","title":"ManifoldsBase.vector_transport_along_project!","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.vector_transport_along_project!-Tuple{AbstractManifold, Any, Any, Any, AbstractVector}","content":" ManifoldsBase.vector_transport_along_project!  ‚Äî  Method vector_transport_along_project!(M::AbstractManifold, Y, p, X, c::AbstractVector) Compute the vector transport of  X  from  $T_p\\mathcal M$  along the curve  c  using a projection. The result is computed in place of  Y . source"},{"id":434,"pagetitle":"Vector transports","title":"ManifoldsBase.vector_transport_direction_diff!","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.vector_transport_direction_diff!-NTuple{6, Any}","content":" ManifoldsBase.vector_transport_direction_diff!  ‚Äî  Method vector_transport_direction_diff!(M::AbstractManifold, Y, p, X, d, m::AbstractRetractionMethod) Compute the vector transport of  X  from  $T_p\\mathcal M$  into the direction  d  using the differential of the  AbstractRetractionMethod m  in place of  Y . source"},{"id":435,"pagetitle":"Vector transports","title":"ManifoldsBase.vector_transport_direction_embedded!","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.vector_transport_direction_embedded!-Tuple{AbstractManifold, Any, Any, Any, Any, AbstractVectorTransportMethod}","content":" ManifoldsBase.vector_transport_direction_embedded!  ‚Äî  Method vector_transport_direction_embedded!(M::AbstractManifold, Y, p, X, d, m::AbstractVectorTransportMethod) Compute the vector transport of  X  from  $T_p\\mathcal M$  into the direction  d  using the  AbstractRetractionMethod m  in the embedding. The default implementataion requires one allocation for the points and tangent vectors in the embedding and the resulting point, but the final projection is performed in place of  Y source"},{"id":436,"pagetitle":"Vector transports","title":"ManifoldsBase.vector_transport_to_diff!","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.vector_transport_to_diff!-Tuple{AbstractManifold, Vararg{Any, 5}}","content":" ManifoldsBase.vector_transport_to_diff!  ‚Äî  Method vector_transport_to_diff(M::AbstractManifold, p, X, q, r) Compute a vector transport by using a  DifferentiatedRetractionVectorTransport r  in place of  Y . source"},{"id":437,"pagetitle":"Vector transports","title":"ManifoldsBase.vector_transport_to_embedded!","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.vector_transport_to_embedded!-Tuple{AbstractManifold, Vararg{Any, 5}}","content":" ManifoldsBase.vector_transport_to_embedded!  ‚Äî  Method vector_transport_to_embedded!(M::AbstractManifold, Y, p, X, q, m::AbstractRetractionMethod) Compute the vector transport of  X  from  $T_p\\mathcal M$  to the point  q  using the  of the  AbstractRetractionMethod m  in th embedding. The default implementataion requires one allocation for the points and tangent vectors in the embedding and the resulting point, but the final projection is performed in place of  Y source"},{"id":438,"pagetitle":"Vector transports","title":"ManifoldsBase.vector_transport_to_project!","ref":"/manifoldsbase/stable/vector_transports/#ManifoldsBase.vector_transport_to_project!-Tuple{AbstractManifold, Vararg{Any, 4}}","content":" ManifoldsBase.vector_transport_to_project!  ‚Äî  Method vector_transport_to_project!(M::AbstractManifold, Y, p, X, q) Compute a vector transport by projecting  $X\\in T_p\\mathcal M$  onto the tangent space  $T_q\\mathcal M$  at  $q$  in place of  Y . source"},{"id":441,"pagetitle":"Home","title":"Manifolds","ref":"/manifolds/stable/#Manifolds","content":" Manifolds"},{"id":442,"pagetitle":"Home","title":"Manifolds.Manifolds","ref":"/manifolds/stable/#Manifolds.Manifolds","content":" Manifolds.Manifolds  ‚Äî  Module Manifolds.jl  provides a library of manifolds aiming for an easy-to-use and fast implementation. source The implemented manifolds are accompanied by their mathematical formulae. The manifolds are implemented using the interface for manifolds given in  ManifoldsBase.jl . You can use that interface to implement your own software on manifolds, such that all manifolds based on that interface can be used within your code. For more information, see the  About  section."},{"id":443,"pagetitle":"Home","title":"Getting started","ref":"/manifolds/stable/#Getting-started","content":" Getting started To install the package just type using Pkg; Pkg.add(\"Manifolds\") Then you can directly start, for example to stop half way from the north pole on the  Sphere  to a point on the the equator, you can generate the  shortest_geodesic . It internally employs  log  and  exp . using Manifolds\nM = Sphere(2)\nŒ≥ = shortest_geodesic(M, [0., 0., 1.], [0., 1., 0.])\nŒ≥(0.5) 3-element Vector{Float64}:\n 0.0\n 0.7071067811865475\n 0.7071067811865476"},{"id":444,"pagetitle":"Home","title":"Citation","ref":"/manifolds/stable/#Citation","content":" Citation If you use  Manifolds.jl  in your work, please cite the following @online{2106.08777,\n    Author = {Seth D. Axen and Mateusz Baran and Ronny Bergmann and Krzysztof Rzecki},\n    Title = {Manifolds.jl: An Extensible Julia Framework for Data Analysis on Manifolds},\n    Year = {2021},\n    Eprint = {2106.08777},\n    Eprinttype = {arXiv},\n} To refer to a certain version we recommend to also cite for example @software{manifoldsjl-zenodo-mostrecent,\n  Author = {Seth D. Axen and Mateusz Baran and Ronny Bergmann},\n  Title = {Manifolds.jl},\n  Doi = {10.5281/ZENODO.4292129},\n  Url = {https://zenodo.org/record/4292129},\n  Publisher = {Zenodo},\n  Year = {2021},\n  Copyright = {MIT License}\n} for the most recent version or a corresponding version specific DOI, see  the list of all versions . Note that both citations are in  BibLaTeX  format."},{"id":447,"pagetitle":"Atlases and charts","title":"Atlases and charts","ref":"/manifolds/stable/features/#atlases_and_charts","content":" Atlases and charts Atlases on an  $n$ -dimensional manifold  $mathcal M$ are collections of charts  $\\mathcal A = \\{(U_i, œÜ_i) \\colon i \\in I\\}$ , where  $I$  is a (finite or infinte) index family, such that  $U_i \\subseteq \\mathcal M$  is an open set and each chart  $œÜ_i: U_i ‚Üí ‚Ñù^n$  is a homeomorphism. This means, that  $œÜ_i$  is bijective ‚Äì sometimes also called one-to-one and onto - and continuous, and its inverse  $œÜ_i^{-1}$  is continuous as well. The inverse  $œÜ_i^{-1}$  is called (local) parametrization. The resulting  parameters $a=œÜ(p)$  of  $p$  (with respect to the chart  $œÜ$ ) are in the literature also called ‚Äú(local) coordinates‚Äù. To distinguish the parameter  $a$  from   get_coordinates  in a basis, we use the terminology parameter in this package. For an atlas  $\\mathcal A$  we further require that \\[\\displaystyle\\bigcup_{i\\in I} U_i = \\mathcal M.\\] We say that  $œÜ_i$  is a chart about  $p$ , if  $p\\in U_i$ . An atlas provides a connection between a manifold and the Euclidean space  $‚Ñù^n$ , since locally, a chart about  $p$  can be used to identify its neighborhood (as long as you stay in  $U_i$ ) with a subset of a Euclidean space. Most manifolds we consider are smooth, i.e. any change of charts  $œÜ_i \\circ œÜ_j^{-1}: ‚Ñù^n ‚Üí ‚Ñù^n$ , where  $i,j\\in I$ , is a smooth function. These changes of charts are also called transition maps. Most operations on manifolds in  Manifolds.jl  avoid operating in a chart through appropriate embeddings and formulas derived for particular manifolds, though atlases provide the most general way of working with manifolds. Compared to these approaches, using an atlas is often more technical and time-consuming. They are extensively used in metric-related functions on  MetricManifold s. Atlases are represented by objects of subtypes of  AbstractAtlas . There are no type restrictions for indices of charts in atlases. Operations using atlases and charts are available through the following functions: get_chart_index  can be used to select an appropriate chart for the neighborhood of a given point  $p$ . This function should work deterministically, i.e. for a fixed  $p$  always return the same chart. get_parameters  converts a point to its parameters with respect to the chart in a chart. get_point  converts parameters (local coordinates) in a chart to the point that corresponds to them. induced_basis  returns a basis of a given vector space at a point induced by a chart  $œÜ$ . transition_map  converts coordinates of a point between two charts, e.g. computes  $œÜ_i\\circ œÜ_j^{-1}: ‚Ñù^n ‚Üí ‚Ñù^n$ ,  $i,j\\in I$ . While an atlas could store charts as explicit functions, it is favourable, that the [ get_parameters ] actually implements a chart  $œÜ$ ,  get_point  its inverse, the prametrization  $œÜ^{-1}$ ."},{"id":448,"pagetitle":"Atlases and charts","title":"Manifolds.AbstractAtlas","ref":"/manifolds/stable/features/#Manifolds.AbstractAtlas","content":" Manifolds.AbstractAtlas  ‚Äî  Type AbstractAtlas{ùîΩ} An abstract class for atlases whith charts that have values in the vector space  ùîΩ‚Åø  for some value of  n .  ùîΩ  is a number system determined by an  AbstractNumbers  object. source"},{"id":449,"pagetitle":"Atlases and charts","title":"Manifolds.InducedBasis","ref":"/manifolds/stable/features/#Manifolds.InducedBasis","content":" Manifolds.InducedBasis  ‚Äî  Type InducedBasis(vs::VectorSpaceType, A::AbstractAtlas, i) The basis induced by chart with index  i  from an  AbstractAtlas A  of vector space of type  vs . For the  vs  a  TangentSpace  this works as  follows: Let  $n$  denote the dimension of the manifold  $\\mathcal M$ . Let the parameter  $a=œÜ_i(p) ‚àà \\mathbb R^n$  and  $j‚àà\\{1,‚Ä¶,n\\}$ . We can look at the  $j$ th parameter curve  $b_j(t) = a + te_j$ , where  $e_j$  denotes the  $j$ th unit vector. Using the parametrisation we obtain a curve  $c_j(t) = œÜ_i^{-1}(b_j(t))$  which fulfills  $c(0) = p$ . Now taking the derivative(s) with respect to  $t$  (and evaluate at  $t=0$ ), we obtain a tangent vector for each  $j$  corresponding to an equivalence class of curves (having the same derivative) as \\[X_j = [c_j] = \\frac{\\mathrm{d}}{\\mathrm{d}t} c_i(t) \\Bigl|_{t=0}\\] and the set  $\\{X_1,\\ldots,X_n\\}$  is the chart-induced basis of  $T_p\\mathcal M$ . See also VectorSpaceType ,  AbstractBasis source"},{"id":450,"pagetitle":"Atlases and charts","title":"Manifolds.RetractionAtlas","ref":"/manifolds/stable/features/#Manifolds.RetractionAtlas","content":" Manifolds.RetractionAtlas  ‚Äî  Type RetractionAtlas{\n    ùîΩ,\n    TRetr<:AbstractRetractionMethod,\n    TInvRetr<:AbstractInverseRetractionMethod,\n    TBasis<:AbstractBasis,\n} <: AbstractAtlas{ùîΩ} An atlas indexed by points on a manifold,  $\\mathcal M = I$  and parameters (local coordinates) are given in  $T_p\\mathcal M$ . This means that a chart  $œÜ_p = \\mathrm{cord}\\circ\\mathrm{retr}_p^{-1}$  is only locally defined (around  $p$ ), where  $\\mathrm{cord}$  is the decomposition of the tangent vector into coordinates with respect to the given basis of the tangent space, cf.  get_coordinates . The parametrization is given by  $œÜ_p^{-1}=\\mathrm{retr}_p\\circ\\mathrm{vec}$ , where  $\\mathrm{vec}$  turns the basis coordinates into a tangent vector, cf.  get_vector . In short: The coordinates with respect to a basis are used together with a retraction as a parametrization. See also AbstractAtlas ,  AbstractInverseRetractionMethod ,  AbstractRetractionMethod ,  AbstractBasis source"},{"id":451,"pagetitle":"Atlases and charts","title":"LinearAlgebra.norm","ref":"/manifolds/stable/features/#LinearAlgebra.norm-Tuple{AbstractManifold, AbstractAtlas, Any, Any, Any}","content":" LinearAlgebra.norm  ‚Äî  Method norm(M::AbstractManifold, A::AbstractAtlas, i, a, Xc) Calculate norm on manifold  M  at point with parameters  a  in chart  i  of an  AbstractAtlas A  of vector with coefficients  Xc  in induced basis. source"},{"id":452,"pagetitle":"Atlases and charts","title":"Manifolds.affine_connection!","ref":"/manifolds/stable/features/#Manifolds.affine_connection!-Tuple{AbstractManifold, Any, AbstractAtlas, Vararg{Any, 4}}","content":" Manifolds.affine_connection!  ‚Äî  Method affine_connection!(M::AbstractManifold, Zc, A::AbstractAtlas, i, a, Xc, Yc) Calculate affine connection on manifold  M  at point with parameters  a  in chart  i  of an an  AbstractAtlas A  of vectors with coefficients  Zc  and  Yc  in induced basis and save the result in  Zc . source"},{"id":453,"pagetitle":"Atlases and charts","title":"Manifolds.affine_connection","ref":"/manifolds/stable/features/#Manifolds.affine_connection-Tuple{AbstractManifold, Vararg{Any, 5}}","content":" Manifolds.affine_connection  ‚Äî  Method affine_connection(M::AbstractManifold, A::AbstractAtlas, i, a, Xc, Yc) Calculate affine connection on manifold  M  at point with parameters  a  in chart  i  of  AbstractAtlas A  of vectors with coefficients  Xc  and  Yc  in induced basis. source"},{"id":454,"pagetitle":"Atlases and charts","title":"Manifolds.check_chart_switch","ref":"/manifolds/stable/features/#Manifolds.check_chart_switch-Tuple{AbstractManifold, AbstractAtlas, Any, Any}","content":" Manifolds.check_chart_switch  ‚Äî  Method check_chart_switch(M::AbstractManifold, A::AbstractAtlas, i, a) Determine whether chart should be switched when an operation in chart  i  from an  AbstractAtlas A  reaches parameters  a  in that chart. By default  false  is returned. source"},{"id":455,"pagetitle":"Atlases and charts","title":"Manifolds.get_chart_index","ref":"/manifolds/stable/features/#Manifolds.get_chart_index-Tuple{AbstractManifold, AbstractAtlas, Any, Any}","content":" Manifolds.get_chart_index  ‚Äî  Method get_chart_index(M::AbstractManifold, A::AbstractAtlas, i, a) Select a chart from an  AbstractAtlas A  for manifold  M  that is suitable for representing the neighborhood of point with parametrization  a  in chart  i . This selection should be deterministic, although different charts may be selected for arbitrarily close but distinct points. See also get_default_atlas source"},{"id":456,"pagetitle":"Atlases and charts","title":"Manifolds.get_chart_index","ref":"/manifolds/stable/features/#Manifolds.get_chart_index-Tuple{AbstractManifold, AbstractAtlas, Any}","content":" Manifolds.get_chart_index  ‚Äî  Method get_chart_index(M::AbstractManifold, A::AbstractAtlas, p) Select a chart from an  AbstractAtlas A  for manifold  M  that is suitable for representing the neighborhood of point  p . This selection should be deterministic, although different charts may be selected for arbitrarily close but distinct points. See also get_default_atlas source"},{"id":457,"pagetitle":"Atlases and charts","title":"Manifolds.get_default_atlas","ref":"/manifolds/stable/features/#Manifolds.get_default_atlas-Tuple{AbstractManifold}","content":" Manifolds.get_default_atlas  ‚Äî  Method get_default_atlas(::AbstractManifold) Determine the default real-valued atlas for the given manifold. source"},{"id":458,"pagetitle":"Atlases and charts","title":"Manifolds.get_parameters","ref":"/manifolds/stable/features/#Manifolds.get_parameters-Tuple{AbstractManifold, AbstractAtlas, Any, Any}","content":" Manifolds.get_parameters  ‚Äî  Method get_parameters(M::AbstractManifold, A::AbstractAtlas, i, p) Calculate parameters (local coordinates) of point  p  on manifold  M  in chart from an  AbstractAtlas A  at index  i . This function is hence an implementation of the chart  $œÜ_i(p), i\\in I$ . The parameters are in the number system determined by  A . If the point  $p\\notin U_i$  is not in the domain of the chart, this method should throw an error. See also get_point ,  get_chart_index source"},{"id":459,"pagetitle":"Atlases and charts","title":"Manifolds.get_point","ref":"/manifolds/stable/features/#Manifolds.get_point-Tuple{AbstractManifold, AbstractAtlas, Any, Any}","content":" Manifolds.get_point  ‚Äî  Method get_point(M::AbstractManifold, A::AbstractAtlas, i, a) Calculate point at parameters (local coordinates)  a  on manifold  M  in chart from an  AbstractAtlas A  at index  i . This function is hence an implementation of the inverse  $œÜ_i^{-1}(a), i\\in I$  of a chart, also called a parametrization. See also get_parameters ,  get_chart_index source"},{"id":460,"pagetitle":"Atlases and charts","title":"Manifolds.induced_basis","ref":"/manifolds/stable/features/#Manifolds.induced_basis-Tuple{AbstractManifold, AbstractAtlas, Any, VectorSpaceType}","content":" Manifolds.induced_basis  ‚Äî  Method induced_basis(M::AbstractManifold, A::AbstractAtlas, i, p, VST::VectorSpaceType) Basis of vector space of type  VST  at point  p  from manifold  M  induced by chart ( A ,  i ). See also VectorSpaceType ,  AbstractAtlas source"},{"id":461,"pagetitle":"Atlases and charts","title":"Manifolds.induced_basis","ref":"/manifolds/stable/features/#Manifolds.induced_basis-Union{Tuple{ùîΩ}, Tuple{AbstractManifold{ùîΩ}, AbstractAtlas, Any}, Tuple{AbstractManifold{ùîΩ}, AbstractAtlas, Any, VectorSpaceType}} where ùîΩ","content":" Manifolds.induced_basis  ‚Äî  Method induced_basis(::AbstractManifold, A::AbstractAtlas, i, VST::VectorSpaceType = TangentSpaceType()) Get the basis induced by chart with index  i  from an  AbstractAtlas A  of vector space of type  vs . Returns an object of type  InducedBasis . See also VectorSpaceType ,  AbstractBasis source"},{"id":462,"pagetitle":"Atlases and charts","title":"Manifolds.inverse_chart_injectivity_radius","ref":"/manifolds/stable/features/#Manifolds.inverse_chart_injectivity_radius-Tuple{AbstractManifold, AbstractAtlas, Any}","content":" Manifolds.inverse_chart_injectivity_radius  ‚Äî  Method inverse_chart_injectivity_radius(M::AbstractManifold, A::AbstractAtlas, i) Injectivity radius of  get_point  for chart  i  from an  AbstractAtlas A  of a manifold  M . source"},{"id":463,"pagetitle":"Atlases and charts","title":"Manifolds.local_metric","ref":"/manifolds/stable/features/#Manifolds.local_metric-Tuple{AbstractManifold, Any, InducedBasis}","content":" Manifolds.local_metric  ‚Äî  Method local_metric(M::AbstractManifold, p, B::InducedBasis) Compute the local metric tensor for vectors expressed in terms of coordinates in basis  B  on manifold  M . The point  p  is not checked. source"},{"id":464,"pagetitle":"Atlases and charts","title":"Manifolds.transition_map","ref":"/manifolds/stable/features/#Manifolds.transition_map-Tuple{AbstractManifold, AbstractAtlas, Any, AbstractAtlas, Any, Any}","content":" Manifolds.transition_map  ‚Äî  Method transition_map(M::AbstractManifold, A_from::AbstractAtlas, i_from, A_to::AbstractAtlas, i_to, a)\ntransition_map(M::AbstractManifold, A::AbstractAtlas, i_from, i_to, a) Given coordinates  a  in chart  (A_from, i_from)  of a point on manifold  M , returns coordinates of that point in chart  (A_to, i_to) . If  A_from  and  A_to  are equal,  A_to  can be omitted. Mathematically this function is the transition map or change of charts, but it might even be between two atlases  $A_{\\text{from}} = \\{(U_i,œÜ_i)\\}_{i\\in I}$  and  $A_{\\text{to}} = \\{(V_j,\\psi_j)\\}_{j\\in J}$ , and hence  $I, J$  are their index sets. We have  $i_{\\text{from}}\\in I$ ,  $i_{\\text{to}}\\in J$ . This method then computes \\[\\bigl(\\psi_{i_{\\text{to}}}\\circ œÜ_{i_{\\text{from}}}^{-1}\\bigr)(a)\\] Note that, similarly to  get_parameters , this method should fail the same way if  $V_{i_{\\text{to}}}\\cap U_{i_{\\text{from}}}=\\emptyset$ . See also AbstractAtlas ,  get_parameters ,  get_point source"},{"id":465,"pagetitle":"Atlases and charts","title":"Manifolds.transition_map_diff!","ref":"/manifolds/stable/features/#Manifolds.transition_map_diff!-Tuple{AbstractManifold, Any, AbstractAtlas, Vararg{Any, 4}}","content":" Manifolds.transition_map_diff!  ‚Äî  Method transition_map_diff!(M::AbstractManifold, c_out, A::AbstractAtlas, i_from, a, c, i_to) Compute  transition_map_diff  on given arguments and save the result in  c_out . source"},{"id":466,"pagetitle":"Atlases and charts","title":"Manifolds.transition_map_diff","ref":"/manifolds/stable/features/#Manifolds.transition_map_diff-Tuple{AbstractManifold, AbstractAtlas, Vararg{Any, 4}}","content":" Manifolds.transition_map_diff  ‚Äî  Method transition_map_diff(M::AbstractManifold, A::AbstractAtlas, i_from, a, c, i_to) Compute differential of transition map from chart  i_from  to chart  i_to  from an  AbstractAtlas A  on manifold  M  at point with parameters  a  on tangent vector with coordinates  c  in the induced basis. source"},{"id":467,"pagetitle":"Atlases and charts","title":"ManifoldsBase.inner","ref":"/manifolds/stable/features/#ManifoldsBase.inner-Tuple{AbstractManifold, AbstractAtlas, Vararg{Any, 4}}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::AbstractManifold, A::AbstractAtlas, i, a, Xc, Yc) Calculate inner product on manifold  M  at point with parameters  a  in chart  i  of an atlas  A  of vectors with coefficients  Xc  and  Yc  in induced basis. source"},{"id":468,"pagetitle":"Atlases and charts","title":"Cotangent space and musical isomorphisms","ref":"/manifolds/stable/features/#Cotangent-space-and-musical-isomorphisms","content":" Cotangent space and musical isomorphisms Related to atlases, there is also support for the cotangent space and coefficients of cotangent vectors in bases of the cotangent space. Functions  sharp  and  flat  implement musical isomorphisms for arbitrary vector bundles."},{"id":469,"pagetitle":"Atlases and charts","title":"Manifolds.RieszRepresenterCotangentVector","ref":"/manifolds/stable/features/#Manifolds.RieszRepresenterCotangentVector","content":" Manifolds.RieszRepresenterCotangentVector  ‚Äî  Type RieszRepresenterCotangentVector(M::AbstractManifold, p, X) Cotangent vector in Riesz representer form on manifold  M  at point  p  with Riesz representer  X . source"},{"id":470,"pagetitle":"Atlases and charts","title":"Manifolds.flat","ref":"/manifolds/stable/features/#Manifolds.flat-Tuple{AbstractManifold, Any, Any}","content":" Manifolds.flat  ‚Äî  Method flat(M::AbstractManifold, p, X) Compute the flat isomorphism (one of the musical isomorphisms) of tangent vector  X  from the vector space of type  M  at point  p  from the underlying  AbstractManifold . The function can be used for example to transform vectors from the tangent bundle to vectors from the cotangent bundle  $‚ô≠ : T\\mathcal M ‚Üí T^{*}\\mathcal M$ source"},{"id":471,"pagetitle":"Atlases and charts","title":"Manifolds.sharp","ref":"/manifolds/stable/features/#Manifolds.sharp-Tuple{AbstractManifold, Any, Any}","content":" Manifolds.sharp  ‚Äî  Method sharp(M::AbstractManifold, p, Œæ) Compute the sharp isomorphism (one of the musical isomorphisms) of vector  Œæ  from the vector space  M  at point  p  from the underlying  AbstractManifold . The function can be used for example to transform vectors from the cotangent bundle to vectors from the tangent bundle  $‚ôØ : T^{*}\\mathcal M ‚Üí T\\mathcal M$ source"},{"id":472,"pagetitle":"Atlases and charts","title":"Computations in charts","ref":"/manifolds/stable/features/#Computations-in-charts","content":" Computations in charts"},{"id":473,"pagetitle":"Atlases and charts","title":"Manifolds.IntegratorTerminatorNearChartBoundary","ref":"/manifolds/stable/features/#Manifolds.IntegratorTerminatorNearChartBoundary","content":" Manifolds.IntegratorTerminatorNearChartBoundary  ‚Äî  Type IntegratorTerminatorNearChartBoundary{TKwargs} An object for determining the point at which integration of a differential equation in a chart on a manifold should be terminated for the purpose of switching a chart. The value stored in  check_chart_switch_kwargs  will be passed as keyword arguments to   check_chart_switch . By default an empty tuple is stored. source"},{"id":474,"pagetitle":"Atlases and charts","title":"Manifolds.estimate_distance_from_bvp","ref":"/manifolds/stable/features/#Manifolds.estimate_distance_from_bvp","content":" Manifolds.estimate_distance_from_bvp  ‚Äî  Function estimate_distance_from_bvp(\n    M::AbstractManifold,\n    a1,\n    a2,\n    A::AbstractAtlas,\n    i;\n    solver=MIRK4(),\n    dt=0.05,\n    kwargs...,\n) Estimate distance between points on  AbstractManifold  M with parameters  a1  and  a2  in chart  i  of  AbstractAtlas A  using solver  solver , employing  solve_chart_log_bvp  to solve the geodesic BVP. source"},{"id":475,"pagetitle":"Atlases and charts","title":"Manifolds.solve_chart_exp_ode","ref":"/manifolds/stable/features/#Manifolds.solve_chart_exp_ode","content":" Manifolds.solve_chart_exp_ode  ‚Äî  Function solve_chart_exp_ode(\n    M::AbstractManifold,\n    a,\n    Xc,\n    A::AbstractAtlas,\n    i0;\n    solver=AutoVern9(Rodas5()),\n    final_time=1.0,\n    check_chart_switch_kwargs=NamedTuple(),\n    kwargs...,\n) Solve geodesic ODE on a manifold  M  from point of coordinates  a  in chart  i0  from an  AbstractAtlas A  in direction of coordinates  Xc  in the induced basis. source"},{"id":476,"pagetitle":"Atlases and charts","title":"Manifolds.solve_chart_log_bvp","ref":"/manifolds/stable/features/#Manifolds.solve_chart_log_bvp","content":" Manifolds.solve_chart_log_bvp  ‚Äî  Function solve_chart_log_bvp(\n    M::AbstractManifold,\n    a1,\n    a2,\n    A::AbstractAtlas,\n    i;\n    solver=MIRK4(),\n    dt::Real=0.05,\n    kwargs...,\n) Solve the BVP corresponding to geodesic calculation on  AbstractManifold  M, between points with parameters  a1  and  a2  in a chart  i  of an  AbstractAtlas A  using solver  solver . Geodesic Œ≥ is sampled at time interval  dt , with Œ≥(0) = a1 and Œ≥(1) = a2. source"},{"id":477,"pagetitle":"Atlases and charts","title":"Manifolds.solve_chart_parallel_transport_ode","ref":"/manifolds/stable/features/#Manifolds.solve_chart_parallel_transport_ode","content":" Manifolds.solve_chart_parallel_transport_ode  ‚Äî  Function solve_chart_parallel_transport_ode(\n    M::AbstractManifold,\n    a,\n    Xc,\n    A::AbstractAtlas,\n    i0,\n    Yc;\n    solver=AutoVern9(Rodas5()),\n    check_chart_switch_kwargs=NamedTuple(),\n    final_time=1.0,\n    kwargs...,\n) Parallel transport vector with coordinates  Yc  along geodesic on a manifold  M  from point of coordinates  a  in a chart  i0  from an  AbstractAtlas A  in direction of coordinates  Xc  in the induced basis. source"},{"id":480,"pagetitle":"Differentiation","title":"Differentiation","ref":"/manifolds/stable/features/#Differentiation","content":" Differentiation Documentation for  Manifolds.jl 's methods and types for finite differences and automatic differentiation."},{"id":481,"pagetitle":"Differentiation","title":"Differentiation backends","ref":"/manifolds/stable/features/#Differentiation-backends","content":" Differentiation backends Further differentiation backends and features are available in  ManifoldDiff.jl ."},{"id":482,"pagetitle":"Differentiation","title":"FiniteDifferenes.jl","ref":"/manifolds/stable/features/#FiniteDifferenes.jl","content":" FiniteDifferenes.jl"},{"id":483,"pagetitle":"Differentiation","title":"Riemannian differentiation backends","ref":"/manifolds/stable/features/#Riemannian-differentiation-backends","content":" Riemannian differentiation backends"},{"id":486,"pagetitle":"Distributions","title":"Distributions","ref":"/manifolds/stable/features/#Distributions","content":" Distributions The following functions and types provide support for manifold-valued and tangent space-valued distributions:"},{"id":487,"pagetitle":"Distributions","title":"Manifolds.FVectorDistribution","ref":"/manifolds/stable/features/#Manifolds.FVectorDistribution","content":" Manifolds.FVectorDistribution  ‚Äî  Type FVectorDistribution{TSpace<:VectorSpaceFiber, T} An abstract distribution for vector bundle fiber-valued distributions (values from a fiber of a vector bundle at point  x  from the given manifold). For example used for tangent vector-valued distributions. source"},{"id":488,"pagetitle":"Distributions","title":"Manifolds.FVectorSupport","ref":"/manifolds/stable/features/#Manifolds.FVectorSupport","content":" Manifolds.FVectorSupport  ‚Äî  Type FVectorSupport(space::AbstractManifold, VectorSpaceFiber) Value support for vector bundle fiber-valued distributions (values from a fiber of a vector bundle at a  point  from the given manifold). For example used for tangent vector-valued distributions. source"},{"id":489,"pagetitle":"Distributions","title":"Manifolds.FVectorvariate","ref":"/manifolds/stable/features/#Manifolds.FVectorvariate","content":" Manifolds.FVectorvariate  ‚Äî  Type FVectorvariate Structure that subtypes  VariateForm , indicating that a single sample is a vector from a fiber of a vector bundle. source"},{"id":490,"pagetitle":"Distributions","title":"Manifolds.MPointDistribution","ref":"/manifolds/stable/features/#Manifolds.MPointDistribution","content":" Manifolds.MPointDistribution  ‚Äî  Type MPointDistribution{TM<:AbstractManifold} An abstract distribution for points on manifold of type  TM . source"},{"id":491,"pagetitle":"Distributions","title":"Manifolds.MPointSupport","ref":"/manifolds/stable/features/#Manifolds.MPointSupport","content":" Manifolds.MPointSupport  ‚Äî  Type MPointSupport(M::AbstractManifold) Value support for manifold-valued distributions (values from given  AbstractManifold M ). source"},{"id":492,"pagetitle":"Distributions","title":"Manifolds.MPointvariate","ref":"/manifolds/stable/features/#Manifolds.MPointvariate","content":" Manifolds.MPointvariate  ‚Äî  Type MPointvariate Structure that subtypes  VariateForm , indicating that a single sample is a point on a manifold. source"},{"id":493,"pagetitle":"Distributions","title":"Distributions.support","ref":"/manifolds/stable/features/#Distributions.support-Tuple{T} where T<:Manifolds.FVectorDistribution","content":" Distributions.support  ‚Äî  Method support(d::FVectorDistribution) Get the object of type  FVectorSupport  for the distribution  d . source"},{"id":494,"pagetitle":"Distributions","title":"Manifolds.ProjectedFVectorDistribution","ref":"/manifolds/stable/features/#Manifolds.ProjectedFVectorDistribution","content":" Manifolds.ProjectedFVectorDistribution  ‚Äî  Type ProjectedFVectorDistribution(type::VectorSpaceFiber, p, d, project!) Generates a random vector from ambient space of manifold  type.manifold  at point  p  and projects it to vector space of type  type  using function  project! , see  project  for documentation. Generated arrays are of type  TResult . source"},{"id":495,"pagetitle":"Distributions","title":"Manifolds.ProjectedPointDistribution","ref":"/manifolds/stable/features/#Manifolds.ProjectedPointDistribution","content":" Manifolds.ProjectedPointDistribution  ‚Äî  Type ProjectedPointDistribution(M::AbstractManifold, d, proj!, p) Generates a random point in ambient space of  M  and projects it to  M  using function  proj! . Generated arrays are of type  TResult , which can be specified by providing the  p  argument. source"},{"id":496,"pagetitle":"Distributions","title":"Manifolds.normal_tvector_distribution","ref":"/manifolds/stable/features/#Manifolds.normal_tvector_distribution-Tuple{AbstractManifold, Any, Any}","content":" Manifolds.normal_tvector_distribution  ‚Äî  Method normal_tvector_distribution(M::Euclidean, p, œÉ) Normal distribution in ambient space with standard deviation  œÉ  projected to tangent space at  p . source"},{"id":497,"pagetitle":"Distributions","title":"Manifolds.projected_distribution","ref":"/manifolds/stable/features/#Manifolds.projected_distribution","content":" Manifolds.projected_distribution  ‚Äî  Function projected_distribution(M::AbstractManifold, d, [p=rand(d)]) Wrap the standard distribution  d  into a manifold-valued distribution. Generated points will be of similar type to  p . By default, the type is not changed. source"},{"id":500,"pagetitle":"Group actions","title":"Group actions","ref":"/manifolds/stable/features/#Group-actions","content":" Group actions Group actions represent actions of a given group on a specified manifold. The following operations are available: action_side : whether action acts from the  LeftSide  or  RightSide  (not to be confused with action direction). apply : performs given action of an element of the group on an object of compatible type. apply_diff : differential of  apply  with respect to the object it acts upon. direction : tells whether a given action is  LeftAction ,  RightAction . inverse_apply : performs given action of the inverse of an element of the group on an object of compatible type. By default inverts the element and calls  apply  but it may be have a faster implementation for some actions. inverse_apply_diff : counterpart of  apply_diff  for  inverse_apply . optimal_alignment : determine the element of a group that, when it acts upon a point, produces the element closest to another given point in the metric of the G-manifold. Furthermore, group operation action features the following: translate : an operation that performs either ( LeftAction ) on the  LeftSide  or ( RightAction ) on the  RightSide  translation, or actions by inverses of elements ( RightAction  on the  LeftSide  and  LeftAction  on the  RightSide ). This is by default performed by calling  compose  with appropriate order of arguments. This function is separated from  compose  mostly to easily represent its differential,  translate_diff . translate_diff : differential of  translate  with respect to the point being translated. adjoint_action : adjoint action of a given element of a Lie group on an element of its Lie algebra. lie_bracket : Lie bracket of two vectors from a Lie algebra corresponding to a given group. The following group actions are available: Group operation action  GroupOperationAction  that describes action of a group on itself. RotationAction , that is action of  SpecialOrthogonal  group on different manifolds. TranslationAction , which is the action of  TranslationGroup  group on different manifolds."},{"id":501,"pagetitle":"Group actions","title":"Manifolds.AbstractGroupAction","ref":"/manifolds/stable/features/#Manifolds.AbstractGroupAction","content":" Manifolds.AbstractGroupAction  ‚Äî  Type AbstractGroupAction{AD<:ActionDirection} An abstract group action on a manifold.  ActionDirection AD  indicates whether it is a left or right action. source"},{"id":502,"pagetitle":"Group actions","title":"Manifolds.adjoint_apply_diff_group","ref":"/manifolds/stable/features/#Manifolds.adjoint_apply_diff_group-Tuple{AbstractGroupAction, Any, Any, Any}","content":" Manifolds.adjoint_apply_diff_group  ‚Äî  Method adjoint_apply_diff_group(A::AbstractGroupAction, a, X, p) Pullback with respect to group element of group action  A . \\[(\\mathrm{d}œÑ^{p,*}) : T_{œÑ_{a} p} \\mathcal M ‚Üí T_{a} \\mathcal G\\] source"},{"id":503,"pagetitle":"Group actions","title":"Manifolds.apply!","ref":"/manifolds/stable/features/#Manifolds.apply!-Tuple{AbstractGroupAction, Any, Any, Any}","content":" Manifolds.apply!  ‚Äî  Method apply!(A::AbstractGroupAction, q, a, p) Apply action  a  to the point  p  with the rule specified by  A . The result is saved in  q . source"},{"id":504,"pagetitle":"Group actions","title":"Manifolds.apply","ref":"/manifolds/stable/features/#Manifolds.apply-Tuple{AbstractGroupAction, Any, Any}","content":" Manifolds.apply  ‚Äî  Method apply(A::AbstractGroupAction, a, p) Apply action  a  to the point  p  using map  $œÑ_a$ , specified by  A . Unless otherwise specified, the right action is defined in terms of the left action: \\[\\mathrm{R}_a = \\mathrm{L}_{a^{-1}}\\] source"},{"id":505,"pagetitle":"Group actions","title":"Manifolds.apply_diff","ref":"/manifolds/stable/features/#Manifolds.apply_diff-Tuple{AbstractGroupAction, Any, Any, Any}","content":" Manifolds.apply_diff  ‚Äî  Method apply_diff(A::AbstractGroupAction, a, p, X) For point  $p ‚àà \\mathcal M$  and tangent vector  $X ‚àà T_p \\mathcal M$ , compute the action on  $X$  of the differential of the action of  $a ‚àà \\mathcal{G}$ , specified by rule  A . Written as  $(\\mathrm{d}œÑ_a)_p$ , with the specified left or right convention, the differential transports vectors \\[(\\mathrm{d}œÑ_a)_p : T_p \\mathcal M ‚Üí T_{œÑ_a p} \\mathcal M\\] source"},{"id":506,"pagetitle":"Group actions","title":"Manifolds.apply_diff_group","ref":"/manifolds/stable/features/#Manifolds.apply_diff_group-Tuple{AbstractGroupAction, Any, Any, Any}","content":" Manifolds.apply_diff_group  ‚Äî  Method apply_diff_group(A::AbstractGroupAction, a, X, p) Compute the value of differential of action  AbstractGroupAction A  on vector  X , where element  a  is acting on  p , with respect to the group element. Let  $\\mathcal G$  be the group acting on manifold  $\\mathcal M$  by the action  A . The action is of element  $g ‚àà \\mathcal G$  on a point  $p ‚àà \\mathcal M$ . The differential transforms vector  X  from the tangent space at  a ‚àà \\mathcal G ,  $X ‚àà T_a \\mathcal G$  into a tangent space of the manifold  $\\mathcal M$ . When action on element  p  is written as  $\\mathrm{d}œÑ^p$ , with the specified left or right convention, the differential transforms vectors \\[(\\mathrm{d}œÑ^p) : T_{a} \\mathcal G ‚Üí T_{œÑ_a p} \\mathcal M\\] See also apply ,  apply_diff source"},{"id":507,"pagetitle":"Group actions","title":"Manifolds.base_group","ref":"/manifolds/stable/features/#Manifolds.base_group-Tuple{AbstractGroupAction}","content":" Manifolds.base_group  ‚Äî  Method base_group(A::AbstractGroupAction) The group that acts in  AbstractGroupAction A . source"},{"id":508,"pagetitle":"Group actions","title":"Manifolds.center_of_orbit","ref":"/manifolds/stable/features/#Manifolds.center_of_orbit","content":" Manifolds.center_of_orbit  ‚Äî  Function center_of_orbit(\n    A::AbstractGroupAction,\n    pts,\n    p,\n    mean_method::AbstractApproximationMethod = GradientDescentEstimation(),\n) Calculate an action element  $a$  of action  A  that is the mean element of the orbit of  p  with respect to given set of points  pts . The  mean  is calculated using the method  mean_method . The orbit of  $p$  with respect to the action of a group  $\\mathcal{G}$  is the set \\[O = \\{ œÑ_a p : a ‚àà \\mathcal{G} \\}.\\] This function is useful for computing means on quotients of manifolds by a Lie group action. source"},{"id":509,"pagetitle":"Group actions","title":"Manifolds.direction","ref":"/manifolds/stable/features/#Manifolds.direction-Union{Tuple{AbstractGroupAction{AD}}, Tuple{AD}} where AD","content":" Manifolds.direction  ‚Äî  Method direction(::AbstractGroupAction{AD}) -> AD Get the direction of the action: either  LeftAction  or  RightAction . source"},{"id":510,"pagetitle":"Group actions","title":"Manifolds.group_manifold","ref":"/manifolds/stable/features/#Manifolds.group_manifold-Tuple{AbstractGroupAction}","content":" Manifolds.group_manifold  ‚Äî  Method group_manifold(A::AbstractGroupAction) The manifold the action  A  acts upon. source"},{"id":511,"pagetitle":"Group actions","title":"Manifolds.inverse_apply!","ref":"/manifolds/stable/features/#Manifolds.inverse_apply!-Tuple{AbstractGroupAction, Any, Any, Any}","content":" Manifolds.inverse_apply!  ‚Äî  Method inverse_apply!(A::AbstractGroupAction, q, a, p) Apply inverse of action  a  to the point  p  with the rule specified by  A . The result is saved in  q . source"},{"id":512,"pagetitle":"Group actions","title":"Manifolds.inverse_apply","ref":"/manifolds/stable/features/#Manifolds.inverse_apply-Tuple{AbstractGroupAction, Any, Any}","content":" Manifolds.inverse_apply  ‚Äî  Method inverse_apply(A::AbstractGroupAction, a, p) Apply inverse of action  a  to the point  p . The action is specified by  A . source"},{"id":513,"pagetitle":"Group actions","title":"Manifolds.inverse_apply_diff","ref":"/manifolds/stable/features/#Manifolds.inverse_apply_diff-Tuple{AbstractGroupAction, Any, Any, Any}","content":" Manifolds.inverse_apply_diff  ‚Äî  Method inverse_apply_diff(A::AbstractGroupAction, a, p, X) For group point  $p ‚àà \\mathcal M$  and tangent vector  $X ‚àà T_p \\mathcal M$ , compute the action on  $X$  of the differential of the inverse action of  $a ‚àà \\mathcal{G}$ , specified by rule  A . Written as  $(\\mathrm{d}œÑ_a^{-1})_p$ , with the specified left or right convention, the differential transports vectors. \\[(\\mathrm{d}œÑ_a^{-1})_p : T_p \\mathcal M ‚Üí T_{œÑ_a^{-1} p} \\mathcal M\\] source"},{"id":514,"pagetitle":"Group actions","title":"Manifolds.optimal_alignment!","ref":"/manifolds/stable/features/#Manifolds.optimal_alignment!-Tuple{AbstractGroupAction, Any, Any, Any}","content":" Manifolds.optimal_alignment!  ‚Äî  Method optimal_alignment!(A::AbstractGroupAction, x, p, q) Calculate an action element of action  A  that acts upon  p  to produce the element closest to  q . The result is written to  x . source"},{"id":515,"pagetitle":"Group actions","title":"Manifolds.optimal_alignment","ref":"/manifolds/stable/features/#Manifolds.optimal_alignment-Tuple{AbstractGroupAction, Any, Any}","content":" Manifolds.optimal_alignment  ‚Äî  Method optimal_alignment(A::AbstractGroupAction, p, q) Calculate an action element  $a$  of action  A  that acts upon  p  to produce the element closest to  q  in the metric of the G-manifold: \\[\\arg\\min_{a ‚àà \\mathcal{G}} d_{\\mathcal M}(œÑ_a p, q)\\] where  $\\mathcal{G}$  is the group that acts on the G-manifold  $\\mathcal M$ . source"},{"id":516,"pagetitle":"Group actions","title":"Group operation action","ref":"/manifolds/stable/features/#Group-operation-action","content":" Group operation action"},{"id":517,"pagetitle":"Group actions","title":"Manifolds.GroupOperationAction","ref":"/manifolds/stable/features/#Manifolds.GroupOperationAction","content":" Manifolds.GroupOperationAction  ‚Äî  Type GroupOperationAction{AD<:ActionDirection,AS<:GroupActionSide,G<:AbstractDecoratorManifold} <: AbstractGroupAction{AD} Action of a group upon itself via left or right translation, either from left or right side. An element  p  of the group can act upon another another element by either: left action from the left side:  $L_p: q ‚Ü¶ p \\circ q$ , right action from the left side:  $L'_p: q ‚Ü¶ p^{-1} \\circ q$ , right action from the right side:  $R_p: q ‚Ü¶ q \\circ p$ , left action from the right side:  $R'_p: q ‚Ü¶ q \\circ p^{-1}$ . Constructor GroupOperationAction(group::AbstractDecoratorManifold, AD::ActionDirectionAndSide = LeftForwardAction()) source"},{"id":518,"pagetitle":"Group actions","title":"Manifolds.action_side","ref":"/manifolds/stable/features/#Manifolds.action_side-Union{Tuple{GroupOperationAction{AD, AS}}, Tuple{AS}, Tuple{AD}} where {AD<:ActionDirection, AS<:Manifolds.GroupActionSide}","content":" Manifolds.action_side  ‚Äî  Method action_side(A::GroupOperationAction) Return whether  GroupOperationAction A  acts on the  LeftSide  or  RightSide . source"},{"id":519,"pagetitle":"Group actions","title":"Manifolds.apply_diff_group","ref":"/manifolds/stable/features/#Manifolds.apply_diff_group-Tuple{GroupOperationAction, Any, Any, Any}","content":" Manifolds.apply_diff_group  ‚Äî  Method apply_diff_group(A::GroupOperationAction, a, X, p) Compute differential of  GroupOperationAction A  with respect to group element at tangent vector  X : \\[(\\mathrm{d}œÑ^p) : T_{a} \\mathcal G ‚Üí T_{œÑ_a p} \\mathcal G\\] There are four cases: left action from the left side:  $L_a: p ‚Ü¶ a \\circ p$ , where \\[(\\mathrm{d}L_a) : T_{a} \\mathcal G ‚Üí T_{a \\circ p} \\mathcal G.\\] right action from the left side:  $L'_a: p ‚Ü¶ a^{-1} \\circ p$ , where \\[(\\mathrm{d}L'_a) : T_{a} \\mathcal G ‚Üí T_{a^{-1} \\circ p} \\mathcal G.\\] right action from the right side:  $R_a: p ‚Ü¶ p \\circ a$ , where \\[(\\mathrm{d}R_a) : T_{a} \\mathcal G ‚Üí T_{p \\circ a} \\mathcal G.\\] left action from the right side:  $R'_a: p ‚Ü¶ p \\circ a^{-1}$ , where \\[(\\mathrm{d}R'_a) : T_{a} \\mathcal G ‚Üí T_{p \\circ a^{-1}} \\mathcal G.\\] source"},{"id":520,"pagetitle":"Group actions","title":"Rotation action","ref":"/manifolds/stable/features/#Rotation-action","content":" Rotation action"},{"id":521,"pagetitle":"Group actions","title":"Manifolds.ColumnwiseMultiplicationAction","ref":"/manifolds/stable/features/#Manifolds.ColumnwiseMultiplicationAction","content":" Manifolds.ColumnwiseMultiplicationAction  ‚Äî  Type ColumnwiseMultiplicationAction{\n    TAD<:ActionDirection,\n    TM<:AbstractManifold,\n    TO<:GeneralUnitaryMultiplicationGroup,\n} <: AbstractGroupAction{TAD} Action of the (special) unitary or orthogonal group  GeneralUnitaryMultiplicationGroup  of type  On  columns of points on a matrix manifold  M . Constructor ColumnwiseMultiplicationAction(\n    M::AbstractManifold,\n    On::GeneralUnitaryMultiplicationGroup,\n    AD::ActionDirection = LeftAction(),\n) source"},{"id":522,"pagetitle":"Group actions","title":"Manifolds.RotationAction","ref":"/manifolds/stable/features/#Manifolds.RotationAction","content":" Manifolds.RotationAction  ‚Äî  Type RotationAction(\n    M::AbstractManifold,\n    SOn::SpecialOrthogonal,\n    AD::ActionDirection = LeftAction(),\n) Space of actions of the  SpecialOrthogonal  group  $\\mathrm{SO}(n)$  on a Euclidean-like manifold  M  of dimension  n . source"},{"id":523,"pagetitle":"Group actions","title":"Manifolds.RotationAroundAxisAction","ref":"/manifolds/stable/features/#Manifolds.RotationAroundAxisAction","content":" Manifolds.RotationAroundAxisAction  ‚Äî  Type RotationAroundAxisAction(axis::AbstractVector) Space of actions of the circle group  RealCircleGroup  on  $‚Ñù^3$  around given  axis . source"},{"id":524,"pagetitle":"Group actions","title":"Manifolds.RowwiseMultiplicationAction","ref":"/manifolds/stable/features/#Manifolds.RowwiseMultiplicationAction","content":" Manifolds.RowwiseMultiplicationAction  ‚Äî  Type RowwiseMultiplicationAction{\n    TAD<:ActionDirection,\n    TM<:AbstractManifold,\n    TO<:GeneralUnitaryMultiplicationGroup,\n} <: AbstractGroupAction{TAD} Action of the (special) unitary or orthogonal group  GeneralUnitaryMultiplicationGroup  of type  On  columns of points on a matrix manifold  M . Constructor RowwiseMultiplicationAction(\n    M::AbstractManifold,\n    On::GeneralUnitaryMultiplicationGroup,\n    AD::ActionDirection = LeftAction(),\n) source"},{"id":525,"pagetitle":"Group actions","title":"Manifolds.apply","ref":"/manifolds/stable/features/#Manifolds.apply-Tuple{Manifolds.RotationAroundAxisAction, Any, Any}","content":" Manifolds.apply  ‚Äî  Method apply(A::RotationAroundAxisAction, Œ∏, p) Rotate point  p  from  Euclidean(3)  manifold around axis  A.axis  by angle  Œ∏ . The formula reads \\[p_{rot} = (\\cos(Œ∏))p + (k√óp) \\sin(Œ∏) + k (k‚ãÖp) (1-\\cos(Œ∏)),\\] where  $k$  is the vector  A.axis  and  ‚ãÖ  is the dot product. source"},{"id":526,"pagetitle":"Group actions","title":"Manifolds.optimal_alignment","ref":"/manifolds/stable/features/#Manifolds.optimal_alignment-Tuple{Manifolds.ColumnwiseMultiplicationAction{LeftAction}, Any, Any}","content":" Manifolds.optimal_alignment  ‚Äî  Method optimal_alignment(A::LeftColumnwiseMultiplicationAction, p, q) Compute optimal alignment for the left  ColumnwiseMultiplicationAction , i.e. the group element  $O^{*}$  that, when it acts on  p , returns the point closest to  q . Details of computation are described in Section 2.2.1 of [ SK16 ]. The formula reads \\[O^{*} = \\begin{cases}\nUV^T & \\text{if } \\operatorname{det}(p q^{\\mathrm{T}}) \\geq 0\\\\\nU K V^{\\mathrm{T}} & \\text{otherwise}\n\\end{cases}\\] where  $U \\Sigma V^{\\mathrm{T}}$  is the SVD decomposition of  $p q^{\\mathrm{T}}$  and  $K$  is the unit diagonal matrix with the last element on the diagonal replaced with -1. source"},{"id":527,"pagetitle":"Group actions","title":"Translation action","ref":"/manifolds/stable/features/#Translation-action","content":" Translation action"},{"id":528,"pagetitle":"Group actions","title":"Manifolds.TranslationAction","ref":"/manifolds/stable/features/#Manifolds.TranslationAction","content":" Manifolds.TranslationAction  ‚Äî  Type TranslationAction(\n    M::AbstractManifold,\n    Rn::TranslationGroup,\n    AD::ActionDirection = LeftAction(),\n) Space of actions of the  TranslationGroup $\\mathrm{T}(n)$  on a Euclidean-like manifold  M . The left and right actions are equivalent. source"},{"id":529,"pagetitle":"Group actions","title":"Rotation-translation action (special Euclidean)","ref":"/manifolds/stable/features/#Rotation-translation-action-(special-Euclidean)","content":" Rotation-translation action (special Euclidean)"},{"id":530,"pagetitle":"Group actions","title":"Manifolds.ColumnwiseSpecialEuclideanAction","ref":"/manifolds/stable/features/#Manifolds.ColumnwiseSpecialEuclideanAction","content":" Manifolds.ColumnwiseSpecialEuclideanAction  ‚Äî  Type ColumnwiseSpecialEuclideanAction{\n    TM<:AbstractManifold,\n    TSE<:SpecialEuclidean,\n    TAD<:ActionDirection,\n} <: AbstractGroupAction{TAD} Action of the special Euclidean group  SpecialEuclidean  of type  SE  columns of points on a matrix manifold  M . Constructor ColumnwiseSpecialEuclideanAction(\n    M::AbstractManifold,\n    SE::SpecialEuclidean,\n    AD::ActionDirection = LeftAction(),\n) source"},{"id":531,"pagetitle":"Group actions","title":"Manifolds.RotationTranslationAction","ref":"/manifolds/stable/features/#Manifolds.RotationTranslationAction","content":" Manifolds.RotationTranslationAction  ‚Äî  Type RotationTranslationAction(\n    M::AbstractManifold,\n    SOn::SpecialEuclidean,\n    AD::ActionDirection = LeftAction(),\n) Space of actions of the  SpecialEuclidean  group  $\\mathrm{SE}(n)$  on a Euclidean-like manifold  M  of dimension  n . Left actions corresponds to active transformations while right actions can be identified with passive transformations for a particular choice of a basis. source"},{"id":532,"pagetitle":"Group actions","title":"Manifolds.RotationTranslationActionOnVector","ref":"/manifolds/stable/features/#Manifolds.RotationTranslationActionOnVector","content":" Manifolds.RotationTranslationActionOnVector  ‚Äî  Type RotationTranslationActionOnVector{TAD,ùîΩ,TE,TSE} Alias for  RotationTranslationAction  where the manifold  M  is  Euclidean  or  TranslationGroup  with size of type  TE , and  SpecialEuclidean  group has size type  TSE . source"},{"id":533,"pagetitle":"Group actions","title":"Manifolds.apply","ref":"/manifolds/stable/features/#Manifolds.apply-Tuple{RotationTranslationActionOnVector{LeftAction, ùîΩ, TE} where {ùîΩ, TE}, ArrayPartition, Any}","content":" Manifolds.apply  ‚Äî  Method apply(::RotationTranslationActionOnVector{LeftAction}, a::ArrayPartition, p) Rotate point  p  by  a.x[2]  and translate it by  a.x[1] . source"},{"id":534,"pagetitle":"Group actions","title":"Manifolds.apply","ref":"/manifolds/stable/features/#Manifolds.apply-Tuple{RotationTranslationActionOnVector{RightAction, ùîΩ, TE} where {ùîΩ, TE}, ArrayPartition, Any}","content":" Manifolds.apply  ‚Äî  Method apply(::RotationTranslationActionOnVector{RightAction}, a::ArrayPartition, p) Translate point  p  by  -a.x[1]  and rotate it by inverse of  a.x[2] . source"},{"id":535,"pagetitle":"Group actions","title":"Manifolds.apply_diff","ref":"/manifolds/stable/features/#Manifolds.apply_diff-Tuple{RotationTranslationActionOnVector{LeftAction, ùîΩ, TE} where {ùîΩ, TE}, ArrayPartition, Any, Any}","content":" Manifolds.apply_diff  ‚Äî  Method apply_diff(\n    ::RotationTranslationActionOnVector{LeftAction},\n    a::ArrayPartition,\n    p,\n    X,\n) Compute differential of  apply  on left  RotationTranslationActionOnVector ,  with respect to  p , i.e. left-multiply vector  X  tangent at  p  by  a.x[2] . source"},{"id":536,"pagetitle":"Group actions","title":"Manifolds.apply_diff","ref":"/manifolds/stable/features/#Manifolds.apply_diff-Tuple{RotationTranslationActionOnVector{RightAction, ùîΩ, TE} where {ùîΩ, TE}, ArrayPartition, Any, Any}","content":" Manifolds.apply_diff  ‚Äî  Method apply_diff(\n    ::RotationTranslationActionOnVector{RightAction},\n    a::ArrayPartition,\n    p,\n    X,\n) Compute differential of  apply  on right  RotationTranslationActionOnVector ,  with respect to  p , i.e. left-divide vector  X  tangent at  p  by  a.x[2] . source"},{"id":537,"pagetitle":"Group actions","title":"Manifolds.apply_diff_group","ref":"/manifolds/stable/features/#Manifolds.apply_diff_group-Tuple{RotationTranslationActionOnVector{LeftAction, ùîΩ, TE} where {ùîΩ, TE}, Identity{Manifolds.SemidirectProductOperation{RotationAction{LeftAction, TranslationGroup{N, ‚Ñù}, SpecialOrthogonal{N}}}} where N, Any, Any}","content":" Manifolds.apply_diff_group  ‚Äî  Method apply_diff_group(\n    ::RotationTranslationActionOnVector{LeftAction},\n    ::SpecialEuclideanIdentity,\n    X,\n    p,\n) Compute differential of  apply  on left  RotationTranslationActionOnVector ,  with respect to  a  at identity, i.e. left-multiply point  p  by  X.x[2] . source"},{"id":538,"pagetitle":"Group actions","title":"Manifolds.inverse_apply","ref":"/manifolds/stable/features/#Manifolds.inverse_apply-Tuple{RotationTranslationActionOnVector{LeftAction, ùîΩ, TE} where {ùîΩ, TE}, ArrayPartition, Any}","content":" Manifolds.inverse_apply  ‚Äî  Method inverse_apply(::RotationTranslationActionOnVector{LeftAction}, a::ArrayPartition, p) Translate point  p  by  -a.x[1]  and rotate it by inverse of  a.x[2] . source"},{"id":539,"pagetitle":"Group actions","title":"Manifolds.inverse_apply","ref":"/manifolds/stable/features/#Manifolds.inverse_apply-Tuple{RotationTranslationActionOnVector{RightAction, ùîΩ, TE} where {ùîΩ, TE}, ArrayPartition, Any}","content":" Manifolds.inverse_apply  ‚Äî  Method inverse_apply(::RotationTranslationActionOnVector{RightAction}, a::ArrayPartition, p) Rotate point  p  by  a.x[2]  and translate it by  a.x[1] . source"},{"id":540,"pagetitle":"Group actions","title":"Manifolds.optimal_alignment","ref":"/manifolds/stable/features/#Manifolds.optimal_alignment-Tuple{Manifolds.ColumnwiseSpecialEuclideanAction{LeftAction}, Any, Any}","content":" Manifolds.optimal_alignment  ‚Äî  Method optimal_alignment(A::LeftColumnwiseSpecialEuclideanAction, p, q) Compute optimal alignment of  p  to  q  under the forward left  ColumnwiseSpecialEuclideanAction . The algorithm, in sequence, computes optimal translation and optimal rotation. source"},{"id":543,"pagetitle":"Integration","title":"Integration","ref":"/manifolds/stable/features/#Integration","content":" Integration"},{"id":544,"pagetitle":"Integration","title":"Manifolds.manifold_volume","ref":"/manifolds/stable/features/#Manifolds.manifold_volume-Tuple{AbstractManifold}","content":" Manifolds.manifold_volume  ‚Äî  Method manifold_volume(M::AbstractManifold) Volume of manifold  M  defined through integration of Riemannian volume element in a chart. Note that for many manifolds there is no universal agreement over the exact ranges over which the integration should happen. For details see [ BST03 ]. source"},{"id":545,"pagetitle":"Integration","title":"Manifolds.volume_density","ref":"/manifolds/stable/features/#Manifolds.volume_density-Tuple{AbstractManifold, Any, Any}","content":" Manifolds.volume_density  ‚Äî  Method volume_density(M::AbstractManifold, p, X) Volume density function of manifold  M , i.e. determinant of the differential of exponential map  exp(M, p, X) . Determinant can be understood as computed in a basis, from the matrix of the linear operator said differential corresponds to. Details are available in Section 4.1 of [ CLLD22 ]. Note that volume density is well-defined only for  X  for which  exp(M, p, X)  is injective. source"},{"id":548,"pagetitle":"Statistics","title":"Statistics","ref":"/manifolds/stable/features/#Statistics","content":" Statistics"},{"id":549,"pagetitle":"Statistics","title":"Manifolds.AbstractEstimationMethod","ref":"/manifolds/stable/features/#Manifolds.AbstractEstimationMethod","content":" Manifolds.AbstractEstimationMethod  ‚Äî  Type AbstractEstimationMethod Deprecated alias for  AbstractApproximationMethod source"},{"id":550,"pagetitle":"Statistics","title":"Statistics.cov","ref":"/manifolds/stable/features/#Statistics.cov-Tuple{AbstractManifold, AbstractVector}","content":" Statistics.cov  ‚Äî  Method Statistics.cov(\n    M::AbstractManifold,\n    x::AbstractVector;\n    basis::AbstractBasis=DefaultOrthonormalBasis(),\n    tangent_space_covariance_estimator::CovarianceEstimator=SimpleCovariance(;\n        corrected=true,\n    ),\n    mean_estimation_method::AbstractApproximationMethod=GradientDescentEstimation(),\n    inverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(\n        M, eltype(x),\n    ),\n) Estimate the covariance matrix of a set of points  x  on manifold  M . Since the covariance matrix on a manifold is a rank 2 tensor, the function returns its coefficients in basis induced by the given tangent space basis. See Section 5 of [ Pen06 ] for details. The mean is calculated using the specified  mean_estimation_method  using [mean](@ref Statistics.mean(::AbstractManifold, ::AbstractVector, ::AbstractApproximationMethod), and tangent vectors at this mean are calculated using the provided  inverse_retraction_method . Finally, the covariance matrix in the tangent plane is estimated using the Euclidean space  estimator  tangent_space_covariance_estimator . The type  CovarianceEstimator  is defined  in  StatsBase.jl   and examples of covariance estimation methods can be found in   CovarianceEstimation.jl . source"},{"id":551,"pagetitle":"Statistics","title":"Statistics.mean!","ref":"/manifolds/stable/features/#Statistics.mean!-Tuple{AbstractManifold, Vararg{Any}}","content":" Statistics.mean!  ‚Äî  Method mean!(M::AbstractManifold, y, x::AbstractVector[, w::AbstractWeights]; kwargs...)\nmean!(\n    M::AbstractManifold,\n    y,\n    x::AbstractVector,\n    [w::AbstractWeights,]\n    method::AbstractApproximationMethod;\n    kwargs...,\n) Compute the  mean  in-place in  y . source"},{"id":552,"pagetitle":"Statistics","title":"Statistics.mean","ref":"/manifolds/stable/features/#Statistics.mean-Tuple{AbstractManifold, AbstractVector, AbstractVector, ExtrinsicEstimation}","content":" Statistics.mean  ‚Äî  Method mean(\n    M::AbstractManifold,\n    x::AbstractVector,\n    [w::AbstractWeights,]\n    method::ExtrinsicEstimation;\n    kwargs...,\n) Estimate the Riemannian center of mass of  x  using  ExtrinsicEstimation , i.e. by computing the mean in the embedding and projecting the result back. See  mean  for a description of the remaining  kwargs . source"},{"id":553,"pagetitle":"Statistics","title":"Statistics.mean","ref":"/manifolds/stable/features/#Statistics.mean-Tuple{AbstractManifold, AbstractVector, AbstractVector, GeodesicInterpolationWithinRadius}","content":" Statistics.mean  ‚Äî  Method mean(\n    M::AbstractManifold,\n    x::AbstractVector,\n    [w::AbstractWeights,]\n    method::GeodesicInterpolationWithinRadius;\n    kwargs...,\n) Estimate the Riemannian center of mass of  x  using  GeodesicInterpolationWithinRadius . See  mean  for a description of  kwargs . source"},{"id":554,"pagetitle":"Statistics","title":"Statistics.mean","ref":"/manifolds/stable/features/#Statistics.mean-Tuple{AbstractManifold, AbstractVector, AbstractVector, GeodesicInterpolation}","content":" Statistics.mean  ‚Äî  Method mean(\n    M::AbstractManifold,\n    x::AbstractVector,\n    [w::AbstractWeights,]\n    method::GeodesicInterpolation;\n    shuffle_rng=nothing,\n    retraction::AbstractRetractionMethod = default_retraction_method(M, eltype(x)),\n    inverse_retraction::AbstractInverseRetractionMethod = default_inverse_retraction_method(M, eltype(x)),\n    kwargs...,\n) Estimate the Riemannian center of mass of  x  in an online fashion using repeated weighted geodesic interpolation. See  GeodesicInterpolation  for details. If  shuffle_rng  is provided, it is used to shuffle the order in which the points are considered for computing the mean. Optionally, pass  retraction  and  inverse_retraction  method types to specify the (inverse) retraction. source"},{"id":555,"pagetitle":"Statistics","title":"Statistics.mean","ref":"/manifolds/stable/features/#Statistics.mean-Tuple{AbstractManifold, Vararg{Any}}","content":" Statistics.mean  ‚Äî  Method mean(M::AbstractManifold, x::AbstractVector[, w::AbstractWeights]; kwargs...) Compute the (optionally weighted) Riemannian center of mass also known as Karcher mean of the vector  x  of points on the  AbstractManifold M , defined as the point that satisfies the minimizer \\[\\operatorname{argmin}_{y ‚àà \\mathcal M} \\frac{1}{2 \\sum_{i=1}^n w_i} \\sum_{i=1}^n w_i\\mathrm{d}_{\\mathcal M}^2(y,x_i),\\] where  $\\mathrm{d}_{\\mathcal M}$  denotes the Riemannian  distance . In the general case, the  GradientDescentEstimation  is used to compute the mean.     mean(         M::AbstractManifold,         x::AbstractVector,         [w::AbstractWeights,]         method::AbstractApproximationMethod=default approximation method(M, mean);         kwargs...,     ) Compute the mean using the specified  method . mean(\n    M::AbstractManifold,\n    x::AbstractVector,\n    [w::AbstractWeights,]\n    method::GradientDescentEstimation;\n    p0=x[1],\n    stop_iter=100,\n    retraction::AbstractRetractionMethod = default_retraction_method(M),\n    inverse_retraction::AbstractInverseRetractionMethod = default_retraction_method(M, eltype(x)),\n    kwargs...,\n) Compute the mean using the gradient descent scheme  GradientDescentEstimation . Optionally, provide  p0 , the starting point (by default set to the first data point).  stop_iter  denotes the maximal number of iterations to perform and the  kwargs...  are passed to  isapprox  to stop, when the minimal change between two iterates is small. For more stopping criteria check the  Manopt.jl  package and use a solver therefrom. Optionally, pass  retraction  and  inverse_retraction  method types to specify the (inverse) retraction. The Theory stems from [ Kar77 ] and is also described in [ PA12 ] as the exponential barycenter. The algorithm is further described in[ ATV13 ]. source"},{"id":556,"pagetitle":"Statistics","title":"Statistics.median!","ref":"/manifolds/stable/features/#Statistics.median!-Tuple{AbstractManifold, Vararg{Any}}","content":" Statistics.median!  ‚Äî  Method median!(M::AbstractManifold, y, x::AbstractVector[, w::AbstractWeights]; kwargs...)\nmedian!(\n    M::AbstractManifold,\n    y,\n    x::AbstractVector,\n    [w::AbstractWeights,]\n    method::AbstractApproximationMethod;\n    kwargs...,\n) computes the  median  in-place in  y . source"},{"id":557,"pagetitle":"Statistics","title":"Statistics.median","ref":"/manifolds/stable/features/#Statistics.median-Tuple{AbstractManifold, AbstractVector, AbstractVector, CyclicProximalPointEstimation}","content":" Statistics.median  ‚Äî  Method median(\n    M::AbstractManifold,\n    x::AbstractVector,\n    [w::AbstractWeights,]\n    method::CyclicProximalPointEstimation;\n    p0=x[1],\n    stop_iter=1000000,\n    retraction::AbstractRetractionMethod = default_retraction_method(M, eltype(x),),\n    inverse_retraction::AbstractInverseRetractionMethod = default_inverse_retraction_method(M, eltype(x),),\n    kwargs...,\n) Compute the median using  CyclicProximalPointEstimation . Optionally, provide  p0 , the starting point (by default set to the first data point).  stop_iter  denotes the maximal number of iterations to perform and the  kwargs...  are passed to  isapprox  to stop, when the minimal change between two iterates is small. For more stopping criteria check the  Manopt.jl  package and use a solver therefrom. Optionally, pass  retraction  and  inverse_retraction  method types to specify the (inverse) retraction. The algorithm is further described in [ Bac14 ]. source"},{"id":558,"pagetitle":"Statistics","title":"Statistics.median","ref":"/manifolds/stable/features/#Statistics.median-Tuple{AbstractManifold, AbstractVector, AbstractVector, ExtrinsicEstimation}","content":" Statistics.median  ‚Äî  Method median(\n    M::AbstractManifold,\n    x::AbstractVector,\n    [w::AbstractWeights,]\n    method::ExtrinsicEstimation;\n    kwargs...,\n) Estimate the median of  x  using  ExtrinsicEstimation , i.e. by computing the median in the embedding and projecting the result back. See  median  for a description of  kwargs . source"},{"id":559,"pagetitle":"Statistics","title":"Statistics.median","ref":"/manifolds/stable/features/#Statistics.median-Tuple{AbstractManifold, AbstractVector, AbstractVector, WeiszfeldEstimation}","content":" Statistics.median  ‚Äî  Method median(\n    M::AbstractManifold,\n    x::AbstractVector,\n    [w::AbstractWeights,]\n    method::WeiszfeldEstimation;\n    Œ± = 1.0,\n    p0=x[1],\n    stop_iter=2000,\n    retraction::AbstractRetractionMethod = default_retraction_method(M, eltype(x)),\n    inverse_retraction::AbstractInverseRetractionMethod = default_inverse_retraction_method(M, eltype(x)),\n    kwargs...,\n) Compute the median using  WeiszfeldEstimation . Optionally, provide  p0 , the starting point (by default set to the first data point).  stop_iter  denotes the maximal number of iterations to perform and the  kwargs...  are passed to  isapprox  to stop, when the minimal change between two iterates is small. For more stopping criteria check the  Manopt.jl  package and use a solver therefrom. The parameter  $Œ±\\in (0,2]$  is a step size. The algorithm is further described in [ FVJ08 ], especially the update rule in Eq. (6), i.e. Let  $q_{k}$  denote the current iterate,  $n$  the number of points  $x_1,\\ldots,x_n$ , and \\[I_k = \\bigl\\{ i \\in \\{1,\\ldots,n\\} \\big| x_i \\neq q_k \\bigr\\}\\] all indices of points that are not equal to the current iterate. Then the update reads  $q_{k+1} = \\exp_{q_k}(Œ±X)$ , where \\[X = \\frac{1}{s}\\sum_{i\\in I_k} \\frac{w_i}{d_{\\mathcal M}(q_k,x_i)}\\log_{q_k}x_i\n\\quad\n\\text{ with }\n\\quad\ns = \\sum_{i\\in I_k} \\frac{w_i}{d_{\\mathcal M}(q_k,x_i)},\\] and where  $\\mathrm{d}_{\\mathcal M}$  denotes the Riemannian  distance . Optionally, pass  retraction  and  inverse_retraction  method types to specify the (inverse) retraction, which by default use the exponential and logarithmic map, respectively. source"},{"id":560,"pagetitle":"Statistics","title":"Statistics.median","ref":"/manifolds/stable/features/#Statistics.median-Tuple{AbstractManifold, Vararg{Any}}","content":" Statistics.median  ‚Äî  Method median(M::AbstractManifold, x::AbstractVector[, w::AbstractWeights]; kwargs...)\nmedian(\n    M::AbstractManifold,\n    x::AbstractVector,\n    [w::AbstractWeights,]\n    method::AbstractApproximationMethod;\n    kwargs...,\n) Compute the (optionally weighted) Riemannian median of the vector  x  of points on the  AbstractManifold M , defined as the point that satisfies the minimizer \\[\\operatorname{argmin}_{y ‚àà \\mathcal M} \\frac{1}{\\sum_{i=1}^n w_i} \\sum_{i=1}^n w_i\\mathrm{d}_{\\mathcal M}(y,x_i),\\] where  $\\mathrm{d}_{\\mathcal M}$  denotes the Riemannian  distance . This function is nonsmooth (i.e nondifferentiable). In the general case, the  CyclicProximalPointEstimation  is used to compute the median. However, this default may be overloaded for specific manifolds. Compute the median using the specified  method . source"},{"id":561,"pagetitle":"Statistics","title":"Statistics.std","ref":"/manifolds/stable/features/#Statistics.std-Tuple{AbstractManifold, Vararg{Any}}","content":" Statistics.std  ‚Äî  Method std(M, x, m=mean(M, x); corrected=true, kwargs...)\nstd(M, x, w::AbstractWeights, m=mean(M, x, w); corrected=false, kwargs...) compute the optionally weighted standard deviation of a  Vector x  of  n  data points on the  AbstractManifold M , i.e. \\[\\sqrt{\\frac{1}{c} \\sum_{i=1}^n w_i d_{\\mathcal M}^2 (x_i,m)},\\] where  c  is a correction term, see  Statistics.std . The mean of  x  can be specified as  m , and the corrected variance can be activated by setting  corrected=true . source"},{"id":562,"pagetitle":"Statistics","title":"Statistics.var","ref":"/manifolds/stable/features/#Statistics.var-Tuple{AbstractManifold, Any}","content":" Statistics.var  ‚Äî  Method var(M, x, m=mean(M, x); corrected=true)\nvar(M, x, w::AbstractWeights, m=mean(M, x, w); corrected=false) compute the (optionally weighted) variance of a  Vector x  of  n  data points on the  AbstractManifold M , i.e. \\[\\frac{1}{c} \\sum_{i=1}^n w_i d_{\\mathcal M}^2 (x_i,m),\\] where  c  is a correction term, see  Statistics.var . The mean of  x  can be specified as  m , and the corrected variance can be activated by setting  corrected=true . All further  kwargs...  are passed to the computation of the mean (if that is not provided). source"},{"id":563,"pagetitle":"Statistics","title":"StatsBase.kurtosis","ref":"/manifolds/stable/features/#StatsBase.kurtosis-Tuple{AbstractManifold, AbstractVector, StatsBase.AbstractWeights}","content":" StatsBase.kurtosis  ‚Äî  Method kurtosis(M::AbstractManifold, x::AbstractVector, k::Int[, w::AbstractWeights], m=mean(M, x[, w])) Compute the excess kurtosis of points in  x  on manifold  M . Optionally provide weights  w  and/or a precomputed  mean m . source"},{"id":564,"pagetitle":"Statistics","title":"StatsBase.mean_and_std","ref":"/manifolds/stable/features/#StatsBase.mean_and_std-Tuple{AbstractManifold, Vararg{Any}}","content":" StatsBase.mean_and_std  ‚Äî  Method mean_and_std(M::AbstractManifold, x::AbstractVector[, w::AbstractWeights]; kwargs...) -> (mean, std) Compute the  mean  and the standard deviation  std  simultaneously. mean_and_std(\n    M::AbstractManifold,\n    x::AbstractVector\n    [w::AbstractWeights,]\n    method::AbstractApproximationMethod;\n    kwargs...,\n) -> (mean, var) Use the  method  for simultaneously computing the mean and standard deviation. To use a mean-specific method, call  mean  and then  std . source"},{"id":565,"pagetitle":"Statistics","title":"StatsBase.mean_and_var","ref":"/manifolds/stable/features/#StatsBase.mean_and_var-Tuple{AbstractManifold, AbstractVector, StatsBase.AbstractWeights, GeodesicInterpolationWithinRadius}","content":" StatsBase.mean_and_var  ‚Äî  Method mean_and_var(\n    M::AbstractManifold,\n    x::AbstractVector\n    [w::AbstractWeights,]\n    method::GeodesicInterpolationWithinRadius;\n    kwargs...,\n) -> (mean, var) Use repeated weighted geodesic interpolation to estimate the mean. Simultaneously, use a Welford-like recursion to estimate the variance. See  GeodesicInterpolationWithinRadius  and  mean_and_var  for more information. source"},{"id":566,"pagetitle":"Statistics","title":"StatsBase.mean_and_var","ref":"/manifolds/stable/features/#StatsBase.mean_and_var-Tuple{AbstractManifold, AbstractVector, StatsBase.AbstractWeights, GeodesicInterpolation}","content":" StatsBase.mean_and_var  ‚Äî  Method mean_and_var(\n    M::AbstractManifold,\n    x::AbstractVector\n    [w::AbstractWeights,]\n    method::GeodesicInterpolation;\n    shuffle_rng::Union{AbstractRNG,Nothing} = nothing,\n    retraction::AbstractRetractionMethod = default_retraction_method(M, eltype(x)),\n    inverse_retraction::AbstractInverseRetractionMethod = default_inverse_retraction_method(M, eltype(x)),\n    kwargs...,\n) -> (mean, var) Use the repeated weighted geodesic interpolation to estimate the mean. Simultaneously, use a Welford-like recursion to estimate the variance. If  shuffle_rng  is provided, it is used to shuffle the order in which the points are considered. Optionally, pass  retraction  and  inverse_retraction  method types to specify the (inverse) retraction. See  GeodesicInterpolation  for details on the geodesic interpolation method. Note The Welford algorithm for the variance is experimental and is not guaranteed to give accurate results except on  Euclidean . source"},{"id":567,"pagetitle":"Statistics","title":"StatsBase.mean_and_var","ref":"/manifolds/stable/features/#StatsBase.mean_and_var-Tuple{AbstractManifold, Vararg{Any}}","content":" StatsBase.mean_and_var  ‚Äî  Method mean_and_var(M::AbstractManifold, x::AbstractVector[, w::AbstractWeights]; kwargs...) -> (mean, var) Compute the  mean  and the  var iance simultaneously. See those functions for a description of the arguments. mean_and_var(\n    M::AbstractManifold,\n    x::AbstractVector\n    [w::AbstractWeights,]\n    method::AbstractApproximationMethod;\n    kwargs...,\n) -> (mean, var) Use the  method  for simultaneously computing the mean and variance. To use a mean-specific method, call  mean  and then  var . source"},{"id":568,"pagetitle":"Statistics","title":"StatsBase.moment","ref":"/manifolds/stable/features/#StatsBase.moment","content":" StatsBase.moment  ‚Äî  Function moment(M::AbstractManifold, x::AbstractVector, k::Int[, w::AbstractWeights], m=mean(M, x[, w])) Compute the  k th central moment of points in  x  on manifold  M . Optionally provide weights  w  and/or a precomputed  mean . source"},{"id":569,"pagetitle":"Statistics","title":"StatsBase.skewness","ref":"/manifolds/stable/features/#StatsBase.skewness-Tuple{AbstractManifold, AbstractVector, StatsBase.AbstractWeights}","content":" StatsBase.skewness  ‚Äî  Method skewness(M::AbstractManifold, x::AbstractVector, k::Int[, w::AbstractWeights], m=mean(M, x[, w])) Compute the standardized skewness of points in  x  on manifold  M . Optionally provide weights  w  and/or a precomputed  mean m . source"},{"id":570,"pagetitle":"Statistics","title":"Literature","ref":"/manifolds/stable/features/#Literature","content":" Literature [ATV13] B.¬†Afsari, R.¬†Tron and R.¬†Vidal.  On the Convergence of Gradient Descent for Finding the Riemannian Center of Mass .  SIAM¬†Journal¬†on¬†Control¬†and¬†Optimization  51 , 2230‚Äì2260  (2013),  arXiv:1201.0925 . [Bac14] M.¬†Baƒç√°k.  Computing medians and means in Hadamard spaces .  SIAM¬†Journal¬†on¬†Optimization  24 , 1542‚Äì1566  (2014),  arXiv:1210.2145 . [FVJ08] P.¬†T.¬†Fletcher, S.¬†Venkatasubramanian and S.¬†Joshi.  Robust statistics on Riemannian manifolds via the geometric median . In:  2008 IEEE Conference on Computer Vision and Pattern Recognition  (2008). [Kar77] H.¬†Karcher.  Riemannian center of mass and mollifier smoothing .  Communications¬†on¬†Pure¬†and¬†Applied¬†Mathematics  30 , 509‚Äì541  (1977). [Pen06] X.¬†Pennec.  Intrinsic Statistics on Riemannian Manifolds: Basic Tools for Geometric Measurements .  Journal¬†of¬†Mathematical¬†Imaging¬†and¬†Vision  25 , 127‚Äì154  (2006). [PA12] X.¬†Pennec and V.¬†Arsigny.  Exponential Barycenters of the Canonical Cartan Connection and Invariant Means on Lie Groups . In:  Matrix Information Geometry  (Springer, Berlin, Heidelberg, 2012); pp.¬†123‚Äì166,  arXiv:00699361 ."},{"id":573,"pagetitle":"Testing","title":"Testing","ref":"/manifolds/stable/features/#Testing","content":" Testing Documentation for testing utilities for  Manifolds.jl . The function  test_manifold  can be used to verify that your manifold correctly implements the  Manifolds.jl  interface. Similarly  test_group  and  test_action  can be used to verify implementation of groups and group actions."},{"id":574,"pagetitle":"Testing","title":"Manifolds.test_action","ref":"/manifolds/stable/features/#Manifolds.test_action","content":" Manifolds.test_action  ‚Äî  Function test_action(\n    A::AbstractGroupAction,\n    a_pts::AbstractVector,\n    m_pts::AbstractVector,\n    X_pts = [];\n    atol = 1e-10,\n    atol_ident_compose = 0,\n    test_optimal_alignment = false,\n    test_mutating_group=true,\n    test_mutating_action=true,\n    test_diff = false,\n    test_switch_direction = true,\n) Tests general properties of the action  A , given at least three different points that lie on it (contained in  a_pts ) and three different point that lie on the manifold it acts upon (contained in  m_pts ). Arguments atol_ident_compose = 0 : absolute tolerance for the test that composition with identity doesn't change the group element. source"},{"id":575,"pagetitle":"Testing","title":"Manifolds.test_group","ref":"/manifolds/stable/features/#Manifolds.test_group","content":" Manifolds.test_group  ‚Äî  Function test_group(\n    G,\n    g_pts::AbstractVector,\n    X_pts::AbstractVector=[],\n    Xe_pts::AbstractVector=[];\n    atol::Real=1e-10,\n    test_mutating::Bool=true,\n    test_exp_lie_log::Bool=true,\n    test_diff::Bool=false,\n    test_invariance::Bool=false,\n    test_lie_bracket::Bool=false,\n    test_adjoint_action::Bool=false,\n    test_inv_diff::Bool=false,\n    test_adjoint_inv_diff::Bool=false,\n    test_apply_diff_group::Bool=false,\n    diff_convs = [(), (LeftForwardAction(),), (RightBackwardAction(),)],\n) Tests general properties of the group  G , given at least three different points elements of it (contained in  g_pts ). Optionally, specify  test_diff  to test differentials of translation, using  X_pts , which must contain at least one tangent vector at  g_pts[1] , and the direction conventions specified in  diff_convs .  Xe_pts  should contain tangent vectors at identity for testing Lie algebra operations. If the group is equipped with an invariant metric,  test_invariance  indicates that the invariance should be checked for the provided points. source"},{"id":576,"pagetitle":"Testing","title":"Manifolds.test_manifold","ref":"/manifolds/stable/features/#Manifolds.test_manifold","content":" Manifolds.test_manifold  ‚Äî  Function test_manifold(\n    M::AbstractManifold,\n    pts::AbstractVector;\n    args,\n) Test general properties of manifold  M , given at least three different points that lie on it (contained in  pts ). Arguments basis_has_specialized_diagonalizing_get = false : if true, assumes that    DiagonalizingOrthonormalBasis  given in  basis_types  has    get_coordinates  and  get_vector  that work without caching. basis_types_to_from = () : basis types that will be tested based on    get_coordinates  and  get_vector . basis_types_vecs = ()  : basis types that will be tested based on  get_vectors default_inverse_retraction_method = ManifoldsBase.LogarithmicInverseRetraction() :   default method for inverse retractions ( log . default_retraction_method = ManifoldsBase.ExponentialRetraction() : default method for   retractions ( exp ). exp_log_atol_multiplier = 0 : change absolute tolerance of exp/log tests   (0 use default, i.e. deactivate atol and use rtol). exp_log_rtol_multiplier = 1 : change the relative tolerance of exp/log tests   (1 use default). This is deactivated if the  exp_log_atol_multiplier  is nonzero. expected_dimension_type = Integer : expected type of value returned by    manifold_dimension . inverse_retraction_methods = [] : inverse retraction methods that will be tested. is_mutating = true : whether mutating variants of functions should be tested. is_point_atol_multiplier = 0 : determines atol of  is_point  checks. is_tangent_atol_multiplier = 0 : determines atol of  is_vector  checks. mid_point12 = test_exp_log ? shortest_geodesic(M, pts[1], pts[2], 0.5) : nothing : if not  nothing , then check   that  mid_point(M, pts[1], pts[2])  is approximately equal to  mid_point12 . This is   by default set to  nothing  if  text_exp_log  is set to false. point_distributions = []  : point distributions to test. rand_tvector_atol_multiplier = 0  : chage absolute tolerance in testing random vectors   (0 use default, i.e. deactivate atol and use rtol) random tangent vectors are tangent   vectors. retraction_atol_multiplier = 0 : change absolute tolerance of (inverse) retraction tests   (0 use default, i.e. deactivate atol and use rtol). retraction_rtol_multiplier = 1 : change the relative tolerance of (inverse) retraction   tests (1 use default). This is deactivated if the  exp_log_atol_multiplier  is nonzero. retraction_methods = [] : retraction methods that will be tested. test_atlases = [] : Vector or tuple of atlases that should be tested. test_exp_log = true : if true, check that  exp  is the inverse of  log . test_injectivity_radius = true : whether implementation of  injectivity_radius    should be tested. test_inplace = false  : if true check if inplace variants work if they are activated,  e.g. check that  exp!(M, p, p, X)  work if  test_exp_log = true .  This in general requires  is_mutating  to be true. test_is_tangent : if true check that the  default_inverse_retraction_method    actually returns valid tangent vectors. test_musical_isomorphisms = false  : test musical isomorphisms. test_mutating_rand = false  : test the mutating random function for points on manifolds. test_project_point = false : test projections onto the manifold. test_project_tangent = false  : test projections on tangent spaces. test_representation_size = true  : test repersentation size of points/tvectprs. test_tangent_vector_broadcasting = true  : test boradcasting operators on TangentSpace. test_vector_spaces = true  : test Vector bundle of this manifold. test_default_vector_transport = false  : test the default vector transport (usually  parallel transport). test_vee_hat = false : test  vee  and  hat  functions. tvector_distributions = []  : tangent vector distributions to test. vector_transport_methods = [] : vector transport methods that should be tested. vector_transport_inverse_retractions = [default_inverse_retraction_method for _ in 1:length(vector_transport_methods)] ` inverse retractions to use with the vector transport method (especially the differentiated ones) vector_transport_to = [ true for _ in 1:length(vector_transport_methods)] : whether  to check the  to  variant of vector transport vector_transport_direction = [ true for _ in 1:length(vector_transport_methods)] : whether  to check the  direction  variant of vector transport source"},{"id":577,"pagetitle":"Testing","title":"Manifolds.find_eps","ref":"/manifolds/stable/features/#Manifolds.find_eps","content":" Manifolds.find_eps  ‚Äî  Function find_eps(x...) Find an appropriate tolerance for given points or tangent vectors, or their types. source"},{"id":578,"pagetitle":"Testing","title":"Manifolds.test_parallel_transport","ref":"/manifolds/stable/features/#Manifolds.test_parallel_transport","content":" Manifolds.test_parallel_transport  ‚Äî  Function test_parallel_transport(M,P; along=false, to=true, diretion=true) Generic tests for parallel transport on  M given at least two pointsin  P . The single functions to transport  along  (a curve),  to  (a point) or (towards a)  direction  are sub-tests that can be activated by the keywords arguemnts !!! Note Since the interface to specify curves is not yet provided, the along keyword does not have an effect yet source"},{"id":581,"pagetitle":"Utilities","title":"Utilities","ref":"/manifolds/stable/features/#Utilities","content":" Utilities"},{"id":582,"pagetitle":"Utilities","title":"Ease of notation","ref":"/manifolds/stable/features/#Ease-of-notation","content":" Ease of notation The following terms introduce a nicer notation for some operations, for example using the ‚àà operator,  $p ‚àà \\mathcal M$  to determine whether  $p$  is a point on the  AbstractManifold $\\mathcal M$ ."},{"id":583,"pagetitle":"Utilities","title":"Base.in","ref":"/manifolds/stable/features/#Base.in","content":" Base.in  ‚Äî  Function Base.in(p, M::AbstractManifold; kwargs...)\np ‚àà M Check, whether a point  p  is a valid point (i.e. in) a  AbstractManifold M . This method employs  is_point  deactivating the error throwing option. source Base.in(p, TpM::TangentSpace; kwargs...)\nX ‚àà TangentSpace(M, p) Check whether  X  is a tangent vector from (in) the tangent space  $T_p\\mathcal M$ , i.e. the  TangentSpace  at  p  on the  AbstractManifold M . This method uses  is_vector  deactivating the error throw option. source"},{"id":584,"pagetitle":"Utilities","title":"Public documentation","ref":"/manifolds/stable/features/#Public-documentation","content":" Public documentation"},{"id":585,"pagetitle":"Utilities","title":"Manifolds.sectional_curvature_matrix","ref":"/manifolds/stable/features/#Manifolds.sectional_curvature_matrix","content":" Manifolds.sectional_curvature_matrix  ‚Äî  Function sectional_curvature_matrix(M::AbstractManifold, p, B::AbstractBasis) Compute the matrix of sectional curvatures of manifold  M  at point  p . Entry  (i, j)  corresponds to sectional curvature of the surface spanned by vectors  i   and  j  from basis  B . source"},{"id":586,"pagetitle":"Utilities","title":"Specific exception types","ref":"/manifolds/stable/features/#Specific-exception-types","content":" Specific exception types For some manifolds it is useful to keep an extra index, at which point on the manifold, the error occurred as well as to collect all errors that occurred on a manifold. This page contains the manifold-specific error messages this package introduces."},{"id":589,"pagetitle":"Centered matrices","title":"Centered matrices","ref":"/manifolds/stable/manifolds/#Centered-matrices","content":" Centered matrices"},{"id":590,"pagetitle":"Centered matrices","title":"Manifolds.CenteredMatrices","ref":"/manifolds/stable/manifolds/#Manifolds.CenteredMatrices","content":" Manifolds.CenteredMatrices  ‚Äî  Type CenteredMatrices{T,ùîΩ} <: AbstractDecoratorManifold{ùîΩ} The manifold of  $m√ón$  real-valued or complex-valued matrices whose columns sum to zero, i.e. \\[\\bigl\\{ p ‚àà ùîΩ^{m√ón}\\ \\big|\\ [1 ‚Ä¶ 1] * p = [0 ‚Ä¶ 0] \\bigr\\},\\] where  $ùîΩ ‚àà \\{‚Ñù,‚ÑÇ\\}$ . Constructor CenteredMatrices(m, n[, field=‚Ñù]; parameter::Symbol=:type) Generate the manifold of  m -by- n  ( field -valued) matrices whose columns sum to zero. parameter : whether a type parameter should be used to store  m  and  n . By default size is stored in type. Value can either be  :field  or  :type . source"},{"id":591,"pagetitle":"Centered matrices","title":"ManifoldsBase.Weingarten","ref":"/manifolds/stable/manifolds/#ManifoldsBase.Weingarten-Tuple{CenteredMatrices, Any, Any, Any}","content":" ManifoldsBase.Weingarten  ‚Äî  Method Y = Weingarten(M::CenteredMatrices, p, X, V)\nWeingarten!(M::CenteredMatrices, Y, p, X, V) Compute the Weingarten map  $\\mathcal W_p$  at  p  on the  CenteredMatrices M  with respect to the tangent vector  $X \\in T_p\\mathcal M$  and the normal vector  $V \\in N_p\\mathcal M$ . Since this a flat space by itself, the result is always the zero tangent vector. source"},{"id":592,"pagetitle":"Centered matrices","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Union{Tuple{T}, Tuple{CenteredMatrices, T}} where T","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::CenteredMatrices, p; kwargs...) Check whether the matrix is a valid point on the  CenteredMatrices M , i.e. is an  m -by- n  matrix whose columns sum to zero. The tolerance for the column sums of  p  can be set using  kwargs... . source"},{"id":593,"pagetitle":"Centered matrices","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Union{Tuple{T}, Tuple{CenteredMatrices, Any, T}} where T","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::CenteredMatrices, p, X; kwargs... ) Check whether  X  is a tangent vector to manifold point  p  on the  CenteredMatrices M , i.e. that  X  is a matrix of size  (m, n)  whose columns sum to zero and its values are from the correct  AbstractNumbers . The tolerance for the column sums of  p  and  X  can be set using  kwargs... . source"},{"id":594,"pagetitle":"Centered matrices","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{CenteredMatrices}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::CenteredMatrices) Return true.  CenteredMatrices  is a flat manifold. source"},{"id":595,"pagetitle":"Centered matrices","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Union{Tuple{CenteredMatrices{<:Any, ùîΩ}}, Tuple{ùîΩ}} where ùîΩ","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::CenteredMatrices) Return the manifold dimension of the  CenteredMatrices m -by- n  matrix  M  over the number system  ùîΩ , i.e. \\[\\dim(\\mathcal M) = (m*n - n) \\dim_‚Ñù ùîΩ,\\] where  $\\dim_‚Ñù ùîΩ$  is the  real_dimension  of  ùîΩ . source"},{"id":596,"pagetitle":"Centered matrices","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{CenteredMatrices, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::CenteredMatrices, p, X) Project the matrix  X  onto the tangent space at  p  on the  CenteredMatrices M , i.e. \\[\\operatorname{proj}_p(X) = X - \\begin{bmatrix}\n1\\\\\n‚ãÆ\\\\\n1\n\\end{bmatrix} * [c_1 \\dots c_n],\\] where  $c_i = \\frac{1}{m}\\sum_{j=1}^m x_{j,i}$   for  $i = 1, \\dots, n$ . source"},{"id":597,"pagetitle":"Centered matrices","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{CenteredMatrices, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::CenteredMatrices, p) Projects  p  from the embedding onto the  CenteredMatrices M , i.e. \\[\\operatorname{proj}_{\\mathcal M}(p) = p - \\begin{bmatrix}\n1\\\\\n‚ãÆ\\\\\n1\n\\end{bmatrix} * [c_1 \\dots c_n],\\] where  $c_i = \\frac{1}{m}\\sum_{j=1}^m p_{j,i}$  for  $i = 1, \\dots, n$ . source"},{"id":600,"pagetitle":"Cholesky space","title":"Cholesky space","ref":"/manifolds/stable/manifolds/#Cholesky-space","content":" Cholesky space The Cholesky space is a Riemannian manifold on the lower triangular matrices. Its metric is based on the cholesky decomposition. The  CholeskySpace  is used to define the  LogCholeskyMetric  on the manifold of   SymmetricPositiveDefinite  matrices."},{"id":601,"pagetitle":"Cholesky space","title":"Manifolds.CholeskySpace","ref":"/manifolds/stable/manifolds/#Manifolds.CholeskySpace","content":" Manifolds.CholeskySpace  ‚Äî  Type CholeskySpace{T} <: AbstractManifold{‚Ñù} The manifold of lower triangular matrices with positive diagonal and a metric based on the cholesky decomposition. The formulae for this manifold are for example summarized in Table 1 of [ Lin19 ]. Constructor CholeskySpace(n; parameter::Symbol=:type) Generate the manifold of  $n√ón$  lower triangular matrices with positive diagonal. source"},{"id":602,"pagetitle":"Cholesky space","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{CholeskySpace, Vararg{Any}}","content":" Base.exp  ‚Äî  Method exp(M::CholeskySpace, p, X) Compute the exponential map on the  CholeskySpace M  emanating from the lower triangular matrix with positive diagonal  p  towards the lower triangular matrix  X  The formula reads \\[\\exp_p X = ‚åä p ‚åã + ‚åä X ‚åã + \\operatorname{diag}(p)\n\\operatorname{diag}(p)\\exp\\bigl( \\operatorname{diag}(X)\\operatorname{diag}(p)^{-1}\\bigr),\\] where  $‚åä‚ãÖ‚åã$  denotes the strictly lower triangular matrix, and  $\\operatorname{diag}$  extracts the diagonal matrix. source"},{"id":603,"pagetitle":"Cholesky space","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{LinearAlgebra.Cholesky, Vararg{Any}}","content":" Base.log  ‚Äî  Method log(M::CholeskySpace, X, p, q) Compute the logarithmic map on the  CholeskySpace M  for the geodesic emanating from the lower triangular matrix with positive diagonal  p  towards  q . The formula reads \\[\\log_p q = ‚åä p ‚åã - ‚åä q ‚åã + \\operatorname{diag}(p)\\log\\bigl(\\operatorname{diag}(q)\\operatorname{diag}(p)^{-1}\\bigr),\\] where  $‚åä‚ãÖ‚åã$  denotes the strictly lower triangular matrix, and  $\\operatorname{diag}$  extracts the diagonal matrix. source"},{"id":604,"pagetitle":"Cholesky space","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Union{Tuple{T}, Tuple{CholeskySpace, T}} where T","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::CholeskySpace, p; kwargs...) Check whether the matrix  p  lies on the  CholeskySpace M , i.e. it's size fits the manifold, it is a lower triangular matrix and has positive entries on the diagonal. The tolerance for the tests can be set using the  kwargs... . source"},{"id":605,"pagetitle":"Cholesky space","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{CholeskySpace, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::CholeskySpace, p, X; kwargs... ) Check whether  v  is a tangent vector to  p  on the  CholeskySpace M , i.e. after  check_point (M,p) ,  X  has to have the same dimension as  p  and a symmetric matrix. The tolerance for the tests can be set using the  kwargs... . source"},{"id":606,"pagetitle":"Cholesky space","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{CholeskySpace, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::CholeskySpace, p, q) Compute the Riemannian distance on the  CholeskySpace M  between two matrices  p ,  q  that are lower triangular with positive diagonal. The formula reads \\[d_{\\mathcal M}(p,q) = \\sqrt{\\sum_{i>j} (p_{ij}-q_{ij})^2 +\n\\sum_{j=1}^m (\\log p_{jj} - \\log q_{jj})^2\n}\\] source"},{"id":607,"pagetitle":"Cholesky space","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{CholeskySpace, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::CholeskySpace, p, X, Y) Compute the inner product on the  CholeskySpace M  at the lower triangular matric with positive diagonal  p  and the two tangent vectors  X , Y , i.e they are both lower triangular matrices with arbitrary diagonal. The formula reads \\[g_p(X,Y) = \\sum_{i>j} X_{ij}Y_{ij} + \\sum_{j=1}^m X_{ii}Y_{ii}p_{ii}^{-2}\\] source"},{"id":608,"pagetitle":"Cholesky space","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{CholeskySpace}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::CholeskySpace) Return true.  CholeskySpace  is a flat manifold. See Proposition 8 of [ Lin19 ]. source"},{"id":609,"pagetitle":"Cholesky space","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{CholeskySpace}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::CholeskySpace) Return the manifold dimension for the  CholeskySpace M , i.e. \\[    \\dim(\\mathcal M) = \\frac{N(N+1)}{2}.\\] source"},{"id":610,"pagetitle":"Cholesky space","title":"ManifoldsBase.parallel_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_to-Tuple{CholeskySpace, Any, Any, Any}","content":" ManifoldsBase.parallel_transport_to  ‚Äî  Method parallel_transport_to(M::CholeskySpace, p, X, q) Parallely transport the tangent vector  X  at  p  along the geodesic to  q  on the  CholeskySpace  manifold  M . The formula reads \\[\\mathcal P_{q‚Üêp}(X) = ‚åä X ‚åã\n+ \\operatorname{diag}(q)\\operatorname{diag}(p)^{-1}\\operatorname{diag}(X),\\] where  $‚åä‚ãÖ‚åã$  denotes the strictly lower triangular matrix, and  $\\operatorname{diag}$  extracts the diagonal matrix. source"},{"id":611,"pagetitle":"Cholesky space","title":"ManifoldsBase.representation_size","ref":"/manifolds/stable/manifolds/#ManifoldsBase.representation_size-Tuple{CholeskySpace}","content":" ManifoldsBase.representation_size  ‚Äî  Method representation_size(M::CholeskySpace) Return the representation size for the  CholeskySpace {N} M , i.e.  (N,N) . source"},{"id":612,"pagetitle":"Cholesky space","title":"ManifoldsBase.zero_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.zero_vector-Tuple{CholeskySpace, Vararg{Any}}","content":" ManifoldsBase.zero_vector  ‚Äî  Method zero_vector(M::CholeskySpace, p) Return the zero tangent vector on the  CholeskySpace M  at  p . source"},{"id":613,"pagetitle":"Cholesky space","title":"Literature","ref":"/manifolds/stable/manifolds/#Literature","content":" Literature"},{"id":616,"pagetitle":"Circle","title":"Circle","ref":"/manifolds/stable/manifolds/#Circle","content":" Circle"},{"id":617,"pagetitle":"Circle","title":"Manifolds.Circle","ref":"/manifolds/stable/manifolds/#Manifolds.Circle","content":" Manifolds.Circle  ‚Äî  Type Circle{ùîΩ} <: AbstractManifold{ùîΩ} The circle  $ùïä^1$  is a manifold here represented by real-valued points in  $[-œÄ,œÄ)$  or complex-valued points  $z ‚àà ‚ÑÇ$  of absolute value  $\\lvert z\\rvert = 1$ . Constructor Circle(ùîΩ=‚Ñù) Generate the  ‚Ñù -valued Circle represented by angles, which alternatively can be set to use the  AbstractNumbers ùîΩ=‚ÑÇ  to obtain the circle represented by  ‚ÑÇ -valued circle of unit numbers. source"},{"id":618,"pagetitle":"Circle","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{Circle, Vararg{Any}}","content":" Base.exp  ‚Äî  Method exp(M::Circle, p, X) Compute the exponential map on the  Circle . \\[\\exp_p X = (p+X)_{2œÄ},\\] where  $(‚ãÖ)_{2œÄ}$  is the (symmetric) remainder with respect to division by  $2œÄ$ , i.e. in  $[-œÄ,œÄ)$ . For the complex-valued case, the same formula as for the  Sphere $ùïä^1$  is applied to values in the complex plane. source"},{"id":619,"pagetitle":"Circle","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{Circle, Vararg{Any}}","content":" Base.log  ‚Äî  Method log(M::Circle, p, q) Compute the logarithmic map on the  Circle M . \\[\\log_p q = (q-p)_{2œÄ},\\] where  $(‚ãÖ)_{2œÄ}$  is the (symmetric) remainder with respect to division by  $2œÄ$ , i.e. in  $[-œÄ,œÄ)$ . For the complex-valued case, the same formula as for the  Sphere $ùïä^1$  is applied to values in the complex plane. source"},{"id":620,"pagetitle":"Circle","title":"Base.rand","ref":"/manifolds/stable/manifolds/#Base.rand-Tuple{Circle}","content":" Base.rand  ‚Äî  Method Random.rand(M::Circle{‚Ñù}; vector_at = nothing, œÉ::Real=1.0) If  vector_at  is  nothing , return a random point on the  Circle $\\mathbb S^1$  by picking a random element from  $[-\\pi,\\pi)$  uniformly. If  vector_at  is not  nothing , return a random tangent vector from the tangent space of the point  vector_at  on the  Circle  by using a normal distribution with mean 0 and standard deviation  œÉ . source"},{"id":621,"pagetitle":"Circle","title":"Manifolds.complex_dot","ref":"/manifolds/stable/manifolds/#Manifolds.complex_dot-Tuple{Any, Any}","content":" Manifolds.complex_dot  ‚Äî  Method complex_dot(a, b) Compute the inner product of two (complex) numbers with in the complex plane. source"},{"id":622,"pagetitle":"Circle","title":"Manifolds.manifold_volume","ref":"/manifolds/stable/manifolds/#Manifolds.manifold_volume-Tuple{Circle}","content":" Manifolds.manifold_volume  ‚Äî  Method manifold_volume(M::Circle) Return the volume of the  Circle M , i.e.  $2œÄ$ . source"},{"id":623,"pagetitle":"Circle","title":"Manifolds.sym_rem","ref":"/manifolds/stable/manifolds/#Manifolds.sym_rem-Union{Tuple{N}, Tuple{N, Any}} where N<:Number","content":" Manifolds.sym_rem  ‚Äî  Method sym_rem(x,[T=œÄ]) Compute symmetric remainder of  x  with respect to the interall 2* T , i.e.  (x+T)%2T , where the default for  T  is  $œÄ$ source"},{"id":624,"pagetitle":"Circle","title":"Manifolds.volume_density","ref":"/manifolds/stable/manifolds/#Manifolds.volume_density-Tuple{Circle, Any, Any}","content":" Manifolds.volume_density  ‚Äî  Method volume_density(::Circle, p, X) Return volume density of  Circle , i.e. 1. source"},{"id":625,"pagetitle":"Circle","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{Circle, Vararg{Any}}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::Circle, p) Check whether  p  is a point on the  Circle M . For the real-valued case,  p  is an angle and hence it checks that  $p ‚àà [-œÄ,œÄ)$ . for the complex-valued case, it is a unit number,  $p ‚àà ‚ÑÇ$  with  $\\lvert p \\rvert = 1$ . source"},{"id":626,"pagetitle":"Circle","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{Circle{‚Ñù}, Vararg{Any}}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::Circle, p, X; kwargs...) Check whether  X  is a tangent vector in the tangent space of  p  on the  Circle M . For the real-valued case represented by angles, all  X  are valid, since the tangent space is the whole real line. For the complex-valued case  X  has to lie on the line parallel to the tangent line at  p  in the complex plane, i.e. their inner product has to be zero. source"},{"id":627,"pagetitle":"Circle","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{Circle, Vararg{Any}}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::Circle, p, q) Compute the distance on the  Circle M , which is the absolute value of the symmetric remainder of  p  and  q  for the real-valued case and the angle between both complex numbers in the Gaussian plane for the complex-valued case. source"},{"id":628,"pagetitle":"Circle","title":"ManifoldsBase.embed","ref":"/manifolds/stable/manifolds/#ManifoldsBase.embed-Tuple{Circle, Any, Any}","content":" ManifoldsBase.embed  ‚Äî  Method embed(M::Circle, p, X) Embed a tangent vector  X  at  p  on  Circle M  in the ambient space. It returns  X . source"},{"id":629,"pagetitle":"Circle","title":"ManifoldsBase.embed","ref":"/manifolds/stable/manifolds/#ManifoldsBase.embed-Tuple{Circle, Any}","content":" ManifoldsBase.embed  ‚Äî  Method embed(M::Circle, p) Embed a point  p  on  Circle M  in the ambient space. It returns  p . source"},{"id":630,"pagetitle":"Circle","title":"ManifoldsBase.get_coordinates","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_coordinates-Tuple{Circle{‚ÑÇ}, Any, Any, DefaultOrthonormalBasis{<:Any, TangentSpaceType}}","content":" ManifoldsBase.get_coordinates  ‚Äî  Method get_coordinates(M::Circle{‚ÑÇ}, p, X, B::DefaultOrthonormalBasis) Return tangent vector coordinates in the Lie algebra of the  Circle . source"},{"id":631,"pagetitle":"Circle","title":"ManifoldsBase.get_vector_orthonormal","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_vector_orthonormal-Tuple{Circle{‚ÑÇ}, Any, Any, Union{ManifoldsBase.ComplexNumbers, ManifoldsBase.RealNumbers}}","content":" ManifoldsBase.get_vector_orthonormal  ‚Äî  Method get_vector(M::Circle{‚ÑÇ}, p, X, B::DefaultOrthonormalBasis) Return tangent vector from the coordinates in the Lie algebra of the  Circle . source"},{"id":632,"pagetitle":"Circle","title":"ManifoldsBase.injectivity_radius","ref":"/manifolds/stable/manifolds/#ManifoldsBase.injectivity_radius-Tuple{Circle}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(M::Circle[, p]) Return the injectivity radius on the  Circle M , i.e.  $œÄ$ . source"},{"id":633,"pagetitle":"Circle","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{Circle, Vararg{Any}}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::Circle, p, X, Y) Compute the inner product of the two tangent vectors  X,Y  from the tangent plane at  p  on the  Circle M  using the restriction of the metric from the embedding, i.e. \\[g_p(X,Y) = X*Y\\] for the real case and \\[g_p(X,Y) = Y^\\mathrm{T}X\\] for the complex case interpreting complex numbers in the Gaussian plane. source"},{"id":634,"pagetitle":"Circle","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{Circle}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::Circle) Return true.  Circle  is a flat manifold. source"},{"id":635,"pagetitle":"Circle","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{Circle}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::Circle) Return the dimension of the  Circle M , i.e.  $\\dim(ùïä^1) = 1$ . source"},{"id":636,"pagetitle":"Circle","title":"ManifoldsBase.parallel_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_to-Tuple{Circle, Any, Any, Any}","content":" ManifoldsBase.parallel_transport_to  ‚Äî  Method  parallel_transport_to(M::Circle, p, X, q) Compute the parallel transport of  X  from the tangent space at  p  to the tangent space at  q  on the  Circle M . For the real-valued case this results in the identity. For the complex-valud case, the formula is the same as for the  Sphere (1)  in the complex plane. \\[\\mathcal P_{q‚Üêp} X = X - \\frac{‚ü®\\log_p q,X‚ü©_p}{d^2_{‚ÑÇ}(p,q)}\n\\bigl(\\log_p q + \\log_q p \\bigr),\\] where  log  denotes the logarithmic map on  M . source"},{"id":637,"pagetitle":"Circle","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Circle, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::Circle, p, X) Project a value  X  onto the tangent space of the point  p  on the  Circle M . For the real-valued case this is just the identity. For the complex valued case  X  is projected onto the line in the complex plane that is parallel to the tangent to  p  on the unit circle and contains  0 . source"},{"id":638,"pagetitle":"Circle","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Circle, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::Circle, p) Project a point  p  onto the  Circle M . For the real-valued case this is the remainder with respect to modulus  $2œÄ$ . For the complex-valued case the result is the projection of  p  onto the unit circle in the complex plane. source"},{"id":639,"pagetitle":"Circle","title":"Statistics.mean","ref":"/manifolds/stable/manifolds/#Statistics.mean-Tuple{Circle{‚ÑÇ}, Any}","content":" Statistics.mean  ‚Äî  Method mean(M::Circle{‚ÑÇ}, x::AbstractVector[, w::AbstractWeights]) Compute the Riemannian  mean  of  x  of points on the  Circle $ùïä^1$ , reprsented by complex numbers, i.e. embedded in the complex plane. Comuting the sum \\[s = \\sum_{i=1}^n x_i\\] the mean is the angle of the complex number  $s$ , so represented in the complex plane as  $\\frac{s}{\\lvert s \\rvert}$ , whenever  $s \\neq 0$ . If the sum  $s=0$ , the mean is not unique. For example for opposite points or equally spaced angles. source"},{"id":640,"pagetitle":"Circle","title":"Statistics.mean","ref":"/manifolds/stable/manifolds/#Statistics.mean-Tuple{Circle{‚Ñù}, Any}","content":" Statistics.mean  ‚Äî  Method mean(M::Circle{‚Ñù}, x::AbstractVector[, w::AbstractWeights]) Compute the Riemannian  mean  of  x  of points on the  Circle $ùïä^1$ , reprsented by real numbers, i.e. the angular mean \\[\\operatorname{atan}\\Bigl( \\sum_{i=1}^n w_i\\sin(x_i),  \\sum_{i=1}^n w_i\\sin(x_i) \\Bigr).\\] source"},{"id":643,"pagetitle":"Connection manifold","title":"Connection manifold","ref":"/manifolds/stable/manifolds/#ConnectionSection","content":" Connection manifold A connection manifold always consists of a  topological manifold  together with a  connection $Œì$ . However, often there is an implicitly assumed (default) connection, like the  LeviCivitaConnection  connection on a Riemannian manifold. It is not necessary to use this decorator if you implement just one (or the first) connection. If you later introduce a second, the old (first) connection can be used without an explicitly stated connection. This manifold decorator serves two purposes: to implement different connections (e.g. in closed form) for one  AbstractManifold to provide a way to compute geodesics on manifolds, where this  AbstractAffineConnection  does not yield a closed formula. An example of usage can be found in Cartan-Schouten connections, see  AbstractCartanSchoutenConnection . Connection manifold Types Functions Charts and bases of vector spaces"},{"id":644,"pagetitle":"Connection manifold","title":"Types","ref":"/manifolds/stable/manifolds/#Types","content":" Types"},{"id":645,"pagetitle":"Connection manifold","title":"Manifolds.AbstractAffineConnection","ref":"/manifolds/stable/manifolds/#Manifolds.AbstractAffineConnection","content":" Manifolds.AbstractAffineConnection  ‚Äî  Type AbstractAffineConnection Abstract type for affine connections on a manifold. source"},{"id":646,"pagetitle":"Connection manifold","title":"Manifolds.ConnectionManifold","ref":"/manifolds/stable/manifolds/#Manifolds.ConnectionManifold","content":" Manifolds.ConnectionManifold  ‚Äî  Type ConnectionManifold{ùîΩ,,M<:AbstractManifold{ùîΩ},G<:AbstractAffineConnection} <: AbstractDecoratorManifold{ùîΩ} Constructor ConnectionManifold(M, C) Decorate the  AbstractManifold M  with  AbstractAffineConnection C . source"},{"id":647,"pagetitle":"Connection manifold","title":"Manifolds.IsConnectionManifold","ref":"/manifolds/stable/manifolds/#Manifolds.IsConnectionManifold","content":" Manifolds.IsConnectionManifold  ‚Äî  Type IsConnectionManifold <: AbstractTrait Specify that a certain decorated Manifold is a connection manifold in the sence that it provides explicit connection properties, extending/changing the default connection properties of a manifold. source"},{"id":648,"pagetitle":"Connection manifold","title":"Manifolds.IsDefaultConnection","ref":"/manifolds/stable/manifolds/#Manifolds.IsDefaultConnection","content":" Manifolds.IsDefaultConnection  ‚Äî  Type IsDefaultConnection{G<:AbstractAffineConnection} Specify that a certain  AbstractAffineConnection  is the default connection for a manifold. This way the corresponding  ConnectionManifold  falls back to the default methods of the manifold it decorates. source"},{"id":649,"pagetitle":"Connection manifold","title":"Manifolds.LeviCivitaConnection","ref":"/manifolds/stable/manifolds/#Manifolds.LeviCivitaConnection","content":" Manifolds.LeviCivitaConnection  ‚Äî  Type LeviCivitaConnection The  Levi-Civita connection  of a Riemannian manifold. source"},{"id":650,"pagetitle":"Connection manifold","title":"Functions","ref":"/manifolds/stable/manifolds/#Functions","content":" Functions"},{"id":651,"pagetitle":"Connection manifold","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{ManifoldsBase.TraitList{IsConnectionManifold}, AbstractDecoratorManifold, Any, Any}","content":" Base.exp  ‚Äî  Method exp(::TraitList{IsConnectionManifold}, M::AbstractDecoratorManifold, p, X) Compute the exponential map on a manifold that  IsConnectionManifold M  equipped with corresponding affine connection. If  M  is a  MetricManifold  with a  IsDefaultMetric  trait, this method falls back to  exp(M, p, X) . Otherwise it numerically integrates the underlying ODE, see  solve_exp_ode . Currently, the numerical integration is only accurate when using a single coordinate chart that covers the entire manifold. This excludes coordinates in an embedded space. source"},{"id":652,"pagetitle":"Connection manifold","title":"Manifolds.christoffel_symbols_first","ref":"/manifolds/stable/manifolds/#Manifolds.christoffel_symbols_first-Tuple{AbstractManifold, Any, AbstractBasis}","content":" Manifolds.christoffel_symbols_first  ‚Äî  Method christoffel_symbols_first(\n    M::AbstractManifold,\n    p,\n    B::AbstractBasis;\n    backend::AbstractDiffBackend = default_differential_backend(),\n) Compute the Christoffel symbols of the first kind in local coordinates of basis  B . The Christoffel symbols are (in Einstein summation convention) \\[Œì_{ijk} = \\frac{1}{2} \\Bigl[g_{kj,i} + g_{ik,j} - g_{ij,k}\\Bigr],\\] where  $g_{ij,k}=\\frac{‚àÇ}{‚àÇ p^k} g_{ij}$  is the coordinate derivative of the local representation of the metric tensor. The dimensions of the resulting multi-dimensional array are ordered  $(i,j,k)$ . source"},{"id":653,"pagetitle":"Connection manifold","title":"Manifolds.christoffel_symbols_second","ref":"/manifolds/stable/manifolds/#Manifolds.christoffel_symbols_second-Tuple{AbstractManifold, Any, AbstractBasis}","content":" Manifolds.christoffel_symbols_second  ‚Äî  Method christoffel_symbols_second(\n    M::AbstractManifold,\n    p,\n    B::AbstractBasis;\n    backend::AbstractDiffBackend = default_differential_backend(),\n) Compute the Christoffel symbols of the second kind in local coordinates of basis  B . For affine connection manifold the Christoffel symbols need to be explicitly implemented while, for a  MetricManifold  they are computed as (in Einstein summation convention) \\[Œì^{l}_{ij} = g^{kl} Œì_{ijk},\\] where  $Œì_{ijk}$  are the Christoffel symbols of the first kind (see  christoffel_symbols_first ), and  $g^{kl}$  is the inverse of the local representation of the metric tensor. The dimensions of the resulting multi-dimensional array are ordered  $(l,i,j)$ . source"},{"id":654,"pagetitle":"Connection manifold","title":"Manifolds.christoffel_symbols_second_jacobian","ref":"/manifolds/stable/manifolds/#Manifolds.christoffel_symbols_second_jacobian-Tuple{AbstractManifold, Any, AbstractBasis}","content":" Manifolds.christoffel_symbols_second_jacobian  ‚Äî  Method christoffel_symbols_second_jacobian(\n    M::AbstractManifold,\n    p,\n    B::AbstractBasis;\n    backend::AbstractDiffBackend = default_differential_backend(),\n) Get partial derivatives of the Christoffel symbols of the second kind for manifold  M  at  p  with respect to the coordinates of  B , i.e. \\[\\frac{‚àÇ}{‚àÇ p^l} Œì^{k}_{ij} = Œì^{k}_{ij,l}.\\] The dimensions of the resulting multi-dimensional array are ordered  $(i,j,k,l)$ . source"},{"id":655,"pagetitle":"Connection manifold","title":"Manifolds.connection","ref":"/manifolds/stable/manifolds/#Manifolds.connection-Tuple{AbstractManifold}","content":" Manifolds.connection  ‚Äî  Method connection(M::AbstractManifold) Get the connection (an object of a subtype of  AbstractAffineConnection ) of  AbstractManifold M . source"},{"id":656,"pagetitle":"Connection manifold","title":"Manifolds.connection","ref":"/manifolds/stable/manifolds/#Manifolds.connection-Tuple{ConnectionManifold}","content":" Manifolds.connection  ‚Äî  Method connection(M::ConnectionManifold) Return the connection associated with  ConnectionManifold M . source"},{"id":657,"pagetitle":"Connection manifold","title":"Manifolds.gaussian_curvature","ref":"/manifolds/stable/manifolds/#Manifolds.gaussian_curvature-Tuple{AbstractManifold, Any, AbstractBasis}","content":" Manifolds.gaussian_curvature  ‚Äî  Method gaussian_curvature(M::AbstractManifold, p, B::AbstractBasis; backend::AbstractDiffBackend = default_differential_backend()) Compute the Gaussian curvature of the manifold  M  at the point  p  using basis  B . This is equal to half of the scalar Ricci curvature, see  ricci_curvature . source"},{"id":658,"pagetitle":"Connection manifold","title":"Manifolds.is_default_connection","ref":"/manifolds/stable/manifolds/#Manifolds.is_default_connection-Tuple{AbstractManifold, AbstractAffineConnection}","content":" Manifolds.is_default_connection  ‚Äî  Method is_default_connection(M::AbstractManifold, G::AbstractAffineConnection) returns whether an  AbstractAffineConnection  is the default metric on the manifold  M  or not. This can be set by defining this function, or setting the  IsDefaultConnection  trait for an  AbstractDecoratorManifold . source"},{"id":659,"pagetitle":"Connection manifold","title":"Manifolds.ricci_tensor","ref":"/manifolds/stable/manifolds/#Manifolds.ricci_tensor-Tuple{AbstractManifold, Any, AbstractBasis}","content":" Manifolds.ricci_tensor  ‚Äî  Method ricci_tensor(M::AbstractManifold, p, B::AbstractBasis; backend::AbstractDiffBackend = default_differential_backend()) Compute the Ricci tensor, also known as the Ricci curvature tensor, of the manifold  M  at the point  p  using basis  B , see  https://en.wikipedia.org/wiki/Ricci_curvature#Introduction_and_local_definition . source"},{"id":660,"pagetitle":"Connection manifold","title":"Manifolds.solve_exp_ode","ref":"/manifolds/stable/manifolds/#Manifolds.solve_exp_ode-Tuple{AbstractManifold, Any, Any, Number}","content":" Manifolds.solve_exp_ode  ‚Äî  Method solve_exp_ode(\n    M::ConnectionManifold,\n    p,\n    X,\n    t::Number,\n    B::AbstractBasis;\n    backend::AbstractDiffBackend = default_differential_backend(),\n    solver = AutoVern9(Rodas5()),\n    kwargs...,\n) Approximate the exponential map on the manifold by evaluating the ODE descripting the geodesic at 1, assuming the default connection of the given manifold by solving the ordinary differential equation \\[\\frac{d^2}{dt^2} p^k + Œì^k_{ij} \\frac{d}{dt} p_i \\frac{d}{dt} p_j = 0,\\] where  $Œì^k_{ij}$  are the Christoffel symbols of the second kind, and the Einstein summation convention is assumed. The argument  solver  follows the  OrdinaryDiffEq  conventions.  kwargs...  specify keyword arguments that will be passed to  OrdinaryDiffEq.solve . Currently, the numerical integration is only accurate when using a single coordinate chart that covers the entire manifold. This excludes coordinates in an embedded space. Note This function only works when  OrdinaryDiffEq.jl  is loaded with using OrdinaryDiffEq source"},{"id":661,"pagetitle":"Connection manifold","title":"ManifoldsBase.riemann_tensor","ref":"/manifolds/stable/manifolds/#ManifoldsBase.riemann_tensor-Tuple{AbstractManifold, Any, AbstractBasis}","content":" ManifoldsBase.riemann_tensor  ‚Äî  Method riemann_tensor(M::AbstractManifold, p, B::AbstractBasis; backend::AbstractDiffBackend=default_differential_backend()) Compute the Riemann tensor  $R^l_{ijk}$ , also known as the Riemann curvature tensor, at the point  p  in local coordinates defined by  B . The dimensions of the resulting multi-dimensional array are ordered  $(l,i,j,k)$ . The function uses the coordinate expression involving the second Christoffel symbol, see  https://en.wikipedia.org/wiki/Riemann_curvature_tensor#Coordinate_expression  for details. See also christoffel_symbols_second ,  christoffel_symbols_second_jacobian source"},{"id":662,"pagetitle":"Connection manifold","title":"Charts and bases of vector spaces","ref":"/manifolds/stable/manifolds/#connections_charts","content":" Charts and bases of vector spaces All connection-related functions take a basis of a vector space as one of the arguments. This is needed because generally there is no way to define these functions without referencing a basis. In some cases there is no need to be explicit about this basis, and then for example a  DefaultOrthonormalBasis  object can be used. In cases where being explicit about these bases is needed, for example when using multiple charts, a basis can be specified, for example using  induced_basis ."},{"id":665,"pagetitle":"Elliptope","title":"Elliptope","ref":"/manifolds/stable/manifolds/#Elliptope","content":" Elliptope"},{"id":666,"pagetitle":"Elliptope","title":"Manifolds.Elliptope","ref":"/manifolds/stable/manifolds/#Manifolds.Elliptope","content":" Manifolds.Elliptope  ‚Äî  Type Elliptope{T} <: AbstractDecoratorManifold{‚Ñù} The Elliptope manifold, also known as the set of correlation matrices, consists of all symmetric positive semidefinite matrices of rank  $k$  with unit diagonal, i.e., \\[\\begin{aligned}\n\\mathcal E(n,k) =\n\\bigl\\{p ‚àà ‚Ñù^{n√ón}\\ \\big|\\ &a^\\mathrm{T}pa \\geq 0 \\text{ for all } a ‚àà ‚Ñù^{n},\\\\\n&p_{ii} = 1 \\text{ for all } i=1,\\ldots,n,\\\\\n&\\text{and } p = qq^{\\mathrm{T}} \\text{ for } q \\in  ‚Ñù^{n√ók} \\text{ with } \\operatorname{rank}(p) = \\operatorname{rank}(q) = k\n\\bigr\\}.\n\\end{aligned}\\] And this manifold is working solely on the matrices  $q$ . Note that this  $q$  is not unique, indeed for any orthogonal matrix  $A$  we have  $(qA)(qA)^{\\mathrm{T}} = qq^{\\mathrm{T}} = p$ , so the manifold implemented here is the quotient manifold. The unit diagonal translates to unit norm columns of  $q$ . The tangent space at  $p$ , denoted  $T_p\\mathcal E(n,k)$ , is also represented by matrices  $Y\\in ‚Ñù^{n√ók}$  and reads as \\[T_p\\mathcal E(n,k) = \\bigl\\{\nX ‚àà ‚Ñù^{n√ón}\\,|\\,X = qY^{\\mathrm{T}} + Yq^{\\mathrm{T}} \\text{ with } X_{ii} = 0 \\text{ for } i=1,\\ldots,n\n\\bigr\\}\\] endowed with the  Euclidean  metric from the embedding, i.e. from the  $‚Ñù^{n√ók}$ This manifold was for example investigated in[ JBAS10 ]. Constructor Elliptope(n::Int, k::Int; parameter::Symbol=:type) generates the manifold  $\\mathcal E(n,k) \\subset ‚Ñù^{n√ón}$ . parameter : whether a type parameter should be used to store  n  and  k . By default size is stored in type. Value can either be  :field  or  :type . source"},{"id":667,"pagetitle":"Elliptope","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{Elliptope, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::Elliptope, q; kwargs...) checks, whether  q  is a valid reprsentation of a point  $p=qq^{\\mathrm{T}}$  on the  Elliptope M , i.e. is a matrix of size  (N,K) , such that  $p$  is symmetric positive semidefinite and has unit trace. Since by construction  $p$  is symmetric, this is not explicitly checked. Since  $p$  is by construction positive semidefinite, this is not checked. The tolerances for positive semidefiniteness and unit trace can be set using the  kwargs... . source"},{"id":668,"pagetitle":"Elliptope","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Union{Tuple{T}, Tuple{Elliptope, Any, T}} where T","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::Elliptope, q, Y; kwargs... ) Check whether  $X = qY^{\\mathrm{T}} + Yq^{\\mathrm{T}}$  is a tangent vector to  $p=qq^{\\mathrm{T}}$  on the  Elliptope M , i.e.  Y  has to be of same dimension as  q  and a  $X$  has to be a symmetric matrix with zero diagonal. The tolerance for the base point check and zero diagonal can be set using the  kwargs... . Note that symmetric of  $X$  holds by construction an is not explicitly checked. source"},{"id":669,"pagetitle":"Elliptope","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{Elliptope}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::Elliptope) Return false.  Elliptope  is not a flat manifold. source"},{"id":670,"pagetitle":"Elliptope","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{Elliptope}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::Elliptope) returns the dimension of  Elliptope M $=\\mathcal E(n,k), n,k ‚àà ‚Ñï$ , i.e. \\[\\dim \\mathcal E(n,k) = n(k-1) - \\frac{k(k-1)}{2}.\\] source"},{"id":671,"pagetitle":"Elliptope","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Elliptope, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::Elliptope, q) project  q  onto the manifold  Elliptope M , by normalizing the rows of  q . source"},{"id":672,"pagetitle":"Elliptope","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Elliptope, Vararg{Any}}","content":" ManifoldsBase.project  ‚Äî  Method project(M::Elliptope, q, Y) Project  Y  onto the tangent space at  q , i.e. row-wise onto the oblique manifold. source"},{"id":673,"pagetitle":"Elliptope","title":"ManifoldsBase.representation_size","ref":"/manifolds/stable/manifolds/#ManifoldsBase.representation_size-Tuple{Elliptope}","content":" ManifoldsBase.representation_size  ‚Äî  Method representation_size(M::Elliptope) Return the size of an array representing an element on the  Elliptope  manifold  M , i.e.  $n√ók$ , the size of such factor of  $p=qq^{\\mathrm{T}}$  on  $\\mathcal M = \\mathcal E(n,k)$ . source"},{"id":674,"pagetitle":"Elliptope","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{Elliptope, Any, Any, ProjectionRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::Elliptope, q, Y, ::ProjectionRetraction) compute a projection based retraction by projecting  $q+Y$  back onto the manifold. source"},{"id":675,"pagetitle":"Elliptope","title":"ManifoldsBase.vector_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.vector_transport_to-Tuple{Elliptope, Any, Any, Any, ProjectionTransport}","content":" ManifoldsBase.vector_transport_to  ‚Äî  Method vector_transport_to(M::Elliptope, p, X, q) transport the tangent vector  X  at  p  to  q  by projecting it onto the tangent space at  q . source"},{"id":676,"pagetitle":"Elliptope","title":"ManifoldsBase.zero_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.zero_vector-Tuple{Elliptope, Vararg{Any}}","content":" ManifoldsBase.zero_vector  ‚Äî  Method zero_vector(M::Elliptope,p) returns the zero tangent vector in the tangent space of the symmetric positive definite matrix  p  on the  Elliptope  manifold  M . source"},{"id":677,"pagetitle":"Elliptope","title":"Literature","ref":"/manifolds/stable/manifolds/#Literature","content":" Literature"},{"id":680,"pagetitle":"Essential manifold","title":"Essential Manifold","ref":"/manifolds/stable/manifolds/#Essential-Manifold","content":" Essential Manifold The essential manifold is modeled as an  AbstractPowerManifold   of the  $3√ó3$ Rotations  and uses  NestedPowerRepresentation ."},{"id":681,"pagetitle":"Essential manifold","title":"Manifolds.EssentialManifold","ref":"/manifolds/stable/manifolds/#Manifolds.EssentialManifold","content":" Manifolds.EssentialManifold  ‚Äî  Type EssentialManifold <: AbstractPowerManifold{‚Ñù} The essential manifold is the space of the essential matrices which is represented as a quotient space of the  Rotations  manifold product  $\\mathrm{SO}(3)^2$ . Let  $R_x(Œ∏), R_y(Œ∏), R_x(Œ∏) \\in ‚Ñù^{x√ó3}$  denote the rotation around the  $z$ ,  $y$ , and  $x$  axis in  $‚Ñù^3$ , respectively, and further the groups \\[H_z = \\bigl\\{(R_z(Œ∏),R_z(Œ∏))\\ \\big|\\ Œ∏ ‚àà [-œÄ,œÄ) \\bigr\\}\\] and \\[H_œÄ = \\bigl\\{ (I,I), (R_x(œÄ), R_x(œÄ)), (I,R_z(œÄ)), (R_x(œÄ), R_y(œÄ))  \\bigr\\}\\] acting elementwise on the left from  $\\mathrm{SO}(3)^2$  (component wise). Then the unsigned Essential manifold  $\\mathcal{M}_{\\text{E}}$  can be identified with the quotient space \\[\\mathcal{M}_{\\text{E}} := (\\text{SO}(3)√ó\\text{SO}(3))/(H_z √ó H_œÄ),\\] and for the signed Essential manifold  $\\mathcal{M}_{\\text{∆é}}$ , the quotient reads \\[\\mathcal{M}_{\\text{∆é}} := (\\text{SO}(3)√ó\\text{SO}(3))/(H_z).\\] An essential matrix is defined as \\[E = (R'_1)^T [T'_2 - T'_1]_{√ó} R'_2,\\] where the poses of two cameras  $(R_i', T_i'), i=1,2$ , are contained in the space of rigid body transformations  $SE(3)$  and the operator  $[‚ãÖ]_{√ó}\\colon ‚Ñù^3 ‚Üí \\operatorname{SkewSym}(3)$  denotes the matrix representation of the cross product operator. For more details see [ TD17 ]. Constructor EssentialManifold(is_signed=true) Generate the manifold of essential matrices, either the signed ( is_signed=true ) or unsigned ( is_signed=false ) variant. source"},{"id":682,"pagetitle":"Essential manifold","title":"Functions","ref":"/manifolds/stable/manifolds/#Functions","content":" Functions"},{"id":683,"pagetitle":"Essential manifold","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{EssentialManifold, Vararg{Any}}","content":" Base.exp  ‚Äî  Method exp(M::EssentialManifold, p, X) Compute the exponential map on the  EssentialManifold  from  p  into direction  X , i.e. \\[\\text{exp}_p(X) =\\text{exp}_g( \\tilde X),  \\quad g \\in \\text(SO)(3)^2,\\] where  $\\tilde X$  is the horizontal lift of  $X$ [ TD17 ]. source"},{"id":684,"pagetitle":"Essential manifold","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{EssentialManifold, Any, Any}","content":" Base.log  ‚Äî  Method log(M::EssentialManifold, p, q) Compute the logarithmic map on the  EssentialManifold M , i.e. the tangent vector, whose geodesic starting from  p  reaches  q  after time 1. Here,  $p=(R_{p_1},R_{p_2})$  and  $q=(R_{q_1},R_{q_2})$  are elements of  $SO(3)^2$ . We use that any essential matrix can, up to scale, be decomposed to \\[E = R_1^T [e_z]_{√ó}R_2,\\] where  $(R_1,R_2)‚ààSO(3)^2$ . Two points in  $SO(3)^2$  are equivalent iff their corresponding essential matrices are equal (up to a sign flip). To compute the logarithm, we first move  q  to another representative of its equivalence class. For this, we find  $t= t_{\\text{opt}}$  for which the function \\[f(t) = f_1 + f_2, \\quad f_i = \\frac{1}{2} Œ∏^2_i(t), \\quad Œ∏_i(t)=d(R_{p_i},R_z(t)R_{b_i}) \\text{ for } i=1,2,\\] where  $d(‚ãÖ,‚ãÖ)$  is the distance function in  $SO(3)$ , is minimized. Further, the group  $H_z$  acting on the left on  $SO(3)^2$  is defined as \\[H_z = \\{(R_z(Œ∏),R_z(Œ∏))\\colon Œ∏ \\in [-œÄ,œÄ) \\},\\] where  $R_z(Œ∏)$  is the rotation around the z axis with angle  $Œ∏$ . Points in  $H_z$  are denoted by  $S_z$ . Then, the logarithm is defined as \\[\\log_p (S_z(t_{\\text{opt}})q) = [\\text{Log}(R_{p_i}^T R_z(t_{\\text{opt}})R_{b_i})]_{i=1,2},\\] where  $\\text{Log}$  is the  logarithm  on  $SO(3)$ . For more details see [ TD17 ]. source"},{"id":685,"pagetitle":"Essential manifold","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{EssentialManifold, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::EssentialManifold, p; kwargs...) Check whether the matrix is a valid point on the  EssentialManifold M , i.e. a 2-element array containing SO(3) matrices. source"},{"id":686,"pagetitle":"Essential manifold","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{EssentialManifold, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::EssentialManifold, p, X; kwargs... ) Check whether  X  is a tangent vector to manifold point  p  on the  EssentialManifold M , i.e.  X  has to be a 2-element array of  3 -by- 3  skew-symmetric matrices. source"},{"id":687,"pagetitle":"Essential manifold","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{EssentialManifold, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::EssentialManifold, p, q) Compute the Riemannian distance between the two points  p  and  q  on the  EssentialManifold . This is done by computing the distance of the equivalence classes  $[p]$  and  $[q]$  of the points  $p=(R_{p_1},R_{p_2}), q=(R_{q_1},R_{q_2}) ‚àà SO(3)^2$ , respectively. Two points in  $SO(3)^2$  are equivalent iff their corresponding essential matrices, given by \\[E = R_1^T [e_z]_{√ó}R_2,\\] are equal (up to a sign flip). Using the logarithmic map, the distance is given by \\[\\text{dist}([p],[q]) = \\| \\text{log}_{[p]} [q] \\| = \\| \\log_p (S_z(t_{\\text{opt}})q) \\|,\\] where  $S_z ‚àà H_z = \\{(R_z(Œ∏),R_z(Œ∏))\\colon Œ∏ \\in [-œÄ,œÄ) \\}$  in which  $R_z(Œ∏)$  is the rotation around the z axis with angle  $Œ∏$  and  $t_{\\text{opt}}$  is the minimizer of the cost function \\[f(t) = f_1 + f_2, \\quad f_i = \\frac{1}{2} Œ∏^2_i(t), \\quad Œ∏_i(t)=d(R_{p_i},R_z(t)R_{b_i}) \\text{ for } i=1,2,\\] where  $d(‚ãÖ,‚ãÖ)$  is the distance function in  $SO(3)$  [ TD17 ]. source"},{"id":688,"pagetitle":"Essential manifold","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{EssentialManifold}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::EssentialManifold) Return false.  EssentialManifold  is not a flat manifold. source"},{"id":689,"pagetitle":"Essential manifold","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{EssentialManifold}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::EssentialManifold{is_signed, ‚Ñù}) Return the manifold dimension of the  EssentialManifold , which is  5 [ TD17 ]. source"},{"id":690,"pagetitle":"Essential manifold","title":"ManifoldsBase.parallel_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_to-Tuple{EssentialManifold, Any, Any, Any}","content":" ManifoldsBase.parallel_transport_to  ‚Äî  Method parallel_transport_to(M::EssentialManifold, p, X, q) Compute the vector transport of the tangent vector  X  at  p  to  q  on the  EssentialManifold M  using left translation of the ambient group. source"},{"id":691,"pagetitle":"Essential manifold","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{EssentialManifold, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::EssentialManifold, p, X) Project the matrix  X  onto the tangent space \\[T_{p} \\text{SO}(3)^2 = T_{\\text{vp}}\\text{SO}(3)^2 ‚äï T_{\\text{hp}}\\text{SO}(3)^2,\\] by first computing its projection onto the vertical space  $T_{\\text{vp}}\\text{SO}(3)^2$  using  vert_proj . Then the orthogonal projection of  X  onto the horizontal space  $T_{\\text{hp}}\\text{SO}(3)^2$  is defined as \\[\\Pi_h(X) = X - \\frac{\\text{vert\\_proj}_p(X)}{2} \\begin{bmatrix} R_1^T e_z \\\\ R_2^T e_z \\end{bmatrix},\\] with  $R_i = R_0 R'_i, i=1,2,$  where  $R'_i$  is part of the pose of camera  $i$ $g_i = (R'_i,T'_i) ‚àà \\text{SE}(3)$  and  $R_0 ‚àà \\text{SO}(3)$  such that  $R_0(T'_2-T'_1) = e_z$ . source"},{"id":692,"pagetitle":"Essential manifold","title":"Internal Functions","ref":"/manifolds/stable/manifolds/#Internal-Functions","content":" Internal Functions"},{"id":693,"pagetitle":"Essential manifold","title":"Manifolds.dist_min_angle_pair","ref":"/manifolds/stable/manifolds/#Manifolds.dist_min_angle_pair-Tuple{Any, Any}","content":" Manifolds.dist_min_angle_pair  ‚Äî  Method dist_min_angle_pair(p, q) This function computes the global minimizer of the function \\[f(t) = f_1 + f_2, \\quad f_i = \\frac{1}{2} Œ∏^2_i(t), \\quad Œ∏_i(t)=d(R_{p_i},R_z(t)R_{b_i}) \\text{ for } i=1,2,\\] for the given values. This is done by finding the discontinuity points  $t_{d_i}, i=1,2$  of its derivative and using Newton's method to minimize the function over the intervals  $[t_{d_1},t_{d_2}]$  and  $[t_{d_2},t_{d_1}+2œÄ]$  separately. Then, the minimizer for which  $f$  is minimal is chosen and given back together with the minimal value. For more details see Algorithm 1 in [ TD17 ]. source"},{"id":694,"pagetitle":"Essential manifold","title":"Manifolds.dist_min_angle_pair_compute_df_break","ref":"/manifolds/stable/manifolds/#Manifolds.dist_min_angle_pair_compute_df_break-Tuple{Any, Any}","content":" Manifolds.dist_min_angle_pair_compute_df_break  ‚Äî  Method dist_min_angle_pair_compute_df_break(t_break, q) This function computes the derivatives of each term  $f_i, i=1,2,$  at discontinuity point  t_break . For more details see [ TD17 ]. source"},{"id":695,"pagetitle":"Essential manifold","title":"Manifolds.dist_min_angle_pair_df_newton","ref":"/manifolds/stable/manifolds/#Manifolds.dist_min_angle_pair_df_newton-NTuple{9, Any}","content":" Manifolds.dist_min_angle_pair_df_newton  ‚Äî  Method dist_min_angle_pair_df_newton(m1, Œ¶1, c1, m2, Œ¶2, c2, t_min, t_low, t_high) This function computes the minimizer of the function \\[f(t) = f_1 + f_2, \\quad f_i = \\frac{1}{2} Œ∏^2_i(t), \\quad Œ∏_i(t)=d(R_{p_i},R_z(t)R_{b_i}) \\text{ for } i=1,2,\\] in the interval  $[$ t_low ,  t_high $]$  using Newton's method. For more details see [ TD17 ]. source"},{"id":696,"pagetitle":"Essential manifold","title":"Manifolds.dist_min_angle_pair_discontinuity_distance","ref":"/manifolds/stable/manifolds/#Manifolds.dist_min_angle_pair_discontinuity_distance-Tuple{Any}","content":" Manifolds.dist_min_angle_pair_discontinuity_distance  ‚Äî  Method dist_min_angle_pair_discontinuity_distance(q) This function computes the point  $t_{\\text{di}}$  for which the first derivative of \\[f(t) = f_1 + f_2, \\quad f_i = \\frac{1}{2} Œ∏^2_i(t), \\quad Œ∏_i(t)=d(R_{p_i},R_z(t)R_{b_i}) \\text{ for } i=1,2,\\] does not exist. This is the case for  $\\sin(Œ∏_i(t_{\\text{di}})) = 0$ . For more details see Proposition 9 and its proof, as well as Lemma 1 in [ TD17 ]. source"},{"id":697,"pagetitle":"Essential manifold","title":"Manifolds.vert_proj","ref":"/manifolds/stable/manifolds/#Manifolds.vert_proj-Tuple{EssentialManifold, Any, Any}","content":" Manifolds.vert_proj  ‚Äî  Method vert_proj(M::EssentialManifold, p, X) Project  X  onto the vertical space  $T_{\\text{vp}}\\text{SO}(3)^2$  with \\[\\text{vert\\_proj}_p(X) = e_z^T(R_1 X_1 + R_2 X_2),\\] where  $e_z$  is the third unit vector,  $X_i ‚àà T_{p}\\text{SO}(3)$  for  $i=1,2,$  and it holds  $R_i = R_0 R'_i, i=1,2,$  where  $R'_i$  is part of the pose of camera  $i$ $g_i = (R_i,T'_i) ‚àà \\text{SE}(3)$  and  $R_0 ‚àà \\text{SO}(3)$  such that  $R_0(T'_2-T'_1) = e_z$  [ TD17 ]. source"},{"id":698,"pagetitle":"Essential manifold","title":"Literature","ref":"/manifolds/stable/manifolds/#Literature","content":" Literature"},{"id":701,"pagetitle":"Euclidean","title":"Euclidean space","ref":"/manifolds/stable/manifolds/#EuclideanSection","content":" Euclidean space The Euclidean space  $‚Ñù^n$  is a simple model space, since it has curvature constantly zero everywhere; hence, nearly all operations simplify. The easiest way to generate an Euclidean space is to use a field, i.e.  AbstractNumbers , e.g. to create the  $‚Ñù^n$  or  $‚Ñù^{n√ón}$  you can simply type  M = ‚Ñù^n  or  ‚Ñù^(n,n) , respectively."},{"id":702,"pagetitle":"Euclidean","title":"Manifolds.Euclidean","ref":"/manifolds/stable/manifolds/#Manifolds.Euclidean","content":" Manifolds.Euclidean  ‚Äî  Type Euclidean{T,ùîΩ} <: AbstractManifold{ùîΩ} Euclidean vector space. Constructor Euclidean(n) Generate the  $n$ -dimensional vector space  $‚Ñù^n$ . Euclidean(n‚ÇÅ,n‚ÇÇ,...,n·µ¢; field=‚Ñù, parameter::Symbol = :field)\nùîΩ^(n‚ÇÅ,n‚ÇÇ,...,n·µ¢) = Euclidean(n‚ÇÅ,n‚ÇÇ,...,n·µ¢; field=ùîΩ) Generate the vector space of  $k = n_1 ‚ãÖ n_2 ‚ãÖ ‚Ä¶ ‚ãÖ n_i$  values, i.e. the manifold  $ùîΩ^{n_1, n_2, ‚Ä¶, n_i}$ ,  $ùîΩ\\in\\{‚Ñù,‚ÑÇ\\}$ , whose elements are interpreted as  $n_1 √ó n_2 √ó ‚Ä¶ √ó n_i$  arrays. For  $i=2$  we obtain a matrix space. The default  field=‚Ñù  can also be set to  field=‚ÑÇ . The dimension of this space is  $k \\dim_‚Ñù ùîΩ$ , where  $\\dim_‚Ñù ùîΩ$  is the  real_dimension  of the field  $ùîΩ$ . parameter : whether a type parameter should be used to store  n . By default size is stored in type. Value can either be  :field  or  :type . Euclidean(; field=‚Ñù) Generate the 1D Euclidean manifold for an  ‚Ñù -,  ‚ÑÇ -valued  real- or complex-valued immutable values (in contrast to 1-element arrays from the constructor above). source"},{"id":703,"pagetitle":"Euclidean","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{Euclidean, Any, Any}","content":" Base.exp  ‚Äî  Method exp(M::Euclidean, p, X) Compute the exponential map on the  Euclidean  manifold  M  from  p  in direction  X , which in this case is just \\[\\exp_p X = p + X.\\] source"},{"id":704,"pagetitle":"Euclidean","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{Euclidean, Vararg{Any}}","content":" Base.log  ‚Äî  Method log(M::Euclidean, p, q) Compute the logarithmic map on the  Euclidean M  from  p  to  q , which in this case is just \\[\\log_p q = q-p.\\] source"},{"id":705,"pagetitle":"Euclidean","title":"LinearAlgebra.norm","ref":"/manifolds/stable/manifolds/#LinearAlgebra.norm-Tuple{Euclidean, Any, Any}","content":" LinearAlgebra.norm  ‚Äî  Method norm(M::Euclidean, p, X) Compute the norm of a tangent vector  X  at  p  on the  Euclidean M , i.e. since every tangent space can be identified with  M  itself in this case, just the (Frobenius) norm of  X . source"},{"id":706,"pagetitle":"Euclidean","title":"Manifolds.manifold_volume","ref":"/manifolds/stable/manifolds/#Manifolds.manifold_volume-Tuple{Euclidean}","content":" Manifolds.manifold_volume  ‚Äî  Method manifold_volume(::Euclidean) Return volume of the  Euclidean  manifold, i.e. infinity. source"},{"id":707,"pagetitle":"Euclidean","title":"Manifolds.volume_density","ref":"/manifolds/stable/manifolds/#Manifolds.volume_density-Tuple{Euclidean, Any, Any}","content":" Manifolds.volume_density  ‚Äî  Method volume_density(M::Euclidean, p, X) Return volume density function of  Euclidean  manifold  M , i.e. 1. source"},{"id":708,"pagetitle":"Euclidean","title":"ManifoldsBase.Weingarten","ref":"/manifolds/stable/manifolds/#ManifoldsBase.Weingarten-Tuple{Euclidean, Any, Any, Any}","content":" ManifoldsBase.Weingarten  ‚Äî  Method Y = Weingarten(M::Euclidean, p, X, V)\nWeingarten!(M::Euclidean, Y, p, X, V) Compute the Weingarten map  $\\mathcal W_p$  at  p  on the  Euclidean M  with respect to the tangent vector  $X \\in T_p\\mathcal M$  and the normal vector  $V \\in N_p\\mathcal M$ . Since this a flat space by itself, the result is always the zero tangent vector. source"},{"id":709,"pagetitle":"Euclidean","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{Euclidean, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::Euclidean, p, q) Compute the Euclidean distance between two points on the  Euclidean  manifold  M , i.e. for vectors it's just the norm of the difference, for matrices and higher order arrays, the matrix and tensor Frobenius norm, respectively. source"},{"id":710,"pagetitle":"Euclidean","title":"ManifoldsBase.embed","ref":"/manifolds/stable/manifolds/#ManifoldsBase.embed-Tuple{Euclidean, Any, Any}","content":" ManifoldsBase.embed  ‚Äî  Method embed(M::Euclidean, p, X) Embed the tangent vector  X  at point  p  in  M . Equivalent to an identity map. source"},{"id":711,"pagetitle":"Euclidean","title":"ManifoldsBase.embed","ref":"/manifolds/stable/manifolds/#ManifoldsBase.embed-Tuple{Euclidean, Any}","content":" ManifoldsBase.embed  ‚Äî  Method embed(M::Euclidean, p) Embed the point  p  in  M . Equivalent to an identity map. source"},{"id":712,"pagetitle":"Euclidean","title":"ManifoldsBase.injectivity_radius","ref":"/manifolds/stable/manifolds/#ManifoldsBase.injectivity_radius-Tuple{Euclidean}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(M::Euclidean) Return the injectivity radius on the  Euclidean M , which is  $‚àû$ . source"},{"id":713,"pagetitle":"Euclidean","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{Euclidean, Vararg{Any}}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::Euclidean, p, X, Y) Compute the inner product on the  Euclidean M , which is just the inner product on the real-valued or complex valued vector space of arrays (or tensors) of size  $n_1 √ó n_2  √ó  ‚Ä¶  √ó n_i$ , i.e. \\[g_p(X,Y) = \\sum_{k ‚àà I} \\overline{X}_{k} Y_{k},\\] where  $I$  is the set of vectors  $k ‚àà ‚Ñï^i$ , such that for all $i ‚â§ j ‚â§ i$  it holds  $1 ‚â§ k_j ‚â§ n_j$  and  $\\overline{‚ãÖ}$  denotes the complex conjugate. For the special case of  $i ‚â§ 2$ , i.e. matrices and vectors, this simplifies to \\[g_p(X,Y) = X^{\\mathrm{H}}Y,\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the Hermitian, i.e. complex conjugate transposed. source"},{"id":714,"pagetitle":"Euclidean","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{Euclidean}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::Euclidean) Return true.  Euclidean  is a flat manifold. source"},{"id":715,"pagetitle":"Euclidean","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Union{Tuple{Euclidean{<:Any, ùîΩ}}, Tuple{ùîΩ}} where ùîΩ","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::Euclidean) Return the manifold dimension of the  Euclidean M , i.e. the product of all array dimensions and the  real_dimension  of the underlying number system. source"},{"id":716,"pagetitle":"Euclidean","title":"ManifoldsBase.parallel_transport_along","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_along-Tuple{Euclidean, Any, Any, AbstractVector}","content":" ManifoldsBase.parallel_transport_along  ‚Äî  Method parallel_transport_along(M::Euclidean, p, X, c) the parallel transport on  Euclidean  is the identiy, i.e. returns  X . source"},{"id":717,"pagetitle":"Euclidean","title":"ManifoldsBase.parallel_transport_direction","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_direction-Tuple{Euclidean, Any, Any, Any}","content":" ManifoldsBase.parallel_transport_direction  ‚Äî  Method parallel_transport_direction(M::Euclidean, p, X, d) the parallel transport on  Euclidean  is the identiy, i.e. returns  X . source"},{"id":718,"pagetitle":"Euclidean","title":"ManifoldsBase.parallel_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_to-Tuple{Euclidean, Any, Any, Any}","content":" ManifoldsBase.parallel_transport_to  ‚Äî  Method parallel_transport_to(M::Euclidean, p, X, q) the parallel transport on  Euclidean  is the identiy, i.e. returns  X . source"},{"id":719,"pagetitle":"Euclidean","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Euclidean, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::Euclidean, p, X) Project an arbitrary vector  X  into the tangent space of a point  p  on the  Euclidean M , which is just the identity, since any tangent space of  M  can be identified with all of  M . source"},{"id":720,"pagetitle":"Euclidean","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Euclidean, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::Euclidean, p) Project an arbitrary point  p  onto the  Euclidean  manifold  M , which is of course just the identity map. source"},{"id":721,"pagetitle":"Euclidean","title":"ManifoldsBase.representation_size","ref":"/manifolds/stable/manifolds/#ManifoldsBase.representation_size-Tuple{Euclidean}","content":" ManifoldsBase.representation_size  ‚Äî  Method representation_size(M::Euclidean) Return the array dimensions required to represent an element on the  Euclidean M , i.e. the vector of all array dimensions. source"},{"id":722,"pagetitle":"Euclidean","title":"ManifoldsBase.riemann_tensor","ref":"/manifolds/stable/manifolds/#ManifoldsBase.riemann_tensor-Tuple{Euclidean, Vararg{Any, 4}}","content":" ManifoldsBase.riemann_tensor  ‚Äî  Method riemann_tensor(M::Euclidean, p, X, Y, Z) Compute the Riemann tensor  $R(X,Y)Z$  at point  p  on  Euclidean  manifold  M . Its value is always the zero tangent vector. ```` source"},{"id":723,"pagetitle":"Euclidean","title":"ManifoldsBase.sectional_curvature","ref":"/manifolds/stable/manifolds/#ManifoldsBase.sectional_curvature-Tuple{Euclidean, Any, Any, Any}","content":" ManifoldsBase.sectional_curvature  ‚Äî  Method sectional_curvature(::Euclidean, p, X, Y) Sectional curvature of  Euclidean  manifold  M  is 0. source"},{"id":724,"pagetitle":"Euclidean","title":"ManifoldsBase.sectional_curvature_max","ref":"/manifolds/stable/manifolds/#ManifoldsBase.sectional_curvature_max-Tuple{Euclidean}","content":" ManifoldsBase.sectional_curvature_max  ‚Äî  Method sectional_curvature_max(::Euclidean) Sectional curvature of  Euclidean  manifold  M  is 0. source"},{"id":725,"pagetitle":"Euclidean","title":"ManifoldsBase.sectional_curvature_min","ref":"/manifolds/stable/manifolds/#ManifoldsBase.sectional_curvature_min-Tuple{Euclidean}","content":" ManifoldsBase.sectional_curvature_min  ‚Äî  Method sectional_curvature_min(M::Euclidean) Sectional curvature of  Euclidean  manifold  M  is 0. source"},{"id":726,"pagetitle":"Euclidean","title":"ManifoldsBase.vector_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.vector_transport_to-Tuple{Euclidean, Any, Any, Any, AbstractVectorTransportMethod}","content":" ManifoldsBase.vector_transport_to  ‚Äî  Method vector_transport_to(M::Euclidean, p, X, q, ::AbstractVectorTransportMethod) Transport the vector  X  from the tangent space at  p  to the tangent space at  q  on the  Euclidean M , which simplifies to the identity. source"},{"id":727,"pagetitle":"Euclidean","title":"ManifoldsBase.zero_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.zero_vector-Tuple{Euclidean, Vararg{Any}}","content":" ManifoldsBase.zero_vector  ‚Äî  Method zero_vector(M::Euclidean, x) Return the zero vector in the tangent space of  x  on the  Euclidean M , which here is just a zero filled array the same size as  x . source"},{"id":730,"pagetitle":"Fiber bundle","title":"Fiber bundles","ref":"/manifolds/stable/manifolds/#FiberBundleSection","content":" Fiber bundles Fiber bundle  $E$  is a manifold that is built on top of another manifold  $\\mathcal M$  (base space). It is characterized by a continuous function  $Œ† : E ‚Üí \\mathcal M$ . For each point  $p ‚àà \\mathcal M$  the preimage of  $p$  by  $Œ†$ ,  $Œ†^{-1}(\\{p\\})$  is called a fiber  $F$ . Bundle projection can be performed using function  bundle_projection . Manifolds.jl  primarily deals with the case of trivial bundles, where  $E$  can be topologically identified with a product  $M√óF$ . Vector bundles  is a special case of a fiber bundle. Other examples include unit tangent bundle. Note that in general fiber bundles don't have a canonical Riemannian structure but can at least be equipped with an  Ehresmann connection , providing notions of parallel transport and curvature."},{"id":731,"pagetitle":"Fiber bundle","title":"Documentation","ref":"/manifolds/stable/manifolds/#Documentation","content":" Documentation"},{"id":732,"pagetitle":"Fiber bundle","title":"Manifolds.FiberBundle","ref":"/manifolds/stable/manifolds/#Manifolds.FiberBundle","content":" Manifolds.FiberBundle  ‚Äî  Type FiberBundle{ùîΩ,TVS<:FiberType,TM<:AbstractManifold{ùîΩ},TVT<:FiberBundleProductVectorTransport} <: AbstractManifold{ùîΩ} Fiber bundle on a  AbstractManifold M  of type  FiberType . Examples include vector bundles, principal bundles or unit tangent bundles, see also  üìñ Fiber Bundle . Fields manifold  ‚Äì the  AbstractManifold               manifold the Fiber bundle is defined on, type      ‚Äì representing the type of fiber we use. Constructor FiberBundle(M::AbstractManifold, type::FiberType) source"},{"id":733,"pagetitle":"Fiber bundle","title":"Manifolds.FiberBundleInverseProductRetraction","ref":"/manifolds/stable/manifolds/#Manifolds.FiberBundleInverseProductRetraction","content":" Manifolds.FiberBundleInverseProductRetraction  ‚Äî  Type struct FiberBundleInverseProductRetraction <: AbstractInverseRetractionMethod end Inverse retraction of the point  y  at point  p  from vector bundle  B  over manifold  B.fiber  (denoted  $\\mathcal M$ ). The inverse retraction is derived as a product manifold-style approximation to the logarithmic map in the Sasaki metric. The considered product manifold is the product between the manifold  $\\mathcal M$  and the topological vector space isometric to the fiber. Notation The point  $p = (x_p, V_p)$  where  $x_p ‚àà \\mathcal M$  and  $V_p$  belongs to the fiber  $F=œÄ^{-1}(\\{x_p\\})$  of the vector bundle  $B$  where  $œÄ$  is the canonical projection of that vector bundle  $B$ . Similarly,  $q = (x_q, V_q)$ . The inverse retraction is calculated as \\[\\operatorname{retr}^{-1}_p q = (\\operatorname{retr}^{-1}_{x_p}(x_q), V_{\\operatorname{retr}^{-1}} - V_p)\\] where  $V_{\\operatorname{retr}^{-1}}$  is the result of vector transport of  $V_q$  to the point  $x_p$ . The difference  $V_{\\operatorname{retr}^{-1}} - V_p$  corresponds to the logarithmic map in the vector space  $F$ . See also  FiberBundleProductRetraction . source"},{"id":734,"pagetitle":"Fiber bundle","title":"Manifolds.FiberBundleProductRetraction","ref":"/manifolds/stable/manifolds/#Manifolds.FiberBundleProductRetraction","content":" Manifolds.FiberBundleProductRetraction  ‚Äî  Type struct FiberBundleProductRetraction <: AbstractRetractionMethod end Product retraction map of tangent vector  $X$  at point  $p$  from vector bundle  B  over manifold  B.fiber  (denoted  $\\mathcal M$ ). The retraction is derived as a product manifold-style approximation to the exponential map in the Sasaki metric. The considered product manifold is the product between the manifold  $\\mathcal M$  and the topological vector space isometric to the fiber. Notation: The point  $p = (x_p, V_p)$  where  $x_p ‚àà \\mathcal M$  and  $V_p$  belongs to the fiber  $F=œÄ^{-1}(\\{x_p\\})$  of the vector bundle  $B$  where  $œÄ$  is the canonical projection of that vector bundle  $B$ . The tangent vector  $X = (V_{X,M}, V_{X,F}) ‚àà T_pB$  where  $V_{X,M}$  is a tangent vector from the tangent space  $T_{x_p}\\mathcal M$  and  $V_{X,F}$  is a tangent vector from the tangent space  $T_{V_p}F$  (isomorphic to  $F$ ). The retraction is calculated as math \\operatorname{retr}_p(X) = (\\exp_{x_p}(V_{X,M}), V_{\\exp}) ` where  $V_{\\exp}$  is the result of vector transport of  $V_p + V_{X,F}$  to the point  $\\exp_{x_p}(V_{X,M})$ . The sum  $V_p + V_{X,F}$  corresponds to the exponential map in the vector space  $F$ . See also  FiberBundleInverseProductRetraction . source"},{"id":735,"pagetitle":"Fiber bundle","title":"Manifolds.FiberBundleProductVectorTransport","ref":"/manifolds/stable/manifolds/#Manifolds.FiberBundleProductVectorTransport","content":" Manifolds.FiberBundleProductVectorTransport  ‚Äî  Type FiberBundleProductVectorTransport{\n    TMP<:AbstractVectorTransportMethod,\n    TMV<:AbstractVectorTransportMethod,\n} <: AbstractVectorTransportMethod Vector transport type on  FiberBundle . Fields method_horizonal  ‚Äì vector transport method of the horizontal part (related to manifold M) method_vertical  ‚Äì vector transport method of the vertical part (related to fibers). The vector transport is derived as a product manifold-style vector transport. The considered product manifold is the product between the manifold  $\\mathcal M$  and the topological vector space isometric to the fiber. Constructor FiberBundleProductVectorTransport(\n    M::AbstractManifold=DefaultManifold();\n    vector_transport_method_horizontal::AbstractVectorTransportMethod = default_vector_transport_method(M),\n    vector_transport_method_vertical::AbstractVectorTransportMethod = default_vector_transport_method(M),\n) Construct the  FiberBundleProductVectorTransport  using the  default_vector_transport_method , which uses  ParallelTransport  if no manifold is provided. source"},{"id":736,"pagetitle":"Fiber bundle","title":"Base.getindex","ref":"/manifolds/stable/manifolds/#Base.getindex-Tuple{ArrayPartition, FiberBundle, Symbol}","content":" Base.getindex  ‚Äî  Method getindex(p::ArrayPartition, M::FiberBundle, s::Symbol)\np[M::FiberBundle, s] Access the element(s) at index  s  of a point  p  on a  FiberBundle M  by using the symbols  :point  and  :vector  or  :fiber  for the base and vector or fiber component, respectively. source"},{"id":737,"pagetitle":"Fiber bundle","title":"Base.setindex!","ref":"/manifolds/stable/manifolds/#Base.setindex!-Tuple{ArrayPartition, Any, FiberBundle, Symbol}","content":" Base.setindex!  ‚Äî  Method setindex!(p::ArrayPartition, val, M::FiberBundle, s::Symbol)\np[M::VectorBundle, s] = val Set the element(s) at index  s  of a point  p  on a  FiberBundle M  to  val  by using the symbols  :point  and  :fiber  or  :vector  for the base and fiber or vector component, respectively. Note The  content  of element of  p  is replaced, not the element itself. source"},{"id":738,"pagetitle":"Fiber bundle","title":"Manifolds.bundle_projection","ref":"/manifolds/stable/manifolds/#Manifolds.bundle_projection-Tuple{FiberBundle, Any}","content":" Manifolds.bundle_projection  ‚Äî  Method bundle_projection(B::FiberBundle, p) Projection of point  p  from the bundle  M  to the base manifold. Returns the point on the base manifold  B.manifold  at which the vector part of  p  is attached. source"},{"id":739,"pagetitle":"Fiber bundle","title":"Manifolds.bundle_transport_tangent_direction","ref":"/manifolds/stable/manifolds/#Manifolds.bundle_transport_tangent_direction","content":" Manifolds.bundle_transport_tangent_direction  ‚Äî  Function bundle_transport_tangent_direction(B::FiberBundle, p, pf, X, d) Compute parallel transport of vertical vector  X  according to Ehresmann connection on  FiberBundle B , in direction  $d\\in T_p \\mathcal M$ .  $X$  is an element of the vertical bundle  $VF\\mathcal M$  at  pf  from tangent to fiber  $\\pi^{-1}({p})$ ,  $p\\in \\mathcal M$ . source"},{"id":740,"pagetitle":"Fiber bundle","title":"Manifolds.bundle_transport_tangent_to","ref":"/manifolds/stable/manifolds/#Manifolds.bundle_transport_tangent_to","content":" Manifolds.bundle_transport_tangent_to  ‚Äî  Function bundle_transport_tangent_to(B::FiberBundle, p, pf, X, q) Compute parallel transport of vertical vector  X  according to Ehresmann connection on  FiberBundle B , to point  $q\\in \\mathcal M$ .  $X$  is an element of the vertical bundle  $VF\\mathcal M$  at  pf  from tangent to fiber  $\\pi^{-1}({p})$ ,  $p\\in \\mathcal M$ . source"},{"id":741,"pagetitle":"Fiber bundle","title":"Manifolds.bundle_transport_to","ref":"/manifolds/stable/manifolds/#Manifolds.bundle_transport_to-Tuple{FiberBundle, Any, Any, Any}","content":" Manifolds.bundle_transport_to  ‚Äî  Method bundle_transport_to(B::FiberBundle, p, X, q) Given a fiber bundle  $B=F \\mathcal M$ , points  $p, q\\in\\mathcal M$ , an element  $X$  of the fiber over  $p$ , transport  $X$  to fiber over  $q$ . Exact meaning of the operation depends on the fiber bundle, or may even be undefined. Some fiber bundles may declare a default local section around each point crossing  X , represented by this function. source"},{"id":742,"pagetitle":"Fiber bundle","title":"ManifoldsBase.base_manifold","ref":"/manifolds/stable/manifolds/#ManifoldsBase.base_manifold-Tuple{FiberBundle}","content":" ManifoldsBase.base_manifold  ‚Äî  Method base_manifold(B::FiberBundle) Return the manifold the  FiberBundle s is build on. source"},{"id":743,"pagetitle":"Fiber bundle","title":"ManifoldsBase.zero_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.zero_vector-Tuple{FiberBundle, Vararg{Any}}","content":" ManifoldsBase.zero_vector  ‚Äî  Method zero_vector(B::FiberBundle, p) Zero tangent vector at point  p  from the fiber bundle  B  over manifold  B.fiber  (denoted  $\\mathcal M$ ). The zero vector belongs to the space  $T_{p}B$ Notation: The point  $p = (x_p, V_p)$  where  $x_p ‚àà \\mathcal M$  and  $V_p$  belongs to the fiber  $F=œÄ^{-1}(\\{x_p\\})$  of the vector bundle  $B$  where  $œÄ$  is the canonical projection of that vector bundle  $B$ . The zero vector is calculated as $\\mathbf{0}_{p} = (\\mathbf{0}_{x_p}, \\mathbf{0}_F)$ where  $\\mathbf{0}_{x_p}$  is the zero tangent vector from  $T_{x_p}\\mathcal M$  and  $\\mathbf{0}_F$  is the zero element of the vector space  $F$ . source"},{"id":746,"pagetitle":"Fixed-rank matrices","title":"Fixed-rank matrices","ref":"/manifolds/stable/manifolds/#FixedRankMatrices","content":" Fixed-rank matrices"},{"id":747,"pagetitle":"Fixed-rank matrices","title":"Manifolds.FixedRankMatrices","ref":"/manifolds/stable/manifolds/#Manifolds.FixedRankMatrices","content":" Manifolds.FixedRankMatrices  ‚Äî  Type FixedRankMatrices{T,ùîΩ} <: AbstractDecoratorManifold{ùîΩ} The manifold of  $m√ón$  real-valued or complex-valued matrices of fixed rank  $k$ , i.e. \\[\\bigl\\{ p ‚àà ùîΩ^{m√ón}\\ \\big|\\ \\operatorname{rank}(p) = k\\bigr\\},\\] where  $ùîΩ ‚àà \\{‚Ñù,‚ÑÇ\\}$  and the rank is the number of linearly independent columns of a matrix. Representation with 3 matrix factors A point  $p ‚àà \\mathcal M$  can be stored using unitary matrices  $U ‚àà ùîΩ^{m√ók}$ ,  $V ‚àà ùîΩ^{n√ók}$  as well as the  $k$  singular values of  $p = U_p S V_p^\\mathrm{H}$ , where  $‚ãÖ^{\\mathrm{H}}$  denotes the complex conjugate transpose or Hermitian. In other words,  $U$  and  $V$  are from the manifolds  Stiefel (m,k,ùîΩ)  and  Stiefel (n,k,ùîΩ) , respectively; see  SVDMPoint  for details. The tangent space  $T_p \\mathcal M$  at a point  $p ‚àà \\mathcal M$  with  $p=U_p S V_p^\\mathrm{H}$  is given by \\[T_p\\mathcal M = \\bigl\\{ U_p M V_p^\\mathrm{H} + U_X V_p^\\mathrm{H} + U_p V_X^\\mathrm{H} :\n    M  ‚àà ùîΩ^{k√ók},\n    U_X  ‚àà ùîΩ^{m√ók},\n    V_X  ‚àà ùîΩ^{n√ók}\n    \\text{ s.t. }\n    U_p^\\mathrm{H}U_X = 0_k,\n    V_p^\\mathrm{H}V_X = 0_k\n\\bigr\\},\\] where  $0_k$  is the  $k√ók$  zero matrix. See  UMVTVector  for details. The (default) metric of this manifold is obtained by restricting the metric on  $‚Ñù^{m√ón}$  to the tangent bundle [ Van13 ]. Constructor FixedRankMatrices(m, n, k[, field=‚Ñù]) Generate the manifold of  m -by- n  ( field -valued) matrices of rank  k . source"},{"id":748,"pagetitle":"Fixed-rank matrices","title":"Manifolds.OrthographicInverseRetraction","ref":"/manifolds/stable/manifolds/#Manifolds.OrthographicInverseRetraction","content":" Manifolds.OrthographicInverseRetraction  ‚Äî  Type OrthographicInverseRetraction <: AbstractInverseRetractionMethod Retractions that are related to orthographic projections, which was first used in [ AM12 ]. source"},{"id":749,"pagetitle":"Fixed-rank matrices","title":"Manifolds.OrthographicRetraction","ref":"/manifolds/stable/manifolds/#Manifolds.OrthographicRetraction","content":" Manifolds.OrthographicRetraction  ‚Äî  Type OrthographicRetraction <: AbstractRetractionMethod Retractions that are related to orthographic projections, which was first used in [ AM12 ]. source"},{"id":750,"pagetitle":"Fixed-rank matrices","title":"Manifolds.SVDMPoint","ref":"/manifolds/stable/manifolds/#Manifolds.SVDMPoint","content":" Manifolds.SVDMPoint  ‚Äî  Type SVDMPoint <: AbstractManifoldPoint A point on a certain manifold, where the data is stored in a svd like fashion, i.e. in the form  $USV^\\mathrm{H}$ , where this structure stores  $U$ ,  $S$  and  $V^\\mathrm{H}$ . The storage might also be shortened to just  $k$  singular values and accordingly shortened  $U$  (columns) and  $V^\\mathrm{H}$  (rows). Constructors SVDMPoint(A)  for a matrix  A , stores its svd factors (i.e. implicitly  $k=\\min\\{m,n\\}$ ) SVDMPoint(S)  for an  SVD  object, stores its svd factors (i.e. implicitly  $k=\\min\\{m,n\\}$ ) SVDMPoint(U,S,Vt)  for the svd factors to initialize the  SVDMPoint (i.e. implicitly k=\\min\\{m,n\\} `) SVDMPoint(A,k)  for a matrix  A , stores its svd factors shortened to the best rank  $k$  approximation SVDMPoint(S,k)  for an  SVD  object, stores its svd factors shortened to the best rank  $k$  approximation SVDMPoint(U,S,Vt,k)  for the svd factors to initialize the  SVDMPoint , stores its svd factors shortened to the best rank  $k$  approximation source"},{"id":751,"pagetitle":"Fixed-rank matrices","title":"Manifolds.UMVTVector","ref":"/manifolds/stable/manifolds/#Manifolds.UMVTVector","content":" Manifolds.UMVTVector  ‚Äî  Type UMVTVector <: TVector A tangent vector that can be described as a product  $U_p M V_p^\\mathrm{H} + U_X V_p^\\mathrm{H} + U_p V_X^\\mathrm{H}$ , where  $X = U_X S V_X^\\mathrm{H}$  is its base point, see for example  FixedRankMatrices . The base point  $p$  is required for example embedding this point, but it is not stored. The fields of thie tangent vector are  U  for  $U_X$ ,  M  and  Vt  to store  $V_X^\\mathrm{H}$ Constructors UMVTVector(U,M,Vt)  store umv factors to initialize the  UMVTVector UMVTVector(U,M,Vt,k)  store the umv factors after shortening them down to inner dimensions  k . source"},{"id":752,"pagetitle":"Fixed-rank matrices","title":"Base.rand","ref":"/manifolds/stable/manifolds/#Base.rand-Tuple{FixedRankMatrices}","content":" Base.rand  ‚Äî  Method Random.rand(M::FixedRankMatrices; vector_at=nothing, kwargs...) If  vector_at  is  nothing , return a random point on the  FixedRankMatrices  manifold. The orthogonal matrices are sampled from the  Stiefel  manifold and the singular values are sampled uniformly at random. If  vector_at  is not  nothing , generate a random tangent vector in the tangent space of the point  vector_at  on the  FixedRankMatrices  manifold  M . source"},{"id":753,"pagetitle":"Fixed-rank matrices","title":"ManifoldDiff.riemannian_Hessian","ref":"/manifolds/stable/manifolds/#ManifoldDiff.riemannian_Hessian-Tuple{FixedRankMatrices, Vararg{Any, 4}}","content":" ManifoldDiff.riemannian_Hessian  ‚Äî  Method Y = riemannian_Hessian(M::FixedRankMatrices, p, G, H, X)\nriemannian_Hessian!(M::FixedRankMatrices, Y, p, G, H, X) Compute the Riemannian Hessian  $\\operatorname{Hess} f(p)[X]$  given the Euclidean gradient  $‚àá f(\\tilde p)$  in  G  and the Euclidean Hessian  $‚àá^2 f(\\tilde p)[\\tilde X]$  in  H , where  $\\tilde p, \\tilde X$  are the representations of  $p,X$  in the embedding,. The Riemannian Hessian can be computed as stated in Remark 4.1 [ Ngu23 ] or Section 2.3 [ Van13 ], that B. Vandereycken adopted for  Manopt (Matlab) . source"},{"id":754,"pagetitle":"Fixed-rank matrices","title":"Manifolds.inverse_retract_orthographic!","ref":"/manifolds/stable/manifolds/#Manifolds.inverse_retract_orthographic!-Tuple{AbstractManifold, Any, Any, Any}","content":" Manifolds.inverse_retract_orthographic!  ‚Äî  Method inverse_retract_orthographic!(M::AbstractManifold, X, p, q) Compute the in-place variant of the  OrthographicInverseRetraction . source"},{"id":755,"pagetitle":"Fixed-rank matrices","title":"Manifolds.retract_orthographic!","ref":"/manifolds/stable/manifolds/#Manifolds.retract_orthographic!-Tuple{AbstractManifold, Any, Any, Any, Number}","content":" Manifolds.retract_orthographic!  ‚Äî  Method retract_orthographic!(M::AbstractManifold, q, p, X, t::Number) Compute the in-place variant of the  OrthographicRetraction . source"},{"id":756,"pagetitle":"Fixed-rank matrices","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{FixedRankMatrices, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::FixedRankMatrices, p; kwargs...) Check whether the matrix or  SVDMPoint x  ids a valid point on the  FixedRankMatrices M , i.e. is an  m -by n  matrix of rank  k . For the  SVDMPoint  the internal representation also has to have the right shape, i.e.  p.U  and  p.Vt  have to be unitary. The keyword arguments are passed to the  rank  function that verifies the rank of  p . source"},{"id":757,"pagetitle":"Fixed-rank matrices","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{FixedRankMatrices, SVDMPoint, UMVTVector}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M:FixedRankMatrices, p, X; kwargs...) Check whether the tangent  UMVTVector X  is from the tangent space of the  SVDMPoint p  on the  FixedRankMatrices M , i.e. that  v.U  and  v.Vt  are (columnwise) orthogonal to  x.U  and  x.Vt , respectively, and its dimensions are consistent with  p  and  X.M , i.e. correspond to  m -by- n  matrices of rank  k . source"},{"id":758,"pagetitle":"Fixed-rank matrices","title":"ManifoldsBase.default_inverse_retraction_method","ref":"/manifolds/stable/manifolds/#ManifoldsBase.default_inverse_retraction_method-Tuple{FixedRankMatrices}","content":" ManifoldsBase.default_inverse_retraction_method  ‚Äî  Method default_inverse_retraction_method(M::FixedRankMatrices) Return  PolarInverseRetraction  as the default inverse retraction for the  FixedRankMatrices  manifold. source"},{"id":759,"pagetitle":"Fixed-rank matrices","title":"ManifoldsBase.default_retraction_method","ref":"/manifolds/stable/manifolds/#ManifoldsBase.default_retraction_method-Tuple{FixedRankMatrices}","content":" ManifoldsBase.default_retraction_method  ‚Äî  Method default_retraction_method(M::FixedRankMatrices) Return  PolarRetraction  as the default retraction for the  FixedRankMatrices  manifold. source"},{"id":760,"pagetitle":"Fixed-rank matrices","title":"ManifoldsBase.default_vector_transport_method","ref":"/manifolds/stable/manifolds/#ManifoldsBase.default_vector_transport_method-Tuple{FixedRankMatrices}","content":" ManifoldsBase.default_vector_transport_method  ‚Äî  Method default_vector_transport_method(M::FixedRankMatrices) Return the  ProjectionTransport  as the default vector transport method for the  FixedRankMatrices  manifold. source"},{"id":761,"pagetitle":"Fixed-rank matrices","title":"ManifoldsBase.embed","ref":"/manifolds/stable/manifolds/#ManifoldsBase.embed-Tuple{FixedRankMatrices, SVDMPoint, UMVTVector}","content":" ManifoldsBase.embed  ‚Äî  Method embed(M::FixedRankMatrices, p, X) Embed the tangent vector  X  at point  p  in  M  from its  UMVTVector  representation  into the set of  $m√ón$  matrices. The formula reads \\[U_pMV_p^{\\mathrm{H}} + U_XV_p^{\\mathrm{H}} + U_pV_X^{\\mathrm{H}}\\] source"},{"id":762,"pagetitle":"Fixed-rank matrices","title":"ManifoldsBase.embed","ref":"/manifolds/stable/manifolds/#ManifoldsBase.embed-Tuple{FixedRankMatrices, SVDMPoint}","content":" ManifoldsBase.embed  ‚Äî  Method embed(::FixedRankMatrices, p::SVDMPoint) Embed the point  p  from its  SVDMPoint  representation into the set of  $m√ón$  matrices by computing  $USV^{\\mathrm{H}}$ . source"},{"id":763,"pagetitle":"Fixed-rank matrices","title":"ManifoldsBase.injectivity_radius","ref":"/manifolds/stable/manifolds/#ManifoldsBase.injectivity_radius-Tuple{FixedRankMatrices}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(::FixedRankMatrices) Return the incjectivity radius of the manifold of  FixedRankMatrices , i.e. 0. See [ HU17 ]. source"},{"id":764,"pagetitle":"Fixed-rank matrices","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{FixedRankMatrices, SVDMPoint, UMVTVector, UMVTVector}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::FixedRankMatrices, p::SVDMPoint, X::UMVTVector, Y::UMVTVector) Compute the inner product of  X  and  Y  in the tangent space of  p  on the  FixedRankMatrices M , which is inherited from the embedding, i.e. can be computed using  dot  on the elements ( U ,  Vt ,  M ) of  X  and  Y . source"},{"id":765,"pagetitle":"Fixed-rank matrices","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{FixedRankMatrices, Any, Any, OrthographicInverseRetraction}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(M, p, q, ::OrthographicInverseRetraction) Compute the orthographic inverse retraction  FixedRankMatrices M  by computing \\[    X = P_{T_{p}M}(q - p) = qVV^\\mathrm{T} + UU^{\\mathrm{T}}q - UU^{\\mathrm{T}}qVV^{\\mathrm{T}} - p,\\] where  $p$  is a  SVDMPoint (U,S,Vt)  and  $P_{T_{p}M}$  is the  project ion onto the tangent space at  $p$ . For more details, see [ AO14 ]. source"},{"id":766,"pagetitle":"Fixed-rank matrices","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{FixedRankMatrices}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::FixedRankMatrices) Return false.  FixedRankMatrices  is not a flat manifold. source"},{"id":767,"pagetitle":"Fixed-rank matrices","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Union{Tuple{FixedRankMatrices{<:Any, ùîΩ}}, Tuple{ùîΩ}} where ùîΩ","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::FixedRankMatrices) Return the manifold dimension for the  ùîΩ -valued  FixedRankMatrices M  of dimension  m x n  of rank  k , namely \\[\\dim(\\mathcal M) = k(m + n - k) \\dim_‚Ñù ùîΩ,\\] where  $\\dim_‚Ñù ùîΩ$  is the  real_dimension  of  ùîΩ . source"},{"id":768,"pagetitle":"Fixed-rank matrices","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{FixedRankMatrices, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M, p, A) Project the matrix  $A ‚àà ‚Ñù^{m,n}$  or from the embedding the tangent space at  $p$  on the  FixedRankMatrices M , further decomposing the result into  $X=UMV^\\mathrm{H}$ , i.e. a  UMVTVector . source"},{"id":769,"pagetitle":"Fixed-rank matrices","title":"ManifoldsBase.representation_size","ref":"/manifolds/stable/manifolds/#ManifoldsBase.representation_size-Tuple{FixedRankMatrices}","content":" ManifoldsBase.representation_size  ‚Äî  Method representation_size(M::FixedRankMatrices) Return the element size of a point on the  FixedRankMatrices M , i.e. the size of matrices on this manifold  $(m,n)$ . source"},{"id":770,"pagetitle":"Fixed-rank matrices","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{FixedRankMatrices, Any, Any, OrthographicRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::FixedRankMatrices, p, X, ::OrthographicRetraction) Compute the OrthographicRetraction on the  FixedRankMatrices M  by finding the nearest point to  $p + X$  in \\[    p + X + N_{p}\\mathcal M \\cap \\mathcal M\\] where  $N_{p}\\mathcal M$  is the Normal Space of  $T_{p}\\mathcal M$ . If  $X$  is sufficiently small, then the nearest such point is unique and can be expressed by \\[    q = (U(S + M) + U_{p})(S + M)^{-1}((S + M)V^{\\mathrm{T}} + V^{\\mathrm{T}}_{p}),\\] where  $p$  is a  SVDMPoint (U,S,Vt)  and  $X$  is an  UMVTVector (Up,M,Vtp) . For more details, see [ AO14 ]. source"},{"id":771,"pagetitle":"Fixed-rank matrices","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{FixedRankMatrices, Any, Any, PolarRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M, p, X, ::PolarRetraction) Compute an SVD-based retraction on the  FixedRankMatrices M  by computing \\[    q = U_kS_kV_k^\\mathrm{H},\\] where  $U_k S_k V_k^\\mathrm{H}$  is the shortened singular value decomposition  $USV^\\mathrm{H}=p+X$ , in the sense that  $S_k$  is the diagonal matrix of size  $k√ók$  with the  $k$  largest singular values and  $U$  and  $V$  are shortened accordingly. source"},{"id":772,"pagetitle":"Fixed-rank matrices","title":"ManifoldsBase.vector_transport_to!","ref":"/manifolds/stable/manifolds/#ManifoldsBase.vector_transport_to!-Tuple{FixedRankMatrices, Any, Any, Any, ProjectionTransport}","content":" ManifoldsBase.vector_transport_to!  ‚Äî  Method vector_transport_to(M::FixedRankMatrices, p, X, q, ::ProjectionTransport) Compute the vector transport of the tangent vector  X  at  p  to  q , using the  project  of  X  to  q . source"},{"id":773,"pagetitle":"Fixed-rank matrices","title":"ManifoldsBase.zero_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.zero_vector-Tuple{FixedRankMatrices, SVDMPoint}","content":" ManifoldsBase.zero_vector  ‚Äî  Method zero_vector(M::FixedRankMatrices, p::SVDMPoint) Return a  UMVTVector  representing the zero tangent vector in the tangent space of  p  on the  FixedRankMatrices M , for example all three elements of the resulting structure are zero matrices. source"},{"id":774,"pagetitle":"Fixed-rank matrices","title":"Literature","ref":"/manifolds/stable/manifolds/#Literature","content":" Literature [AM12] P.-A.¬†Absil and J.¬†Malick.  Projection-like Retractions on Matrix Manifolds .  SIAM¬†Journal¬†on¬†Optimization  22 , 135‚Äì158  (2012). [AO14] P.-A.¬†Absil and I.¬†V.¬†Oseledets.  Low-rank retractions: a survey and new results .  Computational¬†Optimization¬†and¬†Applications  62 , 5‚Äì29  (2014). [HU17] S.¬†Hosseini and A.¬†Uschmajew.  A Riemannian Gradient Sampling Algorithm for Nonsmooth Optimization on Manifolds .  SIAM¬†J.¬†Optim.  27 , 173‚Äì189  (2017). [Ngu23] D.¬†Nguyen.  Operator-Valued Formulas for Riemannian Gradient and Hessian and Families of Tractable Metrics in Riemannian Optimization .  Journal¬†of¬†Optimization¬†Theory¬†and¬†Applications  198 , 135‚Äì164  (2023),  arXiv:2009.10159 . [Van13] B.¬†Vandereycken.  Low-rank matrix completion by Riemannian optimization .  SIAM¬†Journal¬†on¬†Optimization  23 , 1214‚Äì1236  (2013)."},{"id":777,"pagetitle":"Flag","title":"Flag manifold","ref":"/manifolds/stable/manifolds/#Flag-manifold","content":" Flag manifold"},{"id":778,"pagetitle":"Flag","title":"Manifolds.Flag","ref":"/manifolds/stable/manifolds/#Manifolds.Flag","content":" Manifolds.Flag  ‚Äî  Type Flag{T,d} <: AbstractDecoratorManifold{‚Ñù} Flag manifold of  $d$  subspaces of  $‚Ñù^N$  [ YWL21 ]. By default the manifold uses the Stiefel coordinates representation, embedding it in the  Stiefel  manifold. The other available representation is an embedding in  OrthogonalMatrices . It can be utilized using  OrthogonalPoint  and  OrthogonalTVector  wrappers. Tangent space is represented in the block-skew-symmetric form. Constructor Flag(N, n1, n2, ..., nd; parameter::Symbol=:type) Generate the manifold  $\\operatorname{Flag}(n_1, n_2, ..., n_d; N)$  of subspaces \\[ùïç_1 ‚äÜ ùïç_2 ‚äÜ ‚ãØ ‚äÜ V_d, \\quad \\operatorname{dim}(ùïç_i) = n_i\\] where  $ùïç_i$  for  $i ‚àà 1, 2, ‚Ä¶, d$  are subspaces of  $‚Ñù^N$  of dimension  $\\operatorname{dim} ùïç_i = n_i$ . parameter : whether a type parameter should be used to store  n . By default size is stored in type. Value can either be  :field  or  :type . source"},{"id":779,"pagetitle":"Flag","title":"Manifolds.OrthogonalPoint","ref":"/manifolds/stable/manifolds/#Manifolds.OrthogonalPoint","content":" Manifolds.OrthogonalPoint  ‚Äî  Type OrthogonalPoint <: AbstractManifoldPoint A type to represent points on a manifold  Flag  in the orthogonal coordinates representation, i.e. a rotation matrix. source"},{"id":780,"pagetitle":"Flag","title":"Manifolds.OrthogonalTVector","ref":"/manifolds/stable/manifolds/#Manifolds.OrthogonalTVector","content":" Manifolds.OrthogonalTVector  ‚Äî  Type OrthogonalTVector <: TVector A type to represent tangent vectors to points on a  Flag  manifold  in the orthogonal coordinates representation. source"},{"id":781,"pagetitle":"Flag","title":"Manifolds.ZeroTuple","ref":"/manifolds/stable/manifolds/#Manifolds.ZeroTuple","content":" Manifolds.ZeroTuple  ‚Äî  Type ZeroTuple Internal structure for representing shape of a  Flag  manifold. Behaves like a normal tuple, except at index zero returns value 0. source"},{"id":782,"pagetitle":"Flag","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{AbstractMatrix}, Flag, Manifolds.OrthogonalPoint, Manifolds.OrthogonalTVector}","content":" Base.convert  ‚Äî  Method convert(::Type{AbstractMatrix}, M::Flag, p::OrthogonalPoint, X::OrthogonalTVector) Convert tangent vector from  Flag  manifold  M  from orthogonal representation to Stiefel representation. source"},{"id":783,"pagetitle":"Flag","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{AbstractMatrix}, Flag, Manifolds.OrthogonalPoint}","content":" Base.convert  ‚Äî  Method convert(::Type{AbstractMatrix}, M::Flag, p::OrthogonalPoint) Convert point  p  from  Flag  manifold  M  from orthogonal representation to Stiefel representation. source"},{"id":784,"pagetitle":"Flag","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{Manifolds.OrthogonalPoint}, Flag, AbstractMatrix}","content":" Base.convert  ‚Äî  Method convert(::Type{OrthogonalPoint}, M::Flag, p::AbstractMatrix) Convert point  p  from  Flag  manifold  M  from Stiefel representation to orthogonal representation. source"},{"id":785,"pagetitle":"Flag","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{Manifolds.OrthogonalTVector}, Flag, AbstractMatrix, AbstractMatrix}","content":" Base.convert  ‚Äî  Method convert(::Type{OrthogonalTVector}, M::Flag, p::AbstractMatrix, X::AbstractMatrix) Convert tangent vector from  Flag  manifold  M  from Stiefel representation to orthogonal representation. source"},{"id":786,"pagetitle":"Flag","title":"ManifoldsBase.get_embedding","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_embedding-Union{Tuple{Flag{Tuple{Int64}, dp1}}, Tuple{dp1}} where dp1","content":" ManifoldsBase.get_embedding  ‚Äî  Method get_embedding(M::Flag) Get the embedding of the  Flag  manifold  M , i.e. the  Stiefel  manifold. source"},{"id":787,"pagetitle":"Flag","title":"ManifoldsBase.injectivity_radius","ref":"/manifolds/stable/manifolds/#ManifoldsBase.injectivity_radius-Tuple{Flag}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(M::Flag)\ninjectivity_radius(M::Flag, p) Return the injectivity radius on the  Flag M , which is  $\\frac{œÄ}{2}$ . source"},{"id":788,"pagetitle":"Flag","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Union{Tuple{Flag{<:Any, dp1}}, Tuple{dp1}} where dp1","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::Flag) Return dimension of flag manifold  $\\operatorname{Flag}(n_1, n_2, ..., n_d; N)$ . The formula reads  $\\sum_{i=1}^d (n_i-n_{i-1})(N-n_i)$ . source"},{"id":789,"pagetitle":"Flag","title":"The flag manifold represented as points on the  Stiefel  manifold","ref":"/manifolds/stable/manifolds/#The-flag-manifold-represented-as-points-on-the-[Stiefel](@ref)-manifold","content":" The flag manifold represented as points on the  Stiefel  manifold"},{"id":790,"pagetitle":"Flag","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Union{Tuple{dp1}, Tuple{Flag{<:Any, dp1}, AbstractMatrix, AbstractMatrix}} where dp1","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::Flag, p::AbstractMatrix, X::AbstractMatrix; kwargs... ) Check whether  X  is a tangent vector to point  p  on the  Flag  manifold  M $\\operatorname{Flag}(n_1, n_2, ..., n_d; N)$  in the Stiefel representation, i.e. that  X  is a matrix of the form \\[X = \\begin{bmatrix}\n0                     & B_{1,2}               & ‚ãØ & B_{1,d} \\\\\n-B_{1,2}^\\mathrm{T}   & 0                     & ‚ãØ & B_{2,d} \\\\\n\\vdots                & \\vdots                & ‚ã± & \\vdots  \\\\\n-B_{1,d}^\\mathrm{T}   & -B_{2,d}^\\mathrm{T}   & ‚ãØ & 0       \\\\\n-B_{1,d+1}^\\mathrm{T} & -B_{2,d+1}^\\mathrm{T} & ‚ãØ & -B_{d,d+1}^\\mathrm{T}\n\\end{bmatrix}\\] where  $B_{i,j} ‚àà ‚Ñù^{(n_i - n_{i-1}) √ó (n_j - n_{j-1})}$ , for   $1 ‚â§ i < j ‚â§ d+1$ . source"},{"id":791,"pagetitle":"Flag","title":"ManifoldsBase.default_inverse_retraction_method","ref":"/manifolds/stable/manifolds/#ManifoldsBase.default_inverse_retraction_method-Tuple{Flag}","content":" ManifoldsBase.default_inverse_retraction_method  ‚Äî  Method default_inverse_retraction_method(M::Flag) Return  PolarInverseRetraction  as the default inverse retraction for the  Flag  manifold. source"},{"id":792,"pagetitle":"Flag","title":"ManifoldsBase.default_retraction_method","ref":"/manifolds/stable/manifolds/#ManifoldsBase.default_retraction_method-Tuple{Flag}","content":" ManifoldsBase.default_retraction_method  ‚Äî  Method default_retraction_method(M::Flag) Return  PolarRetraction  as the default retraction for the  Flag  manifold. source"},{"id":793,"pagetitle":"Flag","title":"ManifoldsBase.default_vector_transport_method","ref":"/manifolds/stable/manifolds/#ManifoldsBase.default_vector_transport_method-Tuple{Flag}","content":" ManifoldsBase.default_vector_transport_method  ‚Äî  Method default_vector_transport_method(M::Flag) Return the  ProjectionTransport  as the default vector transport method for the  Flag  manifold. source"},{"id":794,"pagetitle":"Flag","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{Flag, Any, Any, PolarInverseRetraction}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(M::Flag, p, q, ::PolarInverseRetraction) Compute the inverse retraction for the  PolarRetraction , on the  Flag  manifold  M . source"},{"id":795,"pagetitle":"Flag","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Flag, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(::Flag, p, X) Project vector  X  in the Euclidean embedding to the tangent space at point  p  on  Flag  manifold. The formula reads [ YWL21 ]: \\[Y_i = X_i - (p_i p_i^{\\mathrm{T}}) X_i + \\sum_{j \\neq i} p_j X_j^{\\mathrm{T}} p_i\\] for  $i$  from 1 to  $d$  where the resulting vector is  $Y = [Y_1, Y_2, ‚Ä¶, Y_d]$  and  $X = [X_1, X_2, ‚Ä¶, X_d]$ ,  $p = [p_1, p_2, ‚Ä¶, p_d]$  are decompositions into basis vector matrices for consecutive subspaces of the flag. source"},{"id":796,"pagetitle":"Flag","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{Flag, Any, Any, PolarRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::Flag, p, X, ::PolarRetraction) Compute the SVD-based retraction  PolarRetraction  on the  Flag M . With  $USV = p + X$  the retraction reads \\[\\operatorname{retr}_p X = UV^\\mathrm{H},\\] where  $\\cdot^{\\mathrm{H}}$  denotes the complex conjugate transposed or Hermitian. source"},{"id":797,"pagetitle":"Flag","title":"The flag manifold represented as orthogonal matrices","ref":"/manifolds/stable/manifolds/#The-flag-manifold-represented-as-orthogonal-matrices","content":" The flag manifold represented as orthogonal matrices"},{"id":798,"pagetitle":"Flag","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Union{Tuple{dp1}, Tuple{Flag{<:Any, dp1}, Manifolds.OrthogonalPoint, Manifolds.OrthogonalTVector}} where dp1","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::Flag, p::OrthogonalPoint, X::OrthogonalTVector; kwargs... ) Check whether  X  is a tangent vector to point  p  on the  Flag  manifold  M $\\operatorname{Flag}(n_1, n_2, ..., n_d; N)$  in the orthogonal matrix representation, i.e. that  X  is block-skew-symmetric with zero diagonal: \\[X = \\begin{bmatrix}\n0                     & B_{1,2}               & ‚ãØ & B_{1,d+1} \\\\\n-B_{1,2}^\\mathrm{T}   & 0                     & ‚ãØ & B_{2,d+1} \\\\\n\\vdots                & \\vdots                & ‚ã± & \\vdots    \\\\\n-B_{1,d+1}^\\mathrm{T} & -B_{2,d+1}^\\mathrm{T} & ‚ãØ & 0\n\\end{bmatrix}\\] where  $B_{i,j} ‚àà ‚Ñù^{(n_i - n_{i-1}) √ó (n_j - n_{j-1})}$ , for   $1 ‚â§ i < j ‚â§ d+1$ . source"},{"id":799,"pagetitle":"Flag","title":"ManifoldsBase.get_embedding","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_embedding-Union{Tuple{N}, Tuple{Flag{ManifoldsBase.TypeParameter{Tuple{N}}}, Manifolds.OrthogonalPoint}} where N","content":" ManifoldsBase.get_embedding  ‚Äî  Method get_embedding(M::Flag, p::OrthogonalPoint) Get embedding of  Flag  manifold  M , i.e. the manifold  OrthogonalMatrices . source"},{"id":800,"pagetitle":"Flag","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Union{Tuple{dp1}, Tuple{Flag{<:Any, dp1}, Manifolds.OrthogonalPoint, Manifolds.OrthogonalTVector}} where dp1","content":" ManifoldsBase.project  ‚Äî  Method project(M::Flag, p::OrthogonalPoint, X::OrthogonalTVector) Project vector  X  to tangent space at point  p  from  Flag  manifold  M $\\operatorname{Flag}(n_1, n_2, ..., n_d; N)$ , in the orthogonal matrix representation. It works by first projecting  X  to the space of  SkewHermitianMatrices  and then setting diagonal blocks to 0: \\[X = \\begin{bmatrix}\n0                     & B_{1,2}               & ‚ãØ & B_{1,d+1} \\\\\n-B_{1,2}^\\mathrm{T}   & 0                     & ‚ãØ & B_{2,d+1} \\\\\n\\vdots                & \\vdots                & ‚ã± & \\vdots    \\\\\n-B_{1,d+1}^\\mathrm{T} & -B_{2,d+1}^\\mathrm{T} & ‚ãØ & 0\n\\end{bmatrix}\\] where  $B_{i,j} ‚àà ‚Ñù^{(n_i - n_{i-1}) √ó (n_j - n_{j-1})}$ , for   $1 ‚â§ i < j ‚â§ d+1$ . source"},{"id":801,"pagetitle":"Flag","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{Flag, Manifolds.OrthogonalPoint, Manifolds.OrthogonalTVector, QRRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::Flag, p::OrthogonalPoint, X::OrthogonalTVector, ::QRRetraction) Compute the QR retraction on the  Flag  in the orthogonal matrix representation as the first order approximation to the exponential map. Similar to QR retraction for [ GeneralUnitaryMatrices ]. source"},{"id":804,"pagetitle":"Generalized Grassmann","title":"Generalized Grassmann","ref":"/manifolds/stable/manifolds/#Generalized-Grassmann","content":" Generalized Grassmann"},{"id":805,"pagetitle":"Generalized Grassmann","title":"Manifolds.GeneralizedGrassmann","ref":"/manifolds/stable/manifolds/#Manifolds.GeneralizedGrassmann","content":" Manifolds.GeneralizedGrassmann  ‚Äî  Type GeneralizedGrassmann{T,ùîΩ,TB<:AbstractMatrix} <: AbstractDecoratorManifold{ùîΩ} The generalized Grassmann manifold  $\\operatorname{Gr}(n,k,B)$  consists of all subspaces spanned by  $k$  linear independent vectors  $ùîΩ^n$ , where  $ùîΩ  ‚àà \\{‚Ñù, ‚ÑÇ\\}$  is either the real- (or complex-) valued vectors. This yields all  $k$ -dimensional subspaces of  $‚Ñù^n$  for the real-valued case and all  $2k$ -dimensional subspaces of  $‚ÑÇ^n$  for the second. The manifold can be represented as \\[\\operatorname{Gr}(n, k, B) := \\bigl\\{ \\operatorname{span}(p)\\ \\big|\\ p ‚àà ùîΩ^{n√ók}, p^\\mathrm{H}Bp = I_k\\},\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the complex conjugate (or Hermitian) transpose and  $I_k$  is the  $k√ók$  identity matrix. This means, that the columns of  $p$  form an unitary basis of the subspace with respect to the scaled inner product, that is a point on  $\\operatorname{Gr}(n,k,B)$ , and hence the subspace can actually be represented by a whole equivalence class of representers. For  $B=I_n$  this simplifies to the  Grassmann  manifold. The tangent space at a point (subspace)  $p$  is given by \\[T_x\\mathrm{Gr}(n,k,B) = \\bigl\\{\nX ‚àà ùîΩ^{n√ók} :\nX^{\\mathrm{H}}Bp + p^{\\mathrm{H}}BX = 0_{k} \\bigr\\},\\] where  $0_{k}$  denotes the  $k√ók$  zero matrix. Note that a point  $p ‚àà \\operatorname{Gr}(n,k,B)$  might be represented by different matrices (i.e. matrices with  $B$ -unitary column vectors that span the same subspace). Different representations of  $p$  also lead to different representation matrices for the tangent space  $T_p\\mathrm{Gr}(n,k,B)$ The manifold is named after  Hermann G. Gra√ümann  (1809-1877). Constructor GeneralizedGrassmann(n, k, B=I_n, field=‚Ñù) Generate the (real-valued) Generalized Grassmann manifold of  $n√ók$  dimensional orthonormal matrices with scalar product  B . source"},{"id":806,"pagetitle":"Generalized Grassmann","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{GeneralizedGrassmann, Vararg{Any}}","content":" Base.exp  ‚Äî  Method exp(M::GeneralizedGrassmann, p, X) Compute the exponential map on the  GeneralizedGrassmann M $= \\mathrm{Gr}(n,k,B)$  starting in  p  with tangent vector (direction)  X . Let  $X^{\\mathrm{H}}BX = USV$  denote the SVD decomposition of  $X^{\\mathrm{H}}BX$ . Then the exponential map is written using \\[\\exp_p X = p V\\cos(S)V^\\mathrm{H} + U\\sin(S)V^\\mathrm{H},\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the complex conjugate transposed or Hermitian and the cosine and sine are applied element wise to the diagonal entries of  $S$ . source"},{"id":807,"pagetitle":"Generalized Grassmann","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{GeneralizedGrassmann, Vararg{Any}}","content":" Base.log  ‚Äî  Method log(M::GeneralizedGrassmann, p, q) Compute the logarithmic map on the  GeneralizedGrassmann M $= \\mathcal M=\\mathrm{Gr}(n,k,B)$ , i.e. the tangent vector  X  whose corresponding  geodesic  starting from  p  reaches  q  after time 1 on  M . The formula reads \\[\\log_p q = V‚ãÖ \\operatorname{atan}(S) ‚ãÖ U^\\mathrm{H},\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the complex conjugate transposed or Hermitian. The matrices  $U$  and  $V$  are the unitary matrices, and  $S$  is the diagonal matrix containing the singular values of the SVD-decomposition \\[USV = (q^\\mathrm{H}Bp)^{-1} ( q^\\mathrm{H} - q^\\mathrm{H}Bpp^\\mathrm{H}).\\] In this formula the  $\\operatorname{atan}$  is meant elementwise. source"},{"id":808,"pagetitle":"Generalized Grassmann","title":"Base.rand","ref":"/manifolds/stable/manifolds/#Base.rand-Tuple{GeneralizedGrassmann}","content":" Base.rand  ‚Äî  Method rand(::GeneralizedGrassmann; vector_at=nothing, œÉ::Real=1.0) When  vector_at  is  nothing , return a random (Gaussian) point  p  on the  GeneralizedGrassmann  manifold  M  by generating a (Gaussian) matrix with standard deviation  œÉ  and return the (generalized) orthogonalized version, i.e. return the projection onto the manifold of the Q component of the QR decomposition of the random matrix of size  $n√ók$ . When  vector_at  is not  nothing , return a (Gaussian) random vector from the tangent space  $T_{vector\\_at}\\mathrm{St}(n,k)$  with mean zero and standard deviation  œÉ  by projecting a random Matrix onto the tangent vector at  vector_at . source"},{"id":809,"pagetitle":"Generalized Grassmann","title":"ManifoldsBase.change_metric","ref":"/manifolds/stable/manifolds/#ManifoldsBase.change_metric-Tuple{GeneralizedGrassmann, EuclideanMetric, Any, Any}","content":" ManifoldsBase.change_metric  ‚Äî  Method change_metric(M::GeneralizedGrassmann, ::EuclideanMetric, p X) Change  X  to the corresponding vector with respect to the metric of the  GeneralizedGrassmann M , i.e. let  $B=LL'$  be the Cholesky decomposition of the matrix  M.B , then the corresponding vector is  $L\\X$ . source"},{"id":810,"pagetitle":"Generalized Grassmann","title":"ManifoldsBase.change_representer","ref":"/manifolds/stable/manifolds/#ManifoldsBase.change_representer-Tuple{GeneralizedGrassmann, EuclideanMetric, Any, Any}","content":" ManifoldsBase.change_representer  ‚Äî  Method change_representer(M::GeneralizedGrassmann, ::EuclideanMetric, p, X) Change  X  to the corresponding representer of a cotangent vector at  p  with respect to the scaled metric of the  GeneralizedGrassmann M , i.e, since \\[g_p(X,Y) = \\operatorname{tr}(Y^{\\mathrm{H}}BZ) = \\operatorname{tr}(X^{\\mathrm{H}}Z) = ‚ü®X,Z‚ü©\\] has to hold for all  $Z$ , where the repreenter  X  is given, the resulting representer with respect to the metric on the  GeneralizedGrassmann  is given by  $Y = B^{-1}X$ . source"},{"id":811,"pagetitle":"Generalized Grassmann","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{GeneralizedGrassmann, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::GeneralizedGrassmann, p) Check whether  p  is representing a point on the  GeneralizedGrassmann M , i.e. its a  n -by- k  matrix of unitary column vectors with respect to the B inner prudct and of correct  eltype  with respect to  ùîΩ . source"},{"id":812,"pagetitle":"Generalized Grassmann","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{GeneralizedGrassmann, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::GeneralizedGrassmann, p, X; kwargs...) Check whether  X  is a tangent vector in the tangent space of  p  on the  GeneralizedGrassmann M , i.e. that  X  is of size and type as well as that \\[    p^{\\mathrm{H}}BX + \\overline{X^{\\mathrm{H}}Bp} = 0_k,\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the complex conjugate transpose or Hermitian,  $\\overline{‚ãÖ}$  the (elementwise) complex conjugate, and  $0_k$  denotes the  $k√ók$  zero natrix. source"},{"id":813,"pagetitle":"Generalized Grassmann","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{GeneralizedGrassmann, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::GeneralizedGrassmann, p, q) Compute the Riemannian distance on  GeneralizedGrassmann  manifold  M $= \\mathrm{Gr}(n,k,B)$ . The distance is given by \\[d_{\\mathrm{Gr}(n,k,B)}(p,q) = \\operatorname{norm}(\\log_p(q)).\\] source"},{"id":814,"pagetitle":"Generalized Grassmann","title":"ManifoldsBase.injectivity_radius","ref":"/manifolds/stable/manifolds/#ManifoldsBase.injectivity_radius-Tuple{GeneralizedGrassmann}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(M::GeneralizedGrassmann)\ninjectivity_radius(M::GeneralizedGrassmann, p) Return the injectivity radius on the  GeneralizedGrassmann M , which is  $\\frac{œÄ}{2}$ . source"},{"id":815,"pagetitle":"Generalized Grassmann","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{GeneralizedGrassmann, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::GeneralizedGrassmann, p, X, Y) Compute the inner product for two tangent vectors  X ,  Y  from the tangent space of  p  on the  GeneralizedGrassmann  manifold  M . The formula reads \\[g_p(X,Y) = \\operatorname{tr}(X^{\\mathrm{H}}BY),\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the complex conjugate transposed or Hermitian. source"},{"id":816,"pagetitle":"Generalized Grassmann","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{GeneralizedGrassmann}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(M::GeneralizedGrassmann) Return true if  GeneralizedGrassmann M  is one-dimensional. source"},{"id":817,"pagetitle":"Generalized Grassmann","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Union{Tuple{GeneralizedGrassmann{<:Any, ùîΩ}}, Tuple{ùîΩ}} where ùîΩ","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::GeneralizedGrassmann) Return the dimension of the  GeneralizedGrassmann(n,k,ùîΩ)  manifold  M , i.e. \\[\\dim \\operatorname{Gr}(n,k,B) = k(n-k) \\dim_‚Ñù ùîΩ,\\] where  $\\dim_‚Ñù ùîΩ$  is the  real_dimension  of  ùîΩ . source"},{"id":818,"pagetitle":"Generalized Grassmann","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{GeneralizedGrassmann, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::GeneralizedGrassmann, p, X) Project the  n -by- k X  onto the tangent space of  p  on the  GeneralizedGrassmann M , which is computed by \\[\\operatorname{proj_p}(X) = X - pp^{\\mathrm{H}}B^\\mathrm{T}X,\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the complex conjugate transposed or Hermitian and  $‚ãÖ^{\\mathrm{T}}$  the transpose. source"},{"id":819,"pagetitle":"Generalized Grassmann","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{GeneralizedGrassmann, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::GeneralizedGrassmann, p) Project  p  from the embedding onto the  GeneralizedGrassmann M , i.e. compute  q  as the polar decomposition of  $p$  such that  $q^{\\mathrm{H}}Bq$  is the identity, where  $‚ãÖ^{\\mathrm{H}}$  denotes the Hermitian, i.e. complex conjugate transpose. source"},{"id":820,"pagetitle":"Generalized Grassmann","title":"ManifoldsBase.representation_size","ref":"/manifolds/stable/manifolds/#ManifoldsBase.representation_size-Tuple{GeneralizedGrassmann}","content":" ManifoldsBase.representation_size  ‚Äî  Method representation_size(M::GeneralizedGrassmann) Return the represenation size or matrix dimension of a point on the  GeneralizedGrassmann M , i.e.  $(n,k)$  for both the real-valued and the complex value case. source"},{"id":821,"pagetitle":"Generalized Grassmann","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{GeneralizedGrassmann, Any, Any, PolarRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::GeneralizedGrassmann, p, X, ::PolarRetraction) Compute the SVD-based retraction  PolarRetraction  on the  GeneralizedGrassmann M , by  project ing  $p + X$  onto  M . source"},{"id":822,"pagetitle":"Generalized Grassmann","title":"ManifoldsBase.zero_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.zero_vector-Tuple{GeneralizedGrassmann, Vararg{Any}}","content":" ManifoldsBase.zero_vector  ‚Äî  Method zero_vector(M::GeneralizedGrassmann, p) Return the zero tangent vector from the tangent space at  p  on the  GeneralizedGrassmann M , which is given by a zero matrix the same size as  p . source"},{"id":823,"pagetitle":"Generalized Grassmann","title":"Statistics.mean","ref":"/manifolds/stable/manifolds/#Statistics.mean-Tuple{GeneralizedGrassmann, Vararg{Any}}","content":" Statistics.mean  ‚Äî  Method mean(\n    M::GeneralizedGrassmann,\n    x::AbstractVector,\n    [w::AbstractWeights,]\n    method = GeodesicInterpolationWithinRadius(œÄ/4);\n    kwargs...,\n) Compute the Riemannian  mean  of  x  using  GeodesicInterpolationWithinRadius . source"},{"id":826,"pagetitle":"Generalized Stiefel","title":"Generalized Stiefel","ref":"/manifolds/stable/manifolds/#Generalized-Stiefel","content":" Generalized Stiefel"},{"id":827,"pagetitle":"Generalized Stiefel","title":"Manifolds.GeneralizedStiefel","ref":"/manifolds/stable/manifolds/#Manifolds.GeneralizedStiefel","content":" Manifolds.GeneralizedStiefel  ‚Äî  Type GeneralizedStiefel{T,ùîΩ,B} <: AbstractDecoratorManifold{ùîΩ} The Generalized Stiefel manifold consists of all  $n√ók$ ,  $n\\geq k$  orthonormal matrices w.r.t. an arbitrary scalar product with symmetric positive definite matrix  $B\\in R^{n√ón}$ , i.e. \\[\\operatorname{St}(n,k,B) = \\bigl\\{ p \\in \\mathbb F^{n√ók}\\ \\big|\\ p^{\\mathrm{H}} B p = I_k \\bigr\\},\\] where  $ùîΩ ‚àà \\{‚Ñù, ‚ÑÇ\\}$ ,  $‚ãÖ^{\\mathrm{H}}$  denotes the complex conjugate transpose or Hermitian, and  $I_k \\in \\mathbb R^{k√ók}$  denotes the  $k√ók$  identity matrix. In the case  $B=I_k$  one gets the usual  Stiefel  manifold. The tangent space at a point  $p\\in\\mathcal M=\\operatorname{St}(n,k,B)$  is given by \\[T_p\\mathcal M = \\{ X \\in ùîΩ^{n√ók} : p^{\\mathrm{H}}BX + X^{\\mathrm{H}}Bp=0_n\\},\\] where  $0_k$  is the  $k√ók$  zero matrix. This manifold is modeled as an embedded manifold to the  Euclidean , i.e. several functions like the  zero_vector  are inherited from the embedding. The manifold is named after  Eduard L. Stiefel  (1909‚Äì1978). Constructor GeneralizedStiefel(n, k, B=I_n, F=‚Ñù) Generate the (real-valued) Generalized Stiefel manifold of  $n√ók$  dimensional orthonormal matrices with scalar product  B . source"},{"id":828,"pagetitle":"Generalized Stiefel","title":"Base.rand","ref":"/manifolds/stable/manifolds/#Base.rand-Tuple{GeneralizedStiefel}","content":" Base.rand  ‚Äî  Method rand(::GeneralizedStiefel; vector_at=nothing, œÉ::Real=1.0) When  vector_at  is  nothing , return a random (Gaussian) point  p  on the  GeneralizedStiefel  manifold  M  by generating a (Gaussian) matrix with standard deviation  œÉ  and return the (generalized) orthogonalized version, i.e. return the projection onto the manifold of the Q component of the QR decomposition of the random matrix of size  $n√ók$ . When  vector_at  is not  nothing , return a (Gaussian) random vector from the tangent space  $T_{vector\\_at}\\mathrm{St}(n,k)$  with mean zero and standard deviation  œÉ  by projecting a random Matrix onto the tangent vector at  vector_at . source"},{"id":829,"pagetitle":"Generalized Stiefel","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{GeneralizedStiefel, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::GeneralizedStiefel, p; kwargs...) Check whether  p  is a valid point on the  GeneralizedStiefel M = $\\operatorname{St}(n,k,B)$ , i.e. that it has the right  AbstractNumbers  type and  $x^{\\mathrm{H}}Bx$  is (approximately) the identity, where  $‚ãÖ^{\\mathrm{H}}$  is the complex conjugate transpose. The settings for approximately can be set with  kwargs... . source"},{"id":830,"pagetitle":"Generalized Stiefel","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{GeneralizedStiefel, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::GeneralizedStiefel, p, X; kwargs...) Check whether  X  is a valid tangent vector at  p  on the  GeneralizedStiefel M = $\\operatorname{St}(n,k,B)$ , i.e. the  AbstractNumbers  fits,  p  is a valid point on  M  and it (approximately) holds that  $p^{\\mathrm{H}}BX + \\overline{X^{\\mathrm{H}}Bp} = 0$ , where  kwargs...  is passed to the  isapprox . source"},{"id":831,"pagetitle":"Generalized Stiefel","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{GeneralizedStiefel, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::GeneralizedStiefel, p, X, Y) Compute the inner product for two tangent vectors  X ,  Y  from the tangent space of  p  on the  GeneralizedStiefel  manifold  M . The formula reads \\[(X, Y)_p = \\operatorname{trace}(v^{\\mathrm{H}}Bw),\\] i.e. the metric induced by the scalar product  B  from the embedding, restricted to the tangent space. source"},{"id":832,"pagetitle":"Generalized Stiefel","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{GeneralizedStiefel}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(M::GeneralizedStiefel) Return true if  GeneralizedStiefel M  is one-dimensional. source"},{"id":833,"pagetitle":"Generalized Stiefel","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{GeneralizedStiefel{<:Any, ‚Ñù}}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::GeneralizedStiefel) Return the dimension of the  GeneralizedStiefel  manifold  M = $\\operatorname{St}(n,k,B,ùîΩ)$ . The dimension is given by \\[\\begin{aligned}\n\\dim \\mathrm{St}(n, k, B, ‚Ñù) &= nk - \\frac{1}{2}k(k+1) \\\\\n\\dim \\mathrm{St}(n, k, B, ‚ÑÇ) &= 2nk - k^2\\\\\n\\dim \\mathrm{St}(n, k, B, ‚Ñç) &= 4nk - k(2k-1)\n\\end{aligned}\\] source"},{"id":834,"pagetitle":"Generalized Stiefel","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{GeneralizedStiefel, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M:GeneralizedStiefel, p, X) Project  X  onto the tangent space of  p  to the  GeneralizedStiefel  manifold  M . The formula reads \\[\\operatorname{proj}_{\\operatorname{St}(n,k)}(p,X) = X - p\\operatorname{Sym}(p^{\\mathrm{H}}BX),\\] where  $\\operatorname{Sym}(y)$  is the symmetrization of  $y$ , e.g. by  $\\operatorname{Sym}(y) = \\frac{y^{\\mathrm{H}}+y}{2}$ . source"},{"id":835,"pagetitle":"Generalized Stiefel","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{GeneralizedStiefel, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::GeneralizedStiefel, p) Project  p  from the embedding onto the  GeneralizedStiefel M , i.e. compute  q  as the polar decomposition of  $p$  such that  $q^{\\mathrm{H}}Bq$  is the identity, where  $‚ãÖ^{\\mathrm{H}}$  denotes the hermitian, i.e. complex conjugate transposed. source"},{"id":836,"pagetitle":"Generalized Stiefel","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{GeneralizedStiefel, Vararg{Any}}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::GeneralizedStiefel, p, X)\nretract(M::GeneralizedStiefel, p, X, ::PolarRetraction)\nretract(M::GeneralizedStiefel, p, X, ::ProjectionRetraction) Compute the SVD-based retraction  PolarRetraction  on the  GeneralizedStiefel  manifold  M , which in this case is the same as the projection based retraction employing the exponential map in the embedding and projecting the result back to the manifold. The default retraction for this manifold is the  ProjectionRetraction . source"},{"id":839,"pagetitle":"Orthogonal and Unitary Matrices","title":"Orthogonal and Unitary matrices","ref":"/manifolds/stable/manifolds/#Orthogonal-and-Unitary-matrices","content":" Orthogonal and Unitary matrices Both  OrthogonalMatrices  and  UnitaryMatrices  are quite similar, as are  Rotations , as well as unitary matrices with determinant equal to one. So these share a {common implementation}(@ref generalunitarymatrices)"},{"id":840,"pagetitle":"Orthogonal and Unitary Matrices","title":"Orthogonal Matrices","ref":"/manifolds/stable/manifolds/#Orthogonal-Matrices","content":" Orthogonal Matrices"},{"id":841,"pagetitle":"Orthogonal and Unitary Matrices","title":"Manifolds.OrthogonalMatrices","ref":"/manifolds/stable/manifolds/#Manifolds.OrthogonalMatrices","content":" Manifolds.OrthogonalMatrices  ‚Äî  Type  OrthogonalMatrices{n} = GeneralUnitaryMatrices{n,‚Ñù,AbsoluteDeterminantOneMatrices} The manifold of (real) orthogonal matrices  $\\mathrm{O}(n)$ . OrthogonalMatrices(n) source"},{"id":842,"pagetitle":"Orthogonal and Unitary Matrices","title":"Unitary Matrices","ref":"/manifolds/stable/manifolds/#Unitary-Matrices","content":" Unitary Matrices"},{"id":843,"pagetitle":"Orthogonal and Unitary Matrices","title":"Manifolds.UnitaryMatrices","ref":"/manifolds/stable/manifolds/#Manifolds.UnitaryMatrices","content":" Manifolds.UnitaryMatrices  ‚Äî  Type const UnitaryMatrices{n,ùîΩ} = AbstarctUnitaryMatrices{n,ùîΩ,AbsoluteDeterminantOneMatrices} The manifold  $U(n,ùîΩ)$  of  $n√ón$  complex matrices (when ùîΩ=‚ÑÇ) or quaternionic matrices (when ùîΩ=‚Ñç) such that $p^{\\mathrm{H}}p = \\mathrm{I}_n,$ where  $\\mathrm{I}_n$  is the  $n√ón$  identity matrix. Such matrices  p  have a property that  $\\lVert \\det(p) \\rVert = 1$ . The tangent spaces are given by \\[    T_pU(n) \\coloneqq \\bigl\\{\n    X \\big| pY \\text{ where } Y \\text{ is skew symmetric, i. e. } Y = -Y^{\\mathrm{H}}\n    \\bigr\\}\\] But note that tangent vectors are represented in the Lie algebra, i.e. just using  $Y$  in the representation above. If you prefer the representation as  X  you can use the  Stiefel (n, n, ‚ÑÇ)  manifold. Constructor UnitaryMatrices(n, ùîΩ::AbstractNumbers=‚ÑÇ) see also  OrthogonalMatrices  for the real valued case. source"},{"id":844,"pagetitle":"Orthogonal and Unitary Matrices","title":"Base.rand","ref":"/manifolds/stable/manifolds/#Base.rand-Tuple{UnitaryMatrices}","content":" Base.rand  ‚Äî  Method rand(::Unitary; vector_at=nothing, œÉ::Real=1.0) Generate a random point on the  UnitaryMatrices  manifold, if  vector_at  is nothing, by computing the QR decomposition of a  $n√óx$  matrix. Generate a tangent vector at  vector_at  by projecting a normally distributed matrix onto the tangent space. source"},{"id":845,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldDiff.riemannian_Hessian","ref":"/manifolds/stable/manifolds/#ManifoldDiff.riemannian_Hessian-Tuple{UnitaryMatrices, Vararg{Any, 4}}","content":" ManifoldDiff.riemannian_Hessian  ‚Äî  Method riemannian_Hessian(M::UnitaryMatrices, p, G, H, X) The Riemannian Hessian can be computed by adopting Eq. (5.6) [ Ngu23 ], so very similar to the complex Stiefel manifold. The only difference is, that here the tangent vectors are stored in the Lie algebra, i.e. the update direction is actually  $pX$  instead of just  $X$  (in Stiefel). and that means the inverse has to be appliead to the (Euclidean) Hessian to map it into the Lie algebra. source"},{"id":846,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.Weingarten","ref":"/manifolds/stable/manifolds/#ManifoldsBase.Weingarten-Tuple{UnitaryMatrices, Any, Any, Any}","content":" ManifoldsBase.Weingarten  ‚Äî  Method Weingarten(M::UnitaryMatrices, p, X, V) Compute the Weingarten map  $\\mathcal W_p$  at  p  on the  Stiefel M  with respect to the tangent vector  $X \\in T_p\\mathcal M$  and the normal vector  $V \\in N_p\\mathcal M$ . The formula is due to [ AMT13 ] given by \\[\\mathcal W_p(X,V) = -\\frac{1}{2}p\\bigl(V^{\\mathrm{H}}X - X^\\mathrm{H}V\\bigr)\\] source"},{"id":847,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{UnitaryMatrices{<:Any, ‚ÑÇ}}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::UnitaryMatrices{n,‚ÑÇ}) where {n} Return the dimension of the manifold unitary matrices. \\[\\dim_{\\mathrm{U}(n)} = n^2.\\] source"},{"id":848,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{UnitaryMatrices{<:Any, ‚Ñç}}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::UnitaryMatrices{<:Any,‚Ñç}) Return the dimension of the manifold unitary matrices. \\[\\dim_{\\mathrm{U}(n, ‚Ñç)} = n(2n+1).\\] source"},{"id":849,"pagetitle":"Orthogonal and Unitary Matrices","title":"Common functions","ref":"/manifolds/stable/manifolds/#generalunitarymatrices","content":" Common functions"},{"id":850,"pagetitle":"Orthogonal and Unitary Matrices","title":"Manifolds.AbsoluteDeterminantOneMatrices","ref":"/manifolds/stable/manifolds/#Manifolds.AbsoluteDeterminantOneMatrices","content":" Manifolds.AbsoluteDeterminantOneMatrices  ‚Äî  Type AbsoluteDeterminantOneMatrices <: AbstractMatrixType A type to indicate that we require (orthogonal / unitary) matrices with normed determinant, i.e. that the absolute value of the determinant is 1. source"},{"id":851,"pagetitle":"Orthogonal and Unitary Matrices","title":"Manifolds.AbstractMatrixType","ref":"/manifolds/stable/manifolds/#Manifolds.AbstractMatrixType","content":" Manifolds.AbstractMatrixType  ‚Äî  Type AbstractMatrixType A plain type to distinguish different types of matrices, for example  DeterminantOneMatrices  and  AbsoluteDeterminantOneMatrices source"},{"id":852,"pagetitle":"Orthogonal and Unitary Matrices","title":"Manifolds.DeterminantOneMatrices","ref":"/manifolds/stable/manifolds/#Manifolds.DeterminantOneMatrices","content":" Manifolds.DeterminantOneMatrices  ‚Äî  Type DeterminantOneMatrices <: AbstractMatrixType A type to indicate that we require special (orthogonal / unitary) matrices, i.e. of determinant 1. source"},{"id":853,"pagetitle":"Orthogonal and Unitary Matrices","title":"Manifolds.GeneralUnitaryMatrices","ref":"/manifolds/stable/manifolds/#Manifolds.GeneralUnitaryMatrices","content":" Manifolds.GeneralUnitaryMatrices  ‚Äî  Type GeneralUnitaryMatrices{T,ùîΩ,S<:AbstractMatrixType} <: AbstractDecoratorManifold A common parametric type for matrices with a unitary property of size  $n√ón$  over the field  $ùîΩ$  which additionally have the  AbstractMatrixType , e.g. are  DeterminantOneMatrices . source"},{"id":854,"pagetitle":"Orthogonal and Unitary Matrices","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{Manifolds.GeneralUnitaryMatrices, Any, Any}","content":" Base.exp  ‚Äî  Method exp(M::Rotations, p, X)\nexp(M::OrthogonalMatrices, p, X)\nexp(M::UnitaryMatrices, p, X) Compute the exponential map, that is, since  $X$  is represented in the Lie algebra, exp_p(X) = p\\mathrm{e}^X For different sizes, like  $n=2,3,4$ , there are specialized implementations. The algorithm used is a more numerically stable form of those proposed in [ GX02 ] and [ AR13 ]. source"},{"id":855,"pagetitle":"Orthogonal and Unitary Matrices","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{Manifolds.GeneralUnitaryMatrices, Any, Any}","content":" Base.log  ‚Äî  Method log(M::Rotations, p, X)\nlog(M::OrthogonalMatrices, p, X)\nlog(M::UnitaryMatrices, p, X) Compute the logarithmic map, that is, since the resulting  $X$  is represented in the Lie algebra, log_p q = \\log(p^{\\mathrm{H}q) which is projected onto the skew symmetric matrices for numerical stability. source"},{"id":856,"pagetitle":"Orthogonal and Unitary Matrices","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{Manifolds.GeneralUnitaryMatrices{<:Any, ‚Ñù}, Vararg{Any}}","content":" Base.log  ‚Äî  Method log(M::Rotations, p, q) Compute the logarithmic map on the  Rotations  manifold  M  which is given by \\[\\log_p q = \\operatorname{log}(p^{\\mathrm{T}}q)\\] where  $\\operatorname{Log}$  denotes the matrix logarithm. For numerical stability, the result is projected onto the set of skew symmetric matrices. For antipodal rotations the function returns deterministically one of the tangent vectors that point at  q . source"},{"id":857,"pagetitle":"Orthogonal and Unitary Matrices","title":"Manifolds.cos_angles_4d_rotation_matrix","ref":"/manifolds/stable/manifolds/#Manifolds.cos_angles_4d_rotation_matrix-Tuple{Any}","content":" Manifolds.cos_angles_4d_rotation_matrix  ‚Äî  Method cos_angles_4d_rotation_matrix(R) 4D rotations can be described by two orthogonal planes that are unchanged by the action of the rotation (vectors within a plane rotate only within the plane). The cosines of the two angles  $Œ±,Œ≤$  of rotation about these planes may be obtained from the distinct real parts of the eigenvalues of the rotation matrix. This function computes these more efficiently by solving the system \\[\\begin{aligned}\n\\cos Œ± + \\cos Œ≤ &= \\frac{1}{2} \\operatorname{tr}(R)\\\\\n\\cos Œ± \\cos Œ≤ &= \\frac{1}{8} \\operatorname{tr}(R)^2\n                 - \\frac{1}{16} \\operatorname{tr}((R - R^T)^2) - 1.\n\\end{aligned}\\] By convention, the returned values are sorted in decreasing order. See also  angles_4d_skew_sym_matrix . source"},{"id":858,"pagetitle":"Orthogonal and Unitary Matrices","title":"Manifolds.manifold_volume","ref":"/manifolds/stable/manifolds/#Manifolds.manifold_volume-Tuple{Manifolds.GeneralUnitaryMatrices{<:Any, ‚ÑÇ, Manifolds.DeterminantOneMatrices}}","content":" Manifolds.manifold_volume  ‚Äî  Method manifold_volume(::GeneralUnitaryMatrices{<:Any,‚ÑÇ,DeterminantOneMatrices}) Volume of the manifold of complex general unitary matrices of determinant one. The formula reads [ BST03 ] \\[\\sqrt{n 2^{n-1}} œÄ^{(n-1)(n+2)/2} \\prod_{k=1}^{n-1}\\frac{1}{k!}\\] source"},{"id":859,"pagetitle":"Orthogonal and Unitary Matrices","title":"Manifolds.manifold_volume","ref":"/manifolds/stable/manifolds/#Manifolds.manifold_volume-Tuple{Manifolds.GeneralUnitaryMatrices{<:Any, ‚Ñù, Manifolds.AbsoluteDeterminantOneMatrices}}","content":" Manifolds.manifold_volume  ‚Äî  Method manifold_volume(::GeneralUnitaryMatrices{<:Any,‚Ñù,AbsoluteDeterminantOneMatrices}) Volume of the manifold of real orthogonal matrices of absolute determinant one. The formula reads [ BST03 ]: \\[\\begin{cases}\n\\frac{2^{k}(2\\pi)^{k^2}}{\\prod_{s=1}^{k-1} (2s)!} & \\text{ if } n = 2k \\\\\n\\frac{2^{k+1}(2\\pi)^{k(k+1)}}{\\prod_{s=1}^{k-1} (2s+1)!} & \\text{ if } n = 2k+1\n\\end{cases}\\] source"},{"id":860,"pagetitle":"Orthogonal and Unitary Matrices","title":"Manifolds.manifold_volume","ref":"/manifolds/stable/manifolds/#Manifolds.manifold_volume-Tuple{Rotations}","content":" Manifolds.manifold_volume  ‚Äî  Method manifold_volume(::GeneralUnitaryMatrices{<:Any,‚Ñù,DeterminantOneMatrices}) Volume of the manifold of real orthogonal matrices of determinant one. The formula reads [ BST03 ]: \\[\\begin{cases}\n2 & \\text{ if } n = 0 \\\\\n\\frac{2^{k-1/2}(2\\pi)^{k^2}}{\\prod_{s=1}^{k-1} (2s)!} & \\text{ if } n = 2k+2 \\\\\n\\frac{2^{k+1/2}(2\\pi)^{k(k+1)}}{\\prod_{s=1}^{k-1} (2s+1)!} & \\text{ if } n = 2k+1\n\\end{cases}\\] It differs from the paper by a factor of  sqrt(2)  due to a different choice of normalization. source"},{"id":861,"pagetitle":"Orthogonal and Unitary Matrices","title":"Manifolds.manifold_volume","ref":"/manifolds/stable/manifolds/#Manifolds.manifold_volume-Tuple{UnitaryMatrices{<:Any, ‚ÑÇ}}","content":" Manifolds.manifold_volume  ‚Äî  Method manifold_volume(::GeneralUnitaryMatrices{<:Any,‚ÑÇ,AbsoluteDeterminantOneMatrices}) Volume of the manifold of complex general unitary matrices of absolute determinant one. The formula reads [ BST03 ] \\[\\sqrt{n 2^{n+1}} œÄ^{n(n+1)/2} \\prod_{k=1}^{n-1}\\frac{1}{k!}\\] source"},{"id":862,"pagetitle":"Orthogonal and Unitary Matrices","title":"Manifolds.volume_density","ref":"/manifolds/stable/manifolds/#Manifolds.volume_density-Tuple{Manifolds.GeneralUnitaryMatrices{<:Any, ‚Ñù}, Any, Any}","content":" Manifolds.volume_density  ‚Äî  Method volume_density(M::GeneralUnitaryMatrices{<:Any,‚Ñù}, p, X) Compute volume density function of a sphere, i.e. determinant of the differential of exponential map  exp(M, p, X) . It is derived from Eq. (4.1) and Corollary 4.4 in [ CLLD22 ]. See also Theorem 4.1 in [ FdHDF19 ], (note that it uses a different convention). source"},{"id":863,"pagetitle":"Orthogonal and Unitary Matrices","title":"Manifolds.volume_density","ref":"/manifolds/stable/manifolds/#Manifolds.volume_density-Tuple{Manifolds.GeneralUnitaryMatrices{ManifoldsBase.TypeParameter{Tuple{2}}, ‚Ñù}, Any, Any}","content":" Manifolds.volume_density  ‚Äî  Method volume_density(M::GeneralUnitaryMatrices{TypeParameter{Tuple{2}},‚Ñù}, p, X) Volume density on O(2)/SO(2) is equal to 1. source"},{"id":864,"pagetitle":"Orthogonal and Unitary Matrices","title":"Manifolds.volume_density","ref":"/manifolds/stable/manifolds/#Manifolds.volume_density-Tuple{Manifolds.GeneralUnitaryMatrices{ManifoldsBase.TypeParameter{Tuple{3}}, ‚Ñù}, Any, Any}","content":" Manifolds.volume_density  ‚Äî  Method volume_density(M::GeneralUnitaryMatrices{TypeParameter{Tuple{3}},‚Ñù}, p, X) Compute the volume density on O(3)/SO(3). The formula reads [ FdHDF19 ] \\[\\frac{1-1\\cos(\\sqrt{2}\\lVert X \\rVert)}{\\lVert X \\rVert^2}.\\] source"},{"id":865,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Union{Tuple{ùîΩ}, Tuple{Manifolds.GeneralUnitaryMatrices{<:Any, ùîΩ, Manifolds.DeterminantOneMatrices}, Any}} where ùîΩ","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::Rotations, p; kwargs...) Check whether  p  is a valid point on the  UnitaryMatrices M , i.e. that  $p$  has a determinant of absolute value one, i.e. that  $p^{\\mathrm{H}}p$ The tolerance for the last test can be set using the  kwargs... . source"},{"id":866,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Union{Tuple{ùîΩ}, Tuple{UnitaryMatrices{<:Any, ùîΩ}, Any}} where ùîΩ","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::UnitaryMatrices, p; kwargs...)\ncheck_point(M::OrthogonalMatrices, p; kwargs...)\ncheck_point(M::GeneralUnitaryMatrices, p; kwargs...) Check whether  p  is a valid point on the  UnitaryMatrices  or [ OrthogonalMatrices ]  M , i.e. that  $p$  has a determinant of absolute value one The tolerance for the last test can be set using the  kwargs... . source"},{"id":867,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Union{Tuple{ùîΩ}, Tuple{Manifolds.GeneralUnitaryMatrices{<:Any, ùîΩ}, Any, Any}} where ùîΩ","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::UnitaryMatrices, p, X; kwargs... )\ncheck_vector(M::OrthogonalMatrices, p, X; kwargs... )\ncheck_vector(M::Rotations, p, X; kwargs... )\ncheck_vector(M::GeneralUnitaryMatrices, p, X; kwargs... ) Check whether  X  is a tangent vector to  p  on the  UnitaryMatrices  space  M , i.e. after  check_point (M,p) ,  X  has to be skew symmetric (Hermitian) and orthogonal to  p . The tolerance for the last test can be set using the  kwargs... . source"},{"id":868,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.embed","ref":"/manifolds/stable/manifolds/#ManifoldsBase.embed-Tuple{Manifolds.GeneralUnitaryMatrices, Any, Any}","content":" ManifoldsBase.embed  ‚Äî  Method embed(M::GeneralUnitaryMatrices, p, X) Embed the tangent vector  X  at point  p  in  M  from its Lie algebra representation (set of skew matrices) into the Riemannian submanifold representation The formula reads \\[X_{\\text{embedded}} = p * X\\] source"},{"id":869,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.get_coordinates","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_coordinates-Tuple{Manifolds.GeneralUnitaryMatrices{<:Any, ‚Ñù}, Vararg{Any}}","content":" ManifoldsBase.get_coordinates  ‚Äî  Method get_coordinates(M::Rotations, p, X)\nget_coordinates(M::OrthogonalMatrices, p, X)\nget_coordinates(M::UnitaryMatrices, p, X) Extract the unique tangent vector components  $X^i$  at point  p  on  Rotations $\\mathrm{SO}(n)$  from the matrix representation  X  of the tangent vector. The basis on the Lie algebra  $ùî∞ùî¨(n)$  is chosen such that for  $\\mathrm{SO}(2)$ ,  $X^1 = Œ∏ = X_{21}$  is the angle of rotation, and for  $\\mathrm{SO}(3)$ ,  $(X^1, X^2, X^3) = (X_{32}, X_{13}, X_{21}) = Œ∏ u$  is the angular velocity and axis-angle representation, where  $u$  is the unit vector along the axis of rotation. For  $\\mathrm{SO}(n)$  where  $n ‚â• 4$ , the additional elements of  $X^i$  are  $X^{j (j - 3)/2 + k + 1} = X_{jk}$ , for  $j ‚àà [4,n], k ‚àà [1,j)$ . source"},{"id":870,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.get_embedding","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_embedding-Union{Tuple{Manifolds.GeneralUnitaryMatrices{ManifoldsBase.TypeParameter{Tuple{n}}, ùîΩ}}, Tuple{ùîΩ}, Tuple{n}} where {n, ùîΩ}","content":" ManifoldsBase.get_embedding  ‚Äî  Method get_embedding(M::OrthogonalMatrices)\nget_embedding(M::Rotations)\nget_embedding(M::UnitaryMatrices) Return the embedding, i.e. The  $\\mathbb F^{n√ón}$ , where  $\\mathbb F = \\mathbb R$  for the first two and  $\\mathbb F = \\mathbb C$  for the unitary matrices. source"},{"id":871,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.get_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_vector-Tuple{Manifolds.GeneralUnitaryMatrices{<:Any, ‚Ñù}, Vararg{Any}}","content":" ManifoldsBase.get_vector  ‚Äî  Method get_vector(M::OrthogonalMatrices, p, X‚Å±, B::DefaultOrthogonalBasis)\nget_vector(M::Rotations, p, X‚Å±, B::DefaultOrthogonalBasis) Convert the unique tangent vector components  X‚Å±  at point  p  on  Rotations  or  OrthogonalMatrices  to the matrix representation  $X$  of the tangent vector. See  get_coordinates  for the conventions used. source"},{"id":872,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.injectivity_radius","ref":"/manifolds/stable/manifolds/#ManifoldsBase.injectivity_radius-Tuple{Manifolds.GeneralUnitaryMatrices{<:Any, ‚ÑÇ, Manifolds.DeterminantOneMatrices}}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(G::GeneralUnitaryMatrices{<:Any,‚ÑÇ,DeterminantOneMatrices}) Return the injectivity radius for general complex unitary matrix manifolds, where the determinant is  $+1$ , which is [1] \\[    \\operatorname{inj}_{\\mathrm{SU}(n)} = œÄ \\sqrt{2}.\\] source"},{"id":873,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.injectivity_radius","ref":"/manifolds/stable/manifolds/#ManifoldsBase.injectivity_radius-Tuple{Manifolds.GeneralUnitaryMatrices}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(G::GeneraliUnitaryMatrices) Return the injectivity radius for general unitary matrix manifolds, which is [1] \\[    \\operatorname{inj}_{\\mathrm{U}(n)} = œÄ.\\] source"},{"id":874,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.injectivity_radius","ref":"/manifolds/stable/manifolds/#ManifoldsBase.injectivity_radius-Union{Tuple{Manifolds.GeneralUnitaryMatrices{ManifoldsBase.TypeParameter{Tuple{n}}, ‚Ñù}}, Tuple{n}} where n","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(G::SpecialOrthogonal)\ninjectivity_radius(G::Orthogonal)\ninjectivity_radius(M::Rotations)\ninjectivity_radius(M::Rotations, ::ExponentialRetraction) Return the radius of injectivity on the  Rotations  manifold  M , which is  $œÄ\\sqrt{2}$ .  [1] source"},{"id":875,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{Manifolds.GeneralUnitaryMatrices}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(M::GeneralUnitaryMatrices) Return true if  GeneralUnitaryMatrices M  is SO(2) or U(1) and false otherwise. source"},{"id":876,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{Manifolds.GeneralUnitaryMatrices{<:Any, ‚ÑÇ, Manifolds.DeterminantOneMatrices}}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::GeneralUnitaryMatrices{<:Any,‚ÑÇ,DeterminantOneMatrices}) Return the dimension of the manifold of special unitary matrices. \\[\\dim_{\\mathrm{SU}(n)} = n^2-1.\\] source"},{"id":877,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{Manifolds.GeneralUnitaryMatrices{<:Any, ‚Ñù}}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::Rotations)\nmanifold_dimension(M::OrthogonalMatrices) Return the dimension of the manifold orthogonal matrices and of the manifold of rotations \\[\\dim_{\\mathrm{O}(n)} = \\dim_{\\mathrm{SO}(n)} = \\frac{n(n-1)}{2}.\\] source"},{"id":878,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Manifolds.GeneralUnitaryMatrices, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::OrthogonalMatrices, p, X)\nproject(M::Rotations, p, X)\nproject(M::UnitaryMatrices, p, X) Orthogonally project the tangent vector  $X ‚àà ùîΩ^{n√ón}$ ,  $\\mathbb F ‚àà \\{\\mathbb R, \\mathbb C\\}$  to the tangent space of  M  at  p , and change the representer to use the corresponding Lie algebra, i.e. we compute \\[    \\operatorname{proj}_p(X) = \\frac{p^{\\mathrm{H}} X - (p^{\\mathrm{H}} X)^{\\mathrm{H}}}{2},\\] source"},{"id":879,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Union{Tuple{ùîΩ}, Tuple{UnitaryMatrices{<:Any, ùîΩ}, Any}} where ùîΩ","content":" ManifoldsBase.project  ‚Äî  Method  project(G::UnitaryMatrices, p)\n project(G::OrthogonalMatrices, p) Project the point  $p ‚àà ùîΩ^{n√ón}$  to the nearest point in  $\\mathrm{U}(n,ùîΩ)=$ Unitary(n,ùîΩ)  under the Frobenius norm. If  $p = U S V^\\mathrm{H}$  is the singular value decomposition of  $p$ , then the projection is \\[  \\operatorname{proj}_{\\mathrm{U}(n,ùîΩ)} \\colon p ‚Ü¶ U V^\\mathrm{H}.\\] source"},{"id":880,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{Manifolds.GeneralUnitaryMatrices, Any, Any, PolarRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::Rotations, p, X, ::PolarRetraction)\nretract(M::OrthogonalMatrices, p, X, ::PolarRetraction) Compute the SVD-based retraction on the  Rotations  and  OrthogonalMatrices M  from  p  in direction  X  (as an element of the Lie group) and is a second-order approximation of the exponential map. Let \\[USV = p + pX\\] be the singular value decomposition, then the formula reads \\[\\operatorname{retr}_p X = UV^\\mathrm{T}.\\] source"},{"id":881,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{Manifolds.GeneralUnitaryMatrices, Any, Any, QRRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::Rotations, p, X, ::QRRetraction)\nretract(M::OrthogonalMatrices, p. X, ::QRRetraction) Compute the QR-based retraction on the  Rotations  and  OrthogonalMatrices M  from  p  in direction  X  (as an element of the Lie group), which is a first-order approximation of the exponential map. This is also the default retraction on these manifolds. source"},{"id":882,"pagetitle":"Orthogonal and Unitary Matrices","title":"ManifoldsBase.riemann_tensor","ref":"/manifolds/stable/manifolds/#ManifoldsBase.riemann_tensor-Tuple{Manifolds.GeneralUnitaryMatrices, Vararg{Any, 4}}","content":" ManifoldsBase.riemann_tensor  ‚Äî  Method riemann_tensor(::GeneralUnitaryMatrices, p, X, Y, Z) Compute the value of Riemann tensor on the  GeneralUnitaryMatrices  manifold. The formula reads [ Ren11 ]  $R(X,Y)Z=\\frac{1}{4}[Z, [X, Y]]$ . source"},{"id":883,"pagetitle":"Orthogonal and Unitary Matrices","title":"Statistics.mean","ref":"/manifolds/stable/manifolds/#Statistics.mean-Tuple{Manifolds.GeneralUnitaryMatrices{<:Any, ‚Ñù}, Any}","content":" Statistics.mean  ‚Äî  Method mean(\n    M::Rotations,\n    x::AbstractVector,\n    [w::AbstractWeights,]\n    method = GeodesicInterpolationWithinRadius(œÄ/2/‚àö2);\n    kwargs...,\n) Compute the Riemannian  mean  of  x  using  GeodesicInterpolationWithinRadius . source"},{"id":884,"pagetitle":"Orthogonal and Unitary Matrices","title":"Footnotes and References","ref":"/manifolds/stable/manifolds/#Footnotes-and-References","content":" Footnotes and References 1 For a derivation of the injectivity radius, see  sethaxen.com/blog/2023/02/the-injectivity-radii-of-the-unitary-groups/ ."},{"id":887,"pagetitle":"Graph manifold","title":"Graph manifold","ref":"/manifolds/stable/manifolds/#Graph-manifold","content":" Graph manifold For a given graph  $G(V,E)$  implemented using  Graphs.jl , the  GraphManifold  models a  PowerManifold  either on the nodes or edges of the graph, depending on the  GraphManifoldType . i.e., it's either a  $\\mathcal M^{\\lvert V \\rvert}$  for the case of a vertex manifold or a  $\\mathcal M^{\\lvert E \\rvert}$  for the case of a edge manifold."},{"id":888,"pagetitle":"Graph manifold","title":"Example","ref":"/manifolds/stable/manifolds/#Example","content":" Example To make a graph manifold over  $‚Ñù^2$  with three vertices and two edges, one can use using Manifolds\nusing Graphs\nM = Euclidean(2)\np = [[1., 4.], [2., 5.], [3., 6.]]\nq = [[4., 5.], [6., 7.], [8., 9.]]\nx = [[6., 5.], [4., 3.], [2., 8.]]\nG = SimpleGraph(3)\nadd_edge!(G, 1, 2)\nadd_edge!(G, 2, 3)\nN = GraphManifold(G, M, VertexManifold()) GraphManifold\nGraph:\n {3, 2} undirected simple Int64 graph\nAbstractManifold on vertices:\n Euclidean(2; field=‚Ñù) It supports all  AbstractPowerManifold   operations (it is based on  NestedPowerRepresentation ) and furthermore it is possible to compute a graph logarithm: incident_log(N, p) 3-element Vector{Vector{Float64}}:\n [1.0, 1.0]\n [0.0, 0.0]\n [-1.0, -1.0]"},{"id":889,"pagetitle":"Graph manifold","title":"Types and functions","ref":"/manifolds/stable/manifolds/#Types-and-functions","content":" Types and functions"},{"id":890,"pagetitle":"Graph manifold","title":"Manifolds.EdgeManifold","ref":"/manifolds/stable/manifolds/#Manifolds.EdgeManifold","content":" Manifolds.EdgeManifold  ‚Äî  Type EdgeManifoldManifold <: GraphManifoldType A type for a  GraphManifold  where the data is given on the edges. source"},{"id":891,"pagetitle":"Graph manifold","title":"Manifolds.GraphManifold","ref":"/manifolds/stable/manifolds/#Manifolds.GraphManifold","content":" Manifolds.GraphManifold  ‚Äî  Type GraphManifold{G,ùîΩ,M,T} <: AbstractPowerManifold{ùîΩ,M,NestedPowerRepresentation} Build a manifold, that is a  PowerManifold  of the  AbstractManifold M  either on the edges or vertices of a graph  G  depending on the  GraphManifoldType T . Fields G  is an  AbstractSimpleGraph M  is a  AbstractManifold source"},{"id":892,"pagetitle":"Graph manifold","title":"Manifolds.GraphManifoldType","ref":"/manifolds/stable/manifolds/#Manifolds.GraphManifoldType","content":" Manifolds.GraphManifoldType  ‚Äî  Type GraphManifoldType This type represents the type of data on the graph that the  GraphManifold  represents. source"},{"id":893,"pagetitle":"Graph manifold","title":"Manifolds.VertexManifold","ref":"/manifolds/stable/manifolds/#Manifolds.VertexManifold","content":" Manifolds.VertexManifold  ‚Äî  Type VectexGraphManifold <: GraphManifoldType A type for a  GraphManifold  where the data is given on the vertices. source"},{"id":894,"pagetitle":"Graph manifold","title":"Manifolds.incident_log","ref":"/manifolds/stable/manifolds/#Manifolds.incident_log-Tuple{GraphManifold{<:Graphs.AbstractGraph, ùîΩ, <:AbstractManifold{ùîΩ}, VertexManifold} where ùîΩ, Any}","content":" Manifolds.incident_log  ‚Äî  Method incident_log(M::GraphManifold, x) Return the tangent vector on the (vertex)  GraphManifold , where at each node the sum of the  log s to incident nodes is computed. For a  SimpleGraph , an egde is interpreted as double edge in the corresponding SimpleDiGraph If the internal graph is a  SimpleWeightedGraph  the weighted sum of the tangent vectors is computed. source"},{"id":895,"pagetitle":"Graph manifold","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{GraphManifold, Vararg{Any}}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::GraphManifold, p) Check whether  p  is a valid point on the  GraphManifold , i.e. its length equals the number of vertices (for  VertexManifold s) or the number of edges (for  EdgeManifold s) and that each element of  p  passes the  check_point  test for the base manifold  M.manifold . source"},{"id":896,"pagetitle":"Graph manifold","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{GraphManifold, Vararg{Any}}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::GraphManifold, p, X; kwargs...) Check whether  p  is a valid point on the  GraphManifold , and  X  it from its tangent space, i.e. its length equals the number of vertices (for  VertexManifold s) or the number of edges (for  EdgeManifold s) and that each element of  X  together with its corresponding entry of  p  passes the  check_vector  test for the base manifold  M.manifold . source"},{"id":897,"pagetitle":"Graph manifold","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{GraphManifold{<:Graphs.AbstractGraph, ùîΩ, <:AbstractManifold{ùîΩ}, EdgeManifold} where ùîΩ}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(N::GraphManifold{G,ùîΩ,M,EdgeManifold}) returns the manifold dimension of the  GraphManifold N  on the edges of a graph  $G=(V,E)$ , i.e. \\[\\dim(\\mathcal N) = \\lvert E \\rvert \\dim(\\mathcal M),\\] where  $\\mathcal M$  is the manifold of the data on the edges. source"},{"id":898,"pagetitle":"Graph manifold","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{GraphManifold{<:Graphs.AbstractGraph, ùîΩ, <:AbstractManifold{ùîΩ}, VertexManifold} where ùîΩ}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(N::GraphManifold{G,ùîΩ,M,VertexManifold}) returns the manifold dimension of the  GraphManifold N  on the vertices of a graph  $G=(V,E)$ , i.e. \\[\\dim(\\mathcal N) = \\lvert V \\rvert \\dim(\\mathcal M),\\] where  $\\mathcal M$  is the manifold of the data on the nodes. source"},{"id":901,"pagetitle":"Grassmann","title":"Grassmannian manifold","ref":"/manifolds/stable/manifolds/#Grassmannian-manifold","content":" Grassmannian manifold"},{"id":902,"pagetitle":"Grassmann","title":"Manifolds.Grassmann","ref":"/manifolds/stable/manifolds/#Manifolds.Grassmann","content":" Manifolds.Grassmann  ‚Äî  Type Grassmann{T,ùîΩ} <: AbstractDecoratorManifold{ùîΩ} The Grassmann manifold  $\\mathrm{Gr}(n,k)$  consists of all subspaces spanned by  $k$  linear independent vectors  $ùîΩ^n$ , where  $ùîΩ  ‚àà \\{‚Ñù, ‚ÑÇ\\}$  is either the real- (or complex-) valued vectors. This yields all  $k$ -dimensional subspaces of  $‚Ñù^n$  for the real-valued case and all  $2k$ -dimensional subspaces of  $‚ÑÇ^n$  for the second. The manifold can be represented as \\[\\mathrm{Gr}(n,k) := \\bigl\\{ \\operatorname{span}(p) : p ‚àà ùîΩ^{n√ók}, p^\\mathrm{H}p = I_k\\},\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the complex conjugate transpose or Hermitian and  $I_k$  is the  $k√ók$  identity matrix. This means, that the columns of  $p$  form an unitary basis of the subspace, that is a point on  $\\operatorname{Gr}(n,k)$ , and hence the subspace can actually be represented by a whole equivalence class of representers. Another interpretation is, that \\[\\mathrm{Gr}(n,k) = \\mathrm{St}(n,k) / \\operatorname{O}(k),\\] i.e the Grassmann manifold is the quotient of the  Stiefel  manifold and the orthogonal group  $\\operatorname{O}(k)$  of orthogonal  $k√ók$  matrices. Note that it doesn't matter whether we start from the Euclidean or canonical metric on the Stiefel manifold, the resulting quotient metric on Grassmann is the same. The tangent space at a point (subspace)  $p$  is given by \\[T_p\\mathrm{Gr}(n,k) = \\bigl\\{\nX ‚àà ùîΩ^{n√ók} :\nX^{\\mathrm{H}}p + p^{\\mathrm{H}}X = 0_{k} \\bigr\\},\\] where  $0_k$  is the  $k√ók$  zero matrix. Note that a point  $p ‚àà \\operatorname{Gr}(n,k)$  might be represented by different matrices (i.e. matrices with unitary column vectors that span the same subspace). Different representations of  $p$  also lead to different representation matrices for the tangent space  $T_p\\mathrm{Gr}(n,k)$ For a representation of points as orthogonal projectors. Here \\[\\operatorname{Gr}(n,k) := \\bigl\\{ p \\in \\mathbb R^{n√ón} : p = p^Àú\\mathrm{T}, p^2 = p, \\operatorname{rank}(p) = k\\},\\] with tangent space \\[T_p\\mathrm{Gr}(n,k) = \\bigl\\{\nX ‚àà \\mathbb R^{n√ón} : X=X^{\\mathrm{T}} \\text{ and } X = pX+Xp \\bigr\\},\\] see also  ProjectorPoint  and  ProjectorTVector . The manifold is named after  Hermann G. Gra√ümann  (1809-1877). A good overview can be found in[ BZA20 ]. Constructor Grassmann(n, k, field=‚Ñù, parameter::Symbol=:type) Generate the Grassmann manifold  $\\operatorname{Gr}(n,k)$ , where the real-valued case  field=‚Ñù  is the default. source"},{"id":903,"pagetitle":"Grassmann","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{ProjectorPoint}, AbstractMatrix}","content":" Base.convert  ‚Äî  Method convert(::Type{ProjectorPoint}, p::AbstractMatrix) Convert a point  p  on  Stiefel  that also represents a point (i.e. subspace) on  Grassmann  to a projector representation of said subspace, i.e. compute the  canonical_project!  for \\[  œÄ^{\\mathrm{SG}}(p) = pp^{\\mathrm{T)}.\\] source"},{"id":904,"pagetitle":"Grassmann","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{ProjectorPoint}, StiefelPoint}","content":" Base.convert  ‚Äî  Method convert(::Type{ProjectorPoint}, ::Stiefelpoint) Convert a point  p  on  Stiefel  that also represents a point (i.e. subspace) on  Grassmann  to a projector representation of said subspace, i.e. compute the  canonical_project!  for \\[  œÄ^{\\mathrm{SG}}(p) = pp^{\\mathrm{T}}.\\] source"},{"id":905,"pagetitle":"Grassmann","title":"Manifolds.get_total_space","ref":"/manifolds/stable/manifolds/#Manifolds.get_total_space-Union{Tuple{Grassmann{ManifoldsBase.TypeParameter{Tuple{n, k}}, ùîΩ}}, Tuple{ùîΩ}, Tuple{k}, Tuple{n}} where {n, k, ùîΩ}","content":" Manifolds.get_total_space  ‚Äî  Method get_total_space(::Grassmann) Return the total space of the  Grassmann  manifold, which is the corresponding Stiefel manifold, independent of whether the points are represented already in the total space or as  ProjectorPoint s. source"},{"id":906,"pagetitle":"Grassmann","title":"ManifoldsBase.change_metric","ref":"/manifolds/stable/manifolds/#ManifoldsBase.change_metric-Tuple{Grassmann, EuclideanMetric, Any, Any}","content":" ManifoldsBase.change_metric  ‚Äî  Method change_metric(M::Grassmann, ::EuclideanMetric, p X) Change  X  to the corresponding vector with respect to the metric of the  Grassmann M , which is just the identity, since the manifold is isometrically embedded. source"},{"id":907,"pagetitle":"Grassmann","title":"ManifoldsBase.change_representer","ref":"/manifolds/stable/manifolds/#ManifoldsBase.change_representer-Tuple{Grassmann, EuclideanMetric, Any, Any}","content":" ManifoldsBase.change_representer  ‚Äî  Method change_representer(M::Grassmann, ::EuclideanMetric, p, X) Change  X  to the corresponding representer of a cotangent vector at  p . Since the  Grassmann  manifold  M , is isometrically embedded, this is the identity source"},{"id":908,"pagetitle":"Grassmann","title":"ManifoldsBase.default_retraction_method","ref":"/manifolds/stable/manifolds/#ManifoldsBase.default_retraction_method-Tuple{Grassmann, Type{ProjectorPoint}}","content":" ManifoldsBase.default_retraction_method  ‚Äî  Method default_retraction_method(M::Grassmann, ::Type{ProjectorPoint}) Return  ExponentialRetraction  as the default on the  Grassmann  manifold with projection matrices source"},{"id":909,"pagetitle":"Grassmann","title":"ManifoldsBase.default_retraction_method","ref":"/manifolds/stable/manifolds/#ManifoldsBase.default_retraction_method-Tuple{Grassmann}","content":" ManifoldsBase.default_retraction_method  ‚Äî  Method default_retraction_method(M::Grassmann)\ndefault_retraction_method(M::Grassmann, ::Type{StiefelPoint}) Return  PolarRetracion  as the default on the  Grassmann  manifold with projection matrices source"},{"id":910,"pagetitle":"Grassmann","title":"ManifoldsBase.default_vector_transport_method","ref":"/manifolds/stable/manifolds/#ManifoldsBase.default_vector_transport_method-Tuple{Grassmann}","content":" ManifoldsBase.default_vector_transport_method  ‚Äî  Method default_vector_transport_method(M::Grassmann) Return the  ProjectionTransport  as the default vector transport method for the  Grassmann  manifold. source"},{"id":911,"pagetitle":"Grassmann","title":"ManifoldsBase.injectivity_radius","ref":"/manifolds/stable/manifolds/#ManifoldsBase.injectivity_radius-Tuple{Grassmann}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(M::Grassmann)\ninjectivity_radius(M::Grassmann, p) Return the injectivity radius on the  Grassmann M , which is  $\\frac{œÄ}{2}$ . source"},{"id":912,"pagetitle":"Grassmann","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{Grassmann}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(M::Grassmann) Return true if  Grassmann M  is one-dimensional. source"},{"id":913,"pagetitle":"Grassmann","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Union{Tuple{Grassmann{<:Any, ùîΩ}}, Tuple{ùîΩ}} where ùîΩ","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::Grassmann) Return the dimension of the  Grassmann (n,k,ùîΩ)  manifold  M , i.e. \\[\\dim \\operatorname{Gr}(n,k) = k(n-k) \\dim_‚Ñù ùîΩ,\\] where  $\\dim_‚Ñù ùîΩ$  is the  real_dimension  of  ùîΩ . source"},{"id":914,"pagetitle":"Grassmann","title":"Statistics.mean","ref":"/manifolds/stable/manifolds/#Statistics.mean-Tuple{Grassmann, Vararg{Any}}","content":" Statistics.mean  ‚Äî  Method mean(\n    M::Grassmann,\n    x::AbstractVector,\n    [w::AbstractWeights,]\n    method = GeodesicInterpolationWithinRadius(œÄ/4);\n    kwargs...,\n) Compute the Riemannian  mean  of  x  using  GeodesicInterpolationWithinRadius . source"},{"id":915,"pagetitle":"Grassmann","title":"The Grassmanian represented as points on the  Stiefel  manifold","ref":"/manifolds/stable/manifolds/#The-Grassmanian-represented-as-points-on-the-[Stiefel](@ref)-manifold","content":" The Grassmanian represented as points on the  Stiefel  manifold"},{"id":916,"pagetitle":"Grassmann","title":"Manifolds.StiefelPoint","ref":"/manifolds/stable/manifolds/#Manifolds.StiefelPoint","content":" Manifolds.StiefelPoint  ‚Äî  Type StiefelPoint <: AbstractManifoldPoint A point on a  Stiefel  manifold. This point is mainly used for representing points on the  Grassmann  where this is also the default representation and hence equivalent to using  AbstractMatrices  thereon. they can also used be used as points on Stiefel. source"},{"id":917,"pagetitle":"Grassmann","title":"Manifolds.StiefelTVector","ref":"/manifolds/stable/manifolds/#Manifolds.StiefelTVector","content":" Manifolds.StiefelTVector  ‚Äî  Type StiefelTVector <: TVector A tangent vector on the  Grassmann  manifold represented by a tangent vector from the tangent space of a corresponding point from the  Stiefel  manifold, see  StiefelPoint . This is the default representation so is can be used interchangeably with just abstract matrices. source"},{"id":918,"pagetitle":"Grassmann","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{Grassmann, Vararg{Any}}","content":" Base.exp  ‚Äî  Method exp(M::Grassmann, p, X) Compute the exponential map on the  Grassmann M $= \\mathrm{Gr}(n,k)$  starting in  p  with tangent vector (direction)  X . Let  $X = USV$  denote the SVD decomposition of  $X$ . Then the exponential map is written using \\[z = p V\\cos(S)V^\\mathrm{H} + U\\sin(S)V^\\mathrm{H},\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the complex conjugate transposed or Hermitian and the cosine and sine are applied element wise to the diagonal entries of  $S$ . A final QR decomposition  $z=QR$  is performed for numerical stability reasons, yielding the result as \\[\\exp_p X = Q.\\] source"},{"id":919,"pagetitle":"Grassmann","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{Grassmann, Vararg{Any}}","content":" Base.log  ‚Äî  Method log(M::Grassmann, p, q) Compute the logarithmic map on the  Grassmann M $= \\mathcal M=\\mathrm{Gr}(n,k)$ , i.e. the tangent vector  X  whose corresponding  geodesic  starting from  p  reaches  q  after time 1 on  M . The formula reads \\[\\log_p q = V‚ãÖ \\operatorname{atan}(S) ‚ãÖ U^\\mathrm{H},\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the complex conjugate transposed or Hermitian. The matrices  $U$  and  $V$  are the unitary matrices, and  $S$  is the diagonal matrix containing the singular values of the SVD-decomposition \\[USV = (q^\\mathrm{H}p)^{-1} ( q^\\mathrm{H} - q^\\mathrm{H}pp^\\mathrm{H}).\\] In this formula the  $\\operatorname{atan}$  is meant elementwise. source"},{"id":920,"pagetitle":"Grassmann","title":"Base.rand","ref":"/manifolds/stable/manifolds/#Base.rand-Tuple{Grassmann}","content":" Base.rand  ‚Äî  Method rand(M::Grassmann; œÉ::Real=1.0, vector_at=nothing) When  vector_at  is  nothing , return a random point  p  on  Grassmann  manifold  M  by generating a random (Gaussian) matrix with standard deviation  œÉ  in matching size, which is orthonormal. When  vector_at  is not  nothing , return a (Gaussian) random vector from the tangent space  $T_p\\mathrm{Gr}(n,k)$  with mean zero and standard deviation  œÉ  by projecting a random Matrix onto the tangent space at  vector_at . source"},{"id":921,"pagetitle":"Grassmann","title":"ManifoldDiff.riemannian_Hessian","ref":"/manifolds/stable/manifolds/#ManifoldDiff.riemannian_Hessian-Tuple{Grassmann, Vararg{Any, 4}}","content":" ManifoldDiff.riemannian_Hessian  ‚Äî  Method riemannian_Hessian(M::Grassmann, p, G, H, X) The Riemannian Hessian can be computed by adopting Eq. (6.6) [ Ngu23 ], where we use for the  EuclideanMetric $Œ±_0=Œ±_1=1$  in their formula. Let  $\\nabla f(p)$  denote the Euclidean gradient  G ,  $\\nabla^2 f(p)[X]$  the Euclidean Hessian  H . Then the formula reads \\[    \\operatorname{Hess}f(p)[X]\n    =\n    \\operatorname{proj}_{T_p\\mathcal M}\\Bigl(\n        ‚àá^2f(p)[X] - X p^{\\mathrm{H}}‚àáf(p)\n    \\Bigr).\\] Compared to Eq. (5.6) also the metric conversion simplifies to the identity. source"},{"id":922,"pagetitle":"Grassmann","title":"Manifolds.uniform_distribution","ref":"/manifolds/stable/manifolds/#Manifolds.uniform_distribution-Tuple{Grassmann{<:Any, ‚Ñù}, Any}","content":" Manifolds.uniform_distribution  ‚Äî  Method uniform_distribution(M::Grassmann{<:Any,‚Ñù}, p) Uniform distribution on given (real-valued)  Grassmann M . Specifically, this is the normalized Haar measure on  M . Generated points will be of similar type as  p . The implementation is based on Section 2.5.1 in [ Chi03 ]; see also Theorem 2.2.2(iii) in [ Chi03 ]. source"},{"id":923,"pagetitle":"Grassmann","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{Grassmann, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::Grassmann, p, q) Compute the Riemannian distance on  Grassmann  manifold  M $= \\mathrm{Gr}(n,k)$ . The distance is given by \\[d_{\\mathrm{Gr}(n,k)}(p,q) = \\operatorname{norm}(\\log_p(q)).\\] source"},{"id":924,"pagetitle":"Grassmann","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{Grassmann, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::Grassmann, p, X, Y) Compute the inner product for two tangent vectors  X ,  Y  from the tangent space of  p  on the  Grassmann  manifold  M . The formula reads \\[g_p(X,Y) = \\operatorname{tr}(X^{\\mathrm{H}}Y),\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the complex conjugate transposed or Hermitian. source"},{"id":925,"pagetitle":"Grassmann","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{Grassmann, Any, Any, PolarInverseRetraction}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(M::Grassmann, p, q, ::PolarInverseRetraction) Compute the inverse retraction for the  PolarRetraction , on the  Grassmann  manifold  M , i.e., \\[\\operatorname{retr}_p^{-1}q = q*(p^\\mathrm{H}q)^{-1} - p,\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the complex conjugate transposed or Hermitian. source"},{"id":926,"pagetitle":"Grassmann","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{Grassmann, Any, Any, QRInverseRetraction}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(M, p, q, ::QRInverseRetraction) Compute the inverse retraction for the  QRRetraction , on the  Grassmann  manifold  M , i.e., \\[\\operatorname{retr}_p^{-1}q = q(p^\\mathrm{H}q)^{-1} - p,\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the complex conjugate transposed or Hermitian. source"},{"id":927,"pagetitle":"Grassmann","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Grassmann, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::Grassmann, p) Project  p  from the embedding onto the  Grassmann M , i.e. compute  q  as the polar decomposition of  $p$  such that  $q^{\\mathrm{H}}q$  is the identity, where  $‚ãÖ^{\\mathrm{H}}$  denotes the Hermitian, i.e. complex conjugate transposed. source"},{"id":928,"pagetitle":"Grassmann","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Grassmann, Vararg{Any}}","content":" ManifoldsBase.project  ‚Äî  Method project(M::Grassmann, p, X) Project the  n -by- k X  onto the tangent space of  p  on the  Grassmann M , which is computed by \\[\\operatorname{proj_p}(X) = X - pp^{\\mathrm{H}}X,\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the complex conjugate transposed or Hermitian. source"},{"id":929,"pagetitle":"Grassmann","title":"ManifoldsBase.representation_size","ref":"/manifolds/stable/manifolds/#ManifoldsBase.representation_size-Tuple{Grassmann}","content":" ManifoldsBase.representation_size  ‚Äî  Method representation_size(M::Grassmann) Return the representation size or matrix dimension of a point on the  Grassmann M , i.e.  $(n,k)$  for both the real-valued and the complex value case. source"},{"id":930,"pagetitle":"Grassmann","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{Grassmann, Any, Any, PolarRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::Grassmann, p, X, ::PolarRetraction) Compute the SVD-based retraction  PolarRetraction  on the  Grassmann M . With  $USV = p + X$  the retraction reads \\[\\operatorname{retr}_p X = UV^\\mathrm{H},\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the complex conjugate transposed or Hermitian. source"},{"id":931,"pagetitle":"Grassmann","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{Grassmann, Any, Any, QRRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::Grassmann, p, X, ::QRRetraction ) Compute the QR-based retraction  QRRetraction  on the  Grassmann M . With  $QR = p + X$  the retraction reads \\[\\operatorname{retr}_p X = QD,\\] where D is a  $m√ón$  matrix with \\[D = \\operatorname{diag}\\left( \\operatorname{sgn}\\left(R_{ii}+\\frac{1}{2}\\right)_{i=1}^n \\right).\\] source"},{"id":932,"pagetitle":"Grassmann","title":"ManifoldsBase.riemann_tensor","ref":"/manifolds/stable/manifolds/#ManifoldsBase.riemann_tensor-Tuple{Grassmann{<:Any, ‚Ñù}, Vararg{Any, 4}}","content":" ManifoldsBase.riemann_tensor  ‚Äî  Method riemann_tensor(::Grassmann{<:Any,‚Ñù}, p, X, Y, Z) Compute the value of Riemann tensor on the real  Grassmann  manifold. The formula reads [ Ren11 ]  $R(X,Y)Z = (XY^\\mathrm{T} - YX^\\mathrm{T})Z + Z(Y^\\mathrm{T}X - X^\\mathrm{T}Y)$ . source"},{"id":933,"pagetitle":"Grassmann","title":"ManifoldsBase.vector_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.vector_transport_to-Tuple{Grassmann, Any, Any, Any, ProjectionTransport}","content":" ManifoldsBase.vector_transport_to  ‚Äî  Method vector_transport_to(M::Grassmann, p, X, q, ::ProjectionTransport) compute the projection based transport on the  Grassmann M  by interpreting  X  from the tangent space at  p  as a point in the embedding and projecting it onto the tangent space at q. source"},{"id":934,"pagetitle":"Grassmann","title":"ManifoldsBase.zero_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.zero_vector-Tuple{Grassmann, Vararg{Any}}","content":" ManifoldsBase.zero_vector  ‚Äî  Method zero_vector(M::Grassmann, p) Return the zero tangent vector from the tangent space at  p  on the  Grassmann M , which is given by a zero matrix the same size as  p . source"},{"id":935,"pagetitle":"Grassmann","title":"The Grassmannian represented as projectors","ref":"/manifolds/stable/manifolds/#The-Grassmannian-represented-as-projectors","content":" The Grassmannian represented as projectors"},{"id":936,"pagetitle":"Grassmann","title":"Manifolds.ProjectorPoint","ref":"/manifolds/stable/manifolds/#Manifolds.ProjectorPoint","content":" Manifolds.ProjectorPoint  ‚Äî  Type ProjectorPoint <: AbstractManifoldPoint A type to represent points on a manifold  Grassmann  that are orthogonal projectors, i.e. a matrix  $p ‚àà \\mathbb F^{n,n}$  projecting onto a  $k$ -dimensional subspace. source"},{"id":937,"pagetitle":"Grassmann","title":"Manifolds.ProjectorTVector","ref":"/manifolds/stable/manifolds/#Manifolds.ProjectorTVector","content":" Manifolds.ProjectorTVector  ‚Äî  Type ProjectorTVector <: TVector A type to represent tangent vectors to points on a  Grassmann  manifold that are orthogonal projectors. source"},{"id":938,"pagetitle":"Grassmann","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{Grassmann, ProjectorPoint, ProjectorTVector}","content":" Base.exp  ‚Äî  Method exp(M::Grassmann, p::ProjectorPoint, X::ProjectorTVector) Compute the exponential map on the  Grassmann  as \\[    \\exp_pX = \\operatorname{Exp}([X,p])p\\operatorname{Exp}(-[X,p]),\\] where  $\\operatorname{Exp}$  denotes the matrix exponential and  $[A,B] = AB-BA$  denotes the matrix commutator. For details, see Proposition 3.2 in [ BZA20 ]. source"},{"id":939,"pagetitle":"Grassmann","title":"Manifolds.canonical_project!","ref":"/manifolds/stable/manifolds/#Manifolds.canonical_project!-Tuple{Grassmann, ProjectorPoint, Any}","content":" Manifolds.canonical_project!  ‚Äî  Method canonical_project!(M::Grassmann, q::ProjectorPoint, p) Compute the canonical projection  $œÄ(p)$  from the  Stiefel  manifold onto the  Grassmann  manifold when represented as  ProjectorPoint , i.e. \\[    œÄ^{\\mathrm{SG}}(p) = pp^{\\mathrm{T}}\\] source"},{"id":940,"pagetitle":"Grassmann","title":"Manifolds.differential_canonical_project!","ref":"/manifolds/stable/manifolds/#Manifolds.differential_canonical_project!-Tuple{Grassmann, ProjectorTVector, Any, Any}","content":" Manifolds.differential_canonical_project!  ‚Äî  Method canonical_project!(M::Grassmann, q::ProjectorPoint, p) Compute the canonical projection  $œÄ(p)$  from the  Stiefel  manifold onto the  Grassmann  manifold when represented as  ProjectorPoint , i.e. \\[    DœÄ^{\\mathrm{SG}}(p)[X] = Xp^{\\mathrm{T}} + pX^{\\mathrm{T}}\\] source"},{"id":941,"pagetitle":"Grassmann","title":"Manifolds.horizontal_lift","ref":"/manifolds/stable/manifolds/#Manifolds.horizontal_lift-Tuple{Stiefel, Any, ProjectorTVector}","content":" Manifolds.horizontal_lift  ‚Äî  Method horizontal_lift(N::Stiefel{n,k}, q, X::ProjectorTVector) Compute the horizontal lift of  X  from the tangent space at  $p=œÄ(q)$  on the  Grassmann  manifold, i.e. \\[Y = Xq ‚àà T_q\\mathrm{St}(n,k)\\] source"},{"id":942,"pagetitle":"Grassmann","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{Grassmann, ProjectorPoint}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(::Grassmann, p::ProjectorPoint; kwargs...) Check whether an orthogonal projector is a point from the  Grassmann (n,k)  manifold, i.e. the  ProjectorPoint $p ‚àà \\mathbb F^{n√ón}$ ,  $\\mathbb F ‚àà \\{\\mathbb R, \\mathbb C\\}$  has to fulfill  $p^{\\mathrm{T}} = p$ ,  $p^2=p$ , and ` \\operatorname{rank} p = k . source"},{"id":943,"pagetitle":"Grassmann","title":"ManifoldsBase.check_size","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_size-Tuple{Grassmann, ProjectorPoint}","content":" ManifoldsBase.check_size  ‚Äî  Method check_size(M::Grassmann, p::ProjectorPoint; kwargs...) Check that the  ProjectorPoint  is of correct size, i.e. from  $\\mathbb F^{n√ón}$ source"},{"id":944,"pagetitle":"Grassmann","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{Grassmann, ProjectorPoint, ProjectorTVector}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(::Grassmann, p::ProjectorPoint, X::ProjectorTVector; kwargs...) Check whether the  ProjectorTVector X  is from the tangent space  $T_p\\operatorname{Gr}(n,k)$  at the  ProjectorPoint p  on the  Grassmann  manifold  $\\operatorname{Gr}(n,k)$ . This means that  X  has to be symmetric and that \\[Xp + pX = X\\] must hold, where the  kwargs  can be used to check both for symmetrix of  $X$ ` and this equality up to a certain tolerance. source"},{"id":945,"pagetitle":"Grassmann","title":"ManifoldsBase.get_embedding","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_embedding-Union{Tuple{ùîΩ}, Tuple{k}, Tuple{n}, Tuple{Grassmann{ManifoldsBase.TypeParameter{Tuple{n, k}}, ùîΩ}, ProjectorPoint}} where {n, k, ùîΩ}","content":" ManifoldsBase.get_embedding  ‚Äî  Method get_embedding(M::Grassmann, p::ProjectorPoint) Return the embedding of the  ProjectorPoint  representation of the  Grassmann  manifold, i.e. the Euclidean space  $\\mathbb F^{n√ón}$ . source"},{"id":946,"pagetitle":"Grassmann","title":"ManifoldsBase.parallel_transport_direction","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_direction-Tuple{Grassmann, ProjectorPoint, ProjectorTVector, ProjectorTVector}","content":" ManifoldsBase.parallel_transport_direction  ‚Äî  Method parallel_transport_direction(\n    M::Grassmann,\n    p::ProjectorPoint,\n    X::ProjectorTVector,\n    d::ProjectorTVector\n) Compute the parallel transport of  X  from the tangent space at  p  into direction  d , i.e. to  $q=\\exp_pd$ . The formula is given in Proposition 3.5 of [ BZA20 ] as \\[\\mathcal{P}_{q ‚Üê p}(X) = \\operatorname{Exp}([d,p])X\\operatorname{Exp}(-[d,p]),\\] where  $\\operatorname{Exp}$  denotes the matrix exponential and  $[A,B] = AB-BA$  denotes the matrix commutator. source"},{"id":947,"pagetitle":"Grassmann","title":"ManifoldsBase.representation_size","ref":"/manifolds/stable/manifolds/#ManifoldsBase.representation_size-Tuple{Grassmann, ProjectorPoint}","content":" ManifoldsBase.representation_size  ‚Äî  Method representation_size(M::Grassmann, p::ProjectorPoint) Return the represenation size or matrix dimension of a point on the  Grassmann M  when using  ProjectorPoint s, i.e.  $(n,n)$ . source"},{"id":948,"pagetitle":"Grassmann","title":"Literature","ref":"/manifolds/stable/manifolds/#Literature","content":" Literature [BZA20] T.¬†Bendokat, R.¬†Zimmermann and P.-A.¬†Absil.  A Grassmann Manifold Handbook: Basic Geometry and Computational Aspects , arXiv¬†Preprint (2020),  arXiv:2011.13699 . [Chi03] Y.¬†Chikuse.  Statistics on Special Manifolds  (Springer New York, 2003). [Ngu23] D.¬†Nguyen.  Operator-Valued Formulas for Riemannian Gradient and Hessian and Families of Tractable Metrics in Riemannian Optimization .  Journal¬†of¬†Optimization¬†Theory¬†and¬†Applications  198 , 135‚Äì164  (2023),  arXiv:2009.10159 . [Ren11] Q.¬†Rentmeesters.  A gradient method for geodesic data fitting on some symmetric Riemannian manifolds . In:  IEEE Conference on Decision and Control and European Control Conference  (2011); pp.¬†7141‚Äì7146."},{"id":951,"pagetitle":"Group manifold","title":"Group manifolds","ref":"/manifolds/stable/manifolds/#GroupManifoldSection","content":" Group manifolds Lie groups, groups that are Riemannian manifolds with a smooth binary group operation  AbstractGroupOperation , are implemented as  AbstractDecoratorManifold  and specifying the group operation using the  IsGroupManifold  or by decorating an existing manifold with a group operation using  GroupManifold . The common addition and multiplication group operations of  AdditionOperation  and  MultiplicationOperation  are provided, though their behavior may be customized for a specific group. There are short introductions at the beginning of each subsection. They briefly mention what is available with links to more detailed descriptions."},{"id":952,"pagetitle":"Group manifold","title":"Contents","ref":"/manifolds/stable/manifolds/#Contents","content":" Contents Group manifolds Contents Groups Group manifold GroupManifold Generic Operations Circle group General linear group Heisenberg group (Special) Orthogonal and (Special) Unitary group Power group Product group Semidirect product group Special Euclidean group Special linear group Translation group Metrics on groups Invariant metrics Cartan-Schouten connections"},{"id":953,"pagetitle":"Group manifold","title":"Groups","ref":"/manifolds/stable/manifolds/#Groups","content":" Groups The following operations are available for group manifolds: Identity : an allocation-free representation of the identity element of the group. inv : get the inverse of a given element. compose : compose two given elements of a group. identity_element  get the identity element of the group, in the representation used by other points from the group."},{"id":954,"pagetitle":"Group manifold","title":"Group manifold","ref":"/manifolds/stable/manifolds/#Group-manifold","content":" Group manifold GroupManifold  adds a group structure to the wrapped manifold. It does not affect metric (or connection) structure of the wrapped manifold, however it can to be further wrapped in  MetricManifold  to get invariant metrics, or in a  ConnectionManifold  to equip it with a Cartan-Schouten connection."},{"id":955,"pagetitle":"Group manifold","title":"Manifolds.AbstractGroupOperation","ref":"/manifolds/stable/manifolds/#Manifolds.AbstractGroupOperation","content":" Manifolds.AbstractGroupOperation  ‚Äî  Type AbstractGroupOperation Abstract type for smooth binary operations  $‚àò$  on elements of a Lie group  $\\mathcal{G}$ : \\[‚àò : \\mathcal{G} √ó \\mathcal{G} ‚Üí \\mathcal{G}\\] An operation can be either defined for a specific group manifold over number system  ùîΩ  or in general, by defining for an operation  Op  the following methods: identity_element!(::AbstractDecoratorManifold, q, q)\ninv!(::AbstractDecoratorManifold, q, p)\n_compose!(::AbstractDecoratorManifold, x, p, q) Note that a manifold is connected with an operation by wrapping it with a decorator,  AbstractDecoratorManifold  using the  IsGroupManifold  to specify the operation. For a concrete case the concrete wrapper  GroupManifold  can be used. source"},{"id":956,"pagetitle":"Group manifold","title":"Manifolds.AbstractInvarianceTrait","ref":"/manifolds/stable/manifolds/#Manifolds.AbstractInvarianceTrait","content":" Manifolds.AbstractInvarianceTrait  ‚Äî  Type AbstractInvarianceTrait <: AbstractTrait A common supertype for anz  AbstractTrait  related to metric invariance source"},{"id":957,"pagetitle":"Group manifold","title":"Manifolds.ActionDirection","ref":"/manifolds/stable/manifolds/#Manifolds.ActionDirection","content":" Manifolds.ActionDirection  ‚Äî  Type ActionDirection Direction of action on a manifold, either  LeftAction  or  RightAction . source"},{"id":958,"pagetitle":"Group manifold","title":"Manifolds.GroupActionSide","ref":"/manifolds/stable/manifolds/#Manifolds.GroupActionSide","content":" Manifolds.GroupActionSide  ‚Äî  Type GroupActionSide Side of action on a manifold, either  LeftSide  or  RightSide . source"},{"id":959,"pagetitle":"Group manifold","title":"Manifolds.GroupExponentialRetraction","ref":"/manifolds/stable/manifolds/#Manifolds.GroupExponentialRetraction","content":" Manifolds.GroupExponentialRetraction  ‚Äî  Type GroupExponentialRetraction{D<:ActionDirectionAndSide} <: AbstractRetractionMethod Retraction using the group exponential  exp_lie  \"translated\" to any point on the manifold. For more details, see  retract . Constructor GroupExponentialRetraction(conv::ActionDirectionAndSide = LeftAction()) source"},{"id":960,"pagetitle":"Group manifold","title":"Manifolds.GroupLogarithmicInverseRetraction","ref":"/manifolds/stable/manifolds/#Manifolds.GroupLogarithmicInverseRetraction","content":" Manifolds.GroupLogarithmicInverseRetraction  ‚Äî  Type GroupLogarithmicInverseRetraction{D<:ActionDirectionAndSide} <: AbstractInverseRetractionMethod Retraction using the group logarithm  log_lie  \"translated\" to any point on the manifold. For more details, see  inverse_retract . Constructor GroupLogarithmicInverseRetraction(conv::ActionDirectionAndSide = LeftForwardAction()) source"},{"id":961,"pagetitle":"Group manifold","title":"Manifolds.HasBiinvariantMetric","ref":"/manifolds/stable/manifolds/#Manifolds.HasBiinvariantMetric","content":" Manifolds.HasBiinvariantMetric  ‚Äî  Type HasBiinvariantMetric <: AbstractInvarianceTrait Specify that the default metric functions for the bi-invariant metric on a  GroupManifold  are to be used. source"},{"id":962,"pagetitle":"Group manifold","title":"Manifolds.HasLeftInvariantMetric","ref":"/manifolds/stable/manifolds/#Manifolds.HasLeftInvariantMetric","content":" Manifolds.HasLeftInvariantMetric  ‚Äî  Type HasLeftInvariantMetric <: AbstractInvarianceTrait Specify that the default metric functions for the left-invariant metric on a  GroupManifold  are to be used. source"},{"id":963,"pagetitle":"Group manifold","title":"Manifolds.HasRightInvariantMetric","ref":"/manifolds/stable/manifolds/#Manifolds.HasRightInvariantMetric","content":" Manifolds.HasRightInvariantMetric  ‚Äî  Type HasRightInvariantMetric <: AbstractInvarianceTrait Specify that the default metric functions for the right-invariant metric on a  GroupManifold  are to be used. source"},{"id":964,"pagetitle":"Group manifold","title":"Manifolds.Identity","ref":"/manifolds/stable/manifolds/#Manifolds.Identity","content":" Manifolds.Identity  ‚Äî  Type Identity{O<:AbstractGroupOperation} Represent the group identity element  $e ‚àà \\mathcal{G}$  on a Lie group  $\\mathcal G$  with  AbstractGroupOperation  of type  O . Similar to the philosophy that points are agnostic of their group at hand, the identity does not store the group  g  it belongs to. However it depends on the type of the  AbstractGroupOperation  used. See also  identity_element  on how to obtain the corresponding  AbstractManifoldPoint  or array representation. Constructors Identity(G::AbstractDecoratorManifold{ùîΩ})\nIdentity(o::O)\nIdentity(::Type{O}) create the identity of the corresponding subtype  O<: AbstractGroupOperation source"},{"id":965,"pagetitle":"Group manifold","title":"Manifolds.IsGroupManifold","ref":"/manifolds/stable/manifolds/#Manifolds.IsGroupManifold","content":" Manifolds.IsGroupManifold  ‚Äî  Type IsGroupManifold{O<:AbstractGroupOperation} <: AbstractTrait A trait to declare an  AbstractManifold   as a manifold with group structure with operation of type  O . Using this trait you can turn a manifold that you implement  implictly  into a Lie group. If you wish to decorate an existing manifold with one (or different)  AbstractGroupAction s, see  GroupManifold . Constructor IsGroupManifold(op::AbstractGroupOperation) source"},{"id":966,"pagetitle":"Group manifold","title":"Manifolds.LeftAction","ref":"/manifolds/stable/manifolds/#Manifolds.LeftAction","content":" Manifolds.LeftAction  ‚Äî  Type LeftAction() Left action of a group on a manifold. For a forward action  $Œ±: G√óX ‚Üí X$  it is characterized by \\[Œ±(g, Œ±(h, x)) = Œ±(gh, x)\\] for all  $g, h ‚àà G$  and  $x ‚àà X$ . source"},{"id":967,"pagetitle":"Group manifold","title":"Manifolds.LeftSide","ref":"/manifolds/stable/manifolds/#Manifolds.LeftSide","content":" Manifolds.LeftSide  ‚Äî  Type LeftSide() An action of a group on a manifold that acts from the left side, i.e.  $Œ±: G√óX ‚Üí X$ . source"},{"id":968,"pagetitle":"Group manifold","title":"Manifolds.RightAction","ref":"/manifolds/stable/manifolds/#Manifolds.RightAction","content":" Manifolds.RightAction  ‚Äî  Type RightAction() Right action of a group on a manifold. For a forward action  $Œ±: G√óX ‚Üí X$  it is characterized by \\[Œ±(g, Œ±(h, x)) = Œ±(hg, x)\\] for all  $g, h ‚àà G$  and  $x ‚àà X$ . Note that a right action may act from either left or right side in an expression. source"},{"id":969,"pagetitle":"Group manifold","title":"Manifolds.RightSide","ref":"/manifolds/stable/manifolds/#Manifolds.RightSide","content":" Manifolds.RightSide  ‚Äî  Type RightSide() An action of a group on a manifold that acts from the right side, i.e.  $Œ±: X√óG ‚Üí X$ . source"},{"id":970,"pagetitle":"Group manifold","title":"Base.inv","ref":"/manifolds/stable/manifolds/#Base.inv-Tuple{AbstractDecoratorManifold, Vararg{Any}}","content":" Base.inv  ‚Äî  Method inv(G::AbstractDecoratorManifold, p) Inverse  $p^{-1} ‚àà \\mathcal{G}$  of an element  $p ‚àà \\mathcal{G}$ , such that  $p \\circ p^{-1} = p^{-1} \\circ p = e ‚àà \\mathcal{G}$ , where  $e$  is the  Identity  element of  $\\mathcal{G}$ . source"},{"id":971,"pagetitle":"Group manifold","title":"Manifolds.adjoint_action","ref":"/manifolds/stable/manifolds/#Manifolds.adjoint_action-Tuple{AbstractDecoratorManifold, Any, Any}","content":" Manifolds.adjoint_action  ‚Äî  Method adjoint_action(G::AbstractDecoratorManifold, p, X) Adjoint action of the element  p  of the Lie group  G  on the element  X  of the corresponding Lie algebra. It is defined as the differential of the group authomorphism  $Œ®_p(q) = pqp‚Åª¬π$  at the identity of  G . The formula reads \\[\\operatorname{Ad}_p(X) = dŒ®_p(e)[X]\\] where  $e$  is the identity element of  G . Note that the adjoint representation of a Lie group isn't generally faithful. Notably the adjoint representation of SO(2) is trivial. source"},{"id":972,"pagetitle":"Group manifold","title":"Manifolds.adjoint_inv_diff","ref":"/manifolds/stable/manifolds/#Manifolds.adjoint_inv_diff-Tuple{AbstractDecoratorManifold, Any}","content":" Manifolds.adjoint_inv_diff  ‚Äî  Method adjoint_inv_diff(G::AbstractDecoratorManifold, p, X) Compute the value of pullback of inverse  $p^{-1} ‚àà \\mathcal{G}$  of an element  $p ‚àà \\mathcal{G}$  at tangent vector  X  at  $p^{-1}$ . The result is a tangent vector at  $p$ . source"},{"id":973,"pagetitle":"Group manifold","title":"Manifolds.compose","ref":"/manifolds/stable/manifolds/#Manifolds.compose-Tuple{AbstractDecoratorManifold, Vararg{Any}}","content":" Manifolds.compose  ‚Äî  Method compose(G::AbstractDecoratorManifold, p, q) Compose elements  $p,q ‚àà \\mathcal{G}$  using the group operation  $p \\circ q$ . For implementing composition on a new group manifold, please overload  _compose  instead so that methods with  Identity  arguments are not ambiguous. source"},{"id":974,"pagetitle":"Group manifold","title":"Manifolds.exp_lie","ref":"/manifolds/stable/manifolds/#Manifolds.exp_lie-Tuple{AbstractManifold, Any}","content":" Manifolds.exp_lie  ‚Äî  Method exp_lie(G, X)\nexp_lie!(G, q, X) Compute the group exponential of the Lie algebra element  X . It is equivalent to the exponential map defined by the  CartanSchoutenMinus  connection. Given an element  $X ‚àà ùî§ = T_e \\mathcal{G}$ , where  $e$  is the  Identity  element of the group  $\\mathcal{G}$ , and  $ùî§$  is its Lie algebra, the group exponential is the map \\[\\exp : ùî§ ‚Üí \\mathcal{G},\\] such that for  $t,s ‚àà ‚Ñù$ ,  $Œ≥(t) = \\exp (t X)$  defines a one-parameter subgroup with the following properties. Note that one-parameter subgroups are commutative (see [ Suh13 ], section 3.5), even if the Lie group itself is not commutative. \\[\\begin{aligned}\nŒ≥(t) &= Œ≥(-t)^{-1}\\\\\nŒ≥(t + s) &= Œ≥(t) \\circ Œ≥(s) = Œ≥(s) \\circ Œ≥(t)\\\\\nŒ≥(0) &= e\\\\\n\\lim_{t ‚Üí 0} \\frac{d}{dt} Œ≥(t) &= X.\n\\end{aligned}\\] Note In general, the group exponential map is distinct from the Riemannian exponential map  exp . For example for the  MultiplicationOperation  and either  Number  or  AbstractMatrix  the Lie exponential is the numeric/matrix exponential. \\[\\exp X = \\operatorname{Exp} X = \\sum_{n=0}^‚àû \\frac{1}{n!} X^n.\\] Since this function also depends on the group operation, make sure to implement the corresponding trait version  exp_lie(::TraitList{<:IsGroupManifold}, G, X) . source"},{"id":975,"pagetitle":"Group manifold","title":"Manifolds.get_coordinates_lie","ref":"/manifolds/stable/manifolds/#Manifolds.get_coordinates_lie-Tuple{ManifoldsBase.TraitList{<:IsGroupManifold}, AbstractManifold, Any, AbstractBasis}","content":" Manifolds.get_coordinates_lie  ‚Äî  Method get_coordinates_lie(G::AbstractManifold, X, B::AbstractBasis) Get the coordinates of an element  X  from the Lie algebra og  G  with respect to a basis  B . This is similar to calling  get_coordinates  at the  p= Identity (G) . source"},{"id":976,"pagetitle":"Group manifold","title":"Manifolds.get_vector_lie","ref":"/manifolds/stable/manifolds/#Manifolds.get_vector_lie-Tuple{ManifoldsBase.TraitList{<:IsGroupManifold}, AbstractManifold, Any, AbstractBasis}","content":" Manifolds.get_vector_lie  ‚Äî  Method get_vector_lie(G::AbstractDecoratorManifold, a, B::AbstractBasis) Reconstruct a tangent vector from the Lie algebra of  G  from cooordinates  a  of a basis  B . This is similar to calling  get_vector  at the  p= Identity (G) . source"},{"id":977,"pagetitle":"Group manifold","title":"Manifolds.identity_element","ref":"/manifolds/stable/manifolds/#Manifolds.identity_element-Tuple{AbstractDecoratorManifold, Any}","content":" Manifolds.identity_element  ‚Äî  Method identity_element(G::AbstractDecoratorManifold, p) Return a point representation of the  Identity  on the  IsGroupManifold G , where  p  indicates the type to represent the identity. source"},{"id":978,"pagetitle":"Group manifold","title":"Manifolds.identity_element","ref":"/manifolds/stable/manifolds/#Manifolds.identity_element-Tuple{AbstractDecoratorManifold}","content":" Manifolds.identity_element  ‚Äî  Method identity_element(G::AbstractDecoratorManifold) Return a point representation of the  Identity  on the  IsGroupManifold G . By default this representation is the default array or number representation. It should return the corresponding default representation of  $e$  as a point on  G  if points are not represented by arrays. source"},{"id":979,"pagetitle":"Group manifold","title":"Manifolds.inv_diff","ref":"/manifolds/stable/manifolds/#Manifolds.inv_diff-Tuple{AbstractDecoratorManifold, Any}","content":" Manifolds.inv_diff  ‚Äî  Method inv_diff(G::AbstractDecoratorManifold, p, X) Compute the value of differential of inverse  $p^{-1} ‚àà \\mathcal{G}$  of an element  $p ‚àà \\mathcal{G}$  at tangent vector  X  at  p . The result is a tangent vector at  $p^{-1}$ . source"},{"id":980,"pagetitle":"Group manifold","title":"Manifolds.inverse_translate","ref":"/manifolds/stable/manifolds/#Manifolds.inverse_translate-Tuple{AbstractDecoratorManifold, Vararg{Any}}","content":" Manifolds.inverse_translate  ‚Äî  Method inverse_translate(G::AbstractDecoratorManifold, p, q, conv::ActionDirectionAndSide=LeftForwardAction()) Inverse translate group element  $q$  by  $p$  with the translation  $œÑ_p^{-1}$  with the specified  conv ention, either left forward ( $L_p^{-1}$ ), left backward ( $R'_p^{-1}$ ), right backward ( $R_p^{-1}$ ) or right forward ( $L'_p^{-1}$ ), defined as ```math \\begin{aligned} L p^{-1} &: q ‚Ü¶ p^{-1} \\circ q\\\nL' p^{-1} &: q ‚Ü¶ p \\circ q\\\nR p^{-1} &: q ‚Ü¶ q \\circ p^{-1}\\\nR' p^{-1} &: q ‚Ü¶ q \\circ p. \\end{aligned} source"},{"id":981,"pagetitle":"Group manifold","title":"Manifolds.inverse_translate_diff","ref":"/manifolds/stable/manifolds/#Manifolds.inverse_translate_diff-Tuple{AbstractDecoratorManifold, Vararg{Any}}","content":" Manifolds.inverse_translate_diff  ‚Äî  Method inverse_translate_diff(G::AbstractDecoratorManifold, p, q, X, conv::ActionDirectionAndSide=LeftForwardAction()) For group elements  $p, q ‚àà \\mathcal{G}$  and tangent vector  $X ‚àà T_q \\mathcal{G}$ , compute the action on  $X$  of the differential of the inverse translation  $œÑ_p$  by  $p$ , with the specified left or right  conv ention. The differential transports vectors: \\[(\\mathrm{d}œÑ_p^{-1})_q : T_q \\mathcal{G} ‚Üí T_{œÑ_p^{-1} q} \\mathcal{G}\\\\\\] source"},{"id":982,"pagetitle":"Group manifold","title":"Manifolds.is_group_manifold","ref":"/manifolds/stable/manifolds/#Manifolds.is_group_manifold-Tuple{AbstractManifold, AbstractGroupOperation}","content":" Manifolds.is_group_manifold  ‚Äî  Method is_group_manifold(G::GroupManifold)\nis_group_manifold(G::AbstractManifold, o::AbstractGroupOperation) returns whether an  AbstractDecoratorManifold  is a group manifold with  AbstractGroupOperation o . For a  GroupManifold G  this checks whether the right operations is stored within  G . source"},{"id":983,"pagetitle":"Group manifold","title":"Manifolds.is_identity","ref":"/manifolds/stable/manifolds/#Manifolds.is_identity-Tuple{AbstractDecoratorManifold, Any}","content":" Manifolds.is_identity  ‚Äî  Method is_identity(G::AbstractDecoratorManifold, q; kwargs) Check whether  q  is the identity on the  IsGroupManifold G , i.e. it is either the  Identity {O}  with the corresponding  AbstractGroupOperation O , or (approximately) the correct point representation. source"},{"id":984,"pagetitle":"Group manifold","title":"Manifolds.lie_bracket","ref":"/manifolds/stable/manifolds/#Manifolds.lie_bracket-Tuple{AbstractDecoratorManifold, Any, Any}","content":" Manifolds.lie_bracket  ‚Äî  Method lie_bracket(G::AbstractDecoratorManifold, X, Y) Lie bracket between elements  X  and  Y  of the Lie algebra corresponding to the Lie group  G , cf.  IsGroupManifold . This can be used to compute the adjoint representation of a Lie algebra. Note that this representation isn't generally faithful. Notably the adjoint representation of ùî∞ùî¨(2) is trivial. source"},{"id":985,"pagetitle":"Group manifold","title":"Manifolds.log_lie","ref":"/manifolds/stable/manifolds/#Manifolds.log_lie-Tuple{AbstractDecoratorManifold, Any}","content":" Manifolds.log_lie  ‚Äî  Method log_lie(G, q)\nlog_lie!(G, X, q) Compute the Lie group logarithm of the Lie group element  q . It is equivalent to the logarithmic map defined by the  CartanSchoutenMinus  connection. Given an element  $q ‚àà \\mathcal{G}$ , compute the right inverse of the group exponential map  exp_lie , that is, the element  $\\log q = X ‚àà ùî§ = T_e \\mathcal{G}$ , such that  $q = \\exp X$ Note In general, the group logarithm map is distinct from the Riemannian logarithm map  log . For matrix Lie groups this is equal to the (matrix) logarithm: \\[\\log q = \\operatorname{Log} q = \\sum_{n=1}^‚àû \\frac{(-1)^{n+1}}{n} (q - e)^n,\\] where  $e$  here is the  Identity  element, that is,  $1$  for numeric  $q$  or the identity matrix  $I_m$  for matrix  $q ‚àà ‚Ñù^{m√óm}$ . Since this function also depends on the group operation, make sure to implement either _log_lie(G, q)  and  _log_lie!(G, X, q)  for the points not being the  Identity the trait version  log_lie(::TraitList{<:IsGroupManifold}, G, e) ,  log_lie(::TraitList{<:IsGroupManifold}, G, X, e)  for own implementations of the identity case. source"},{"id":986,"pagetitle":"Group manifold","title":"Manifolds.switch_direction","ref":"/manifolds/stable/manifolds/#Manifolds.switch_direction-Tuple{ActionDirection}","content":" Manifolds.switch_direction  ‚Äî  Method switch_direction(::ActionDirection) Returns type of action between left and right. This function does not affect side of action, see  switch_side . source"},{"id":987,"pagetitle":"Group manifold","title":"Manifolds.switch_side","ref":"/manifolds/stable/manifolds/#Manifolds.switch_side-Tuple{Manifolds.GroupActionSide}","content":" Manifolds.switch_side  ‚Äî  Method switch_side(::GroupActionSide) Returns side of action between left and right. This function does not affect the action being left or right, see  switch_direction . source"},{"id":988,"pagetitle":"Group manifold","title":"Manifolds.translate","ref":"/manifolds/stable/manifolds/#Manifolds.translate-Tuple{AbstractDecoratorManifold, Vararg{Any}}","content":" Manifolds.translate  ‚Äî  Method translate(G::AbstractDecoratorManifold, p, q, conv::ActionDirectionAndSide=LeftForwardAction()]) Translate group element  $q$  by  $p$  with the translation  $œÑ_p$  with the specified  conv ention, either left forward ( $L_p$ ), left backward ( $R'_p$ ), right backward ( $R_p$ ) or right forward ( $L'_p$ ), defined as \\[\\begin{aligned}\nL_p &: q ‚Ü¶ p \\circ q\\\\\nL'_p &: q ‚Ü¶ p^{-1} \\circ q\\\\\nR_p &: q ‚Ü¶ q \\circ p\\\\\nR'_p &: q ‚Ü¶ q \\circ p^{-1}.\n\\end{aligned}\\] source"},{"id":989,"pagetitle":"Group manifold","title":"Manifolds.translate_diff","ref":"/manifolds/stable/manifolds/#Manifolds.translate_diff-Tuple{AbstractDecoratorManifold, Vararg{Any}}","content":" Manifolds.translate_diff  ‚Äî  Method translate_diff(G::AbstractDecoratorManifold, p, q, X, conv::ActionDirectionAndSide=LeftForwardAction()) For group elements  $p, q ‚àà \\mathcal{G}$  and tangent vector  $X ‚àà T_q \\mathcal{G}$ , compute the action of the differential of the translation  $œÑ_p$  by  $p$  on  $X$ , with the specified left or right  conv ention. The differential transports vectors: \\[(\\mathrm{d}œÑ_p)_q : T_q \\mathcal{G} ‚Üí T_{œÑ_p q} \\mathcal{G}\\\\\\] source"},{"id":990,"pagetitle":"Group manifold","title":"ManifoldsBase.hat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.hat-Union{Tuple{O}, Tuple{ManifoldsBase.TraitList{IsGroupManifold{O}}, AbstractDecoratorManifold, Identity{O}, Any}} where O<:AbstractGroupOperation","content":" ManifoldsBase.hat  ‚Äî  Method hat(M::AbstractDecoratorManifold{ùîΩ,O}, ::Identity{O}, X‚Å±) where {ùîΩ,O<:AbstractGroupOperation} Given a basis  $e_i$  on the tangent space at a the  Identity  and tangent component vector  $X^i$ , compute the equivalent vector representation ``X=X^i e_i**, where Einstein summation notation is used: \\[‚àß : X^i ‚Ü¶ X^i e_i\\] For array manifolds, this converts a vector representation of the tangent vector to an array representation. The  vee  map is the  hat  map's inverse. source"},{"id":991,"pagetitle":"Group manifold","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{ManifoldsBase.TraitList{<:IsGroupManifold}, AbstractDecoratorManifold, Any, Any, Manifolds.GroupLogarithmicInverseRetraction}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(\n    G::AbstractDecoratorManifold,\n    p,\n    X,\n    method::GroupLogarithmicInverseRetraction,\n) Compute the inverse retraction using the group logarithm  log_lie  \"translated\" to any point on the manifold. With a group translation ( translate )  $œÑ_p$  in a specified direction, the retraction is \\[\\operatorname{retr}_p^{-1} = (\\mathrm{d}œÑ_p)_e \\circ \\log \\circ œÑ_p^{-1},\\] where  $\\log$  is the group logarithm ( log_lie ), and  $(\\mathrm{d}œÑ_p)_e$  is the action of the differential of translation  $œÑ_p$  evaluated at the identity element  $e$  (see  translate_diff ). source"},{"id":992,"pagetitle":"Group manifold","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{ManifoldsBase.TraitList{<:IsGroupManifold}, AbstractDecoratorManifold, Any, Any, Manifolds.GroupExponentialRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(\n    G::AbstractDecoratorManifold,\n    p,\n    X,\n    method::GroupExponentialRetraction,\n) Compute the retraction using the group exponential  exp_lie  \"translated\" to any point on the manifold. With a group translation ( translate )  $œÑ_p$  in a specified direction, the retraction is \\[\\operatorname{retr}_p = œÑ_p \\circ \\exp \\circ (\\mathrm{d}œÑ_p^{-1})_p,\\] where  $\\exp$  is the group exponential ( exp_lie ), and  $(\\mathrm{d}œÑ_p^{-1})_p$  is the action of the differential of inverse translation  $œÑ_p^{-1}$  evaluated at  $p$  (see  inverse_translate_diff ). source"},{"id":993,"pagetitle":"Group manifold","title":"ManifoldsBase.vee","ref":"/manifolds/stable/manifolds/#ManifoldsBase.vee-Union{Tuple{O}, Tuple{ManifoldsBase.TraitList{IsGroupManifold{O}}, AbstractDecoratorManifold, Identity{O}, Any}} where O<:AbstractGroupOperation","content":" ManifoldsBase.vee  ‚Äî  Method vee(M::AbstractManifold, p, X) Given a basis  $e_i$  on the tangent space at a point  p  and tangent vector  X , compute the vector components  $X^i$ , such that  $X = X^i e_i$ , where Einstein summation notation is used: \\[\\vee : X^i e_i ‚Ü¶ X^i\\] For array manifolds, this converts an array representation of the tangent vector to a vector representation. The  hat  map is the  vee  map's inverse. source"},{"id":994,"pagetitle":"Group manifold","title":"GroupManifold","ref":"/manifolds/stable/manifolds/#GroupManifold","content":" GroupManifold As a concrete wrapper for manifolds (e.g. when the manifold per se is a group manifold but another group structure should be implemented), there is the  GroupManifold"},{"id":995,"pagetitle":"Group manifold","title":"Manifolds.GroupManifold","ref":"/manifolds/stable/manifolds/#Manifolds.GroupManifold","content":" Manifolds.GroupManifold  ‚Äî  Type GroupManifold{ùîΩ,M<:AbstractManifold{ùîΩ},O<:AbstractGroupOperation} <: AbstractDecoratorManifold{ùîΩ} Concrete decorator for a smooth manifold that equips the manifold with a group operation, thus making it a Lie group. See  IsGroupManifold  for more details. Group manifolds by default forward metric-related operations to the wrapped manifold. Constructor GroupManifold(manifold, op) Define the group operation  op  acting on the manifold  manifold , hence if  op  acts smoothly, this forms a Lie group. source"},{"id":996,"pagetitle":"Group manifold","title":"Base.rand","ref":"/manifolds/stable/manifolds/#Base.rand-Tuple{GroupManifold}","content":" Base.rand  ‚Äî  Method rand(::GroupManifold; vector_at=nothing, œÉ=1.0)\nrand!(::GroupManifold, pX; vector_at=nothing, kwargs...)\nrand(::TraitList{IsGroupManifold}, M; vector_at=nothing, œÉ=1.0)\nrand!(TraitList{IsGroupManifold}, M, pX; vector_at=nothing, kwargs...) Compute a random point or tangent vector on a Lie group. For points this just means to generate a random point on the underlying manifold itself. For tangent vectors, an element in the Lie Algebra is generated. source"},{"id":997,"pagetitle":"Group manifold","title":"Generic Operations","ref":"/manifolds/stable/manifolds/#Generic-Operations","content":" Generic Operations For groups based on an addition operation or a group operation, several default implementations are provided."},{"id":998,"pagetitle":"Group manifold","title":"Addition Operation","ref":"/manifolds/stable/manifolds/#Addition-Operation","content":" Addition Operation"},{"id":999,"pagetitle":"Group manifold","title":"Manifolds.AdditionOperation","ref":"/manifolds/stable/manifolds/#Manifolds.AdditionOperation","content":" Manifolds.AdditionOperation  ‚Äî  Type AdditionOperation <: AbstractGroupOperation Group operation that consists of simple addition. source"},{"id":1000,"pagetitle":"Group manifold","title":"Manifolds.adjoint_inv_diff","ref":"/manifolds/stable/manifolds/#Manifolds.adjoint_inv_diff-Tuple{ManifoldsBase.TraitList{<:IsGroupManifold{AdditionOperation}}, AbstractDecoratorManifold, Any, Any}","content":" Manifolds.adjoint_inv_diff  ‚Äî  Method adjoint_inv_diff(::AdditionGroupTrait, G::AbstractDecoratorManifold, p, X) Compute the value of pullback of additive matrix inversion  $p ‚Ü¶ -p$  at  $X$ , i.e.  $-X$ . source"},{"id":1001,"pagetitle":"Group manifold","title":"Manifolds.inv_diff","ref":"/manifolds/stable/manifolds/#Manifolds.inv_diff-Tuple{ManifoldsBase.TraitList{<:IsGroupManifold{AdditionOperation}}, AbstractDecoratorManifold, Any, Any}","content":" Manifolds.inv_diff  ‚Äî  Method inv_diff(::AdditionGroupTrait, G::AbstractDecoratorManifold, p, X) Compute the value of differential of additive matrix inversion  $p ‚Ü¶ -p$  at  $X$ , i.e.  $-X$ . source"},{"id":1002,"pagetitle":"Group manifold","title":"Multiplication Operation","ref":"/manifolds/stable/manifolds/#Multiplication-Operation","content":" Multiplication Operation"},{"id":1003,"pagetitle":"Group manifold","title":"Manifolds.MultiplicationOperation","ref":"/manifolds/stable/manifolds/#Manifolds.MultiplicationOperation","content":" Manifolds.MultiplicationOperation  ‚Äî  Type MultiplicationOperation <: AbstractGroupOperation Group operation that consists of multiplication. source"},{"id":1004,"pagetitle":"Group manifold","title":"Manifolds.adjoint_inv_diff","ref":"/manifolds/stable/manifolds/#Manifolds.adjoint_inv_diff-Tuple{ManifoldsBase.TraitList{<:IsGroupManifold{<:MultiplicationOperation}}, AbstractDecoratorManifold, Any, Any}","content":" Manifolds.adjoint_inv_diff  ‚Äî  Method adjoint_inv_diff(::MultiplicationGroupTrait, G::AbstractDecoratorManifold, p, X) Compute the value of differential of matrix inversion  $p ‚Ü¶ p^{-1}$  at  $X$ . When tangent vectors are represented in Lie algebra in a left-invariant way, the formula reads  $-p^\\mathrm{T}X(p^{-1})^\\mathrm{T}$ . For matrix groups with ambient space tangent vectors, the formula would read  $-(p^{-1})^\\mathrm{T}X(p^{-1})^\\mathrm{T}$ . See the section about matrix inverse in [ Gil08 ]. source"},{"id":1005,"pagetitle":"Group manifold","title":"Manifolds.inv_diff","ref":"/manifolds/stable/manifolds/#Manifolds.inv_diff-Tuple{ManifoldsBase.TraitList{<:IsGroupManifold{<:MultiplicationOperation}}, AbstractDecoratorManifold, Any, Any}","content":" Manifolds.inv_diff  ‚Äî  Method inv_diff(::MultiplicationGroupTrait, G::AbstractDecoratorManifold, p, X) Compute the value of differential of matrix inversion  $p ‚Ü¶ p^{-1}$  at  $X$ . When tangent vectors are represented in Lie algebra in a left-invariant way, the formula reads  $-pXp^{-1}$ . For matrix groups with ambient space tangent vectors, the formula would read  $-p^{-1}Xp^{-1}$ . See the section about matrix inverse in [ Gil08 ]. source"},{"id":1006,"pagetitle":"Group manifold","title":"Circle group","ref":"/manifolds/stable/manifolds/#Circle-group","content":" Circle group"},{"id":1007,"pagetitle":"Group manifold","title":"Manifolds.CircleGroup","ref":"/manifolds/stable/manifolds/#Manifolds.CircleGroup","content":" Manifolds.CircleGroup  ‚Äî  Type CircleGroup <: GroupManifold{Circle{‚ÑÇ},MultiplicationOperation} The circle group is the complex circle ( Circle(‚ÑÇ) ) equipped with the group operation of complex multiplication ( MultiplicationOperation ). source"},{"id":1008,"pagetitle":"Group manifold","title":"Manifolds.RealCircleGroup","ref":"/manifolds/stable/manifolds/#Manifolds.RealCircleGroup","content":" Manifolds.RealCircleGroup  ‚Äî  Type RealCircleGroup <: GroupManifold{Circle{‚Ñù},AdditionOperation} The real circle group is the real circle ( Circle(‚Ñù) ) equipped with the group operation of addition ( AdditionOperation ). source"},{"id":1009,"pagetitle":"Group manifold","title":"General linear group","ref":"/manifolds/stable/manifolds/#General-linear-group","content":" General linear group"},{"id":1010,"pagetitle":"Group manifold","title":"Manifolds.GeneralLinear","ref":"/manifolds/stable/manifolds/#Manifolds.GeneralLinear","content":" Manifolds.GeneralLinear  ‚Äî  Type GeneralLinear{T,ùîΩ} <: AbstractDecoratorManifold{ùîΩ} The general linear group, that is, the group of all invertible matrices in  $ùîΩ^{n√ón}$ . The default metric is the left- $\\mathrm{GL}(n)$ -right- $\\mathrm{O}(n)$ -invariant metric whose inner product is \\[‚ü®X_p,Y_p‚ü©_p = ‚ü®p^{-1}X_p,p^{-1}Y_p‚ü©_\\mathrm{F} = ‚ü®X_e, Y_e‚ü©_\\mathrm{F},\\] where  $X_p, Y_p ‚àà T_p \\mathrm{GL}(n, ùîΩ)$ ,  $X_e = p^{-1}X_p ‚àà ùî§ùî©(n) = T_e \\mathrm{GL}(n, ùîΩ) = ùîΩ^{n√ón}$  is the corresponding vector in the Lie algebra, and  $‚ü®‚ãÖ,‚ãÖ‚ü©_\\mathrm{F}$  denotes the Frobenius inner product. By default, tangent vectors  $X_p$  are represented with their corresponding Lie algebra vectors  $X_e = p^{-1}X_p$ . source"},{"id":1011,"pagetitle":"Group manifold","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{GeneralLinear, Any, Any}","content":" Base.exp  ‚Äî  Method exp(G::GeneralLinear, p, X) Compute the exponential map on the  GeneralLinear  group. The exponential map is \\[\\exp_p \\colon X ‚Ü¶ p \\operatorname{Exp}(X^\\mathrm{H}) \\operatorname{Exp}(X - X^\\mathrm{H}),\\] where  $\\operatorname{Exp}(‚ãÖ)$  denotes the matrix exponential, and  $‚ãÖ^\\mathrm{H}$  is the conjugate transpose [ ALRV14 ] [ NM16 ]. source"},{"id":1012,"pagetitle":"Group manifold","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{GeneralLinear, Any, Any}","content":" Base.log  ‚Äî  Method log(G::GeneralLinear, p, q) Compute the logarithmic map on the  GeneralLinear(n)  group. The algorithm proceeds in two stages. First, the point  $r = p^{-1} q$  is projected to the nearest element (under the Frobenius norm) of the direct product subgroup  $\\mathrm{O}(n) √ó S^+$ , whose logarithmic map is exactly computed using the matrix logarithm. This initial tangent vector is then refined using the  NLSolveInverseRetraction . For  GeneralLinear(n, ‚ÑÇ) , the logarithmic map is instead computed on the realified supergroup  GeneralLinear(2n)  and the resulting tangent vector is then complexified. Note that this implementation is experimental. source"},{"id":1013,"pagetitle":"Group manifold","title":"Base.rand","ref":"/manifolds/stable/manifolds/#Base.rand-Tuple{GeneralLinear}","content":" Base.rand  ‚Äî  Method Random.rand(G::GeneralLinear; vector_at=nothing, kwargs...) If  vector_at  is  nothing , return a random point on the  GeneralLinear  group  G  by using  rand  in the embedding. If  vector_at  is not  nothing , return a random tangent vector from the tangent space of the point  vector_at  on the  GeneralLinear  by using by using  rand  in the embedding. source"},{"id":1014,"pagetitle":"Group manifold","title":"Heisenberg group","ref":"/manifolds/stable/manifolds/#Heisenberg-group","content":" Heisenberg group"},{"id":1015,"pagetitle":"Group manifold","title":"Manifolds.HeisenbergGroup","ref":"/manifolds/stable/manifolds/#Manifolds.HeisenbergGroup","content":" Manifolds.HeisenbergGroup  ‚Äî  Type HeisenbergGroup{T} <: AbstractDecoratorManifold{‚Ñù} Heisenberg group  HeisenbergGroup(n)  is the group of  $(n+2)√ó(n+2)$  matrices [ BP08 ] \\[\\begin{bmatrix} 1 & \\mathbf{a} & c \\\\\n\\mathbf{0} & I_n & \\mathbf{b} \\\\\n0 & \\mathbf{0} & 1 \\end{bmatrix}\\] where  $I_n$  is the  $n√ón$  unit matrix,  $\\mathbf{a}$  is a row vector of length  $n$ ,  $\\mathbf{b}$  is a column vector of length  $n$  and  $c$  is a real number. The group operation is matrix multiplication. The left-invariant metric on the manifold is used. source"},{"id":1016,"pagetitle":"Group manifold","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{HeisenbergGroup, Any, Any}","content":" Base.exp  ‚Äî  Method exp(M::HeisenbergGroup, p, X) Exponential map on the  HeisenbergGroup M  with the left-invariant metric. The expression reads \\[\\exp_{\\begin{bmatrix} 1 & \\mathbf{a}_p & c_p \\\\\n\\mathbf{0} & I_n & \\mathbf{b}_p \\\\\n0 & \\mathbf{0} & 1 \\end{bmatrix}}\\left(\\begin{bmatrix} 0 & \\mathbf{a}_X & c_X \\\\\n\\mathbf{0} & 0_n & \\mathbf{b}_X \\\\\n0 & \\mathbf{0} & 0 \\end{bmatrix}\\right) =\n\\begin{bmatrix} 1 & \\mathbf{a}_p + \\mathbf{a}_X & c_p + c_X + \\mathbf{a}_X‚ãÖ\\mathbf{b}_X/2 + \\mathbf{a}_p‚ãÖ\\mathbf{b}_X \\\\\n\\mathbf{0} & I_n & \\mathbf{b}_p + \\mathbf{b}_X \\\\\n0 & \\mathbf{0} & 1 \\end{bmatrix}\\] where  $I_n$  is the  $n√ón$  identity matrix,  $0_n$  is the  $n√ón$  zero matrix and  $\\mathbf{a}‚ãÖ\\mathbf{b}$  is dot product of vectors. source"},{"id":1017,"pagetitle":"Group manifold","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{HeisenbergGroup, Any, Any}","content":" Base.log  ‚Äî  Method log(G::HeisenbergGroup, p, q) Compute the logarithmic map on the  HeisenbergGroup  group. The formula reads \\[\\log_{\\begin{bmatrix} 1 & \\mathbf{a}_p & c_p \\\\\n\\mathbf{0} & I_n & \\mathbf{b}_p \\\\\n0 & \\mathbf{0} & 1 \\end{bmatrix}}\\left(\\begin{bmatrix} 1 & \\mathbf{a}_q & c_q \\\\\n\\mathbf{0} & I_n & \\mathbf{b}_q \\\\\n0 & \\mathbf{0} & 1 \\end{bmatrix}\\right) =\n\\begin{bmatrix} 0 & \\mathbf{a}_q - \\mathbf{a}_p & c_q - c_p + \\mathbf{a}_p‚ãÖ\\mathbf{b}_p - \\mathbf{a}_q‚ãÖ\\mathbf{b}_q - (\\mathbf{a}_q - \\mathbf{a}_p)‚ãÖ(\\mathbf{b}_q - \\mathbf{b}_p) / 2 \\\\\n\\mathbf{0} & 0_n & \\mathbf{b}_q - \\mathbf{b}_p \\\\\n0 & \\mathbf{0} & 0 \\end{bmatrix}\\] where  $I_n$  is the  $n√ón$  identity matrix,  $0_n$  is the  $n√ón$  zero matrix and  $\\mathbf{a}‚ãÖ\\mathbf{b}$  is dot product of vectors. source"},{"id":1018,"pagetitle":"Group manifold","title":"Base.rand","ref":"/manifolds/stable/manifolds/#Base.rand-Tuple{HeisenbergGroup}","content":" Base.rand  ‚Äî  Method Random.rand(M::HeisenbergGroup; vector_at = nothing, œÉ::Real=1.0) If  vector_at  is  nothing , return a random point on the  HeisenbergGroup M  by sampling elements of the first row and the last column from the normal distribution with mean 0 and standard deviation  œÉ . If  vector_at  is not  nothing , return a random tangent vector from the tangent space of the point  vector_at  on the  HeisenbergGroup  by using a normal distribution with mean 0 and standard deviation  œÉ . source"},{"id":1019,"pagetitle":"Group manifold","title":"Manifolds.exp_lie","ref":"/manifolds/stable/manifolds/#Manifolds.exp_lie-Tuple{HeisenbergGroup, Any}","content":" Manifolds.exp_lie  ‚Äî  Method exp_lie(M::HeisenbergGroup, X) Lie group exponential for the  HeisenbergGroup M  of the vector  X . The formula reads \\[\\exp\\left(\\begin{bmatrix} 0 & \\mathbf{a} & c \\\\\n\\mathbf{0} & 0_n & \\mathbf{b} \\\\\n0 & \\mathbf{0} & 0 \\end{bmatrix}\\right) = \\begin{bmatrix} 1 & \\mathbf{a} & c + \\mathbf{a}‚ãÖ\\mathbf{b}/2 \\\\\n\\mathbf{0} & I_n & \\mathbf{b} \\\\\n0 & \\mathbf{0} & 1 \\end{bmatrix}\\] where  $I_n$  is the  $n√ón$  identity matrix,  $0_n$  is the  $n√ón$  zero matrix and  $\\mathbf{a}‚ãÖ\\mathbf{b}$  is dot product of vectors. source"},{"id":1020,"pagetitle":"Group manifold","title":"Manifolds.log_lie","ref":"/manifolds/stable/manifolds/#Manifolds.log_lie-Tuple{HeisenbergGroup, Any}","content":" Manifolds.log_lie  ‚Äî  Method log_lie(M::HeisenbergGroup, p) Lie group logarithm for the  HeisenbergGroup M  of the point  p . The formula reads \\[\\log\\left(\\begin{bmatrix} 1 & \\mathbf{a} & c \\\\\n\\mathbf{0} & I_n & \\mathbf{b} \\\\\n0 & \\mathbf{0} & 1 \\end{bmatrix}\\right) =\n\\begin{bmatrix} 0 & \\mathbf{a} & c - \\mathbf{a}‚ãÖ\\mathbf{b}/2 \\\\\n\\mathbf{0} & 0_n & \\mathbf{b} \\\\\n0 & \\mathbf{0} & 0 \\end{bmatrix}\\] where  $I_n$  is the  $n√ón$  identity matrix,  $0_n$  is the  $n√ón$  zero matrix and  $\\mathbf{a}‚ãÖ\\mathbf{b}$  is dot product of vectors. source"},{"id":1021,"pagetitle":"Group manifold","title":"ManifoldsBase.get_coordinates","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_coordinates-Tuple{HeisenbergGroup, Any, Any, DefaultOrthonormalBasis{‚Ñù, TangentSpaceType}}","content":" ManifoldsBase.get_coordinates  ‚Äî  Method get_coordinates(M::HeisenbergGroup, p, X, ::DefaultOrthonormalBasis{‚Ñù,TangentSpaceType}) Get coordinates of tangent vector  X  at point  p  from the  HeisenbergGroup M . Given a matrix \\[\\begin{bmatrix} 1 & \\mathbf{a} & c \\\\\n\\mathbf{0} & I_n & \\mathbf{b} \\\\\n0 & \\mathbf{0} & 1 \\end{bmatrix}\\] the coordinates are concatenated vectors  $\\mathbf{a}$ ,  $\\mathbf{b}$ , and number  $c$ . source"},{"id":1022,"pagetitle":"Group manifold","title":"ManifoldsBase.get_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_vector-Tuple{HeisenbergGroup, Any, Any, DefaultOrthonormalBasis{‚Ñù, TangentSpaceType}}","content":" ManifoldsBase.get_vector  ‚Äî  Method get_vector(M::HeisenbergGroup, p, X‚Å±, ::DefaultOrthonormalBasis{‚Ñù,TangentSpaceType}) Get tangent vector with coordinates  X‚Å±  at point  p  from the  HeisenbergGroup M . Given a vector of coordinates  $\\begin{bmatrix}\\mathbb{a} & \\mathbb{b} & c\\end{bmatrix}$  the tangent vector is equal to \\[\\begin{bmatrix} 1 & \\mathbf{a} & c \\\\\n\\mathbf{0} & I_n & \\mathbf{b} \\\\\n0 & \\mathbf{0} & 1 \\end{bmatrix}\\] source"},{"id":1023,"pagetitle":"Group manifold","title":"ManifoldsBase.injectivity_radius","ref":"/manifolds/stable/manifolds/#ManifoldsBase.injectivity_radius-Tuple{HeisenbergGroup}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(M::HeisenbergGroup) Return the injectivity radius on the  HeisenbergGroup M , which is  $‚àû$ . source"},{"id":1024,"pagetitle":"Group manifold","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{HeisenbergGroup, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::HeisenbergGroup, p, X) Project a matrix  X  in the Euclidean embedding onto the Lie algebra of  HeisenbergGroup M . Sets the diagonal elements to 0 and all non-diagonal elements except the first row and the last column to 0. source"},{"id":1025,"pagetitle":"Group manifold","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{HeisenbergGroup, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::HeisenbergGroup, p) Project a matrix  p  in the Euclidean embedding onto the  HeisenbergGroup M . Sets the diagonal elements to 1 and all non-diagonal elements except the first row and the last column to 0. source"},{"id":1026,"pagetitle":"Group manifold","title":"(Special) Orthogonal and (Special) Unitary group","ref":"/manifolds/stable/manifolds/#(Special)-Orthogonal-and-(Special)-Unitary-group","content":" (Special) Orthogonal and (Special) Unitary group Since the orthogonal, unitary and special orthogonal and special unitary groups share many common functions, these are also implemented on a common level."},{"id":1027,"pagetitle":"Group manifold","title":"Common functions","ref":"/manifolds/stable/manifolds/#Common-functions","content":" Common functions"},{"id":1028,"pagetitle":"Group manifold","title":"Manifolds.GeneralUnitaryMultiplicationGroup","ref":"/manifolds/stable/manifolds/#Manifolds.GeneralUnitaryMultiplicationGroup","content":" Manifolds.GeneralUnitaryMultiplicationGroup  ‚Äî  Type GeneralUnitaryMultiplicationGroup{T,ùîΩ,S} <: AbstractDecoratorManifold{ùîΩ} A generic type for Lie groups based on a unitary property and matrix multiplcation, see e.g.  Orthogonal ,  SpecialOrthogonal ,  Unitary , and  SpecialUnitary source"},{"id":1029,"pagetitle":"Group manifold","title":"Manifolds.exp_lie","ref":"/manifolds/stable/manifolds/#Manifolds.exp_lie-Tuple{Manifolds.GeneralUnitaryMultiplicationGroup{ManifoldsBase.TypeParameter{Tuple{2}}, ‚Ñù}, Any}","content":" Manifolds.exp_lie  ‚Äî  Method  exp_lie(G::Orthogonal{TypeParameter{Tuple{2}}}, X)\n exp_lie(G::SpecialOrthogonal{TypeParameter{Tuple{2}}}, X) Compute the Lie group exponential map on the  Orthogonal (2)  or  SpecialOrthogonal (2)  group. Given  $X = \\begin{pmatrix} 0 & -Œ∏ \\\\ Œ∏ & 0 \\end{pmatrix}$ , the group exponential is \\[\\exp_e \\colon X ‚Ü¶ \\begin{pmatrix} \\cos Œ∏ & -\\sin Œ∏ \\\\ \\sin Œ∏ & \\cos Œ∏ \\end{pmatrix}.\\] source"},{"id":1030,"pagetitle":"Group manifold","title":"Manifolds.exp_lie","ref":"/manifolds/stable/manifolds/#Manifolds.exp_lie-Tuple{Manifolds.GeneralUnitaryMultiplicationGroup{ManifoldsBase.TypeParameter{Tuple{4}}, ‚Ñù}, Any}","content":" Manifolds.exp_lie  ‚Äî  Method  exp_lie(G::Orthogonal{TypeParameter{Tuple{4}}}, X)\n exp_lie(G::SpecialOrthogonal{TypeParameter{Tuple{4}}}, X) Compute the group exponential map on the  Orthogonal (4)  or the  SpecialOrthogonal  group. The algorithm used is a more numerically stable form of those proposed in [ GX02 ], [ AR13 ]. source"},{"id":1031,"pagetitle":"Group manifold","title":"Orthogonal group","ref":"/manifolds/stable/manifolds/#Orthogonal-group","content":" Orthogonal group"},{"id":1032,"pagetitle":"Group manifold","title":"Manifolds.Orthogonal","ref":"/manifolds/stable/manifolds/#Manifolds.Orthogonal","content":" Manifolds.Orthogonal  ‚Äî  Type Orthogonal{T} = GeneralUnitaryMultiplicationGroup{T,‚Ñù,AbsoluteDeterminantOneMatrices} Orthogonal group  $\\mathrm{O}(n)$  represented by  OrthogonalMatrices . Constructor Orthogonal(n::Int; parameter::Symbol=:type) source"},{"id":1033,"pagetitle":"Group manifold","title":"Special orthogonal group","ref":"/manifolds/stable/manifolds/#Special-orthogonal-group","content":" Special orthogonal group"},{"id":1034,"pagetitle":"Group manifold","title":"Manifolds.SpecialOrthogonal","ref":"/manifolds/stable/manifolds/#Manifolds.SpecialOrthogonal","content":" Manifolds.SpecialOrthogonal  ‚Äî  Type SpecialOrthogonal{n} = GeneralUnitaryMultiplicationGroup{n,‚Ñù,DeterminantOneMatrices} Special orthogonal group  $\\mathrm{SO}(n)$  represented by rotation matrices, see  Rotations . Constructor SpecialOrthogonal(n) source"},{"id":1035,"pagetitle":"Group manifold","title":"Special unitary group","ref":"/manifolds/stable/manifolds/#Special-unitary-group","content":" Special unitary group"},{"id":1036,"pagetitle":"Group manifold","title":"Manifolds.SpecialUnitary","ref":"/manifolds/stable/manifolds/#Manifolds.SpecialUnitary","content":" Manifolds.SpecialUnitary  ‚Äî  Type SpecialUnitary{n} = GeneralUnitaryMultiplicationGroup{n,‚Ñù,GeneralUnitaryMatrices{n,‚ÑÇ,DeterminantOneMatrices}} The special unitary group  $\\mathrm{SU}(n)$  represented by unitary matrices of determinant +1. The tangent spaces are of the form \\[T_p\\mathrm{SU}(x) = \\bigl\\{ X \\in \\mathbb C^{n√ón} \\big| X = pY \\text{ where } Y = -Y^{\\mathrm{H}} \\bigr\\}\\] and we represent tangent vectors by just storing the  SkewHermitianMatrices $Y$ , or in other words we represent the tangent spaces employing the Lie algebra  $\\mathfrak{su}(n)$ . Constructor SpecialUnitary(n) Generate the Lie group of  $n√ón$  unitary matrices with determinant +1. source"},{"id":1037,"pagetitle":"Group manifold","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{SpecialUnitary, Vararg{Any}}","content":" ManifoldsBase.project  ‚Äî  Method project(G::SpecialUnitary, p) Project  p  to the nearest point on the  SpecialUnitary  group  G . Given the singular value decomposition  $p = U S V^\\mathrm{H}$ , with the singular values sorted in descending order, the projection is \\[\\operatorname{proj}_{\\mathrm{SU}(n)}(p) =\nU\\operatorname{diag}\\left[1,1,‚Ä¶,\\det(U V^\\mathrm{H})\\right] V^\\mathrm{H}.\\] The diagonal matrix ensures that the determinant of the result is  $+1$ . source"},{"id":1038,"pagetitle":"Group manifold","title":"Unitary group","ref":"/manifolds/stable/manifolds/#Unitary-group","content":" Unitary group"},{"id":1039,"pagetitle":"Group manifold","title":"Manifolds.Unitary","ref":"/manifolds/stable/manifolds/#Manifolds.Unitary","content":" Manifolds.Unitary  ‚Äî  Type  Unitary{n,ùîΩ} = GeneralUnitaryMultiplicationGroup{n,ùîΩ,AbsoluteDeterminantOneMatrices} The group of unitary matrices  $\\mathrm{U}(n, ùîΩ)$ , either complex (when ùîΩ=‚ÑÇ) or quaternionic (when ùîΩ=‚Ñç) The group consists of all points  $p ‚àà ùîΩ^{n√ón}$  where  $p^{\\mathrm{H}}p = pp^{\\mathrm{H}} = I$ . The tangent spaces are if the form \\[T_p\\mathrm{U}(n) = \\bigl\\{ X \\in ùîΩ^{n√ón} \\big| X = pY \\text{ where } Y = -Y^{\\mathrm{H}} \\bigr\\}\\] and we represent tangent vectors by just storing the  SkewHermitianMatrices $Y$ , or in other words we represent the tangent spaces employing the Lie algebra  $\\mathfrak{u}(n, ùîΩ)$ . Quaternionic unitary group is isomorphic to the compact symplectic group of the same dimension. Constructor Unitary(n, ùîΩ::AbstractNumbers=‚ÑÇ) Construct  $\\mathrm{U}(n, ùîΩ)$ . See also  Orthogonal(n)  for the real-valued case. source"},{"id":1040,"pagetitle":"Group manifold","title":"Manifolds.exp_lie","ref":"/manifolds/stable/manifolds/#Manifolds.exp_lie-Tuple{Unitary{ManifoldsBase.TypeParameter{Tuple{2}}, ‚ÑÇ}, Any}","content":" Manifolds.exp_lie  ‚Äî  Method exp_lie(G::Unitary{TypeParameter{Tuple{2}},‚ÑÇ}, X) Compute the group exponential map on the  Unitary(2)  group, which is \\[\\exp_e \\colon X ‚Ü¶ e^{\\operatorname{tr}(X) / 2} \\left(\\cos Œ∏ I + \\frac{\\sin Œ∏}{Œ∏} \\left(X - \\frac{\\operatorname{tr}(X)}{2} I\\right)\\right),\\] where  $Œ∏ = \\frac{1}{2} \\sqrt{4\\det(X) - \\operatorname{tr}(X)^2}$ . source"},{"id":1041,"pagetitle":"Group manifold","title":"Power group","ref":"/manifolds/stable/manifolds/#Power-group","content":" Power group"},{"id":1042,"pagetitle":"Group manifold","title":"Manifolds.PowerGroup","ref":"/manifolds/stable/manifolds/#Manifolds.PowerGroup-Tuple{AbstractPowerManifold}","content":" Manifolds.PowerGroup  ‚Äî  Method PowerGroup{ùîΩ,T} <: GroupManifold{ùîΩ,<:AbstractPowerManifold{ùîΩ,M,RPT},ProductOperation} Decorate a power manifold with a  ProductOperation . Constituent manifold of the power manifold must also have a  IsGroupManifold  or a decorated instance of one. This type is mostly useful for equipping the direct product of group manifolds with an  Identity  element. Constructor PowerGroup(manifold::AbstractPowerManifold) source"},{"id":1043,"pagetitle":"Group manifold","title":"Manifolds.PowerGroupNested","ref":"/manifolds/stable/manifolds/#Manifolds.PowerGroupNested","content":" Manifolds.PowerGroupNested  ‚Äî  Type PowerGroupNested Alias to  PowerGroup  with  NestedPowerRepresentation  representation. source"},{"id":1044,"pagetitle":"Group manifold","title":"Manifolds.PowerGroupNestedReplacing","ref":"/manifolds/stable/manifolds/#Manifolds.PowerGroupNestedReplacing","content":" Manifolds.PowerGroupNestedReplacing  ‚Äî  Type PowerGroupNestedReplacing Alias to  PowerGroup  with  NestedReplacingPowerRepresentation  representation. source"},{"id":1045,"pagetitle":"Group manifold","title":"Product group","ref":"/manifolds/stable/manifolds/#Product-group","content":" Product group"},{"id":1046,"pagetitle":"Group manifold","title":"Manifolds.ProductGroup","ref":"/manifolds/stable/manifolds/#Manifolds.ProductGroup-Union{Tuple{ProductManifold{ùîΩ}}, Tuple{ùîΩ}} where ùîΩ","content":" Manifolds.ProductGroup  ‚Äî  Method ProductGroup{ùîΩ,T} <: GroupManifold{ùîΩ,ProductManifold{T},ProductOperation} Decorate a product manifold with a  ProductOperation . Each submanifold must also have a  IsGroupManifold  or a decorated instance of one. This type is mostly useful for equipping the direct product of group manifolds with an  Identity  element. Constructor ProductGroup(manifold::ProductManifold) source"},{"id":1047,"pagetitle":"Group manifold","title":"Manifolds.ProductOperation","ref":"/manifolds/stable/manifolds/#Manifolds.ProductOperation","content":" Manifolds.ProductOperation  ‚Äî  Type ProductOperation <: AbstractGroupOperation Direct product group operation. source"},{"id":1048,"pagetitle":"Group manifold","title":"Semidirect product group","ref":"/manifolds/stable/manifolds/#Semidirect-product-group","content":" Semidirect product group"},{"id":1049,"pagetitle":"Group manifold","title":"Manifolds.SemidirectProductGroup","ref":"/manifolds/stable/manifolds/#Manifolds.SemidirectProductGroup-Union{Tuple{ùîΩ}, Tuple{AbstractDecoratorManifold{ùîΩ}, AbstractDecoratorManifold{ùîΩ}, AbstractGroupAction}} where ùîΩ","content":" Manifolds.SemidirectProductGroup  ‚Äî  Method SemidirectProductGroup(N::GroupManifold, H::GroupManifold, A::AbstractGroupAction) A group that is the semidirect product of a normal group  $\\mathcal{N}$  and a subgroup  $\\mathcal{H}$ , written  $\\mathcal{G} = \\mathcal{N} ‚ãä_Œ∏ \\mathcal{H}$ , where  $Œ∏: \\mathcal{H} √ó \\mathcal{N} ‚Üí \\mathcal{N}$  is an automorphism action of  $\\mathcal{H}$  on  $\\mathcal{N}$ . The group  $\\mathcal{G}$  has the composition rule \\[g \\circ g' = (n, h) \\circ (n', h') = (n \\circ Œ∏_h(n'), h \\circ h')\\] and the inverse \\[g^{-1} = (n, h)^{-1} = (Œ∏_{h^{-1}}(n^{-1}), h^{-1}).\\] source"},{"id":1050,"pagetitle":"Group manifold","title":"Manifolds.SemidirectProductOperation","ref":"/manifolds/stable/manifolds/#Manifolds.SemidirectProductOperation","content":" Manifolds.SemidirectProductOperation  ‚Äî  Type SemidirectProductOperation(action::AbstractGroupAction) Group operation of a semidirect product group. The operation consists of the operation  opN  on a normal subgroup  N , the operation  opH  on a subgroup  H , and an automorphism  action  of elements of  H  on  N . Only the action is stored. source"},{"id":1051,"pagetitle":"Group manifold","title":"Manifolds.identity_element","ref":"/manifolds/stable/manifolds/#Manifolds.identity_element-Tuple{SemidirectProductGroup}","content":" Manifolds.identity_element  ‚Äî  Method identity_element(G::SemidirectProductGroup) Get the identity element of  SemidirectProductGroup G . Uses  ArrayPartition  from  RecursiveArrayTools.jl  to represent the point. source"},{"id":1052,"pagetitle":"Group manifold","title":"Manifolds.translate_diff","ref":"/manifolds/stable/manifolds/#Manifolds.translate_diff-Tuple{SemidirectProductGroup, Any, Any, Any, Tuple{LeftAction, LeftSide}}","content":" Manifolds.translate_diff  ‚Äî  Method translate_diff(G::SemidirectProductGroup, p, q, X, conX::LeftForwardAction) Perform differential of the left translation on the semidirect product group  G . Since the left translation is defined as (cf.  SemidirectProductGroup ): \\[L_{(n', h')} (n, h) = ( L_{n'} Œ∏_{h'}(n), L_{h'} h)\\] then its differential can be computed as \\[\\mathrm{d}L_{(n', h')}(X_n, X_h) = ( \\mathrm{d}L_{n'} (\\mathrm{d}Œ∏_{h'}(X_n)), \\mathrm{d}L_{h'} X_h).\\] source"},{"id":1053,"pagetitle":"Group manifold","title":"Special Euclidean group","ref":"/manifolds/stable/manifolds/#Special-Euclidean-group","content":" Special Euclidean group"},{"id":1054,"pagetitle":"Group manifold","title":"Manifolds.SpecialEuclidean","ref":"/manifolds/stable/manifolds/#Manifolds.SpecialEuclidean","content":" Manifolds.SpecialEuclidean  ‚Äî  Type SpecialEuclidean(n) Special Euclidean group  $\\mathrm{SE}(n)$ , the group of rigid motions. $\\mathrm{SE}(n)$  is the semidirect product of the  TranslationGroup  on  $‚Ñù^n$  and  SpecialOrthogonal (n) \\[\\mathrm{SE}(n) ‚âê \\mathrm{T}(n) ‚ãä_Œ∏ \\mathrm{SO}(n),\\] where  $Œ∏$  is the canonical action of  $\\mathrm{SO}(n)$  on  $\\mathrm{T}(n)$  by vector rotation. This constructor is equivalent to calling Tn = TranslationGroup(n)\nSOn = SpecialOrthogonal(n)\nSemidirectProductGroup(Tn, SOn, RotationAction(Tn, SOn)) Points on  $\\mathrm{SE}(n)$  may be represented as points on the underlying product manifold  $\\mathrm{T}(n) √ó \\mathrm{SO}(n)$ . For group-specific functions, they may also be represented as affine matrices with size  (n + 1, n + 1)  (see  affine_matrix ), for which the group operation is  MultiplicationOperation . source"},{"id":1055,"pagetitle":"Group manifold","title":"Manifolds.SpecialEuclideanInGeneralLinear","ref":"/manifolds/stable/manifolds/#Manifolds.SpecialEuclideanInGeneralLinear","content":" Manifolds.SpecialEuclideanInGeneralLinear  ‚Äî  Type SpecialEuclideanInGeneralLinear An explicit isometric and homomorphic embedding of  $\\mathrm{SE}(n)$  in  $\\mathrm{GL}(n+1)$  and  $ùî∞ùî¢(n)$  in  $ùî§ùî©(n+1)$ . Note that this is  not  a transparently isometric embedding. Constructor SpecialEuclideanInGeneralLinear(n) source"},{"id":1056,"pagetitle":"Group manifold","title":"Manifolds._get_parameter","ref":"/manifolds/stable/manifolds/#Manifolds._get_parameter-Tuple{AbstractManifold}","content":" Manifolds._get_parameter  ‚Äî  Method _get_parameter(M::AbstractManifold) Similar to  get_parameter  but it can be specialized for manifolds without breaking manifolds being parametrized by other manifolds. source"},{"id":1057,"pagetitle":"Group manifold","title":"Manifolds.adjoint_action","ref":"/manifolds/stable/manifolds/#Manifolds.adjoint_action-Tuple{GroupManifold{‚Ñù, ProductManifold{‚Ñù, Tuple{TranslationGroup{ManifoldsBase.TypeParameter{Tuple{3}}, ‚Ñù}, SpecialOrthogonal{ManifoldsBase.TypeParameter{Tuple{3}}}}}, Manifolds.SemidirectProductOperation{RotationAction{LeftAction, TranslationGroup{ManifoldsBase.TypeParameter{Tuple{3}}, ‚Ñù}, SpecialOrthogonal{ManifoldsBase.TypeParameter{Tuple{3}}}}}}, Any, TFVector{<:Any, VeeOrthogonalBasis{‚Ñù}}}","content":" Manifolds.adjoint_action  ‚Äî  Method adjoint_action(::SpecialEuclidean{TypeParameter{Tuple{3}}}, p, fX::TFVector{<:Any,VeeOrthogonalBasis{‚Ñù}}) Adjoint action of the  SpecialEuclidean  group on the vector with coefficients  fX  tangent at point  p . The formula for the coefficients reads  $t√ó(R‚ãÖœâ) + R‚ãÖr$  for the translation part and  $R‚ãÖœâ$  for the rotation part, where  t  is the translation part of  p ,  R  is the rotation matrix part of  p ,  r  is the translation part of  fX  and  œâ  is the rotation part of  fX ,  $√ó$  is the cross product and  $‚ãÖ$  is the matrix product. source"},{"id":1058,"pagetitle":"Group manifold","title":"Manifolds.affine_matrix","ref":"/manifolds/stable/manifolds/#Manifolds.affine_matrix-Tuple{SpecialEuclidean, Any}","content":" Manifolds.affine_matrix  ‚Äî  Method affine_matrix(G::SpecialEuclidean, p) -> AbstractMatrix Represent the point  $p ‚àà \\mathrm{SE}(n)$  as an affine matrix. For  $p = (t, R) ‚àà \\mathrm{SE}(n)$ , where  $t ‚àà \\mathrm{T}(n), R ‚àà \\mathrm{SO}(n)$ , the affine representation is the  $n + 1 √ó n + 1$  matrix \\[\\begin{pmatrix}\nR & t \\\\\n0^\\mathrm{T} & 1\n\\end{pmatrix}.\\] This function embeds  $\\mathrm{SE}(n)$  in the general linear group  $\\mathrm{GL}(n+1)$ . It is an isometric embedding and group homomorphism [ Ric88 ]. See also  screw_matrix  for matrix representations of the Lie algebra. source"},{"id":1059,"pagetitle":"Group manifold","title":"Manifolds.exp_lie","ref":"/manifolds/stable/manifolds/#Manifolds.exp_lie-Tuple{GroupManifold{‚Ñù, ProductManifold{‚Ñù, Tuple{TranslationGroup{ManifoldsBase.TypeParameter{Tuple{2}}, ‚Ñù}, SpecialOrthogonal{ManifoldsBase.TypeParameter{Tuple{2}}}}}, Manifolds.SemidirectProductOperation{RotationAction{LeftAction, TranslationGroup{ManifoldsBase.TypeParameter{Tuple{2}}, ‚Ñù}, SpecialOrthogonal{ManifoldsBase.TypeParameter{Tuple{2}}}}}}, Any}","content":" Manifolds.exp_lie  ‚Äî  Method exp_lie(G::SpecialEuclidean{TypeParameter{Tuple{2}}}, X) Compute the group exponential of  $X = (b, Œ©) ‚àà ùî∞ùî¢(2)$ , where  $b ‚àà ùî±(2)$  and  $Œ© ‚àà ùî∞ùî¨(2)$ : \\[\\exp X = (t, R) = (U(Œ∏) b, \\exp Œ©),\\] where  $t ‚àà \\mathrm{T}(2)$ ,  $R = \\exp Œ©$  is the group exponential on  $\\mathrm{SO}(2)$ , \\[U(Œ∏) = \\frac{\\sin Œ∏}{Œ∏} I_2 + \\frac{1 - \\cos Œ∏}{Œ∏^2} Œ©,\\] and  $Œ∏ = \\frac{1}{\\sqrt{2}} \\lVert Œ© \\rVert_e$  (see  norm ) is the angle of the rotation. source"},{"id":1060,"pagetitle":"Group manifold","title":"Manifolds.exp_lie","ref":"/manifolds/stable/manifolds/#Manifolds.exp_lie-Tuple{GroupManifold{‚Ñù, ProductManifold{‚Ñù, Tuple{TranslationGroup{ManifoldsBase.TypeParameter{Tuple{3}}, ‚Ñù}, SpecialOrthogonal{ManifoldsBase.TypeParameter{Tuple{3}}}}}, Manifolds.SemidirectProductOperation{RotationAction{LeftAction, TranslationGroup{ManifoldsBase.TypeParameter{Tuple{3}}, ‚Ñù}, SpecialOrthogonal{ManifoldsBase.TypeParameter{Tuple{3}}}}}}, Any}","content":" Manifolds.exp_lie  ‚Äî  Method exp_lie(G::SpecialEuclidean{TypeParameter{Tuple{3}}}, X) Compute the group exponential of  $X = (b, Œ©) ‚àà ùî∞ùî¢(3)$ , where  $b ‚àà ùî±(3)$  and  $Œ© ‚àà ùî∞ùî¨(3)$ : \\[\\exp X = (t, R) = (U(Œ∏) b, \\exp Œ©),\\] where  $t ‚àà \\mathrm{T}(3)$ ,  $R = \\exp Œ©$  is the group exponential on  $\\mathrm{SO}(3)$ , \\[U(Œ∏) = I_3 + \\frac{1 - \\cos Œ∏}{Œ∏^2} Œ© + \\frac{Œ∏ - \\sin Œ∏}{Œ∏^3} Œ©^2,\\] and  $Œ∏ = \\frac{1}{\\sqrt{2}} \\lVert Œ© \\rVert_e$  (see  norm ) is the angle of the rotation. source"},{"id":1061,"pagetitle":"Group manifold","title":"Manifolds.exp_lie","ref":"/manifolds/stable/manifolds/#Manifolds.exp_lie-Tuple{SpecialEuclidean, Any}","content":" Manifolds.exp_lie  ‚Äî  Method exp_lie(G::SpecialEuclidean{n}, X) Compute the group exponential of  $X = (b, Œ©) ‚àà ùî∞ùî¢(n)$ , where  $b ‚àà ùî±(n)$  and  $Œ© ‚àà ùî∞ùî¨(n)$ : \\[\\exp X = (t, R),\\] where  $t ‚àà \\mathrm{T}(n)$  and  $R = \\exp Œ©$  is the group exponential on  $\\mathrm{SO}(n)$ . In the  screw_matrix  representation, the group exponential is the matrix exponential (see  exp_lie ). source"},{"id":1062,"pagetitle":"Group manifold","title":"Manifolds.lie_bracket","ref":"/manifolds/stable/manifolds/#Manifolds.lie_bracket-Tuple{SpecialEuclidean, ArrayPartition, ArrayPartition}","content":" Manifolds.lie_bracket  ‚Äî  Method lie_bracket(G::SpecialEuclidean, X::ArrayPartition, Y::ArrayPartition)\nlie_bracket(G::SpecialEuclidean, X::AbstractMatrix, Y::AbstractMatrix) Calculate the Lie bracket between elements  X  and  Y  of the special Euclidean Lie algebra. For the matrix representation (which can be obtained using  screw_matrix ) the formula is  $[X, Y] = XY-YX$ , while in the  ArrayPartition  representation the formula reads  $[X, Y] = [(t_1, R_1), (t_2, R_2)] = (R_1 t_2 - R_2 t_1, R_1 R_2 - R_2 R_1)$ . source"},{"id":1063,"pagetitle":"Group manifold","title":"Manifolds.log_lie","ref":"/manifolds/stable/manifolds/#Manifolds.log_lie-Tuple{GroupManifold{‚Ñù, ProductManifold{‚Ñù, Tuple{TranslationGroup{ManifoldsBase.TypeParameter{Tuple{2}}, ‚Ñù}, SpecialOrthogonal{ManifoldsBase.TypeParameter{Tuple{2}}}}}, Manifolds.SemidirectProductOperation{RotationAction{LeftAction, TranslationGroup{ManifoldsBase.TypeParameter{Tuple{2}}, ‚Ñù}, SpecialOrthogonal{ManifoldsBase.TypeParameter{Tuple{2}}}}}}, Any}","content":" Manifolds.log_lie  ‚Äî  Method log_lie(G::SpecialEuclidean{TypeParameter{Tuple{2}}}, p) Compute the group logarithm of  $p = (t, R) ‚àà \\mathrm{SE}(2)$ , where  $t ‚àà \\mathrm{T}(2)$  and  $R ‚àà \\mathrm{SO}(2)$ : \\[\\log p = (b, Œ©) = (U(Œ∏)^{-1} t, \\log R),\\] where  $b ‚àà ùî±(2)$ ,  $Œ© = \\log R ‚àà ùî∞ùî¨(2)$  is the group logarithm on  $\\mathrm{SO}(2)$ , \\[U(Œ∏) = \\frac{\\sin Œ∏}{Œ∏} I_2 + \\frac{1 - \\cos Œ∏}{Œ∏^2} Œ©,\\] and  $Œ∏ = \\frac{1}{\\sqrt{2}} \\lVert Œ© \\rVert_e$  (see  norm ) is the angle of the rotation. source"},{"id":1064,"pagetitle":"Group manifold","title":"Manifolds.log_lie","ref":"/manifolds/stable/manifolds/#Manifolds.log_lie-Tuple{GroupManifold{‚Ñù, ProductManifold{‚Ñù, Tuple{TranslationGroup{ManifoldsBase.TypeParameter{Tuple{3}}, ‚Ñù}, SpecialOrthogonal{ManifoldsBase.TypeParameter{Tuple{3}}}}}, Manifolds.SemidirectProductOperation{RotationAction{LeftAction, TranslationGroup{ManifoldsBase.TypeParameter{Tuple{3}}, ‚Ñù}, SpecialOrthogonal{ManifoldsBase.TypeParameter{Tuple{3}}}}}}, Any}","content":" Manifolds.log_lie  ‚Äî  Method log_lie(G::SpecialEuclidean{TypeParameter{Tuple{3}}}, p) Compute the group logarithm of  $p = (t, R) ‚àà \\mathrm{SE}(3)$ , where  $t ‚àà \\mathrm{T}(3)$  and  $R ‚àà \\mathrm{SO}(3)$ : \\[\\log p = (b, Œ©) = (U(Œ∏)^{-1} t, \\log R),\\] where  $b ‚àà ùî±(3)$ ,  $Œ© = \\log R ‚àà ùî∞ùî¨(3)$  is the group logarithm on  $\\mathrm{SO}(3)$ , \\[U(Œ∏) = I_3 + \\frac{1 - \\cos Œ∏}{Œ∏^2} Œ© + \\frac{Œ∏ - \\sin Œ∏}{Œ∏^3} Œ©^2,\\] and  $Œ∏ = \\frac{1}{\\sqrt{2}} \\lVert Œ© \\rVert_e$  (see  norm ) is the angle of the rotation. source"},{"id":1065,"pagetitle":"Group manifold","title":"Manifolds.log_lie","ref":"/manifolds/stable/manifolds/#Manifolds.log_lie-Tuple{SpecialEuclidean, Any}","content":" Manifolds.log_lie  ‚Äî  Method log_lie(G::SpecialEuclidean, p) Compute the group logarithm of  $p = (t, R) ‚àà \\mathrm{SE}(n)$ , where  $t ‚àà \\mathrm{T}(n)$  and  $R ‚àà \\mathrm{SO}(n)$ : \\[\\log p = (b, Œ©),\\] where  $b ‚àà ùî±(n)$  and  $Œ© = \\log R ‚àà ùî∞ùî¨(n)$  is the group logarithm on  $\\mathrm{SO}(n)$ . In the  affine_matrix  representation, the group logarithm is the matrix logarithm (see  log_lie ): source"},{"id":1066,"pagetitle":"Group manifold","title":"Manifolds.screw_matrix","ref":"/manifolds/stable/manifolds/#Manifolds.screw_matrix-Tuple{SpecialEuclidean, Any}","content":" Manifolds.screw_matrix  ‚Äî  Method screw_matrix(G::SpecialEuclidean, X) -> AbstractMatrix Represent the Lie algebra element  $X ‚àà ùî∞ùî¢(n) = T_e \\mathrm{SE}(n)$  as a screw matrix. For  $X = (b, Œ©) ‚àà ùî∞ùî¢(n)$ , where  $Œ© ‚àà ùî∞ùî¨(n) = T_e \\mathrm{SO}(n)$ , the screw representation is the  $n + 1 √ó n + 1$  matrix \\[\\begin{pmatrix}\nŒ© & b \\\\\n0^\\mathrm{T} & 0\n\\end{pmatrix}.\\] This function embeds  $ùî∞ùî¢(n)$  in the general linear Lie algebra  $ùî§ùî©(n+1)$  but it's not a homomorphic embedding (see  SpecialEuclideanInGeneralLinear  for a homomorphic one). See also  affine_matrix  for matrix representations of the Lie group. source"},{"id":1067,"pagetitle":"Group manifold","title":"Manifolds.translate_diff","ref":"/manifolds/stable/manifolds/#Manifolds.translate_diff-Tuple{SpecialEuclidean, Any, Any, Any, Tuple{RightAction, RightSide}}","content":" Manifolds.translate_diff  ‚Äî  Method translate_diff(G::SpecialEuclidean, p, q, X, ::RightBackwardAction) Differential of the right action of the  SpecialEuclidean  group on itself. The formula for the rotation part is the differential of the right rotation action, while the formula for the translation part reads \\[R_q‚ãÖX_R‚ãÖt_p + X_t\\] where  $R_q$  is the rotation part of  q ,  $X_R$  is the rotation part of  X ,  $t_p$  is the translation part of  p  and  $X_t$  is the translation part of  X . source"},{"id":1068,"pagetitle":"Group manifold","title":"ManifoldsBase.embed","ref":"/manifolds/stable/manifolds/#ManifoldsBase.embed-Tuple{EmbeddedManifold{‚Ñù, <:SpecialEuclidean, <:GeneralLinear}, Any, Any}","content":" ManifoldsBase.embed  ‚Äî  Method embed(M::SpecialEuclideanInGeneralLinear, p, X) Embed the tangent vector X at point  p  on  SpecialEuclidean  in the  GeneralLinear  group. Point  p  can use any representation valid for  SpecialEuclidean . The embedding is similar from the one defined by  screw_matrix  but the translation part is multiplied by inverse of the rotation part. source"},{"id":1069,"pagetitle":"Group manifold","title":"ManifoldsBase.embed","ref":"/manifolds/stable/manifolds/#ManifoldsBase.embed-Tuple{EmbeddedManifold{‚Ñù, <:SpecialEuclidean, <:GeneralLinear}, Any}","content":" ManifoldsBase.embed  ‚Äî  Method embed(M::SpecialEuclideanInGeneralLinear, p) Embed the point  p  on  SpecialEuclidean  in the  GeneralLinear  group. The embedding is calculated using  affine_matrix . source"},{"id":1070,"pagetitle":"Group manifold","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{EmbeddedManifold{‚Ñù, <:SpecialEuclidean, <:GeneralLinear}, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::SpecialEuclideanInGeneralLinear, p, X) Project tangent vector  X  at point  p  in  GeneralLinear  to the  SpecialEuclidean  Lie algebra. This reverses the transformation performed by  embed source"},{"id":1071,"pagetitle":"Group manifold","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{EmbeddedManifold{‚Ñù, <:SpecialEuclidean, <:GeneralLinear}, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::SpecialEuclideanInGeneralLinear, p) Project point  p  in  GeneralLinear  to the  SpecialEuclidean  group. This is performed by extracting the rotation and translation part as in  affine_matrix . source"},{"id":1072,"pagetitle":"Group manifold","title":"Special linear group","ref":"/manifolds/stable/manifolds/#Special-linear-group","content":" Special linear group"},{"id":1073,"pagetitle":"Group manifold","title":"Manifolds.SpecialLinear","ref":"/manifolds/stable/manifolds/#Manifolds.SpecialLinear","content":" Manifolds.SpecialLinear  ‚Äî  Type SpecialLinear{T,ùîΩ} <: AbstractDecoratorManifold The special linear group  $\\mathrm{SL}(n,ùîΩ)$  that is, the group of all invertible matrices with unit determinant in  $ùîΩ^{n√ón}$ . The Lie algebra  $ùî∞ùî©(n, ùîΩ) = T_e \\mathrm{SL}(n,ùîΩ)$  is the set of all matrices in  $ùîΩ^{n√ón}$  with trace of zero. By default, tangent vectors  $X_p ‚àà T_p \\mathrm{SL}(n,ùîΩ)$  for  $p ‚àà \\mathrm{SL}(n,ùîΩ)$  are represented with their corresponding Lie algebra vector  $X_e = p^{-1}X_p ‚àà ùî∞ùî©(n, ùîΩ)$ . The default metric is the same left- $\\mathrm{GL}(n)$ -right- $\\mathrm{O}(n)$ -invariant metric used for  GeneralLinear(n, ùîΩ) . The resulting geodesic on  $\\mathrm{GL}(n,ùîΩ)$  emanating from an element of  $\\mathrm{SL}(n,ùîΩ)$  in the direction of an element of  $ùî∞ùî©(n, ùîΩ)$  is a closed subgroup of  $\\mathrm{SL}(n,ùîΩ)$ . As a result, most metric functions forward to  GeneralLinear . source"},{"id":1074,"pagetitle":"Group manifold","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{SpecialLinear, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(G::SpecialLinear, p, X) Orthogonally project  $X ‚àà ùîΩ^{n√ón}$  onto the tangent space of  $p$  to the  SpecialLinear $G = \\mathrm{SL}(n, ùîΩ)$ . The formula reads \\[\\operatorname{proj}_{p}\n    = (\\mathrm{d}L_p)_e ‚àò \\operatorname{proj}_{ùî∞ùî©(n, ùîΩ)} ‚àò (\\mathrm{d}L_p^{-1})_p\n    \\colon X ‚Ü¶ X - \\frac{\\operatorname{tr}(X)}{n} I,\\] where the last expression uses the tangent space representation as the Lie algebra. source"},{"id":1075,"pagetitle":"Group manifold","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{SpecialLinear, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(G::SpecialLinear, p) Project  $p ‚àà \\mathrm{GL}(n, ùîΩ)$  to the  SpecialLinear  group  $G=\\mathrm{SL}(n, ùîΩ)$ . Given the singular value decomposition of  $p$ , written  $p = U S V^\\mathrm{H}$ , the formula for the projection is \\[\\operatorname{proj}_{\\mathrm{SL}(n, ùîΩ)}(p) = U S D V^\\mathrm{H},\\] where \\[D_{ij} = Œ¥_{ij} \\begin{cases}\n    1            & \\text{ if } i ‚â† n \\\\\n    \\det(p)^{-1} & \\text{ if } i = n\n\\end{cases}.\\] source"},{"id":1076,"pagetitle":"Group manifold","title":"Translation group","ref":"/manifolds/stable/manifolds/#Translation-group","content":" Translation group"},{"id":1077,"pagetitle":"Group manifold","title":"Manifolds.TranslationGroup","ref":"/manifolds/stable/manifolds/#Manifolds.TranslationGroup","content":" Manifolds.TranslationGroup  ‚Äî  Type TranslationGroup{T,ùîΩ} <: GroupManifold{Euclidean{T,ùîΩ},AdditionOperation} Translation group  $\\mathrm{T}(n)$  represented by translation arrays. Constructor TranslationGroup(n‚ÇÅ,...,n·µ¢; field=ùîΩ, parameter::Symbol=:type) Generate the translation group on  $ùîΩ^{n‚ÇÅ,‚Ä¶,n·µ¢}$  =  Euclidean(n‚ÇÅ,...,n·µ¢; field=ùîΩ) , which is isomorphic to the group itself. source"},{"id":1078,"pagetitle":"Group manifold","title":"Metrics on groups","ref":"/manifolds/stable/manifolds/#Metrics-on-groups","content":" Metrics on groups Lie groups by default typically forward all metric-related operations like exponential or logarithmic map to the underlying manifold, for example  SpecialOrthogonal  uses methods for  Rotations  (which is, incidentally, bi-invariant), or  SpecialEuclidean  uses product metric of the translation and rotation parts (which is not invariant under group operation). It is, however, possible to change the metric used by a group by wrapping it in a  MetricManifold  decorator."},{"id":1079,"pagetitle":"Group manifold","title":"Invariant metrics","ref":"/manifolds/stable/manifolds/#Invariant-metrics","content":" Invariant metrics"},{"id":1080,"pagetitle":"Group manifold","title":"Manifolds.LeftInvariantMetric","ref":"/manifolds/stable/manifolds/#Manifolds.LeftInvariantMetric","content":" Manifolds.LeftInvariantMetric  ‚Äî  Type LeftInvariantMetric <: AbstractMetric An  AbstractMetric  that changes the metric of a Lie group to the left-invariant metric obtained by left-translations to the identity. Adds the  HasLeftInvariantMetric  trait. source"},{"id":1081,"pagetitle":"Group manifold","title":"Manifolds.RightInvariantMetric","ref":"/manifolds/stable/manifolds/#Manifolds.RightInvariantMetric","content":" Manifolds.RightInvariantMetric  ‚Äî  Type RightInvariantMetric <: AbstractMetric An  AbstractMetric  that changes the metric of a Lie group to the right-invariant metric obtained by right-translations to the identity. Adds the  HasRightInvariantMetric  trait. source"},{"id":1082,"pagetitle":"Group manifold","title":"Manifolds.direction","ref":"/manifolds/stable/manifolds/#Manifolds.direction-Tuple{AbstractDecoratorManifold}","content":" Manifolds.direction  ‚Äî  Method direction(::AbstractDecoratorManifold) -> AD Get the direction of the action a certain Lie group with its implicit metric has. source"},{"id":1083,"pagetitle":"Group manifold","title":"Manifolds.has_approx_invariant_metric","ref":"/manifolds/stable/manifolds/#Manifolds.has_approx_invariant_metric-Tuple{AbstractDecoratorManifold, Any, Any, Any, Any, Tuple{ActionDirection, Manifolds.GroupActionSide}}","content":" Manifolds.has_approx_invariant_metric  ‚Äî  Method has_approx_invariant_metric(\n    G::AbstractDecoratorManifold,\n    p,\n    X,\n    Y,\n    qs::AbstractVector,\n    conv::ActionDirectionAndSide = LeftForwardAction();\n    kwargs...,\n) -> Bool Check whether the metric on the group  $\\mathcal{G}$  is (approximately) invariant using a set of predefined points. Namely, for  $p ‚àà \\mathcal{G}$ ,  $X,Y ‚àà T_p \\mathcal{G}$ , a metric  $g$ , and a translation map  $œÑ_q$  in the specified direction, check for each  $q ‚àà \\mathcal{G}$  that the following condition holds: \\[g_p(X, Y) ‚âà g_{œÑ_q p}((\\mathrm{d}œÑ_q)_p X, (\\mathrm{d}œÑ_q)_p Y).\\] This is necessary but not sufficient for invariance. Optionally,  kwargs  passed to  isapprox  may be provided. source"},{"id":1084,"pagetitle":"Group manifold","title":"Cartan-Schouten connections","ref":"/manifolds/stable/manifolds/#Cartan-Schouten-connections","content":" Cartan-Schouten connections"},{"id":1085,"pagetitle":"Group manifold","title":"Manifolds.AbstractCartanSchoutenConnection","ref":"/manifolds/stable/manifolds/#Manifolds.AbstractCartanSchoutenConnection","content":" Manifolds.AbstractCartanSchoutenConnection  ‚Äî  Type AbstractCartanSchoutenConnection Abstract type for Cartan-Schouten connections, that is connections whose geodesics going through group identity are one-parameter subgroups. See [ PL20 ] for details. source"},{"id":1086,"pagetitle":"Group manifold","title":"Manifolds.CartanSchoutenMinus","ref":"/manifolds/stable/manifolds/#Manifolds.CartanSchoutenMinus","content":" Manifolds.CartanSchoutenMinus  ‚Äî  Type CartanSchoutenMinus The unique Cartan-Schouten connection such that all left-invariant vector fields are globally defined by their value at identity. It is biinvariant with respect to the group operation. source"},{"id":1087,"pagetitle":"Group manifold","title":"Manifolds.CartanSchoutenPlus","ref":"/manifolds/stable/manifolds/#Manifolds.CartanSchoutenPlus","content":" Manifolds.CartanSchoutenPlus  ‚Äî  Type CartanSchoutenPlus The unique Cartan-Schouten connection such that all right-invariant vector fields are globally defined by their value at identity. It is biinvariant with respect to the group operation. source"},{"id":1088,"pagetitle":"Group manifold","title":"Manifolds.CartanSchoutenZero","ref":"/manifolds/stable/manifolds/#Manifolds.CartanSchoutenZero","content":" Manifolds.CartanSchoutenZero  ‚Äî  Type CartanSchoutenZero The unique torsion-free Cartan-Schouten connection. It is biinvariant with respect to the group operation. If the metric on the underlying manifold is bi-invariant then it is equivalent to the Levi-Civita connection of that metric. source"},{"id":1089,"pagetitle":"Group manifold","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Union{Tuple{ùîΩ}, Tuple{ConnectionManifold{ùîΩ, <:AbstractDecoratorManifold{ùîΩ}, <:AbstractCartanSchoutenConnection}, Any, Any}} where ùîΩ","content":" Base.exp  ‚Äî  Method exp(M::ConnectionManifold{ùîΩ,<:AbstractDecoratorManifold{ùîΩ},<:AbstractCartanSchoutenConnection}, p, X) where {ùîΩ} Compute the exponential map on the  ConnectionManifold M  with a Cartan-Schouten connection. See Sections 5.3.2 and 5.3.3 of [ PL20 ] for details. source"},{"id":1090,"pagetitle":"Group manifold","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Union{Tuple{ùîΩ}, Tuple{ConnectionManifold{ùîΩ, <:AbstractDecoratorManifold{ùîΩ}, <:AbstractCartanSchoutenConnection}, Any, Any}} where ùîΩ","content":" Base.log  ‚Äî  Method log(M::ConnectionManifold{ùîΩ,<:AbstractDecoratorManifold{ùîΩ},<:AbstractCartanSchoutenConnection}, p, q) where {ùîΩ} Compute the logarithmic map on the  ConnectionManifold M  with a Cartan-Schouten connection. See Sections 5.3.2 and 5.3.3 of [ PL20 ] for details. source"},{"id":1091,"pagetitle":"Group manifold","title":"ManifoldsBase.parallel_transport_direction","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_direction-Tuple{ConnectionManifold{ùîΩ, M, CartanSchoutenZero} where {ùîΩ, M}, Identity, Any, Any}","content":" ManifoldsBase.parallel_transport_direction  ‚Äî  Method parallel_transport_direction(M::CartanSchoutenZeroGroup, ::Identity, X, d) Transport tangent vector  X  at identity on the group manifold with the  CartanSchoutenZero  connection in the direction  d . See [ PL20 ] for details. source"},{"id":1092,"pagetitle":"Group manifold","title":"ManifoldsBase.parallel_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_to-Tuple{ConnectionManifold{ùîΩ, M, CartanSchoutenMinus} where {ùîΩ, M}, Any, Any, Any}","content":" ManifoldsBase.parallel_transport_to  ‚Äî  Method parallel_transport_to(M::CartanSchoutenMinusGroup, p, X, q) Transport tangent vector  X  at point  p  on the group manifold  M  with the  CartanSchoutenMinus  connection to point  q . See [ PL20 ] for details. source"},{"id":1093,"pagetitle":"Group manifold","title":"ManifoldsBase.parallel_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_to-Tuple{ConnectionManifold{ùîΩ, M, CartanSchoutenPlus} where {ùîΩ, M}, Any, Any, Any}","content":" ManifoldsBase.parallel_transport_to  ‚Äî  Method vector_transport_to(M::CartanSchoutenPlusGroup, p, X, q) Transport tangent vector  X  at point  p  on the group manifold  M  with the  CartanSchoutenPlus  connection to point  q . See [ PL20 ] for details. source"},{"id":1094,"pagetitle":"Group manifold","title":"ManifoldsBase.parallel_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_to-Tuple{ConnectionManifold{ùîΩ, M, CartanSchoutenZero} where {ùîΩ, M}, Identity, Any, Any}","content":" ManifoldsBase.parallel_transport_to  ‚Äî  Method parallel_transport_to(M::CartanSchoutenZeroGroup, p::Identity, X, q) Transport vector  X  at identity of group  M  equipped with the  CartanSchoutenZero  connection to point  q  using parallel transport. source"},{"id":1097,"pagetitle":"Hamiltonian","title":"Hamiltonian matrices","ref":"/manifolds/stable/manifolds/#Hamiltonian-matrices","content":" Hamiltonian matrices"},{"id":1098,"pagetitle":"Hamiltonian","title":"Manifolds.Hamiltonian","ref":"/manifolds/stable/manifolds/#Manifolds.Hamiltonian","content":" Manifolds.Hamiltonian  ‚Äî  Type Hamiltonian{T,S<:AbstractMatrix{<:T}} <: AbstractMatrix{T} A type to store a Hamiltonian matrix, that is a square matrix for which  $A^+ = -A$  where \\[A^+ = J_{2n}A^{\\mathrm{T}}J_{2n}, \\qquad J_{2n} \\begin{pmatrix} 0 & I_n\\\\-I_n & 0 \\end{pmatrix},\\] and  $I_n$  denotes the  $n√ón$ source"},{"id":1099,"pagetitle":"Hamiltonian","title":"Manifolds.HamiltonianMatrices","ref":"/manifolds/stable/manifolds/#Manifolds.HamiltonianMatrices","content":" Manifolds.HamiltonianMatrices  ‚Äî  Type HamiltonianMatrices{T,ùîΩ} <: AbstractDecoratorManifold{ùîΩ} The  AbstractManifold  consisting of (real-valued) hamiltonian matrices of size  $n√ón$ , i.e. the set \\[\\mathfrak{sp}(2n,ùîΩ) = \\bigl\\{p  ‚àà ùîΩ^{2n√ó2n}\\ \\big|\\ p^+ = p \\bigr\\},\\] where  $‚ãÖ^{+}$  denotes the  symplectic_inverse , and  $ùîΩ ‚àà \\{ ‚Ñù, ‚ÑÇ\\}$ . Though it is slightly redundant, usually the matrices are stored as  $2n√ó2n$  arrays. The symbol  $\\mathfak{sp}$  refers to the main usage within  Manifolds.jl  that is the Lie algebra to the  SymplecticMatrices  interpreted as a Lie group with the matrix multiplication as group operation. Constructor HamiltonianMatrices(2n::Int, field::AbstractNumbers=‚Ñù) Generate the manifold of  $2n√ó2n$  Hamiltonian matrices. source"},{"id":1100,"pagetitle":"Hamiltonian","title":"Base.:^","ref":"/manifolds/stable/manifolds/#Base.:^-Tuple{Hamiltonian, typeof(+)}","content":" Base.:^  ‚Äî  Method ^(A::Hamilonian, ::typeof(+)) Compute the  symplectic_inverse  of a Hamiltonian (A) source"},{"id":1101,"pagetitle":"Hamiltonian","title":"Base.rand","ref":"/manifolds/stable/manifolds/#Base.rand-Tuple{HamiltonianMatrices}","content":" Base.rand  ‚Äî  Method pX = rand(M::HamiltonianMatrices; œÉ::Real=1.0, vector_at=nothing)\nrand!(M::HamiltonianMatrices, pX; œÉ::Real=1.0, vector_at=nothing) Generate a random Hamiltonian matrix. Since these are a submanifold of  $‚Ñù^{2n√ó2n}$ , the same method applies for points and tangent vectors. This can also be done in-place of  pX . The construction is based on generating one normally-distributed  $n√ón$  matrix  $A$  and two symmetric  $n√ón$  matrices  $B, C$  which are then stacked: \\[p = \\begin{pmatrix} A & B\\\\ C & -A^{\\mathrm{T}} \\end{pmatrix}\\] source"},{"id":1102,"pagetitle":"Hamiltonian","title":"Manifolds.is_hamiltonian","ref":"/manifolds/stable/manifolds/#Manifolds.is_hamiltonian-Tuple{AbstractMatrix}","content":" Manifolds.is_hamiltonian  ‚Äî  Method is_hamiltonian(A::AbstractMatrix; kwargs...) Test whether a matrix  A  is hamiltonian. The test consists of verifying whether \\[A^+ = -A\\] where  $A^+$  denotes the  symplectic_inverse  of  A . The passed keyword arguments are passed on to  isapprox  check within source"},{"id":1103,"pagetitle":"Hamiltonian","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{HamiltonianMatrices, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::HamiltonianMatrices{n,ùîΩ}, p; kwargs...) Check whether  p  is a valid manifold point on the  HamiltonianMatrices M , i.e. whether  p is_hamiltonian . The tolerance for the test of  p  can be set using  kwargs... . source"},{"id":1104,"pagetitle":"Hamiltonian","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{HamiltonianMatrices, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::HamiltonianMatrices{n,ùîΩ}, p, X; kwargs... ) Check whether  X  is a tangent vector to manifold point  p  on the  HamiltonianMatrices M , i.e.  X  has to be a Hamiltonian matrix The tolerance for  is_hamiltonian X  can be set using  kwargs... . source"},{"id":1105,"pagetitle":"Hamiltonian","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{HamiltonianMatrices}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::HamiltonianMatrices) Return true.  HamiltonianMatrices  is a flat manifold. source"},{"id":1108,"pagetitle":"Hyperbolic space","title":"Hyperbolic space","ref":"/manifolds/stable/manifolds/#HyperbolicSpace","content":" Hyperbolic space The hyperbolic space can be represented in three different models. Hyperboloid  which is the default model, i.e. is used when using arbitrary array types for points and tangent vectors Poincar√© ball  with separate types for points and tangent vectors and a  visualization  for the two-dimensional case Poincar√© half space  with separate types for points and tangent vectors and a  visualization  for the two-dimensional cae. In the following the common functions are collected. A function in this general section uses vectors interpreted as if in the  hyperboloid model , and other representations usually just convert to this representation to use these general functions."},{"id":1109,"pagetitle":"Hyperbolic space","title":"Manifolds.Hyperbolic","ref":"/manifolds/stable/manifolds/#Manifolds.Hyperbolic","content":" Manifolds.Hyperbolic  ‚Äî  Type Hyperbolic{T} <: AbstractDecoratorManifold{‚Ñù} The hyperbolic space  $\\mathcal H^n$  represented by  $n+1$ -Tuples, i.e. embedded in the  Lorentz ian manifold equipped with the  MinkowskiMetric $‚ü®‚ãÖ,‚ãÖ‚ü©_{\\mathrm{M}}$ . The space is defined as \\[\\mathcal H^n = \\Bigl\\{p ‚àà ‚Ñù^{n+1}\\ \\Big|\\ ‚ü®p,p‚ü©_{\\mathrm{M}}= -p_{n+1}^2\n  + \\displaystyle\\sum_{k=1}^n p_k^2 = -1, p_{n+1} > 0\\Bigr\\},.\\] The tangent space  $T_p \\mathcal H^n$  is given by \\[T_p \\mathcal H^n := \\bigl\\{\nX ‚àà ‚Ñù^{n+1} : ‚ü®p,X‚ü©_{\\mathrm{M}} = 0\n\\bigr\\}.\\] Note that while the  MinkowskiMetric  renders the  Lorentz  manifold (only) pseudo-Riemannian, on the tangent bundle of the Hyperbolic space it induces a Riemannian metric. The corresponding sectional curvature is  $-1$ . If  p  and  X  are  Vector s of length  n+1  they are assumed to be a  HyperboloidPoint  and a  HyperboloidTVector , respectively Other models are the Poincar√© ball model, see  PoincareBallPoint  and  PoincareBallTVector , respectiely and the Poincar√© half space model, see  PoincareHalfSpacePoint  and  PoincareHalfSpaceTVector , respectively. Constructor Hyperbolic(n::Int; parameter::Symbol=:type) Generate the Hyperbolic manifold of dimension  n . source"},{"id":1110,"pagetitle":"Hyperbolic space","title":"Manifolds.HyperboloidPoint","ref":"/manifolds/stable/manifolds/#Manifolds.HyperboloidPoint","content":" Manifolds.HyperboloidPoint  ‚Äî  Type HyperboloidPoint <: AbstractManifoldPoint In the Hyperboloid model of the  Hyperbolic $\\mathcal H^n$  points are represented as vectors in  $‚Ñù^{n+1}$  with  MinkowskiMetric  equal to  $-1$ . This representation is the default, i.e.  AbstractVector s are assumed to have this repesentation. source"},{"id":1111,"pagetitle":"Hyperbolic space","title":"Manifolds.HyperboloidTVector","ref":"/manifolds/stable/manifolds/#Manifolds.HyperboloidTVector","content":" Manifolds.HyperboloidTVector  ‚Äî  Type HyperboloidTVector <: TVector In the Hyperboloid model of the  Hyperbolic $\\mathcal H^n$  tangent vctors are represented as vectors in  $‚Ñù^{n+1}$  with  MinkowskiMetric $‚ü®p,X‚ü©_{\\mathrm{M}}=0$  to their base point  $p$ . This representation is the default, i.e. vectors are assumed to have this repesentation. source"},{"id":1112,"pagetitle":"Hyperbolic space","title":"Manifolds.PoincareBallPoint","ref":"/manifolds/stable/manifolds/#Manifolds.PoincareBallPoint","content":" Manifolds.PoincareBallPoint  ‚Äî  Type PoincareBallPoint <: AbstractManifoldPoint A point on the  Hyperbolic  manifold  $\\mathcal H^n$  can be represented as a vector of norm less than one in  $\\mathbb R^n$ . source"},{"id":1113,"pagetitle":"Hyperbolic space","title":"Manifolds.PoincareBallTVector","ref":"/manifolds/stable/manifolds/#Manifolds.PoincareBallTVector","content":" Manifolds.PoincareBallTVector  ‚Äî  Type PoincareBallTVector <: TVector In the Poincar√© ball model of the  Hyperbolic $\\mathcal H^n$  tangent vectors are represented as vectors in  $‚Ñù^{n}$ . source"},{"id":1114,"pagetitle":"Hyperbolic space","title":"Manifolds.PoincareHalfSpacePoint","ref":"/manifolds/stable/manifolds/#Manifolds.PoincareHalfSpacePoint","content":" Manifolds.PoincareHalfSpacePoint  ‚Äî  Type PoincareHalfSpacePoint <: AbstractManifoldPoint A point on the  Hyperbolic  manifold  $\\mathcal H^n$  can be represented as a vector in the half plane, i.e.  $x ‚àà ‚Ñù^n$  with  $x_d > 0$ . source"},{"id":1115,"pagetitle":"Hyperbolic space","title":"Manifolds.PoincareHalfSpaceTVector","ref":"/manifolds/stable/manifolds/#Manifolds.PoincareHalfSpaceTVector","content":" Manifolds.PoincareHalfSpaceTVector  ‚Äî  Type PoincareHalfPlaneTVector <: TVector In the Poincar√© half plane model of the  Hyperbolic $\\mathcal H^n$  tangent vectors are represented as vectors in  $‚Ñù^{n}$ . source"},{"id":1116,"pagetitle":"Hyperbolic space","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{Hyperbolic, Vararg{Any}}","content":" Base.exp  ‚Äî  Method exp(M::Hyperbolic, p, X) Compute the exponential map on the  Hyperbolic  space  $\\mathcal H^n$  emanating from  p  towards  X . The formula reads \\[\\exp_p X = \\cosh(\\sqrt{‚ü®X,X‚ü©_{\\mathrm{M}}})p\n+ \\sinh(\\sqrt{‚ü®X,X‚ü©_{\\mathrm{M}}})\\frac{X}{\\sqrt{‚ü®X,X‚ü©_{\\mathrm{M}}}},\\] where  $‚ü®‚ãÖ,‚ãÖ‚ü©_{\\mathrm{M}}$  denotes the  MinkowskiMetric  on the embedding, the  Lorentz ian manifold. source"},{"id":1117,"pagetitle":"Hyperbolic space","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{Hyperbolic, Vararg{Any}}","content":" Base.log  ‚Äî  Method log(M::Hyperbolic, p, q) Compute the logarithmic map on the  Hyperbolic  space  $\\mathcal H^n$ , the tangent vector representing the  geodesic  starting from  p  reaches  q  after time 1. The formula reads for  $p ‚â† q$ \\[\\log_p q = d_{\\mathcal H^n}(p,q)\n\\frac{q-‚ü®p,q‚ü©_{\\mathrm{M}} p}{\\lVert q-‚ü®p,q‚ü©_{\\mathrm{M}} p \\rVert_2},\\] where  $‚ü®‚ãÖ,‚ãÖ‚ü©_{\\mathrm{M}}$  denotes the  MinkowskiMetric  on the embedding, the  Lorentz ian manifold. For  $p=q$  the logarihmic map is equal to the zero vector. source"},{"id":1118,"pagetitle":"Hyperbolic space","title":"Manifolds.manifold_volume","ref":"/manifolds/stable/manifolds/#Manifolds.manifold_volume-Tuple{Hyperbolic}","content":" Manifolds.manifold_volume  ‚Äî  Method manifold_dimension(M::Hyperbolic) Return the volume of the hyperbolic space manifold  $\\mathcal H^n$ , i.e. infinity. source"},{"id":1119,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{Hyperbolic, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::Hyperbolic, p; kwargs...) Check whether  p  is a valid point on the  Hyperbolic M . For the  HyperboloidPoint  or plain vectors this means that,  p  is a vector of length  $n+1$  with inner product in the embedding of -1, see  MinkowskiMetric . The tolerance for the last test can be set using the  kwargs... . For the  PoincareBallPoint  a valid point is a vector  $p ‚àà ‚Ñù^n$  with a norm stricly less than 1. For the  PoincareHalfSpacePoint  a valid point is a vector from  $p ‚àà ‚Ñù^n$  with a positive last entry, i.e.  $p_n>0$ source"},{"id":1120,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{Hyperbolic, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::Hyperbolic, p, X; kwargs... ) Check whether  X  is a tangent vector to  p  on the  Hyperbolic M , i.e. after  check_point (M,p) ,  X  has to be of the same dimension as  p . The tolerance for the last test can be set using the  kwargs... . For a the hyperboloid model or vectors,  X  has to be  orthogonal to  p  with respect to the inner product from the embedding, see  MinkowskiMetric . For a the Poincar√© ball as well as the Poincar√© half plane model,  X  has to be a vector from  $‚Ñù^{n}$ . source"},{"id":1121,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.injectivity_radius","ref":"/manifolds/stable/manifolds/#ManifoldsBase.injectivity_radius-Tuple{Hyperbolic}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(M::Hyperbolic)\ninjectivity_radius(M::Hyperbolic, p) Return the injectivity radius on the  Hyperbolic , which is  $‚àû$ . source"},{"id":1122,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{Hyperbolic}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::Hyperbolic) Return false.  Hyperbolic  is not a flat manifold. source"},{"id":1123,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{Hyperbolic}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::Hyperbolic) Return the dimension of the hyperbolic space manifold  $\\mathcal H^n$ , i.e.  $\\dim(\\mathcal H^n) = n$ . source"},{"id":1124,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.parallel_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_to-Tuple{Hyperbolic, Any, Any, Any}","content":" ManifoldsBase.parallel_transport_to  ‚Äî  Method parallel_transport_to(M::Hyperbolic, p, X, q) Compute the paralllel transport of the  X  from the tangent space at  p  on the  Hyperbolic  space  $\\mathcal H^n$  to the tangent at  q  along the  geodesic  connecting  p  and  q . The formula reads \\[\\mathcal P_{q‚Üêp}X = X - \\frac{‚ü®\\log_p q,X‚ü©_p}{d^2_{\\mathcal H^n}(p,q)}\n\\bigl(\\log_p q + \\log_qp \\bigr),\\] where  $‚ü®‚ãÖ,‚ãÖ‚ü©_p$  denotes the inner product in the tangent space at  p . source"},{"id":1125,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Hyperbolic, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::Hyperbolic, p, X) Perform an orthogonal projection with respect to the Minkowski inner product of  X  onto the tangent space at  p  of the  Hyperbolic  space  M . The formula reads \\[Y = X + ‚ü®p,X‚ü©_{\\mathrm{M}} p,\\] where  $‚ü®‚ãÖ, ‚ãÖ‚ü©_{\\mathrm{M}}$  denotes the  MinkowskiMetric  on the embedding, the  Lorentz ian manifold. Note Projection is only available for the (default)  HyperboloidTVector  representation, the others don't have such an embedding source"},{"id":1126,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.riemann_tensor","ref":"/manifolds/stable/manifolds/#ManifoldsBase.riemann_tensor-Tuple{Hyperbolic, Vararg{Any, 4}}","content":" ManifoldsBase.riemann_tensor  ‚Äî  Method riemann_tensor(M::Hyperbolic{n}, p, X, Y, Z) Compute the Riemann tensor  $R(X,Y)Z$  at point  p  on  Hyperbolic M . The formula reads (see e.g., [ Lee19 ] Proposition 8.36) \\[R(X,Y)Z = - (\\langle Z, Y \\rangle X - \\langle Z, X \\rangle Y)\\] source"},{"id":1127,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.sectional_curvature","ref":"/manifolds/stable/manifolds/#ManifoldsBase.sectional_curvature-Tuple{Hyperbolic, Any, Any, Any}","content":" ManifoldsBase.sectional_curvature  ‚Äî  Method sectional_curvature(::Hyperbolic, p, X, Y) Sectional curvature of  Hyperbolic M  is -1 if dimension is > 1 and 0 otherwise. source"},{"id":1128,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.sectional_curvature_max","ref":"/manifolds/stable/manifolds/#ManifoldsBase.sectional_curvature_max-Tuple{Hyperbolic}","content":" ManifoldsBase.sectional_curvature_max  ‚Äî  Method sectional_curvature_max(::Hyperbolic) Sectional curvature of  Hyperbolic M  is -1 if dimension is > 1 and 0 otherwise. source"},{"id":1129,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.sectional_curvature_min","ref":"/manifolds/stable/manifolds/#ManifoldsBase.sectional_curvature_min-Tuple{Hyperbolic}","content":" ManifoldsBase.sectional_curvature_min  ‚Äî  Method sectional_curvature_min(M::Hyperbolic) Sectional curvature of  Hyperbolic M  is -1 if dimension is > 1 and 0 otherwise. source"},{"id":1130,"pagetitle":"Hyperbolic space","title":"Statistics.mean","ref":"/manifolds/stable/manifolds/#Statistics.mean-Tuple{Hyperbolic, Vararg{Any}}","content":" Statistics.mean  ‚Äî  Method mean(\n    M::Hyperbolic,\n    x::AbstractVector,\n    [w::AbstractWeights,]\n    method = CyclicProximalPointEstimation();\n    kwargs...,\n) Compute the Riemannian  mean  of  x  on the  Hyperbolic  space using  CyclicProximalPointEstimation . source"},{"id":1131,"pagetitle":"Hyperbolic space","title":"hyperboloid model","ref":"/manifolds/stable/manifolds/#hyperboloid_model","content":" hyperboloid model"},{"id":1132,"pagetitle":"Hyperbolic space","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{HyperboloidPoint}, PoincareBallPoint}","content":" Base.convert  ‚Äî  Method convert(::Type{HyperboloidPoint}, p::PoincareBallPoint)\nconvert(::Type{AbstractVector}, p::PoincareBallPoint) convert a point  PoincareBallPoint x  (from  $‚Ñù^n$ ) from the Poincar√© ball model of the  Hyperbolic  manifold  $\\mathcal H^n$  to a  HyperboloidPoint $œÄ(p) ‚àà ‚Ñù^{n+1}$ . The isometry is defined by \\[œÄ(p) = \\frac{1}{1-\\lVert p \\rVert^2}\n\\begin{pmatrix}2p_1\\\\‚ãÆ\\\\2p_n\\\\1+\\lVert p \\rVert^2\\end{pmatrix}\\] Note that this is also used, when the type to convert to is a vector. source"},{"id":1133,"pagetitle":"Hyperbolic space","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{HyperboloidPoint}, PoincareHalfSpacePoint}","content":" Base.convert  ‚Äî  Method convert(::Type{HyperboloidPoint}, p::PoincareHalfSpacePoint)\nconvert(::Type{AbstractVector}, p::PoincareHalfSpacePoint) convert a point  PoincareHalfSpacePoint p  (from  $‚Ñù^n$ ) from the Poincar√© half plane model of the  Hyperbolic  manifold  $\\mathcal H^n$  to a  HyperboloidPoint $œÄ(p) ‚àà ‚Ñù^{n+1}$ . This is done in two steps, namely transforming it to a Poincare ball point and from there further on to a Hyperboloid point. source"},{"id":1134,"pagetitle":"Hyperbolic space","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{HyperboloidTVector}, PoincareBallPoint, PoincareBallTVector}","content":" Base.convert  ‚Äî  Method convert(::Type{HyperboloidTVector}, p::PoincareBallPoint, X::PoincareBallTVector)\nconvert(::Type{AbstractVector}, p::PoincareBallPoint, X::PoincareBallTVector) Convert the  PoincareBallTVector X  from the tangent space at  p  to a  HyperboloidTVector  by computing the push forward of the isometric map, cf.  convert(::Type{HyperboloidPoint}, p::PoincareBallPoint) . The push forward  $œÄ_*(p)$  maps from  $‚Ñù^n$  to a subspace of  $‚Ñù^{n+1}$ , the formula reads \\[œÄ_*(p)[X] = \\begin{pmatrix}\n    \\frac{2X_1}{1-\\lVert p \\rVert^2} + \\frac{4}{(1-\\lVert p \\rVert^2)^2}‚ü®X,p‚ü©p_1\\\\\n    ‚ãÆ\\\\\n    \\frac{2X_n}{1-\\lVert p \\rVert^2} + \\frac{4}{(1-\\lVert p \\rVert^2)^2}‚ü®X,p‚ü©p_n\\\\\n    \\frac{4}{(1-\\lVert p \\rVert^2)^2}‚ü®X,p‚ü©\n\\end{pmatrix}.\\] source"},{"id":1135,"pagetitle":"Hyperbolic space","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{HyperboloidTVector}, PoincareHalfSpacePoint, PoincareHalfSpaceTVector}","content":" Base.convert  ‚Äî  Method convert(::Type{HyperboloidTVector}, p::PoincareHalfSpacePoint, X::PoincareHalfSpaceTVector)\nconvert(::Type{AbstractVector}, p::PoincareHalfSpacePoint, X::PoincareHalfSpaceTVector) convert a point  PoincareHalfSpaceTVector X  (from  $‚Ñù^n$ ) at  p  from the Poincar√© half plane model of the  Hyperbolic  manifold  $\\mathcal H^n$  to a  HyperboloidTVector $œÄ(p) ‚àà ‚Ñù^{n+1}$ . This is done in two steps, namely transforming it to a Poincare ball point and from there further on to a Hyperboloid point. source"},{"id":1136,"pagetitle":"Hyperbolic space","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{Tuple{HyperboloidPoint, HyperboloidTVector}}, Tuple{PoincareBallPoint, PoincareBallTVector}}","content":" Base.convert  ‚Äî  Method convert(\n    ::Type{Tuple{HyperboloidPoint,HyperboloidTVector}}.\n    (p,X)::Tuple{PoincareBallPoint,PoincareBallTVector}\n)\nconvert(\n    ::Type{Tuple{P,T}},\n    (p, X)::Tuple{PoincareBallPoint,PoincareBallTVector},\n) where {P<:AbstractVector, T <: AbstractVector} Convert a  PoincareBallPoint p  and a  PoincareBallTVector X  to a  HyperboloidPoint  and a  HyperboloidTVector  simultaneously, see  convert(::Type{HyperboloidPoint}, ::PoincareBallPoint)  and  convert(::Type{HyperboloidTVector}, ::PoincareBallPoint, ::PoincareBallTVector)  for the formulae. source"},{"id":1137,"pagetitle":"Hyperbolic space","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{Tuple{HyperboloidPoint, HyperboloidTVector}}, Tuple{PoincareHalfSpacePoint, PoincareHalfSpaceTVector}}","content":" Base.convert  ‚Äî  Method convert(\n    ::Type{Tuple{HyperboloidPoint,HyperboloidTVector},\n    (p,X)::Tuple{PoincareHalfSpacePoint, PoincareHalfSpaceTVector}\n)\nconvert(\n    ::Type{Tuple{T,T},\n    (p,X)::Tuple{PoincareHalfSpacePoint, PoincareHalfSpaceTVector}\n) where {T<:AbstractVector} convert a point  PoincareHalfSpaceTVector X  (from  $‚Ñù^n$ ) at  p  from the Poincar√© half plane model of the  Hyperbolic  manifold  $\\mathcal H^n$  to a tuple of a  HyperboloidPoint  and a  HyperboloidTVector $œÄ(p) ‚àà ‚Ñù^{n+1}$  simultaneously. This is done in two steps, namely transforming it to the Poincare ball model and from there further on to a Hyperboloid. source"},{"id":1138,"pagetitle":"Hyperbolic space","title":"ManifoldDiff.riemannian_Hessian","ref":"/manifolds/stable/manifolds/#ManifoldDiff.riemannian_Hessian-Tuple{Hyperbolic, Vararg{Any, 4}}","content":" ManifoldDiff.riemannian_Hessian  ‚Äî  Method Y = riemannian_Hessian(M::Hyperbolic, p, G, H, X)\nriemannian_Hessian!(M::Hyperbolic, Y, p, G, H, X) Compute the Riemannian Hessian  $\\operatorname{Hess} f(p)[X]$  given the Euclidean gradient  $‚àá f(\\tilde p)$  in  G  and the Euclidean Hessian  $‚àá^2 f(\\tilde p)[\\tilde X]$  in  H , where  $\\tilde p, \\tilde X$  are the representations of  $p,X$  in the embedding,. Let  $\\mathbf{g} = \\mathbf{g}^{-1} = \\operatorname{diag}(1,...,1,-1)$ . Then using Remark 4.1 [ Ngu23 ] the formula reads \\[\\operatorname{Hess}f(p)[X]\n=\n\\operatorname{proj}_{T_p\\mathcal M}\\bigl(\n    \\mathbf{g}^{-1}\\nabla^2f(p)[X] + X‚ü®p,\\mathbf{g}^{-1}‚àáf(p)‚ü©_p\n\\bigr).\\] source"},{"id":1139,"pagetitle":"Hyperbolic space","title":"Manifolds.volume_density","ref":"/manifolds/stable/manifolds/#Manifolds.volume_density-Tuple{Hyperbolic, Any, Any}","content":" Manifolds.volume_density  ‚Äî  Method volume_density(M::Hyperbolic, p, X) Compute volume density function of the hyperbolic manifold. The formula reads  $(\\sinh(\\lVert X\\rVert)/\\lVert X\\rVert)^(n-1)$  where  n  is the dimension of  M . It is derived from Eq. (4.1) in[ CLLD22 ]. source"},{"id":1140,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.change_representer","ref":"/manifolds/stable/manifolds/#ManifoldsBase.change_representer-Tuple{Hyperbolic, EuclideanMetric, Any, Any}","content":" ManifoldsBase.change_representer  ‚Äî  Method change_representer(M::Hyperbolic, ::EuclideanMetric, p, X) Change the Eucliden representer  X  of a cotangent vector at point  p . We only have to correct for the metric, which means that the sign of the last entry changes, since for the result  $Y$   we are looking for a tangent vector such that \\[    g_p(Y,Z) = -y_{n+1}z_{n+1} + \\sum_{i=1}^n y_iz_i = \\sum_{i=1}^{n+1} z_ix_i\\] holds, which directly yields  $y_i=x_i$  for  $i=1,\\ldots,n$  and  $y_{n+1}=-x_{n+1}$ . source"},{"id":1141,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{Hyperbolic, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::Hyperbolic, p, q)\ndistance(M::Hyperbolic, p::HyperboloidPoint, q::HyperboloidPoint) Compute the distance on the  Hyperbolic M , which reads \\[d_{\\mathcal H^n}(p,q) = \\operatorname{acosh}( - ‚ü®p, q‚ü©_{\\mathrm{M}}),\\] where  $‚ü®‚ãÖ,‚ãÖ‚ü©_{\\mathrm{M}}$  denotes the  MinkowskiMetric  on the embedding, the  Lorentz ian manifold. source"},{"id":1142,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.get_coordinates","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_coordinates-Tuple{Hyperbolic, Any, Any, DefaultOrthonormalBasis}","content":" ManifoldsBase.get_coordinates  ‚Äî  Method get_coordinates(M::Hyperbolic, p, X, ::DefaultOrthonormalBasis) Compute the coordinates of the vector  X  with respect to the orthogonalized version of the unit vectors from  $‚Ñù^n$ , where  $n$  is the manifold dimension of the  Hyperbolic M , utting them intop the tangent space at  p  and orthonormalizing them. source"},{"id":1143,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.get_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_vector-Tuple{Hyperbolic, Any, Any, DefaultOrthonormalBasis}","content":" ManifoldsBase.get_vector  ‚Äî  Method get_vector(M::Hyperbolic, p, c, ::DefaultOrthonormalBasis) Compute the vector from the coordinates with respect to the orthogonalized version of the unit vectors from  $‚Ñù^n$ , where  $n$  is the manifold dimension of the  Hyperbolic M , utting them intop the tangent space at  p  and orthonormalizing them. source"},{"id":1144,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{Hyperbolic, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::Hyperbolic, p, X, Y)\ninner(M::Hyperbolic, p::HyperboloidPoint, X::HyperboloidTVector, Y::HyperboloidTVector) Cmpute the inner product in the Hyperboloid model, i.e. the  minkowski_metric  in the embedding. The formula reads \\[g_p(X,Y) = ‚ü®X,Y‚ü©_{\\mathrm{M}} = -X_{n}Y_{n} + \\displaystyle\\sum_{k=1}^{n-1} X_kY_k.\\] This employs the metric of the embedding, see  Lorentz  space. source"},{"id":1145,"pagetitle":"Hyperbolic space","title":"Visualization of the Hyperboloid","ref":"/manifolds/stable/manifolds/#hyperboloid_plot","content":" Visualization of the Hyperboloid For the case of  Hyperbolic (2)  there is plotting available based on a  PlottingRecipe . You can easily plot points, connecting geodesics as well as tangent vectors. Note The recipes are only loaded if  Plots.jl  or  RecipesBase.jl  is loaded. If we consider a set of points, we can first plot these and their connecting geodesics using the  geodesic_interpolation  for the points. This variable specifies with how many points a geodesic between two successive points is sampled (per default it's  -1 , which deactivates geodesics) and the line style is set to be a path. In general you can plot the surface of the hyperboloid either as wireframe ( wireframe=true ) additionally specifying  wires  (or  wires_x  and  wires_y ) to change the density of wires and a  wireframe_color . The same holds for the plot as a  surface  (which is  false  by default) and its  surface_resolution  (or  surface_resolution_x  or  surface_resolution_y ) and a  surface_color . using Manifolds, Plots\nM = Hyperbolic(2)\npts =  [ [0.85*cos(œÜ), 0.85*sin(œÜ), sqrt(0.85^2+1)] for œÜ ‚àà range(0,2œÄ,length=11) ]\nscene = plot(M, pts; geodesic_interpolation=100) To just plot the points atop, we can just omit the  geodesic_interpolation  parameter to obtain a scatter plot. Note that we avoid redrawing the wireframe in the following  plot!  calls. plot!(scene, M, pts; wireframe=false) We can further generate tangent vectors in these spaces and use a plot for there. Keep in mind that a tangent vector in plotting always requires its base point. pts2 = [ [0.45 .*cos(œÜ + 6œÄ/11), 0.45 .*sin(œÜ + 6œÄ/11), sqrt(0.45^2+1) ] for œÜ ‚àà range(0,2œÄ,length=11)]\nvecs = log.(Ref(M),pts,pts2)\nplot!(scene, M, pts, vecs; wireframe=false) Just to illustrate, for the first point the tangent vector is pointing along the following geodesic plot!(scene, M, [pts[1], pts2[1]]; geodesic_interpolation=100, wireframe=false)"},{"id":1146,"pagetitle":"Hyperbolic space","title":"Internal functions","ref":"/manifolds/stable/manifolds/#Internal-functions","content":" Internal functions The following functions are available for internal use to construct points in the hyperboloid model"},{"id":1147,"pagetitle":"Hyperbolic space","title":"Manifolds._hyperbolize","ref":"/manifolds/stable/manifolds/#Manifolds._hyperbolize-Tuple{Hyperbolic, Any, Any}","content":" Manifolds._hyperbolize  ‚Äî  Method _hyperbolize(M, p, Y) Given the  Hyperbolic (n)  manifold using the hyperboloid model and a point  p  thereon, we can put a vector  $Y\\in ‚Ñù^n$   into the tangent space by computing its last component such that for the resulting  p  we have that its  minkowski_metric  is  $‚ü®p,X‚ü©_{\\mathrm{M}} = 0$ , i.e.  $X_{n+1} = \\frac{‚ü®\\tilde p, Y‚ü©}{p_{n+1}}$ , where  $\\tilde p = (p_1,\\ldots,p_n)$ . source"},{"id":1148,"pagetitle":"Hyperbolic space","title":"Manifolds._hyperbolize","ref":"/manifolds/stable/manifolds/#Manifolds._hyperbolize-Tuple{Hyperbolic, Any}","content":" Manifolds._hyperbolize  ‚Äî  Method _hyperbolize(M, q) Given the  Hyperbolic (n)  manifold using the hyperboloid model, a point from the  $q\\in ‚Ñù^n$  can be set onto the manifold by computing its last component such that for the resulting  p  we have that its  minkowski_metric  is  $‚ü®p,p‚ü©_{\\mathrm{M}} = - 1$ , i.e.  $p_{n+1} = \\sqrt{\\lVert q \\rVert^2 - 1}$ source"},{"id":1149,"pagetitle":"Hyperbolic space","title":"Poincar√© ball model","ref":"/manifolds/stable/manifolds/#poincare_ball","content":" Poincar√© ball model"},{"id":1150,"pagetitle":"Hyperbolic space","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{PoincareBallPoint}, Any}","content":" Base.convert  ‚Äî  Method convert(::Type{PoincareBallPoint}, p::HyperboloidPoint)\nconvert(::Type{PoincareBallPoint}, p::T) where {T<:AbstractVector} convert a  HyperboloidPoint $p‚àà‚Ñù^{n+1}$  from the hyperboloid model of the  Hyperbolic  manifold  $\\mathcal H^n$  to a  PoincareBallPoint $œÄ(p)‚àà‚Ñù^{n}$  in the Poincar√© ball model. The isometry is defined by \\[œÄ(p) = \\frac{1}{1+p_{n+1}} \\begin{pmatrix}p_1\\\\‚ãÆ\\\\p_n\\end{pmatrix}\\] Note that this is also used, when  x  is a vector. source"},{"id":1151,"pagetitle":"Hyperbolic space","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{PoincareBallPoint}, PoincareHalfSpacePoint}","content":" Base.convert  ‚Äî  Method convert(::Type{PoincareBallPoint}, p::PoincareHalfSpacePoint) convert a point  PoincareHalfSpacePoint p  (from  $‚Ñù^n$ ) from the Poincar√© half plane model of the  Hyperbolic  manifold  $\\mathcal H^n$  to a  PoincareBallPoint $œÄ(p) ‚àà ‚Ñù^n$ . Denote by  $\\tilde p = (p_1,\\ldots,p_{d-1})^{\\mathrm{T}}$ . Then the isometry is defined by \\[œÄ(p) = \\frac{1}{\\lVert \\tilde p \\rVert^2 + (p_n+1)^2}\n\\begin{pmatrix}2p_1\\\\‚ãÆ\\\\2p_{n-1}\\\\\\lVert p\\rVert^2 - 1\\end{pmatrix}.\\] source"},{"id":1152,"pagetitle":"Hyperbolic space","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{PoincareBallTVector}, Any}","content":" Base.convert  ‚Äî  Method convert(::Type{PoincareBallTVector}, p::HyperboloidPoint, X::HyperboloidTVector)\nconvert(::Type{PoincareBallTVector}, p::P, X::T) where {P<:AbstractVector, T<:AbstractVector} convert a  HyperboloidTVector X  at  p  to a  PoincareBallTVector  on the  Hyperbolic  manifold  $\\mathcal H^n$  by computing the push forward  $œÄ_*(p)[X]$  of the isometry  $œÄ$  that maps from the Hyperboloid to the Poincar√© ball, cf.  convert(::Type{PoincareBallPoint}, ::HyperboloidPoint) . The formula reads \\[œÄ_*(p)[X] = \\frac{1}{p_{n+1}+1}\\Bigl(\\tilde X - \\frac{X_{n+1}}{p_{n+1}+1}\\tilde p \\Bigl),\\] where  $\\tilde X = \\begin{pmatrix}X_1\\\\‚ãÆ\\\\X_n\\end{pmatrix}$  and  $\\tilde p = \\begin{pmatrix}p_1\\\\‚ãÆ\\\\p_n\\end{pmatrix}$ . source"},{"id":1153,"pagetitle":"Hyperbolic space","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{PoincareBallTVector}, PoincareHalfSpacePoint, PoincareHalfSpaceTVector}","content":" Base.convert  ‚Äî  Method convert(\n    ::Type{PoincareBallTVector},\n    p::PoincareHalfSpacePoint,\n    X::PoincareHalfSpaceTVector\n) convert a  PoincareHalfSpaceTVector X  at  p  to a  PoincareBallTVector  on the  Hyperbolic  manifold  $\\mathcal H^n$  by computing the push forward  $œÄ_*(p)[X]$  of the isometry  $œÄ$  that maps from the Poincar√© half space to the Poincar√© ball, cf.  convert(::Type{PoincareBallPoint}, ::PoincareHalfSpacePoint) . The formula reads \\[œÄ_*(p)[X] =\n\\frac{1}{\\lVert \\tilde p\\rVert^2 + (1+p_n)^2}\n\\begin{pmatrix}\n2X_1\\\\\n‚ãÆ\\\\\n2X_{n-1}\\\\\n2‚ü®X,p‚ü©\n\\end{pmatrix}\n-\n\\frac{2}{(\\lVert \\tilde p\\rVert^2 + (1+p_n)^2)^2}\n\\begin{pmatrix}\n2p_1(‚ü®X,p‚ü©+X_n)\\\\\n‚ãÆ\\\\\n2p_{n-1}(‚ü®X,p‚ü©+X_n)\\\\\n(\\lVert p \\rVert^2-1)(‚ü®X,p‚ü©+X_n)\n\\end{pmatrix}\\] where  $\\tilde p = \\begin{pmatrix}p_1\\\\‚ãÆ\\\\p_{n-1}\\end{pmatrix}$ . source"},{"id":1154,"pagetitle":"Hyperbolic space","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{Tuple{PoincareBallPoint, PoincareBallTVector}}, Tuple{HyperboloidPoint, HyperboloidTVector}}","content":" Base.convert  ‚Äî  Method convert(\n    ::Type{Tuple{PoincareBallPoint,PoincareBallTVector}},\n    (p,X)::Tuple{HyperboloidPoint,HyperboloidTVector}\n)\nconvert(\n    ::Type{Tuple{PoincareBallPoint,PoincareBallTVector}},\n    (p, X)::Tuple{P,T},\n) where {P<:AbstractVector, T <: AbstractVector} Convert a  HyperboloidPoint p  and a  HyperboloidTVector X  to a  PoincareBallPoint  and a  PoincareBallTVector  simultaneously, see  convert(::Type{PoincareBallPoint}, ::HyperboloidPoint)  and  convert(::Type{PoincareBallTVector}, ::HyperboloidPoint, ::HyperboloidTVector)  for the formulae. source"},{"id":1155,"pagetitle":"Hyperbolic space","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{Tuple{PoincareBallPoint, PoincareBallTVector}}, Tuple{PoincareHalfSpacePoint, PoincareHalfSpaceTVector}}","content":" Base.convert  ‚Äî  Method convert(\n    ::Type{Tuple{PoincareBallPoint,PoincareBallTVector}},\n    (p,X)::Tuple{HyperboloidPoint,HyperboloidTVector}\n)\nconvert(\n    ::Type{Tuple{PoincareBallPoint,PoincareBallTVector}},\n    (p, X)::Tuple{T,T},\n) where {T <: AbstractVector} Convert a  PoincareHalfSpacePoint p  and a  PoincareHalfSpaceTVector X  to a  PoincareBallPoint  and a  PoincareBallTVector  simultaneously, see  convert(::Type{PoincareBallPoint}, ::PoincareHalfSpacePoint)  and  convert(::Type{PoincareBallTVector}, ::PoincareHalfSpacePoint, ::PoincareHalfSpaceTVector)  for the formulae. source"},{"id":1156,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.change_metric","ref":"/manifolds/stable/manifolds/#ManifoldsBase.change_metric-Tuple{Hyperbolic, EuclideanMetric, PoincareBallPoint, PoincareBallTVector}","content":" ManifoldsBase.change_metric  ‚Äî  Method change_metric(M::Hyperbolic, ::EuclideanMetric, p::PoincareBallPoint, X::PoincareBallTVector) Since in the metric we always have the term  $Œ± = \\frac{2}{1-\\sum_{i=1}^n p_i^2}$  per element, the correction for the metric reads  $Z = \\frac{1}{Œ±}X$ . source"},{"id":1157,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.change_representer","ref":"/manifolds/stable/manifolds/#ManifoldsBase.change_representer-Tuple{Hyperbolic, EuclideanMetric, PoincareBallPoint, PoincareBallTVector}","content":" ManifoldsBase.change_representer  ‚Äî  Method change_representer(M::Hyperbolic, ::EuclideanMetric, p::PoincareBallPoint, X::PoincareBallTVector) Since in the metric we have the term  $Œ± = \\frac{2}{1-\\sum_{i=1}^n p_i^2}$  per element, the correction for the gradient reads  $Y = \\frac{1}{Œ±^2}X$ . source"},{"id":1158,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{Hyperbolic, PoincareBallPoint, PoincareBallPoint}","content":" ManifoldsBase.distance  ‚Äî  Method distance(::Hyperbolic, p::PoincareBallPoint, q::PoincareBallPoint) Compute the distance on the  Hyperbolic  manifold  $\\mathcal H^n$  represented in the Poincar√© ball model. The formula reads \\[d_{\\mathcal H^n}(p,q) =\n\\operatorname{acosh}\\Bigl(\n  1 + \\frac{2\\lVert p - q \\rVert^2}{(1-\\lVert p\\rVert^2)(1-\\lVert q\\rVert^2)}\n\\Bigr)\\] source"},{"id":1159,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{Hyperbolic, PoincareBallPoint, PoincareBallTVector, PoincareBallTVector}","content":" ManifoldsBase.inner  ‚Äî  Method inner(::Hyperbolic, p::PoincareBallPoint, X::PoincareBallTVector, Y::PoincareBallTVector) Compute the inner product in the Poincar√© ball model. The formula reads \\[g_p(X,Y) = \\frac{4}{(1-\\lVert p \\rVert^2)^2}  ‚ü®X, Y‚ü© .\\] source"},{"id":1160,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Hyperbolic, PoincareBallPoint, PoincareBallTVector}","content":" ManifoldsBase.project  ‚Äî  Method project(::Hyperbolic, ::PoincareBallPoint, ::PoincareBallTVector) projction of tangent vectors in the Poincar√© ball model is just the identity, since the tangent space consists of all  $‚Ñù^n$ . source"},{"id":1161,"pagetitle":"Hyperbolic space","title":"Visualization of the Poincar√© ball","ref":"/manifolds/stable/manifolds/#poincare_ball_plot","content":" Visualization of the Poincar√© ball For the case of  Hyperbolic (2)  there is a plotting available based on a  PlottingRecipe  you can easily plot points, connecting geodesics as well as tangent vectors. Note The recipes are only loaded if  Plots.jl  or  RecipesBase.jl  is loaded. If we consider a set of points, we can first plot these and their connecting geodesics using the  geodesic_interpolation  For the points. This variable specifies with how many points a geodesic between two successive points is sampled (per default it's  -1 , which deactivates geodesics) and the line style is set to be a path. Another keyword argument added is the border of the Poincar√© disc, namely  circle_points = 720  resolution of the drawn boundary (every hlaf angle) as well as its color,  hyperbolic_border_color = RGBA(0.0, 0.0, 0.0, 1.0) . using Manifolds, Plots\nM = Hyperbolic(2)\npts = PoincareBallPoint.( [0.85 .* [cos(œÜ), sin(œÜ)] for œÜ ‚àà range(0,2œÄ,length=11)])\nscene = plot(M, pts, geodesic_interpolation = 100) To just plot the points atop, we can just omit the  geodesic_interpolation  parameter to obtain a scatter plot plot!(scene, M, pts) We can further generate tangent vectors in these spaces and use a plot for there. Keep in mind, that a tangent vector in plotting always requires its base point pts2 = PoincareBallPoint.( [0.45 .* [cos(œÜ + 6œÄ/11), sin(œÜ + 6œÄ/11)] for œÜ ‚àà range(0,2œÄ,length=11)])\nvecs = log.(Ref(M),pts,pts2)\nplot!(scene, M, pts,vecs) Just to illustrate, for the first point the tangent vector is pointing along the following geodesic plot!(scene, M, [pts[1], pts2[1]], geodesic_interpolation=100)"},{"id":1162,"pagetitle":"Hyperbolic space","title":"Poincar√© half space model","ref":"/manifolds/stable/manifolds/#poincare_halfspace","content":" Poincar√© half space model"},{"id":1163,"pagetitle":"Hyperbolic space","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{PoincareHalfSpacePoint}, Any}","content":" Base.convert  ‚Äî  Method convert(::Type{PoincareHalfSpacePoint}, p::Hyperboloid)\nconvert(::Type{PoincareHalfSpacePoint}, p) convert a  HyperboloidPoint  or  Vector p  (from  $‚Ñù^{n+1}$ ) from the Hyperboloid model of the  Hyperbolic  manifold  $\\mathcal H^n$  to a  PoincareHalfSpacePoint $œÄ(x) ‚àà ‚Ñù^{n}$ . This is done in two steps, namely transforming it to a Poincare ball point and from there further on to a PoincareHalfSpacePoint point. source"},{"id":1164,"pagetitle":"Hyperbolic space","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{PoincareHalfSpacePoint}, PoincareBallPoint}","content":" Base.convert  ‚Äî  Method convert(::Type{PoincareHalfSpacePoint}, p::PoincareBallPoint) convert a point  PoincareBallPoint p  (from  $‚Ñù^n$ ) from the Poincar√© ball model of the  Hyperbolic  manifold  $\\mathcal H^n$  to a  PoincareHalfSpacePoint $œÄ(p) ‚àà ‚Ñù^n$ . Denote by  $\\tilde p = (p_1,\\ldots,p_{n-1})$ . Then the isometry is defined by \\[œÄ(p) = \\frac{1}{\\lVert \\tilde p \\rVert^2 - (p_n-1)^2}\n\\begin{pmatrix}2p_1\\\\‚ãÆ\\\\2p_{n-1}\\\\1-\\lVert p\\rVert^2\\end{pmatrix}.\\] source"},{"id":1165,"pagetitle":"Hyperbolic space","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{PoincareHalfSpaceTVector}, Any}","content":" Base.convert  ‚Äî  Method convert(::Type{PoincareHalfSpaceTVector}, p::HyperboloidPoint, ::HyperboloidTVector)\nconvert(::Type{PoincareHalfSpaceTVector}, p::P, X::T) where {P<:AbstractVector, T<:AbstractVector} convert a  HyperboloidTVector X  at  p  to a  PoincareHalfSpaceTVector  on the  Hyperbolic  manifold  $\\mathcal H^n$  by computing the push forward  $œÄ_*(p)[X]$  of the isometry  $œÄ$  that maps from the Hyperboloid to the Poincar√© half space, cf.  convert(::Type{PoincareHalfSpacePoint}, ::HyperboloidPoint) . This is done similarly to the approach there, i.e. by using the Poincar√© ball model as an intermediate step. source"},{"id":1166,"pagetitle":"Hyperbolic space","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{PoincareHalfSpaceTVector}, PoincareBallPoint, PoincareBallTVector}","content":" Base.convert  ‚Äî  Method convert(::Type{PoincareHalfSpaceTVector}, p::PoincareBallPoint, X::PoincareBallTVector) convert a  PoincareBallTVector X  at  p  to a  PoincareHalfSpacePoint  on the  Hyperbolic  manifold  $\\mathcal H^n$  by computing the push forward  $œÄ_*(p)[X]$  of the isometry  $œÄ$  that maps from the Poincar√© ball to the Poincar√© half space, cf.  convert(::Type{PoincareHalfSpacePoint}, ::PoincareBallPoint) . The formula reads \\[œÄ_*(p)[X] =\n\\frac{1}{\\lVert \\tilde p\\rVert^2 + (1-p_n)^2}\n\\begin{pmatrix}\n2X_1\\\\\n‚ãÆ\\\\\n2X_{n-1}\\\\\n-2‚ü®X,p‚ü©\n\\end{pmatrix}\n-\n\\frac{2}{(\\lVert \\tilde p\\rVert^2 + (1-p_n)^2)^2}\n\\begin{pmatrix}\n2p_1(‚ü®X,p‚ü©-X_n)\\\\\n‚ãÆ\\\\\n2p_{n-1}(‚ü®X,p‚ü©-X_n)\\\\\n(\\lVert p \\rVert^2-1)(‚ü®X,p‚ü©-X_n)\n\\end{pmatrix}\\] where  $\\tilde p = \\begin{pmatrix}p_1\\\\‚ãÆ\\\\p_{n-1}\\end{pmatrix}$ . source"},{"id":1167,"pagetitle":"Hyperbolic space","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{Tuple{PoincareHalfSpacePoint, PoincareHalfSpaceTVector}}, Tuple{HyperboloidPoint, HyperboloidTVector}}","content":" Base.convert  ‚Äî  Method convert(\n    ::Type{Tuple{PoincareHalfSpacePoint,PoincareHalfSpaceTVector}},\n    (p,X)::Tuple{HyperboloidPoint,HyperboloidTVector}\n)\nconvert(\n    ::Type{Tuple{PoincareHalfSpacePoint,PoincareHalfSpaceTVector}},\n    (p, X)::Tuple{P,T},\n) where {P<:AbstractVector, T <: AbstractVector} Convert a  HyperboloidPoint p  and a  HyperboloidTVector X  to a  PoincareHalfSpacePoint  and a  PoincareHalfSpaceTVector  simultaneously, see  convert(::Type{PoincareHalfSpacePoint}, ::HyperboloidPoint)  and  convert(::Type{PoincareHalfSpaceTVector}, ::Tuple{HyperboloidPoint,HyperboloidTVector})  for the formulae. source"},{"id":1168,"pagetitle":"Hyperbolic space","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{Tuple{PoincareHalfSpacePoint, PoincareHalfSpaceTVector}}, Tuple{PoincareBallPoint, PoincareBallTVector}}","content":" Base.convert  ‚Äî  Method convert(\n    ::Type{Tuple{PoincareHalfSpacePoint,PoincareHalfSpaceTVector}},\n    (p,X)::Tuple{PoincareBallPoint,PoincareBallTVector}\n) Convert a  PoincareBallPoint p  and a  PoincareBallTVector X  to a  PoincareHalfSpacePoint  and a  PoincareHalfSpaceTVector  simultaneously, see  convert(::Type{PoincareHalfSpacePoint}, ::PoincareBallPoint)  and  convert(::Type{PoincareHalfSpaceTVector}, ::PoincareBallPoint,::PoincareBallTVector)  for the formulae. source"},{"id":1169,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{Hyperbolic, PoincareHalfSpacePoint, PoincareHalfSpacePoint}","content":" ManifoldsBase.distance  ‚Äî  Method distance(::Hyperbolic, p::PoincareHalfSpacePoint, q::PoincareHalfSpacePoint) Compute the distance on the  Hyperbolic  manifold  $\\mathcal H^n$  represented in the Poincar√© half space model. The formula reads \\[d_{\\mathcal H^n}(p,q) = \\operatorname{acosh}\\Bigl( 1 + \\frac{\\lVert p - q \\rVert^2}{2 p_n q_n} \\Bigr)\\] source"},{"id":1170,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{Hyperbolic, PoincareHalfSpacePoint, PoincareHalfSpaceTVector, PoincareHalfSpaceTVector}","content":" ManifoldsBase.inner  ‚Äî  Method inner(\n    ::Hyperbolic,\n    p::PoincareHalfSpacePoint,\n    X::PoincareHalfSpaceTVector,\n    Y::PoincareHalfSpaceTVector\n) Compute the inner product in the Poincar√© half space model. The formula reads \\[g_p(X,Y) = \\frac{‚ü®X,Y‚ü©}{p_n^2}.\\] source"},{"id":1171,"pagetitle":"Hyperbolic space","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Hyperbolic, PoincareHalfSpaceTVector}","content":" ManifoldsBase.project  ‚Äî  Method project(::Hyperbolic, ::PoincareHalfSpacePoint ::PoincareHalfSpaceTVector) projction of tangent vectors in the Poincar√© half space model is just the identity, since the tangent space consists of all  $‚Ñù^n$ . source"},{"id":1172,"pagetitle":"Hyperbolic space","title":"Visualization on the Poincar√© half plane","ref":"/manifolds/stable/manifolds/#poincare_half_plane_plot","content":" Visualization on the Poincar√© half plane For the case of  Hyperbolic (2)  there is a plotting available based on a  PlottingRecipe  you can easily plot points, connecting geodesics as well as tangent vectors. Note The recipes are only loaded if  Plots.jl  or  RecipesBase.jl  is loaded. We again have two different recipes, one for points, one for tangent vectors, where the first one again can be equipped with geodesics between the points. In the following example we generate 7 points on an ellipse in the  Hyperboloid model . using Manifolds, Plots\nM = Hyperbolic(2)\npre_pts = [2.0 .* [5.0*cos(œÜ), sin(œÜ)] for œÜ ‚àà range(0,2œÄ,length=7)]\npts = convert.(\n    Ref(PoincareHalfSpacePoint),\n    Manifolds._hyperbolize.(Ref(M), pre_pts)\n)\nscene = plot(M, pts, geodesic_interpolation = 100) To just plot the points atop, we can just omit the  geodesic_interpolation  parameter to obtain a scatter plot plot!(scene, M, pts) We can further generate tangent vectors in these spaces and use a plot for there. Keep in mind, that a tangent vector in plotting always requires its base point. Here we would like to look at the tangent vectors pointing to the  origin origin = PoincareHalfSpacePoint([0.0,1.0])\nvecs = [log(M,p,origin) for p ‚àà pts]\nscene = plot!(scene, M, pts, vecs) And we can again look at the corresponding geodesics, for example plot!(scene, M, [pts[1], origin], geodesic_interpolation=100)\nplot!(scene, M, [pts[2], origin], geodesic_interpolation=100)"},{"id":1173,"pagetitle":"Hyperbolic space","title":"Literature","ref":"/manifolds/stable/manifolds/#Literature","content":" Literature [CLLD22] E.¬†Chevallier, D.¬†Li, Y.¬†Lu and D.¬†B.¬†Dunson.  Exponential-wrapped distributions on symmetric spaces . ArXiv¬†Preprint (2022). [Lee19] J.¬†M.¬†Lee.  Introduction to Riemannian Manifolds  (Springer Cham, 2019). [Ngu23] D.¬†Nguyen.  Operator-Valued Formulas for Riemannian Gradient and Hessian and Families of Tractable Metrics in Riemannian Optimization .  Journal¬†of¬†Optimization¬†Theory¬†and¬†Applications  198 , 135‚Äì164  (2023),  arXiv:2009.10159 ."},{"id":1176,"pagetitle":"Lorentzian manifold","title":"Lorentzian Manifold","ref":"/manifolds/stable/manifolds/#Lorentzian-Manifold","content":" Lorentzian Manifold The  Lorentz manifold  is a  pseudo-Riemannian manifold . It is named after the Dutch physicist  Hendrik Lorentz  (1853‚Äì1928). The default  LorentzMetric  is the  MinkowskiMetric  named after the German mathematician  Hermann Minkowski  (1864‚Äì1909). Within  Manifolds.jl  it is used as the embedding of the  Hyperbolic  space."},{"id":1177,"pagetitle":"Lorentzian manifold","title":"Manifolds.Lorentz","ref":"/manifolds/stable/manifolds/#Manifolds.Lorentz","content":" Manifolds.Lorentz  ‚Äî  Type Lorentz{T} = MetricManifold{Euclidean{T,‚Ñù},LorentzMetric} The Lorentz manifold (or Lorentzian) is a pseudo-Riemannian manifold. Constructor Lorentz(n[, metric=MinkowskiMetric()]) Generate the Lorentz manifold of dimension  n  with the  LorentzMetric m , which is by default set to the  MinkowskiMetric . source"},{"id":1178,"pagetitle":"Lorentzian manifold","title":"Manifolds.LorentzMetric","ref":"/manifolds/stable/manifolds/#Manifolds.LorentzMetric","content":" Manifolds.LorentzMetric  ‚Äî  Type LorentzMetric <: AbstractMetric Abstract type for Lorentz metrics, which have a single time dimension. These metrics assume the spacelike convention with the time dimension being last, giving the signature  $(++...+-)$ . source"},{"id":1179,"pagetitle":"Lorentzian manifold","title":"Manifolds.MinkowskiMetric","ref":"/manifolds/stable/manifolds/#Manifolds.MinkowskiMetric","content":" Manifolds.MinkowskiMetric  ‚Äî  Type MinkowskiMetric <: LorentzMetric As a special metric of signature   $(++...+-)$ , i.e. a  LorentzMetric , see  minkowski_metric  for the formula. source"},{"id":1180,"pagetitle":"Lorentzian manifold","title":"Manifolds.minkowski_metric","ref":"/manifolds/stable/manifolds/#Manifolds.minkowski_metric-Tuple{Any, Any}","content":" Manifolds.minkowski_metric  ‚Äî  Method minkowski_metric(a, b) Compute the minkowski metric on  $\\mathbb R^n$  is given by \\[‚ü®a,b‚ü©_{\\mathrm{M}} = -a_{n}b_{n} +\n\\displaystyle\\sum_{k=1}^{n-1} a_kb_k.\\] source"},{"id":1183,"pagetitle":"Metric manifold","title":"Metric manifold","ref":"/manifolds/stable/manifolds/#Metric-manifold","content":" Metric manifold A Riemannian manifold always consists of a  topological manifold  together with a smoothly varying metric  $g$ . However, often there is an implicitly assumed (default) metric, like the usual inner product on  Euclidean  space. This decorator takes this into account. It is not necessary to use this decorator if you implement just one (or the first) metric. If you later introduce a second, the old (first) metric can be used with the (non  MetricManifold )  AbstractManifold , i.e. without an explicitly stated metric. This manifold decorator serves two purposes: to implement different metrics (e.g. in closed form) for one  AbstractManifold to provide a way to compute geodesics on manifolds, where this  AbstractMetric  does not yield closed formula. Metric manifold Types Implement Different Metrics on the same Manifold Implementation of Metrics Metrics, charts and bases of vector spaces Note that a metric manifold is has a  IsConnectionManifold  trait referring to the  LeviCivitaConnection  of the metric  $g$ , and thus a large part of metric manifold's functionality relies on this. Let's first look at the provided types."},{"id":1184,"pagetitle":"Metric manifold","title":"Types","ref":"/manifolds/stable/manifolds/#Types","content":" Types"},{"id":1185,"pagetitle":"Metric manifold","title":"Manifolds.IsDefaultMetric","ref":"/manifolds/stable/manifolds/#Manifolds.IsDefaultMetric","content":" Manifolds.IsDefaultMetric  ‚Äî  Type IsDefaultMetric{G<:AbstractMetric} Specify that a certain  AbstractMetric  is the default metric for a manifold. This way the corresponding  MetricManifold  falls back to the default methods of the manifold it decorates. source"},{"id":1186,"pagetitle":"Metric manifold","title":"Manifolds.IsMetricManifold","ref":"/manifolds/stable/manifolds/#Manifolds.IsMetricManifold","content":" Manifolds.IsMetricManifold  ‚Äî  Type IsMetricManifold <: AbstractTrait Specify that a certain decorated Manifold is a metric manifold in the sence that it provides explicit metric properties, extending/changing the default metric properties of a manifold. source"},{"id":1187,"pagetitle":"Metric manifold","title":"Manifolds.MetricManifold","ref":"/manifolds/stable/manifolds/#Manifolds.MetricManifold","content":" Manifolds.MetricManifold  ‚Äî  Type MetricManifold{ùîΩ,M<:AbstractManifold{ùîΩ},G<:AbstractMetric} <: AbstractDecoratorManifold{ùîΩ} Equip a  AbstractManifold  explicitly with an  AbstractMetric G . For a Metric AbstractManifold, by default, assumes, that you implement the linear form from  local_metric  in order to evaluate the exponential map. If the corresponding  AbstractMetric G  yields closed form formulae for e.g. the exponential map and this is implemented directly (without solving the ode), you can of course still implement that directly. Constructor MetricManifold(M, G) Generate the  AbstractManifold M  as a manifold with the  AbstractMetric G . source"},{"id":1188,"pagetitle":"Metric manifold","title":"Implement Different Metrics on the same Manifold","ref":"/manifolds/stable/manifolds/#Implement-Different-Metrics-on-the-same-Manifold","content":" Implement Different Metrics on the same Manifold In order to distinguish different metrics on one manifold, one can introduce two  AbstractMetric s and use this type to dispatch on the metric, see  SymmetricPositiveDefinite . To avoid overhead, one  AbstractMetric  can then be marked as being the default, i.e. the one that is used, when no  MetricManifold  decorator is present. This avoids reimplementation of the first existing metric, access to the metric-dependent functions that were implemented using the undecorated manifold, as well as the transparent fallback of the corresponding  MetricManifold  with default metric to the undecorated implementations. This does not cause any runtime overhead. Introducing a default  AbstractMetric  serves a better readability of the code when working with different metrics."},{"id":1189,"pagetitle":"Metric manifold","title":"Implementation of Metrics","ref":"/manifolds/stable/manifolds/#Implementation-of-Metrics","content":" Implementation of Metrics For the case that a  local_metric  is implemented as a bilinear form that is positive definite, the following further functions are provided, unless the corresponding  AbstractMetric  is marked as default ‚Äì then the fallbacks mentioned in the last section are used for e.g. the exponential map."},{"id":1190,"pagetitle":"Metric manifold","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{MetricManifold, Vararg{Any}}","content":" Base.log  ‚Äî  Method log(N::MetricManifold{M,G}, p, q) Copute the logarithmic map on the  AbstractManifold M  equipped with the  AbstractMetric G . If the metric was declared the default metric using the  IsDefaultMetric  trait or  is_default_metric , this method falls back to  log(M,p,q) . Otherwise, you have to provide an implementation for the non-default  AbstractMetric G  metric within its  MetricManifold {M,G} . source"},{"id":1191,"pagetitle":"Metric manifold","title":"Manifolds.connection","ref":"/manifolds/stable/manifolds/#Manifolds.connection-Tuple{MetricManifold}","content":" Manifolds.connection  ‚Äî  Method connection(::MetricManifold) Return the  LeviCivitaConnection  for a metric manifold. source"},{"id":1192,"pagetitle":"Metric manifold","title":"Manifolds.det_local_metric","ref":"/manifolds/stable/manifolds/#Manifolds.det_local_metric-Tuple{AbstractManifold, Any, AbstractBasis}","content":" Manifolds.det_local_metric  ‚Äî  Method det_local_metric(M::AbstractManifold, p, B::AbstractBasis) Return the determinant of local matrix representation of the metric tensor  $g$ , i.e. of the matrix  $G(p)$  representing the metric in the tangent space at  $p$  with as a matrix. See also  local_metric source"},{"id":1193,"pagetitle":"Metric manifold","title":"Manifolds.einstein_tensor","ref":"/manifolds/stable/manifolds/#Manifolds.einstein_tensor-Tuple{AbstractManifold, Any, AbstractBasis}","content":" Manifolds.einstein_tensor  ‚Äî  Method einstein_tensor(M::AbstractManifold, p, B::AbstractBasis; backend::AbstractDiffBackend = diff_badefault_differential_backendckend()) Compute the Einstein tensor of the manifold  M  at the point  p , see  https://en.wikipedia.org/wiki/Einstein_tensor source"},{"id":1194,"pagetitle":"Metric manifold","title":"Manifolds.flat","ref":"/manifolds/stable/manifolds/#Manifolds.flat-Tuple{MetricManifold, Any, TFVector}","content":" Manifolds.flat  ‚Äî  Method flat(N::MetricManifold{M,G}, p, X::TFVector) Compute the musical isomorphism to transform the tangent vector  X  from the  AbstractManifold M  equipped with  AbstractMetric G  to a cotangent by computing \\[X^‚ô≠= G_p X,\\] where  $G_p$  is the local matrix representation of  G , see  local_metric source"},{"id":1195,"pagetitle":"Metric manifold","title":"Manifolds.inverse_local_metric","ref":"/manifolds/stable/manifolds/#Manifolds.inverse_local_metric-Tuple{AbstractManifold, Any, AbstractBasis}","content":" Manifolds.inverse_local_metric  ‚Äî  Method inverse_local_metric(M::AbstractcManifold{ùîΩ}, p, B::AbstractBasis) Return the local matrix representation of the inverse metric (cometric) tensor of the tangent space at  p  on the  AbstractManifold M  with respect to the  AbstractBasis  basis  B . The metric tensor (see  local_metric ) is usually denoted by  $G = (g_{ij}) ‚àà ùîΩ^{d√ód}$ , where  $d$  is the dimension of the manifold. Then the inverse local metric is denoted by  $G^{-1} = g^{ij}$ . source"},{"id":1196,"pagetitle":"Metric manifold","title":"Manifolds.is_default_metric","ref":"/manifolds/stable/manifolds/#Manifolds.is_default_metric-Tuple{AbstractManifold, AbstractMetric}","content":" Manifolds.is_default_metric  ‚Äî  Method is_default_metric(M::AbstractManifold, G::AbstractMetric) returns whether an  AbstractMetric  is the default metric on the manifold  M  or not. This can be set by defining this function, or setting the  IsDefaultMetric  trait for an  AbstractDecoratorManifold . source"},{"id":1197,"pagetitle":"Metric manifold","title":"Manifolds.local_metric","ref":"/manifolds/stable/manifolds/#Manifolds.local_metric-Tuple{AbstractManifold, Any, AbstractBasis}","content":" Manifolds.local_metric  ‚Äî  Method local_metric(M::AbstractManifold{ùîΩ}, p, B::AbstractBasis) Return the local matrix representation at the point  p  of the metric tensor  $g$  with respect to the  AbstractBasis B  on the  AbstractManifold M . Let  $d$ denote the dimension of the manifold and  $b_1,\\ldots,b_d$  the basis vectors. Then the local matrix representation is a matrix  $G\\in ùîΩ^{n√ón}$  whose entries are given by  $g_{ij} = g_p(b_i,b_j), i,j\\in\\{1,‚Ä¶,d\\}$ . This yields the property for two tangent vectors (using Einstein summation convention)  $X = X^ib_i, Y=Y^ib_i \\in T_p\\mathcal M$  we get  $g_p(X, Y) = g_{ij} X^i Y^j$ . source"},{"id":1198,"pagetitle":"Metric manifold","title":"Manifolds.local_metric_jacobian","ref":"/manifolds/stable/manifolds/#Manifolds.local_metric_jacobian-Tuple{AbstractManifold, Any, AbstractBasis, ManifoldDiff.AbstractDiffBackend}","content":" Manifolds.local_metric_jacobian  ‚Äî  Method local_metric_jacobian(\n    M::AbstractManifold,\n    p,\n    B::AbstractBasis;\n    backend::AbstractDiffBackend,\n) Get partial derivatives of the local metric of  M  at  p  in basis  B  with respect to the coordinates of  p ,  $\\frac{‚àÇ}{‚àÇ p^k} g_{ij} = g_{ij,k}$ . The dimensions of the resulting multi-dimensional array are ordered  $(i,j,k)$ . source"},{"id":1199,"pagetitle":"Metric manifold","title":"Manifolds.log_local_metric_density","ref":"/manifolds/stable/manifolds/#Manifolds.log_local_metric_density-Tuple{AbstractManifold, Any, AbstractBasis}","content":" Manifolds.log_local_metric_density  ‚Äî  Method log_local_metric_density(M::AbstractManifold, p, B::AbstractBasis) Return the natural logarithm of the metric density  $œÅ$  of  M  at  p , which is given by  $œÅ = \\log \\sqrt{|\\det [g_{ij}]|}$  for the metric tensor expressed in basis  B . source"},{"id":1200,"pagetitle":"Metric manifold","title":"Manifolds.metric","ref":"/manifolds/stable/manifolds/#Manifolds.metric-Tuple{MetricManifold}","content":" Manifolds.metric  ‚Äî  Method metric(M::MetricManifold) Get the metric  $g$  of the manifold  M . source"},{"id":1201,"pagetitle":"Metric manifold","title":"Manifolds.ricci_curvature","ref":"/manifolds/stable/manifolds/#Manifolds.ricci_curvature-Tuple{AbstractManifold, Any, AbstractBasis}","content":" Manifolds.ricci_curvature  ‚Äî  Method ricci_curvature(M::AbstractManifold, p, B::AbstractBasis; backend::AbstractDiffBackend = default_differential_backend()) Compute the Ricci scalar curvature of the manifold  M  at the point  p  using basis  B . The curvature is computed as the trace of the Ricci curvature tensor with respect to the metric, that is  $R=g^{ij}R_{ij}$  where  $R$  is the scalar Ricci curvature at  p ,  $g^{ij}$  is the inverse local metric (see  inverse_local_metric ) at  p  and  $R_{ij}$  is the Riccie curvature tensor, see  ricci_tensor . Both the tensor and inverse local metric are expressed in local coordinates defined by  B , and the formula uses the Einstein summation convention. source"},{"id":1202,"pagetitle":"Metric manifold","title":"Manifolds.sharp","ref":"/manifolds/stable/manifolds/#Manifolds.sharp-Tuple{MetricManifold, Any, CoTFVector}","content":" Manifolds.sharp  ‚Äî  Method sharp(N::MetricManifold{M,G}, p, Œæ::CoTFVector) Compute the musical isomorphism to transform the cotangent vector  Œæ  from the  AbstractManifold M  equipped with  AbstractMetric G  to a tangent by computing \\[Œæ^‚ôØ = G_p^{-1} Œæ,\\] where  $G_p$  is the local matrix representation of  G , i.e. one employs  inverse_local_metric  here to obtain  $G_p^{-1}$ . source"},{"id":1203,"pagetitle":"Metric manifold","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{MetricManifold, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(N::MetricManifold{M,G}, p, X, Y) Compute the inner product of  X  and  Y  from the tangent space at  p  on the  AbstractManifold M  using the  AbstractMetric G . If  M  has  G  as its  IsDefaultMetric  trait, this is done using  inner(M, p, X, Y) , otherwise the  local_metric (M, p)  is employed as \\[g_p(X, Y) = ‚ü®X, G_p Y‚ü©,\\] where  $G_p$  is the loal matrix representation of the  AbstractMetric G . source"},{"id":1204,"pagetitle":"Metric manifold","title":"Metrics, charts and bases of vector spaces","ref":"/manifolds/stable/manifolds/#Metrics,-charts-and-bases-of-vector-spaces","content":" Metrics, charts and bases of vector spaces Metric-related functions, similarly to connection-related functions, need to operate in a basis of a vector space, see  here . Metric-related functions can take bases of associated tangent spaces as arguments. For example  local_metric  can take the basis of the tangent space it is supposed to operate on instead of a custom basis of the space of symmetric bilinear operators."},{"id":1207,"pagetitle":"Multinomial matrices","title":"Multinomial matrices","ref":"/manifolds/stable/manifolds/#Multinomial-matrices","content":" Multinomial matrices"},{"id":1208,"pagetitle":"Multinomial matrices","title":"Manifolds.MultinomialMatrices","ref":"/manifolds/stable/manifolds/#Manifolds.MultinomialMatrices","content":" Manifolds.MultinomialMatrices  ‚Äî  Type MultinomialMatrices{n,m} <: AbstractPowerManifold{‚Ñù} The multinomial manifold consists of  m  column vectors, where each column is of length  n  and unit norm, i.e. \\[\\mathcal{MN}(n,m) \\coloneqq \\bigl\\{\n    p ‚àà ‚Ñù^{n√óm}\\ \\big|\\ p_{i,j} > 0 \\text{ for all } i=1,‚Ä¶,n, j=1,‚Ä¶,m\n    \\text{ and } p^{\\mathrm{T}}\\mathbb{1}_m = \\mathbb{1}_n\\bigr\\},\\] where  $\\mathbb{1}_k$  is the vector of length  $k$  containing ones. This yields exactly the same metric as considering the product metric of the probablity vectors, i.e.  PowerManifold  of the  $(n-1)$ -dimensional  ProbabilitySimplex . The  ProbabilitySimplex  is stored internally within  M.manifold , such that all functions of  AbstractPowerManifold   can be used directly. Constructor MultinomialMatrices(n::Int, m::Int; parameter::Symbol=:type) Generate the manifold of matrices  $‚Ñù^{n√óm}$  such that the  $m$  columns are discrete probability distributions, i.e. sum up to one. parameter : whether a type parameter should be used to store  n  and  m . By default size is stored in type. Value can either be  :field  or  :type . source"},{"id":1209,"pagetitle":"Multinomial matrices","title":"Functions","ref":"/manifolds/stable/manifolds/#Functions","content":" Functions Most functions are directly implemented for an  AbstractPowerManifold   with  ArrayPowerRepresentation  except the following special cases:"},{"id":1210,"pagetitle":"Multinomial matrices","title":"ManifoldDiff.riemannian_gradient","ref":"/manifolds/stable/manifolds/#ManifoldDiff.riemannian_gradient-Tuple{MultinomialMatrices, Any, Any}","content":" ManifoldDiff.riemannian_gradient  ‚Äî  Method riemannian_gradient(M::MultinomialMatrices, p, Y; kwargs...) Let  $Y$  denote the Euclidean gradient of a function  $\\tilde f$  defined in the embedding neighborhood of  M , then the Riemannian gradient is given by Equation 5 of [ DH19 ] as \\[  \\operatorname{grad} f(p) = \\proj_{T_p\\mathcal M}(Y‚äôp)\\] where  $‚äô$  denotes the Hadamard or elementwise product. source"},{"id":1211,"pagetitle":"Multinomial matrices","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{MultinomialMatrices, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::MultinomialMatrices, p) Checks whether  p  is a valid point on the  MultinomialMatrices (m,n) M , i.e. is a matrix of  m  discrete probability distributions as columns from  $‚Ñù^n$ , i.e. each column is a point from  ProbabilitySimplex (n-1) . source"},{"id":1212,"pagetitle":"Multinomial matrices","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{MultinomialMatrices, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::MultinomialMatrices p, X; kwargs...) Checks whether  X  is a valid tangent vector to  p  on the  MultinomialMatrices M . This means, that  p  is valid, that  X  is of correct dimension and columnswise a tangent vector to the columns of  p  on the  ProbabilitySimplex . source"},{"id":1215,"pagetitle":"Multinomial doubly stochastic matrices","title":"Multinomial doubly stochastic matrices","ref":"/manifolds/stable/manifolds/#Multinomial-doubly-stochastic-matrices","content":" Multinomial doubly stochastic matrices"},{"id":1216,"pagetitle":"Multinomial doubly stochastic matrices","title":"Manifolds.AbstractMultinomialDoublyStochastic","ref":"/manifolds/stable/manifolds/#Manifolds.AbstractMultinomialDoublyStochastic","content":" Manifolds.AbstractMultinomialDoublyStochastic  ‚Äî  Type AbstractMultinomialDoublyStochastic <: AbstractDecoratorManifold{‚Ñù} A common type for manifolds that are doubly stochastic, for example by direct constraint  MultinomialDoubleStochastic  or by symmetry  MultinomialSymmetric , or additionally by symmetric positive definiteness  MultinomialSymmetricPositiveDefinite  as long as they are also modeled as  IsIsometricEmbeddedManifold . That way they share the inner product (just by restriction), and even the Riemannian gradient source"},{"id":1217,"pagetitle":"Multinomial doubly stochastic matrices","title":"Manifolds.MultinomialDoubleStochastic","ref":"/manifolds/stable/manifolds/#Manifolds.MultinomialDoubleStochastic","content":" Manifolds.MultinomialDoubleStochastic  ‚Äî  Type MultinomialDoublyStochastic{T} <: AbstractMultinomialDoublyStochastic The set of doubly stochastic multinomial matrices consists of all  $n√ón$  matrices with stochastic columns and rows, i.e. \\[\\begin{aligned}\n\\mathcal{DP}(n) \\coloneqq \\bigl\\{p ‚àà ‚Ñù^{n√ón}\\ \\big|\\ &p_{i,j} > 0 \\text{ for all } i=1,‚Ä¶,n, j=1,‚Ä¶,m,\\\\\n& p\\mathbf{1}_n = p^{\\mathrm{T}}\\mathbf{1}_n = \\mathbf{1}_n\n\\bigr\\},\n\\end{aligned}\\] where  $\\mathbf{1}_n$  is the vector of length  $n$  containing ones. The tangent space can be written as \\[T_p\\mathcal{DP}(n) \\coloneqq \\bigl\\{\nX ‚àà ‚Ñù^{n√ón}\\ \\big|\\ X = X^{\\mathrm{T}} \\text{ and }\nX\\mathbf{1}_n = X^{\\mathrm{T}}\\mathbf{1}_n = \\mathbf{0}_n\n\\bigr\\},\\] where  $\\mathbf{0}_n$  is the vector of length  $n$  containing zeros. More details can be found in Section III [ DH19 ]. Constructor MultinomialDoubleStochastic(n::Int; parameter::Symbol=:type) Generate the manifold of matrices  $‚Ñù^{n√ón}$  that are doubly stochastic and symmetric. source"},{"id":1218,"pagetitle":"Multinomial doubly stochastic matrices","title":"Base.rand","ref":"/manifolds/stable/manifolds/#Base.rand-Tuple{MultinomialDoubleStochastic}","content":" Base.rand  ‚Äî  Method rand(::MultinomialDoubleStochastic; vector_at=nothing, œÉ::Real=1.0, kwargs...) Generate random points on the  MultinomialDoubleStochastic  manifold or tangent vectors at the point  vector_at  if that is not  nothing . Let  $n√ón$  denote the matrix dimension of the  MultinomialDoubleStochastic . When  vector_at  is nothing, this is done by generating a random matrix rand(n,n)  with positive entries and projecting it onto the manifold. The  kwargs...  are passed to this projection. When  vector_at  is not  nothing , a random matrix in the ambient space is generated and projected onto the tangent space source"},{"id":1219,"pagetitle":"Multinomial doubly stochastic matrices","title":"ManifoldDiff.riemannian_gradient","ref":"/manifolds/stable/manifolds/#ManifoldDiff.riemannian_gradient-Tuple{Manifolds.AbstractMultinomialDoublyStochastic, Any, Any}","content":" ManifoldDiff.riemannian_gradient  ‚Äî  Method riemannian_gradient(M::AbstractMultinomialDoublyStochastic, p, Y; kwargs...) Let  $Y$  denote the Euclidean gradient of a function  $\\tilde f$  defined in the embedding neighborhood of  M , then the Riemannian gradient is given by Lemma 1 [ DH19 ] as \\[  \\operatorname{grad} f(p) = \\proj_{T_p\\mathcal M}(Y‚äôp)\\] where  $‚äô$  denotes the Hadamard or elementwise product, and the projection is the projection onto the tangent space of the corresponding manifold. source"},{"id":1220,"pagetitle":"Multinomial doubly stochastic matrices","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{MultinomialDoubleStochastic, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::MultinomialDoubleStochastic, p) Checks whether  p  is a valid point on the  MultinomialDoubleStochastic (n) M , i.e. is a  matrix with positive entries whose rows and columns sum to one. source"},{"id":1221,"pagetitle":"Multinomial doubly stochastic matrices","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{MultinomialDoubleStochastic, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::MultinomialDoubleStochastic p, X; kwargs...) Checks whether  X  is a valid tangent vector to  p  on the  MultinomialDoubleStochastic M . This means, that  p  is valid, that  X  is of correct dimension and sums to zero along any column or row. source"},{"id":1222,"pagetitle":"Multinomial doubly stochastic matrices","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{MultinomialDoubleStochastic}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::MultinomialDoubleStochastic) Return false.  MultinomialDoubleStochastic  is not a flat manifold. source"},{"id":1223,"pagetitle":"Multinomial doubly stochastic matrices","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{MultinomialDoubleStochastic}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::MultinomialDoubleStochastic) returns the dimension of the  MultinomialDoubleStochastic  manifold namely \\[\\operatorname{dim}_{\\mathcal{DP}(n)} = (n-1)^2.\\] source"},{"id":1224,"pagetitle":"Multinomial doubly stochastic matrices","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Manifolds.AbstractMultinomialDoublyStochastic, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(\n    M::AbstractMultinomialDoublyStochastic,\n    p;\n    maxiter = 100,\n    tolerance = eps(eltype(p))\n) project a matrix  p  with positive entries applying Sinkhorn's algorithm. Note that this projct method ‚Äì different from the usual case, accepts keywords. source"},{"id":1225,"pagetitle":"Multinomial doubly stochastic matrices","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{MultinomialDoubleStochastic, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::MultinomialDoubleStochastic, p, Y) Project  Y  onto the tangent space at  p  on the  MultinomialDoubleStochastic M , return the result in  X . The formula reads \\[    \\operatorname{proj}_p(Y) = Y - (Œ±\\mathbf{1}_n^{\\mathrm{T}} + \\mathbf{1}_nŒ≤^{\\mathrm{T}}) ‚äô p,\\] where  $‚äô$  denotes the Hadamard or elementwise product and  $\\mathbb{1}_n$  is the vector of length  $n$  containing ones. The two vectors  $Œ±,Œ≤ ‚àà ‚Ñù^{n√ón}$  are computed as a solution (typically using the left pseudo inverse) of \\[    \\begin{pmatrix} I_n & p\\\\p^{\\mathrm{T}} & I_n \\end{pmatrix}\n    \\begin{pmatrix} Œ±\\\\ Œ≤\\end{pmatrix}\n    =\n    \\begin{pmatrix} Y\\mathbf{1}\\\\Y^{\\mathrm{T}}\\mathbf{1}\\end{pmatrix},\\] where  $I_n$  is the  $n√ón$  unit matrix and  $\\mathbf{1}_n$  is the vector of length  $n$  containing ones. source"},{"id":1226,"pagetitle":"Multinomial doubly stochastic matrices","title":"ManifoldsBase.representation_size","ref":"/manifolds/stable/manifolds/#ManifoldsBase.representation_size-Tuple{Manifolds.AbstractMultinomialDoublyStochastic}","content":" ManifoldsBase.representation_size  ‚Äî  Method representation_size(M::AbstractMultinomialDoublyStochastic) return the representation size of doubly stochastic matrices, whic are embedded in the  $‚Ñù^{n√ón}$  matrices and hence the answer here is `` source"},{"id":1227,"pagetitle":"Multinomial doubly stochastic matrices","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{MultinomialDoubleStochastic, Any, Any, ProjectionRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::MultinomialDoubleStochastic, p, X, ::ProjectionRetraction) compute a projection based retraction by projecting  $p\\odot\\exp(X‚®∏p)$  back onto the manifold, where  $‚äô,‚®∏$  are elementwise multiplication and division, respectively. Similarly,  $\\exp$  refers to the elementwise exponentiation. source"},{"id":1228,"pagetitle":"Multinomial doubly stochastic matrices","title":"Literature","ref":"/manifolds/stable/manifolds/#Literature","content":" Literature [DH19] A.¬†Douik and B.¬†Hassibi.  Manifold Optimization Over the Set of Doubly Stochastic Matrices: A Second-Order Geometry .  IEEE¬†Transactions¬†on¬†Signal¬†Processing  67 , 5761‚Äì5774  (2019),  arXiv:1802.02628 ."},{"id":1231,"pagetitle":"Multinomial symmetric matrices","title":"Multinomial symmetric matrices","ref":"/manifolds/stable/manifolds/#Multinomial-symmetric-matrices","content":" Multinomial symmetric matrices"},{"id":1232,"pagetitle":"Multinomial symmetric matrices","title":"Manifolds.MultinomialSymmetric","ref":"/manifolds/stable/manifolds/#Manifolds.MultinomialSymmetric","content":" Manifolds.MultinomialSymmetric  ‚Äî  Type MultinomialSymmetric{T} <: AbstractMultinomialDoublyStochastic The multinomial symmetric matrices manifold consists of all symmetric  $n√ón$  matrices with positive entries such that each column sums to one, i.e. \\[\\begin{aligned}\n\\mathcal{SP}(n) \\coloneqq \\bigl\\{p ‚àà ‚Ñù^{n√ón}\\ \\big|\\ &p_{i,j} > 0 \\text{ for all } i=1,‚Ä¶,n, j=1,‚Ä¶,m,\\\\\n& p^\\mathrm{T} = p,\\\\\n& p\\mathbf{1}_n = \\mathbf{1}_n\n\\bigr\\},\n\\end{aligned}\\] where  $\\mathbf{1}_n$  is the vector of length  $n$  containing ones. It is modeled as  IsIsometricEmbeddedManifold . via the  AbstractMultinomialDoublyStochastic  type, since it shares a few functions also with  AbstractMultinomialDoublyStochastic , most and foremost projection of a point from the embedding onto the manifold. The tangent space can be written as \\[T_p\\mathcal{SP}(n) \\coloneqq \\bigl\\{\nX ‚àà ‚Ñù^{n√ón}\\ \\big|\\ X = X^{\\mathrm{T}} \\text{ and }\nX\\mathbf{1}_n = \\mathbf{0}_n\n\\bigr\\},\\] where  $\\mathbf{0}_n$  is the vector of length  $n$  containing zeros. More details can be found in Section IV [ DH19 ]. Constructor MultinomialSymmetric(n) Generate the manifold of matrices  $‚Ñù^{n√ón}$  that are doubly stochastic and symmetric. source"},{"id":1233,"pagetitle":"Multinomial symmetric matrices","title":"Base.rand","ref":"/manifolds/stable/manifolds/#Base.rand-Tuple{MultinomialSymmetric}","content":" Base.rand  ‚Äî  Method rand(::MultinomialSymmetric; vector_at=nothing, œÉ::Real=1.0, kwargs...) Generate random points on the  MultinomialSymmetric  manifold or tangent vectors at the point  vector_at  if that is not  nothing . Let  $n√ón$  denote the matrix dimension of the  MultinomialSymmetric . When  vector_at  is nothing, this is done by generating a random matrix  rand(n, n)  with positive entries and projecting it onto the manifold. The  kwargs...  are passed to this projection. When  vector_at  is not  nothing , a random matrix in the ambient space is generated and projected onto the tangent space source"},{"id":1234,"pagetitle":"Multinomial symmetric matrices","title":"ManifoldDiff.riemannian_Hessian","ref":"/manifolds/stable/manifolds/#ManifoldDiff.riemannian_Hessian-Tuple{MultinomialSymmetric, Vararg{Any, 4}}","content":" ManifoldDiff.riemannian_Hessian  ‚Äî  Method Y = riemannian_Hessian(M::MultinomialSymmetric, p, G, H, X)\nriemannian_Hessian!(M::MultinomialSymmetric, Y, p, G, H, X) Compute the Riemannian Hessian  $\\operatorname{Hess} f(p)[X]$  given the Euclidean gradient  $‚àá f(\\tilde p)$  in  G  and the Euclidean Hessian  $‚àá^2 f(\\tilde p)[\\tilde X]$  in  H , where  $\\tilde p, \\tilde X$  are the representations of  $p,X$  in the embedding,. The Riemannian Hessian can be computed as stated in Corollary 3 [ DH19 ]. source"},{"id":1235,"pagetitle":"Multinomial symmetric matrices","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{MultinomialSymmetric, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::MultinomialSymmetric, p) Checks whether  p  is a valid point on the  MultinomialSymmetric (m,n) M , i.e. is a symmetric matrix with positive entries whose rows sum to one. source"},{"id":1236,"pagetitle":"Multinomial symmetric matrices","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{MultinomialSymmetric, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::MultinomialSymmetric p, X; kwargs...) Checks whether  X  is a valid tangent vector to  p  on the  MultinomialSymmetric M . This means, that  p  is valid, that  X  is of correct dimension, symmetric, and sums to zero along any row. source"},{"id":1237,"pagetitle":"Multinomial symmetric matrices","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{MultinomialSymmetric}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::MultinomialSymmetric) Return false.  MultinomialSymmetric  is not a flat manifold. source"},{"id":1238,"pagetitle":"Multinomial symmetric matrices","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{MultinomialSymmetric}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::MultinomialSymmetric) returns the dimension of the  MultinomialSymmetric  manifold namely \\[\\operatorname{dim}_{\\mathcal{SP}(n)} = \\frac{n(n-1)}{2}.\\] source"},{"id":1239,"pagetitle":"Multinomial symmetric matrices","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{MultinomialSymmetric, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::MultinomialSymmetric, p, Y) Project  Y  onto the tangent space at  p  on the  MultinomialSymmetric M , return the result in  X . The formula from [ DH19 ], Sec. VI reads \\[    \\operatorname{proj}_p(Y) = Y - (Œ±\\mathbf{1}_n^{\\mathrm{T}} + \\mathbf{1}_n Œ±^{\\mathrm{T}}) ‚äô p,\\] where  $‚äô$  denotes the Hadamard or elementwise product and  $\\mathbb{1}_n$  is the vector of length  $n$  containing ones. The two vector  $Œ± ‚àà ‚Ñù^{n√ón}$  is given by solving \\[    (I_n+p)Œ± =  Y\\mathbf{1},\\] where  $I_n$  is teh  $n√ón$  unit matrix and  $\\mathbf{1}_n$  is the vector of length  $n$  containing ones. source"},{"id":1240,"pagetitle":"Multinomial symmetric matrices","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{MultinomialSymmetric, Any, Any, ProjectionRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::MultinomialSymmetric, p, X, ::ProjectionRetraction) compute a projection based retraction by projecting  $p‚äô\\exp(X‚®∏p)$  back onto the manifold, where  $‚äô,‚®∏$  are elementwise multiplication and division, respectively. Similarly,  $\\exp$  refers to the elementwise exponentiation. source"},{"id":1241,"pagetitle":"Multinomial symmetric matrices","title":"Literature","ref":"/manifolds/stable/manifolds/#Literature","content":" Literature [DH19] A.¬†Douik and B.¬†Hassibi.  Manifold Optimization Over the Set of Doubly Stochastic Matrices: A Second-Order Geometry .  IEEE¬†Transactions¬†on¬†Signal¬†Processing  67 , 5761‚Äì5774  (2019),  arXiv:1802.02628 ."},{"id":1244,"pagetitle":"Multinomial symmetric positive definite matrices","title":"Multinomial symmetric positive definite matrices","ref":"/manifolds/stable/manifolds/#Multinomial-symmetric-positive-definite-matrices","content":" Multinomial symmetric positive definite matrices"},{"id":1245,"pagetitle":"Multinomial symmetric positive definite matrices","title":"Manifolds.MultinomialSymmetricPositiveDefinite","ref":"/manifolds/stable/manifolds/#Manifolds.MultinomialSymmetricPositiveDefinite","content":" Manifolds.MultinomialSymmetricPositiveDefinite  ‚Äî  Type MultinomialSymmetricPositiveDefinite <: AbstractMultinomialDoublyStochastic The symmetric positive definite multinomial matrices manifold consists of all symmetric  $n√ón$  matrices with positive eigenvalues, and positive entries such that each column sums to one, i.e. \\[\\begin{aligned}\n\\mathcal{SP}^+(n) \\coloneqq \\bigl\\{\n    p ‚àà ‚Ñù^{n√ón}\\ \\big|\\ &p_{i,j} > 0 \\text{ for all } i=1,‚Ä¶,n, j=1,‚Ä¶,m,\\\\\n& p^\\mathrm{T} = p,\\\\\n& p\\mathbf{1}_n = \\mathbf{1}_n\\\\\na^\\mathrm{T}pa > 0 \\text{ for all } a ‚àà ‚Ñù^{n}\\backslash\\{\\mathbf{0}_n\\}\n\\bigr\\},\n\\end{aligned}\\] where  $\\mathbf{1}_n$  and  $\\mathbr{0}_n$  are the vectors of length  $n$  containing ones and zeros, respectively. More details about this manifold can be found in [ DH19 ]. Constructor MultinomialSymmetricPositiveDefinite(n) Generate the manifold of matrices  $\\mathbb R^{n√ón}$  that are symmetric, positive definite, and doubly stochastic. source"},{"id":1246,"pagetitle":"Multinomial symmetric positive definite matrices","title":"Random.rand!","ref":"/manifolds/stable/manifolds/#Random.rand!-Tuple{Random.AbstractRNG, MultinomialSymmetricPositiveDefinite, AbstractMatrix}","content":" Random.rand!  ‚Äî  Method Random.rand!(\n    rng::AbstractRNG,\n    M::MultinomialSymmetricPositiveDefinite,\n    p::AbstractMatrix,\n) Generate a random point on  MultinomialSymmetricPositiveDefinite  manifold. The steps are as follows: Generate a random  totally positive matrix   a. Construct a vector  L  of  n  random positive increasing real numbers.  b. Construct the  Vandermonde matrix V  based on the sequence  L .  c. Perform LU factorization of  V  in such way that both L and U components have     positive elements.  d. Convert the LU factorization into LDU factorization by taking the diagonal of U     and dividing U by it,  V=LDU .  e. Construct a new matrix  R = UDL  which is totally positive. Project the totally positive matrix  R  onto the manifold of  MultinomialDoubleStochastic  matrices. Symmetrize the projected matrix and return the result. This method roughly follows the procedure described in https://math.stackexchange.com/questions/2773460/how-to-generate-a-totally-positive-matrix-randomly-using-software-like-maple source"},{"id":1247,"pagetitle":"Multinomial symmetric positive definite matrices","title":"Literature","ref":"/manifolds/stable/manifolds/#Literature","content":" Literature [DH19] A.¬†Douik and B.¬†Hassibi.  Manifold Optimization Over the Set of Doubly Stochastic Matrices: A Second-Order Geometry .  IEEE¬†Transactions¬†on¬†Signal¬†Processing  67 , 5761‚Äì5774  (2019),  arXiv:1802.02628 ."},{"id":1250,"pagetitle":"Oblique manifold","title":"Oblique manifold","ref":"/manifolds/stable/manifolds/#Oblique-manifold","content":" Oblique manifold The oblique manifold  $\\mathcal{OB}(n,m)$  is modeled as an  AbstractPowerManifold   of the (real-valued)  Sphere  and uses  ArrayPowerRepresentation . Points on the torus are hence matrices,  $x ‚àà ‚Ñù^{n,m}$ ."},{"id":1251,"pagetitle":"Oblique manifold","title":"Manifolds.Oblique","ref":"/manifolds/stable/manifolds/#Manifolds.Oblique","content":" Manifolds.Oblique  ‚Äî  Type Oblique{T,ùîΩ,S} <: AbstractPowerManifold{ùîΩ} The oblique manifold  $\\mathcal{OB}(n,m)$  is the set of ùîΩ-valued matrices with unit norm column endowed with the metric from the embedding. This yields exactly the same metric as considering the product metric of the unit norm vectors, i.e.  PowerManifold  of the  $(n-1)$ -dimensional  Sphere . The  Sphere  is stored internally within  M.manifold , such that all functions of  AbstractPowerManifold   can be used directly. Constructor Oblique(n::Int, m::Int, field::AbstractNumbers=‚Ñù; parameter::Symbol=:type) Generate the manifold of matrices  $\\mathbb R^{n√óm}$  such that the  $m$  columns are unit vectors, i.e. from the  Sphere (n-1) . source"},{"id":1252,"pagetitle":"Oblique manifold","title":"Functions","ref":"/manifolds/stable/manifolds/#Functions","content":" Functions Most functions are directly implemented for an  AbstractPowerManifold   with  ArrayPowerRepresentation  except the following special cases:"},{"id":1253,"pagetitle":"Oblique manifold","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{Oblique, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::Oblique, p) Checks whether  p  is a valid point on the  Oblique {m,n} M , i.e. is a matrix of  m  unit columns from  $\\mathbb R^{n}$ , i.e. each column is a point from  Sphere (n-1) . source"},{"id":1254,"pagetitle":"Oblique manifold","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{Oblique, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::Oblique p, X; kwargs...) Checks whether  X  is a valid tangent vector to  p  on the  Oblique M . This means, that  p  is valid, that  X  is of correct dimension and columnswise a tangent vector to the columns of  p  on the  Sphere . source"},{"id":1255,"pagetitle":"Oblique manifold","title":"ManifoldsBase.parallel_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_to-Tuple{Oblique, Any, Any, Any}","content":" ManifoldsBase.parallel_transport_to  ‚Äî  Method parallel_transport_to(M::Oblique, p, X, q) Compute the parallel transport on the  Oblique  manifold by doing a column wise parallel transport on the  Sphere source"},{"id":1258,"pagetitle":"Positive numbers","title":"Positive Numbers","ref":"/manifolds/stable/manifolds/#Positive-Numbers","content":" Positive Numbers The manifold  PositiveNumbers  represents positive numbers with hyperbolic geometry. Additionally, there are also short forms for its corresponding  PowerManifold s, i.e.  PositiveVectors ,  PositiveMatrices , and  PositiveArrays ."},{"id":1259,"pagetitle":"Positive numbers","title":"Manifolds.PositiveNumbers","ref":"/manifolds/stable/manifolds/#Manifolds.PositiveNumbers","content":" Manifolds.PositiveNumbers  ‚Äî  Type PositiveNumbers <: AbstractManifold{‚Ñù} The hyperbolic manifold of positive numbers  $H^1$  is a the hyperbolic manifold represented by just positive numbers. Constructor PositiveNumbers() Generate the  ‚Ñù -valued hyperbolic model represented by positive positive numbers. To use this with arrays (1-element arrays), please use  SymmetricPositiveDefinite (1) . source"},{"id":1260,"pagetitle":"Positive numbers","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{PositiveNumbers, Any, Any}","content":" Base.exp  ‚Äî  Method exp(M::PositiveNumbers, p, X) Compute the exponential map on the  PositiveNumbers M . \\[\\exp_p X = p\\operatorname{exp}(X/p).\\] source"},{"id":1261,"pagetitle":"Positive numbers","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{PositiveNumbers, Any, Any}","content":" Base.log  ‚Äî  Method log(M::PositiveNumbers, p, q) Compute the logarithmic map on the  PositiveNumbers M . \\[\\log_p q = p\\log\\frac{q}{p}.\\] source"},{"id":1262,"pagetitle":"Positive numbers","title":"ManifoldDiff.riemannian_Hessian","ref":"/manifolds/stable/manifolds/#ManifoldDiff.riemannian_Hessian-Tuple{PositiveNumbers, Vararg{Any, 4}}","content":" ManifoldDiff.riemannian_Hessian  ‚Äî  Method riemannian_Hessian(M::SymmetricPositiveDefinite, p, G, H, X) The Riemannian Hessian can be computed as stated in Eq. (7.3) [ Ngu23 ]. Let  $\\nabla f(p)$  denote the Euclidean gradient  G ,  $\\nabla^2 f(p)[X]$  the Euclidean Hessian  H . Then the formula reads \\[    \\operatorname{Hess}f(p)[X] = p\\bigl(‚àá^2 f(p)[X]\\bigr)p + X\\bigl(‚àáf(p)\\bigr)p\\] source"},{"id":1263,"pagetitle":"Positive numbers","title":"Manifolds.PositiveArrays","ref":"/manifolds/stable/manifolds/#Manifolds.PositiveArrays-Union{Tuple{Vararg{Int64, I}}, Tuple{I}} where I","content":" Manifolds.PositiveArrays  ‚Äî  Method PositiveArrays(n‚ÇÅ, n‚ÇÇ, ..., n·µ¢; parameter::Symbol=:type) Generate the manifold of  i -dimensional arrays with positive entries. This manifold is modeled as a  PowerManifold  of  PositiveNumbers . parameter : whether a type parameter should be used to store  n . By default size is stored in a type parameter. Value can either be  :field  or  :type . source"},{"id":1264,"pagetitle":"Positive numbers","title":"Manifolds.PositiveMatrices","ref":"/manifolds/stable/manifolds/#Manifolds.PositiveMatrices-Tuple{Integer, Integer}","content":" Manifolds.PositiveMatrices  ‚Äî  Method PositiveMatrices(m::Integer, n::Integer; parameter::Symbol=:type) Generate the manifold of matrices with positive entries. This manifold is modeled as a  PowerManifold  of  PositiveNumbers . parameter : whether a type parameter should be used to store  n . By default size is stored in a type parameter. Value can either be  :field  or  :type . source"},{"id":1265,"pagetitle":"Positive numbers","title":"Manifolds.PositiveVectors","ref":"/manifolds/stable/manifolds/#Manifolds.PositiveVectors-Tuple{Integer}","content":" Manifolds.PositiveVectors  ‚Äî  Method PositiveVectors(n::Integer; parameter::Symbol=:type) Generate the manifold of vectors with positive entries. This manifold is modeled as a  PowerManifold  of  PositiveNumbers . parameter : whether a type parameter should be used to store  n . By default size is stored in a type parameter. Value can either be  :field  or  :type . source"},{"id":1266,"pagetitle":"Positive numbers","title":"Manifolds.manifold_volume","ref":"/manifolds/stable/manifolds/#Manifolds.manifold_volume-Tuple{PositiveNumbers}","content":" Manifolds.manifold_volume  ‚Äî  Method manifold_volume(M::PositiveNumbers) Return volume of  PositiveNumbers M , i.e.  Inf . source"},{"id":1267,"pagetitle":"Positive numbers","title":"Manifolds.volume_density","ref":"/manifolds/stable/manifolds/#Manifolds.volume_density-Tuple{PositiveNumbers, Any, Any}","content":" Manifolds.volume_density  ‚Äî  Method volume_density(M::PositiveNumbers, p, X) Compute volume density function of  PositiveNumbers . The formula reads \\[\\theta_p(X) = \\exp(X / p)\\] source"},{"id":1268,"pagetitle":"Positive numbers","title":"ManifoldsBase.change_metric","ref":"/manifolds/stable/manifolds/#ManifoldsBase.change_metric-Tuple{PositiveNumbers, EuclideanMetric, Any, Any}","content":" ManifoldsBase.change_metric  ‚Äî  Method change_metric(M::PositiveNumbers, E::EuclideanMetric, p, X) Given a tangent vector  $X ‚àà T_p\\mathcal M$  representing a linear function with respect to the  EuclideanMetric g_E , this function changes the representer into the one with respect to the positivity metric of  PositiveNumbers M . For all  $Z,Y$  we are looking for the function  $c$  on the tangent space at  $p$  such that \\[    ‚ü®Z,Y‚ü© = XY = \\frac{c(Z)c(Y)}{p^2} = g_p(c(Y),c(Z))\\] and hence  $C(X) = pX$ . source"},{"id":1269,"pagetitle":"Positive numbers","title":"ManifoldsBase.change_representer","ref":"/manifolds/stable/manifolds/#ManifoldsBase.change_representer-Tuple{PositiveNumbers, EuclideanMetric, Any, Any}","content":" ManifoldsBase.change_representer  ‚Äî  Method change_representer(M::PositiveNumbers, E::EuclideanMetric, p, X) Given a tangent vector  $X ‚àà T_p\\mathcal M$  representing a linear function with respect to the  EuclideanMetric g_E , this function changes the representer into the one with respect to the positivity metric representation of  PositiveNumbers M . For all tangent vectors  $Y$  the result  $Z$  has to fulfill \\[    ‚ü®X,Y‚ü© = XY = \\frac{ZY}{p^2} = g_p(YZ)\\] and hence  $Z = p^2X$ source"},{"id":1270,"pagetitle":"Positive numbers","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{PositiveNumbers, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::PositiveNumbers, p) Check whether  p  is a point on the  PositiveNumbers M , i.e.  $p>0$ . source"},{"id":1271,"pagetitle":"Positive numbers","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{PositiveNumbers, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::PositiveNumbers, p, X; kwargs...) Check whether  X  is a tangent vector in the tangent space of  p  on the  PositiveNumbers M . For the real-valued case represented by positive numbers, all  X  are valid, since the tangent space is the whole real line. For the complex-valued case  X  [...] source"},{"id":1272,"pagetitle":"Positive numbers","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{PositiveNumbers, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::PositiveNumbers, p, q) Compute the distance on the  PositiveNumbers M , which is \\[d(p,q) = \\Bigl\\lvert \\log \\frac{p}{q} \\Bigr\\rvert = \\lvert \\log p - \\log q\\rvert.\\] source"},{"id":1273,"pagetitle":"Positive numbers","title":"ManifoldsBase.get_coordinates","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_coordinates-Tuple{PositiveNumbers, Any, Any, DefaultOrthonormalBasis{‚Ñù}}","content":" ManifoldsBase.get_coordinates  ‚Äî  Method get_coordinates(::PositiveNumbers, p, X, ::DefaultOrthonormalBasis{‚Ñù}) Compute the coordinate of vector  X  which is tangent to  p  on the  PositiveNumbers  manifold. The formula is  $X / p$ . source"},{"id":1274,"pagetitle":"Positive numbers","title":"ManifoldsBase.get_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_vector-Tuple{PositiveNumbers, Any, Any, DefaultOrthonormalBasis{‚Ñù}}","content":" ManifoldsBase.get_vector  ‚Äî  Method get_vector(::PositiveNumbers, p, c, ::DefaultOrthonormalBasis{‚Ñù}) Compute the vector with coordinate  c  which is tangent to  p  on the  PositiveNumbers  manifold. The formula is  $p * c$ . source"},{"id":1275,"pagetitle":"Positive numbers","title":"ManifoldsBase.injectivity_radius","ref":"/manifolds/stable/manifolds/#ManifoldsBase.injectivity_radius-Tuple{PositiveNumbers}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(M::PositiveNumbers[, p]) Return the injectivity radius on the  PositiveNumbers M , i.e.  $\\infty$ . source"},{"id":1276,"pagetitle":"Positive numbers","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{PositiveNumbers, Vararg{Any}}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::PositiveNumbers, p, X, Y) Compute the inner product of the two tangent vectors  X,Y  from the tangent plane at  p  on the  PositiveNumbers M , i.e. \\[g_p(X,Y) = \\frac{XY}{p^2}.\\] source"},{"id":1277,"pagetitle":"Positive numbers","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{PositiveNumbers}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::PositiveNumbers) Return false.  PositiveNumbers  is not a flat manifold. source"},{"id":1278,"pagetitle":"Positive numbers","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{PositiveNumbers}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::PositiveNumbers) Return the dimension of the  PositiveNumbers M , i.e. of the 1-dimensional hyperbolic space, \\[\\dim(H^1) = 1\\] source"},{"id":1279,"pagetitle":"Positive numbers","title":"ManifoldsBase.parallel_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_to-Tuple{PositiveNumbers, Any, Any, Any}","content":" ManifoldsBase.parallel_transport_to  ‚Äî  Method parallel_transport_to(M::PositiveNumbers, p, X, q) Compute the parallel transport of  X  from the tangent space at  p  to the tangent space at  q  on the  PositiveNumbers M . \\[\\mathcal P_{q\\gets p}(X) = X‚ãÖ\\frac{q}{p}.\\] source"},{"id":1280,"pagetitle":"Positive numbers","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{PositiveNumbers, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::PositiveNumbers, p, X) Project a value  X  onto the tangent space of the point  p  on the  PositiveNumbers M , which is just the identity. source"},{"id":1283,"pagetitle":"Power manifold","title":"Power manifold","ref":"/manifolds/stable/manifolds/#PowerManifoldSection","content":" Power manifold A power manifold is based on a  AbstractManifold $\\mathcal M$  to build a  $\\mathcal M^{n_1√ón_2 √ó‚ãØ√ón_m}$ . In the case where  $m=1$  we can represent a manifold-valued vector of data of length  $n_1$ , for example a time series. The case where  $m=2$  is useful for representing manifold-valued matrices of data of size  $n_1√ón_2$ , for example certain types of images. There are three available representations for points and vectors on a power manifold: ArrayPowerRepresentation  (the default one), very efficient but only applicable when points on the underlying manifold are represented using plain  AbstractArray s. NestedPowerRepresentation , applicable to any manifold. It assumes that points on the underlying manifold are represented using mutable data types. NestedReplacingPowerRepresentation , applicable to any manifold. It does not mutate points on the underlying manifold, replacing them instead when appropriate. Below are some examples of usage of these representations."},{"id":1284,"pagetitle":"Power manifold","title":"Example","ref":"/manifolds/stable/manifolds/#Example","content":" Example There are two ways to store the data: in a multidimensional array or in a nested array. Let's look at an example for both. Let  $\\mathcal M$  be  Sphere(2)  the 2-sphere and we want to look at vectors of length 4."},{"id":1285,"pagetitle":"Power manifold","title":"ArrayPowerRepresentation","ref":"/manifolds/stable/manifolds/#ArrayPowerRepresentation","content":" ArrayPowerRepresentation For the default, the  ArrayPowerRepresentation , we store the data in a multidimensional array, using Manifolds\nM = PowerManifold(Sphere(2), 4)\np = cat([1.0, 0.0, 0.0],\n        [1/sqrt(2.0), 1/sqrt(2.0), 0.0],\n        [1/sqrt(2.0), 0.0, 1/sqrt(2.0)],\n        [0.0, 1.0, 0.0]\n    ,dims=2) 3√ó4 Matrix{Float64}:\n 1.0  0.707107  0.707107  0.0\n 0.0  0.707107  0.0       1.0\n 0.0  0.0       0.707107  0.0 which is a valid point i.e. is_point(M, p) true This can also be used in combination with  HybridArrays.jl  and  StaticArrays.jl , by setting using HybridArrays, StaticArrays\nq = HybridArray{Tuple{3,StaticArrays.Dynamic()},Float64,2}(p) 3√ó4 HybridArrays.HybridMatrix{3, StaticArraysCore.Dynamic(), Float64, 2, Matrix{Float64}} with indices SOneTo(3)√óBase.OneTo(4):\n 1.0  0.707107  0.707107  0.0\n 0.0  0.707107  0.0       1.0\n 0.0  0.0       0.707107  0.0 which is still a valid point on  M  and  PowerManifold  works with these, too. An advantage of this representation is that it is quite efficient, especially when a  HybridArray  (from the  HybridArrays.jl  package) is used to represent a point on the power manifold. A disadvantage is not being able to easily identify parts of the multidimensional array that correspond to a single point on the base manifold. Another problem is, that accessing a single point is  p[:, 1]  which might be unintuitive."},{"id":1286,"pagetitle":"Power manifold","title":"NestedPowerRepresentation","ref":"/manifolds/stable/manifolds/#NestedPowerRepresentation","content":" NestedPowerRepresentation For the  NestedPowerRepresentation  we can now do using Manifolds\nM = PowerManifold(Sphere(2), NestedPowerRepresentation(), 4)\np = [ [1.0, 0.0, 0.0],\n      [1/sqrt(2.0), 1/sqrt(2.0), 0.0],\n      [1/sqrt(2.0), 0.0, 1/sqrt(2.0)],\n      [0.0, 1.0, 0.0],\n    ] 4-element Vector{Vector{Float64}}:\n [1.0, 0.0, 0.0]\n [0.7071067811865475, 0.7071067811865475, 0.0]\n [0.7071067811865475, 0.0, 0.7071067811865475]\n [0.0, 1.0, 0.0] which is again a valid point so  is_point(M, p)  here also yields true. A disadvantage might be that with nested arrays one loses a little bit of performance. The data however is nicely encapsulated. Accessing the first data item is just  p[1] . For accessing points on power manifolds in both representations you can use  get_component  and  set_component!  functions. They work work both point representations. using Manifolds\nM = PowerManifold(Sphere(2), NestedPowerRepresentation(), 4)\np = [ [1.0, 0.0, 0.0],\n      [1/sqrt(2.0), 1/sqrt(2.0), 0.0],\n      [1/sqrt(2.0), 0.0, 1/sqrt(2.0)],\n      [0.0, 1.0, 0.0],\n    ]\nset_component!(M, p, [0.0, 0.0, 1.0], 4)\nget_component(M, p, 4) 3-element Vector{Float64}:\n 0.0\n 0.0\n 1.0"},{"id":1287,"pagetitle":"Power manifold","title":"NestedReplacingPowerRepresentation","ref":"/manifolds/stable/manifolds/#NestedReplacingPowerRepresentation","content":" NestedReplacingPowerRepresentation The final representation is the  NestedReplacingPowerRepresentation . It is similar to the  NestedPowerRepresentation  but it does not perform in-place operations on the points on the underlying manifold. The example below uses this representation to store points on a power manifold of the  SpecialEuclidean  group in-line in an  Vector  for improved efficiency. When having a mixture of both, i.e. an array structure that is nested (like  ¬¥NestedPowerRepresentation ) in the sense that the elements of the main vector are immutable, then changing the elements can not be done in an in-place way and hence  NestedReplacingPowerRepresentation  has to be used. using Manifolds, StaticArrays\nR2 = Rotations(2)\n\nG = SpecialEuclidean(2)\nN = 5\nGN = PowerManifold(G, NestedReplacingPowerRepresentation(), N)\n\nq = [1.0 0.0; 0.0 1.0]\np1 = [ArrayPartition(SVector{2,Float64}([i - 0.1, -i]), SMatrix{2,2,Float64}(exp(R2, q, hat(R2, q, i)))) for i in 1:N]\np2 = [ArrayPartition(SVector{2,Float64}([i - 0.1, -i]), SMatrix{2,2,Float64}(exp(R2, q, hat(R2, q, -i)))) for i in 1:N]\n\nX = similar(p1);\n\nlog!(GN, X, p1, p2) 5-element Vector{ArrayPartition{Float64, Tuple{StaticArraysCore.SVector{2, Float64}, StaticArraysCore.SMatrix{2, 2, Float64, 4}}}}:\n ([0.0, 0.0], [0.0 2.0; -2.0 0.0])\n ([0.0, 0.0], [0.0 -2.2831853071795862; 2.2831853071795862 0.0])\n ([0.0, 0.0], [0.0 -0.28318530717958645; 0.28318530717958645 0.0])\n ([0.0, 0.0], [0.0 1.7168146928204135; -1.7168146928204135 0.0])\n ([0.0, 0.0], [0.0 -2.566370614359173; 2.566370614359173 0.0])"},{"id":1288,"pagetitle":"Power manifold","title":"Types and Functions","ref":"/manifolds/stable/manifolds/#Types-and-Functions","content":" Types and Functions"},{"id":1289,"pagetitle":"Power manifold","title":"Manifolds.ArrayPowerRepresentation","ref":"/manifolds/stable/manifolds/#Manifolds.ArrayPowerRepresentation","content":" Manifolds.ArrayPowerRepresentation  ‚Äî  Type ArrayPowerRepresentation Representation of points and tangent vectors on a power manifold using multidimensional arrays where first dimensions are equal to  representation_size  of the wrapped manifold and the following ones are equal to the number of elements in each direction. Torus  uses this representation. source"},{"id":1290,"pagetitle":"Power manifold","title":"Manifolds.PowerFVectorDistribution","ref":"/manifolds/stable/manifolds/#Manifolds.PowerFVectorDistribution","content":" Manifolds.PowerFVectorDistribution  ‚Äî  Type PowerFVectorDistribution([type::VectorSpaceFiber], [x], distr) Generates a random vector at a  point  from vector space (a fiber of a tangent bundle) of type  type  using the power distribution of  distr . Vector space type and  point  can be automatically inferred from distribution  distr . source"},{"id":1291,"pagetitle":"Power manifold","title":"Manifolds.PowerMetric","ref":"/manifolds/stable/manifolds/#Manifolds.PowerMetric","content":" Manifolds.PowerMetric  ‚Äî  Type PowerMetric <: AbstractMetric Represent the  AbstractMetric  on an  AbstractPowerManifold , i.e. the inner product on the tangent space is the sum of the inner product of each elements tangent space of the power manifold. source"},{"id":1292,"pagetitle":"Power manifold","title":"Manifolds.PowerPointDistribution","ref":"/manifolds/stable/manifolds/#Manifolds.PowerPointDistribution","content":" Manifolds.PowerPointDistribution  ‚Äî  Type PowerPointDistribution(M::AbstractPowerManifold, distribution) Power distribution on manifold  M , based on  distribution . source"},{"id":1293,"pagetitle":"Power manifold","title":"ManifoldDiff.riemannian_Hessian","ref":"/manifolds/stable/manifolds/#ManifoldDiff.riemannian_Hessian-Tuple{AbstractPowerManifold, Vararg{Any, 4}}","content":" ManifoldDiff.riemannian_Hessian  ‚Äî  Method Y = riemannian_Hessian(M::AbstractPowerManifold, p, G, H, X)\nriemannian_Hessian!(M::AbstractPowerManifold, Y, p, G, H, X) Compute the Riemannian Hessian  $\\operatorname{Hess} f(p)[X]$  given the Euclidean gradient  $‚àá f(\\tilde p)$  in  G  and the Euclidean Hessian  $‚àá^2 f(\\tilde p)[\\tilde X]$  in  H , where  $\\tilde p, \\tilde X$  are the representations of  $p,X$  in the embedding,. On an abstract power manifold, this decouples and can be computed elementwise. source"},{"id":1294,"pagetitle":"Power manifold","title":"Manifolds.flat","ref":"/manifolds/stable/manifolds/#Manifolds.flat-Tuple{AbstractPowerManifold, Vararg{Any}}","content":" Manifolds.flat  ‚Äî  Method flat(M::AbstractPowerManifold, p, X) use the musical isomorphism to transform the tangent vector  X  from the tangent space at  p  on an  AbstractPowerManifold M  to a cotangent vector. This can be done elementwise for each entry of  X  (and  p ). source"},{"id":1295,"pagetitle":"Power manifold","title":"Manifolds.manifold_volume","ref":"/manifolds/stable/manifolds/#Manifolds.manifold_volume-Tuple{PowerManifold}","content":" Manifolds.manifold_volume  ‚Äî  Method manifold_volume(M::PowerManifold) Return the manifold volume of an  PowerManifold M . source"},{"id":1296,"pagetitle":"Power manifold","title":"Manifolds.sharp","ref":"/manifolds/stable/manifolds/#Manifolds.sharp-Tuple{AbstractPowerManifold, Vararg{Any}}","content":" Manifolds.sharp  ‚Äî  Method sharp(M::AbstractPowerManifold, p, Œæ::RieszRepresenterCotangentVector) Use the musical isomorphism to transform the cotangent vector  Œæ  from the tangent space at  p  on an  AbstractPowerManifold M  to a tangent vector. This can be done elementwise for every entry of  Œæ  (and  p ). source"},{"id":1297,"pagetitle":"Power manifold","title":"Manifolds.volume_density","ref":"/manifolds/stable/manifolds/#Manifolds.volume_density-Tuple{PowerManifold, Any, Any}","content":" Manifolds.volume_density  ‚Äî  Method volume_density(M::PowerManifold, p, X) Return volume density on the  PowerManifold M , i.e. product of constituent volume densities. source"},{"id":1300,"pagetitle":"Probability simplex","title":"The probability simplex","ref":"/manifolds/stable/manifolds/#The-probability-simplex","content":" The probability simplex"},{"id":1301,"pagetitle":"Probability simplex","title":"Manifolds.FisherRaoMetric","ref":"/manifolds/stable/manifolds/#Manifolds.FisherRaoMetric","content":" Manifolds.FisherRaoMetric  ‚Äî  Type FisherRaoMetric <: AbstractMetric The Fisher-Rao metric or Fisher information metric is a particular Riemannian metric which can be defined on a smooth statistical manifold, i.e., a smooth manifold whose points are probability measures defined on a common probability space. See for example the  ProbabilitySimplex . source"},{"id":1302,"pagetitle":"Probability simplex","title":"Manifolds.ProbabilitySimplex","ref":"/manifolds/stable/manifolds/#Manifolds.ProbabilitySimplex","content":" Manifolds.ProbabilitySimplex  ‚Äî  Type ProbabilitySimplex{T,boundary} <: AbstractDecoratorManifold{ùîΩ} The (relative interior of) the probability simplex is the set \\[Œî^n := \\biggl\\{ p ‚àà ‚Ñù^{n+1}\\ \\big|\\ p_i > 0 \\text{ for all } i=1,‚Ä¶,n+1,\n\\text{ and } ‚ü®\\mathbb{1},p‚ü© = \\sum_{i=1}^{n+1} p_i = 1\\biggr\\},\\] where  $\\mathbb{1}=(1,‚Ä¶,1)^{\\mathrm{T}}‚àà ‚Ñù^{n+1}$  denotes the vector containing only ones. If  boundary  is set to  :open , then the object represents an open simplex. Otherwise, that is when  boundary  is set to  :closed , the boundary is also included: \\[\\hat{Œî}^n := \\biggl\\{ p ‚àà ‚Ñù^{n+1}\\ \\big|\\ p_i \\geq 0 \\text{ for all } i=1,‚Ä¶,n+1,\n\\text{ and } ‚ü®\\mathbb{1},p‚ü© = \\sum_{i=1}^{n+1} p_i = 1\\biggr\\},\\] This set is also called the unit simplex or standard simplex. The tangent space is given by \\[T_pŒî^n = \\biggl\\{ X ‚àà ‚Ñù^{n+1}\\ \\big|\\ ‚ü®\\mathbb{1},X‚ü© = \\sum_{i=1}^{n+1} X_i = 0 \\biggr\\}\\] The manifold is implemented assuming the Fisher-Rao metric for the multinomial distribution, which is equivalent to the induced metric from isometrically embedding the probability simplex in the  $n$ -sphere of radius 2. The corresponding diffeomorphism  $\\varphi: \\mathbb Œî^n ‚Üí \\mathcal N$ , where  $\\mathcal N \\subset 2ùïä^n$  is given by  $\\varphi(p) = 2\\sqrt{p}$ . This implementation follows the notation in [ APSS17 ]. Constructor ProbabilitySimplex(n::Int; boundary::Symbol=:open) source"},{"id":1303,"pagetitle":"Probability simplex","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{ProbabilitySimplex, Vararg{Any}}","content":" Base.exp  ‚Äî  Method exp(M::ProbabilitySimplex, p, X) Compute the exponential map on the probability simplex. \\[\\exp_pX = \\frac{1}{2}\\Bigl(p+\\frac{X_p^2}{\\lVert X_p \\rVert^2}\\Bigr)\n+ \\frac{1}{2}\\Bigl(p - \\frac{X_p^2}{\\lVert X_p \\rVert^2}\\Bigr)\\cos(\\lVert X_p\\rVert)\n+ \\frac{1}{\\lVert X_p \\rVert}\\sqrt{p}\\sin(\\lVert X_p\\rVert),\\] where  $X_p = \\frac{X}{\\sqrt{p}}$ , with its division meant elementwise, as well as for the operations  $X_p^2$  and  $\\sqrt{p}$ . source"},{"id":1304,"pagetitle":"Probability simplex","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{ProbabilitySimplex, Vararg{Any}}","content":" Base.log  ‚Äî  Method log(M::ProbabilitySimplex, p, q) Compute the logarithmic map of  p  and  q  on the  ProbabilitySimplex M . \\[\\log_pq = \\frac{d_{Œî^n}(p,q)}{\\sqrt{1-‚ü®\\sqrt{p},\\sqrt{q}‚ü©}}(\\sqrt{pq} - ‚ü®\\sqrt{p},\\sqrt{q}‚ü©p),\\] where  $pq$  and  $\\sqrt{p}$  is meant elementwise. source"},{"id":1305,"pagetitle":"Probability simplex","title":"Base.rand","ref":"/manifolds/stable/manifolds/#Base.rand-Tuple{ProbabilitySimplex}","content":" Base.rand  ‚Äî  Method rand(::ProbabilitySimplex; vector_at=nothing, œÉ::Real=1.0) When  vector_at  is  nothing , return a random (uniform over the Fisher-Rao metric; that is, uniform with respect to the  n -sphere whose positive orthant is mapped to the simplex). point  x  on the  ProbabilitySimplex  manifold  M  according to the isometric embedding into the  n -sphere by normalizing the vector length of a sample from a multivariate Gaussian. See [ Mar72 ]. When  vector_at  is not  nothing , return a (Gaussian) random vector from the tangent space  $T_{p}\\mathrm{\\Delta}^n$ by shifting a multivariate Gaussian with standard deviation  œÉ  to have a zero component sum. source"},{"id":1306,"pagetitle":"Probability simplex","title":"ManifoldDiff.riemannian_gradient","ref":"/manifolds/stable/manifolds/#ManifoldDiff.riemannian_gradient-Tuple{ProbabilitySimplex, Any, Any}","content":" ManifoldDiff.riemannian_gradient  ‚Äî  Method X = riemannian_gradient(M::ProbabilitySimplex, p, Y)\nriemannian_gradient!(M::ProbabilitySimplex, X, p, Y) Given a gradient  $Y = \\operatorname{grad} \\tilde f(p)$  in the embedding  $‚Ñù^{n+1}$  of the  ProbabilitySimplex $Œî^n$ , this function computes the Riemannian gradient  $X = \\operatorname{grad} f(p)$  where  $f$  is the function  $\\tilde f$  restricted to the manifold. The formula reads \\[    X = p ‚äô Y - ‚ü®p, Y‚ü©p,\\] where  $‚äô$  denotes the emelementwise product. source"},{"id":1307,"pagetitle":"Probability simplex","title":"Manifolds.manifold_volume","ref":"/manifolds/stable/manifolds/#Manifolds.manifold_volume-Tuple{ProbabilitySimplex}","content":" Manifolds.manifold_volume  ‚Äî  Method manifold_volume(::ProbabilitySimplex) Return the volume of the  ProbabilitySimplex , i.e. volume of the  n -dimensional  Sphere  divided by  $2^{n+1}$ , corresponding to the volume of its positive orthant. source"},{"id":1308,"pagetitle":"Probability simplex","title":"Manifolds.volume_density","ref":"/manifolds/stable/manifolds/#Manifolds.volume_density-Tuple{ProbabilitySimplex, Any, Any}","content":" Manifolds.volume_density  ‚Äî  Method volume_density(M::ProbabilitySimplex, p, X) Compute the volume density at point  p  on  ProbabilitySimplex M  for tangent vector  X . It is computed using isometry with positive orthant of a sphere. source"},{"id":1309,"pagetitle":"Probability simplex","title":"ManifoldsBase.change_metric","ref":"/manifolds/stable/manifolds/#ManifoldsBase.change_metric-Tuple{ProbabilitySimplex, EuclideanMetric, Any, Any}","content":" ManifoldsBase.change_metric  ‚Äî  Method change_metric(M::ProbabilitySimplex, ::EuclideanMetric, p, X) To change the metric, we are looking for a function  $c\\colon T_pŒî^n ‚Üí T_pŒî^n$  such that for all  $X,Y ‚àà T_pŒî^n$  This can be achieved by rewriting representer change in matrix form as  (Diagonal(p) - p * p') * X  and taking square root of the matrix source"},{"id":1310,"pagetitle":"Probability simplex","title":"ManifoldsBase.change_representer","ref":"/manifolds/stable/manifolds/#ManifoldsBase.change_representer-Tuple{ProbabilitySimplex, EuclideanMetric, Any, Any}","content":" ManifoldsBase.change_representer  ‚Äî  Method change_representer(M::ProbabilitySimplex, ::EuclideanMetric, p, X) Given a tangent vector with respect to the metric from the embedding, the  EuclideanMetric , the representer of a linear functional on the tangent space is adapted as  $Z = p .* X .- p .* dot(p, X)$ . The first part ‚Äúcompensates‚Äù for the divsion by  $p$  in the Riemannian metric on the  ProbabilitySimplex  and the second part performs appropriate projection to keep the vector tangent. For details see Proposition 2.3 in [ APSS17 ]. source"},{"id":1311,"pagetitle":"Probability simplex","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Union{Tuple{boundary}, Tuple{ProbabilitySimplex{<:Any, boundary}, Any}} where boundary","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::ProbabilitySimplex, p; kwargs...) Check whether  p  is a valid point on the  ProbabilitySimplex M , i.e. is a point in the embedding with positive entries that sum to one The tolerance for the last test can be set using the  kwargs... . source"},{"id":1312,"pagetitle":"Probability simplex","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Union{Tuple{T}, Tuple{ProbabilitySimplex, Any, T}} where T","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::ProbabilitySimplex, p, X; kwargs... ) Check whether  X  is a tangent vector to  p  on the  ProbabilitySimplex M , i.e. after  check_point (M,p) ,  X  has to be of same dimension as  p  and its elements have to sum to one. The tolerance for the last test can be set using the  kwargs... . source"},{"id":1313,"pagetitle":"Probability simplex","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{ProbabilitySimplex, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M, p, q) Compute the distance between two points on the  ProbabilitySimplex M . The formula reads \\[d_{Œî^n}(p,q) = 2\\arccos \\biggl( \\sum_{i=1}^{n+1} \\sqrt{p_i q_i} \\biggr)\\] source"},{"id":1314,"pagetitle":"Probability simplex","title":"ManifoldsBase.injectivity_radius","ref":"/manifolds/stable/manifolds/#ManifoldsBase.injectivity_radius-Tuple{ProbabilitySimplex, Any}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(M::ProbabilitySimplex, p) Compute the injectivity radius on the  ProbabilitySimplex M  at the point  p , i.e. the distanceradius to a point near/on the boundary, that could be reached by following the geodesic. source"},{"id":1315,"pagetitle":"Probability simplex","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Union{Tuple{boundary}, Tuple{ProbabilitySimplex{<:Any, boundary}, Any, Any, Any}} where boundary","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::ProbabilitySimplex, p, X, Y) Compute the inner product of two tangent vectors  X ,  Y  from the tangent space  $T_pŒî^n$  at  p . The formula reads \\[g_p(X,Y) = \\sum_{i=1}^{n+1}\\frac{X_iY_i}{p_i}\\] When  M  includes boundary, we can just skip coordinates where  $p_i$  is equal to 0, see Proposition 2.1 in [ AJLS17 ]. source"},{"id":1316,"pagetitle":"Probability simplex","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{ProbabilitySimplex, Any, Any, SoftmaxInverseRetraction}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(M::ProbabilitySimplex, p, q, ::SoftmaxInverseRetraction) Compute a first order approximation by projection. The formula reads \\[\\operatorname{retr}^{-1}_p q = \\bigl( I_{n+1} - \\frac{1}{n}\\mathbb{1}^{n+1,n+1} \\bigr)(\\log(q)-\\log(p))\\] where  $\\mathbb{1}^{m,n}$  is the size  (m,n)  matrix containing ones, and  $\\log$  is applied elementwise. source"},{"id":1317,"pagetitle":"Probability simplex","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{ProbabilitySimplex}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::ProbabilitySimplex) Return false.  ProbabilitySimplex  is not a flat manifold. source"},{"id":1318,"pagetitle":"Probability simplex","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{ProbabilitySimplex}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::ProbabilitySimplex) Returns the manifold dimension of the probability simplex in  $‚Ñù^{n+1}$ , i.e. \\[    \\dim_{Œî^n} = n.\\] source"},{"id":1319,"pagetitle":"Probability simplex","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{ProbabilitySimplex, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::ProbabilitySimplex, p, Y) Project  Y  from the embedding onto the tangent space at  p  on the  ProbabilitySimplex M . The formula reads ` math \\operatorname{proj}_{Œî^n}(p,Y) = Y - \\bar{Y}  where  $\\bar{Y}$  denotes mean of  $Y$ . source"},{"id":1320,"pagetitle":"Probability simplex","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{ProbabilitySimplex, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::ProbabilitySimplex, p) project  p  from the embedding onto the  ProbabilitySimplex M . The formula reads \\[\\operatorname{proj}_{Œî^n}(p) = \\frac{1}{‚ü®\\mathbb 1,p‚ü©}p,\\] where  $\\mathbb 1 ‚àà ‚Ñù$  denotes the vector of ones. Not that this projection is only well-defined if  $p$  has positive entries. source"},{"id":1321,"pagetitle":"Probability simplex","title":"ManifoldsBase.representation_size","ref":"/manifolds/stable/manifolds/#ManifoldsBase.representation_size-Tuple{ProbabilitySimplex}","content":" ManifoldsBase.representation_size  ‚Äî  Method representation_size(::ProbabilitySimplex) Return the representation size of points in the  $n$ -dimensional probability simplex, i.e. an array size of  (n+1,) . source"},{"id":1322,"pagetitle":"Probability simplex","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{ProbabilitySimplex, Any, Any, SoftmaxRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::ProbabilitySimplex, p, X, ::SoftmaxRetraction) Compute a first order approximation by applying the softmax function. The formula reads \\[\\operatorname{retr}_p X = \\frac{p\\mathrm{e}^X}{‚ü®p,\\mathrm{e}^X‚ü©},\\] where multiplication, exponentiation and division are meant elementwise. source"},{"id":1323,"pagetitle":"Probability simplex","title":"ManifoldsBase.riemann_tensor","ref":"/manifolds/stable/manifolds/#ManifoldsBase.riemann_tensor-Tuple{ProbabilitySimplex, Vararg{Any, 4}}","content":" ManifoldsBase.riemann_tensor  ‚Äî  Method riemann_tensor(::ProbabilitySimplex, p, X, Y, Z) Compute the Riemann tensor  $R(X,Y)Z$  at point  p  on  ProbabilitySimplex M . It is computed using isometry with positive orthant of a sphere. source"},{"id":1324,"pagetitle":"Probability simplex","title":"ManifoldsBase.zero_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.zero_vector-Tuple{ProbabilitySimplex, Any}","content":" ManifoldsBase.zero_vector  ‚Äî  Method zero_vector(M::ProbabilitySimplex, p) Return the zero tangent vector in the tangent space of the point  p   from the  ProbabilitySimplex M , i.e. its representation by the zero vector in the embedding. source"},{"id":1325,"pagetitle":"Probability simplex","title":"Statistics.mean","ref":"/manifolds/stable/manifolds/#Statistics.mean-Tuple{ProbabilitySimplex, Vararg{Any}}","content":" Statistics.mean  ‚Äî  Method mean(\n    M::ProbabilitySimplex,\n    x::AbstractVector,\n    [w::AbstractWeights,]\n    method = GeodesicInterpolation();\n    kwargs...,\n) Compute the Riemannian  mean  of  x  using  GeodesicInterpolation . source"},{"id":1326,"pagetitle":"Probability simplex","title":"Euclidean metric","ref":"/manifolds/stable/manifolds/#Euclidean-metric","content":" Euclidean metric"},{"id":1327,"pagetitle":"Probability simplex","title":"Base.rand","ref":"/manifolds/stable/manifolds/#Base.rand-Tuple{MetricManifold{‚Ñù, <:ProbabilitySimplex, <:EuclideanMetric}}","content":" Base.rand  ‚Äî  Method rand(::MetricManifold{‚Ñù,<:ProbabilitySimplex,<:EuclideanMetric}; vector_at=nothing, œÉ::Real=1.0) When  vector_at  is  nothing , return a random (uniform) point  x  on the  ProbabilitySimplex  with the Euclidean metric manifold  M  by normalizing independent exponential draws to unit sum, see [ Dev86 ], Theorems 2.1 and 2.2 on p. 207 and 208, respectively. When  vector_at  is not  nothing , return a (Gaussian) random vector from the tangent space  $T_{p}\\mathrm{\\Delta}^n$ by shifting a multivariate Gaussian with standard deviation  œÉ  to have a zero component sum. source"},{"id":1328,"pagetitle":"Probability simplex","title":"Manifolds.manifold_volume","ref":"/manifolds/stable/manifolds/#Manifolds.manifold_volume-Tuple{MetricManifold{‚Ñù, <:ProbabilitySimplex, <:EuclideanMetric}}","content":" Manifolds.manifold_volume  ‚Äî  Method manifold_volume(::MetricManifold{‚Ñù,<:ProbabilitySimplex{n},<:EuclideanMetric})) where {n} Return the volume of the  ProbabilitySimplex  with the Euclidean metric. The formula reads  $\\frac{\\sqrt{n+1}}{n!}$ source"},{"id":1329,"pagetitle":"Probability simplex","title":"Manifolds.volume_density","ref":"/manifolds/stable/manifolds/#Manifolds.volume_density-Tuple{MetricManifold{‚Ñù, <:ProbabilitySimplex, <:EuclideanMetric}, Any, Any}","content":" Manifolds.volume_density  ‚Äî  Method volume_density(::MetricManifold{‚Ñù,<:ProbabilitySimplex,<:EuclideanMetric}, p, X) Compute the volume density at point  p  on  ProbabilitySimplex M  for tangent vector  X . It is equal to 1. source"},{"id":1330,"pagetitle":"Probability simplex","title":"Real probability amplitudes","ref":"/manifolds/stable/manifolds/#Real-probability-amplitudes","content":" Real probability amplitudes An isometric embedding of interior of  ProbabilitySimplex  in positive orthant of the  Sphere  is established through functions  simplex_to_amplitude  and  amplitude_to_simplex . Some properties extend to the boundary but not all. This embedding isometrically maps the Fisher-Rao metric on the open probability simplex to the sphere of radius 1 with Euclidean metric. More details can be found in Section 2.2 of [ AJLS17 ]. The name derives from the notion of probability amplitudes in quantum mechanics. They are complex-valued and their squared norm corresponds to probability. This construction restricted to real valued amplitudes results in this embedding."},{"id":1331,"pagetitle":"Probability simplex","title":"Manifolds.amplitude_to_simplex","ref":"/manifolds/stable/manifolds/#Manifolds.amplitude_to_simplex-Tuple{ProbabilitySimplex, Any}","content":" Manifolds.amplitude_to_simplex  ‚Äî  Method amplitude_to_simplex(M::ProbabilitySimplex, p) Convert point (real) probability amplitude  p  on to a point on  ProbabilitySimplex . The formula reads  $(p_1^2, p_2^2, ‚Ä¶, p_{N+1}^2)$ . This is an isometry from the interior of the positive orthant of a sphere to interior of the probability simplex. source"},{"id":1332,"pagetitle":"Probability simplex","title":"Manifolds.amplitude_to_simplex_diff","ref":"/manifolds/stable/manifolds/#Manifolds.amplitude_to_simplex_diff-Tuple{ProbabilitySimplex, Any, Any}","content":" Manifolds.amplitude_to_simplex_diff  ‚Äî  Method amplitude_to_simplex_diff(M::ProbabilitySimplex, p, X) Compute differential of  amplitude_to_simplex  of a point  p  on  ProbabilitySimplex  at tangent vector  X  from the tangent space at  p  from a sphere. source"},{"id":1333,"pagetitle":"Probability simplex","title":"Manifolds.simplex_to_amplitude","ref":"/manifolds/stable/manifolds/#Manifolds.simplex_to_amplitude-Tuple{ProbabilitySimplex, Any}","content":" Manifolds.simplex_to_amplitude  ‚Äî  Method simplex_to_amplitude(M::ProbabilitySimplex, p) Convert point  p  on  ProbabilitySimplex  to (real) probability amplitude. The formula reads  $(\\sqrt{p_1}, \\sqrt{p_2}, ‚Ä¶, \\sqrt{p_{N+1}})$ . This is an isometry from the interior of the probability simplex to the interior of the positive orthant of a sphere. source"},{"id":1334,"pagetitle":"Probability simplex","title":"Manifolds.simplex_to_amplitude_diff","ref":"/manifolds/stable/manifolds/#Manifolds.simplex_to_amplitude_diff-Tuple{ProbabilitySimplex, Any, Any}","content":" Manifolds.simplex_to_amplitude_diff  ‚Äî  Method simplex_to_amplitude_diff(M::ProbabilitySimplex, p, X) Compute differential of  simplex_to_amplitude  of a point on  p  one  ProbabilitySimplex  at tangent vector  X  from the tangent space at  p  from a sphere. source"},{"id":1335,"pagetitle":"Probability simplex","title":"Literature","ref":"/manifolds/stable/manifolds/#Literature","content":" Literature [AJLS17] N.¬†Ay, J.¬†Jost, H.¬†V.¬†L√™ and L.¬†Schwachh√∂fer.  Information Geometry  (Springer Cham, 2017). [Dev86] L.¬†Devroye.  Non-Uniform Random Variate Generation  (Springer New York, NY, 1986). [Mar72] G.¬†Marsaglia.  Choosing a Point from the Surface of a Sphere .  Annals¬†of¬†Mathematical¬†Statistics  43 , 645‚Äì646  (1972). [APSS17] F.¬†√Östr√∂m, S.¬†Petra, B.¬†Schmitzer and C.¬†Schn√∂rr.  Image Labeling by Assignment .  Journal¬†of¬†Mathematical¬†Imaging¬†and¬†Vision  58 , 211‚Äì238  (2017),  arXiv:1603.05285 ."},{"id":1338,"pagetitle":"Product manifold","title":"Product manifold","ref":"/manifolds/stable/manifolds/#ProductManifoldSection","content":" Product manifold Product manifold  $\\mathcal M = \\mathcal{M}_1 √ó \\mathcal{M}_2 √ó ‚Ä¶ √ó \\mathcal{M}_n$  of manifolds  $\\mathcal{M}_1, \\mathcal{M}_2, ‚Ä¶, \\mathcal{M}_n$ . Points on the product manifold can be constructed using  ArrayPartition  (from  RecursiveArrayTools.jl ) with canonical projections  $Œ†_i : \\mathcal{M} ‚Üí \\mathcal{M}_i$  for  $i ‚àà 1, 2, ‚Ä¶, n$  provided by  submanifold_component ."},{"id":1339,"pagetitle":"Product manifold","title":"Manifolds.ProductFVectorDistribution","ref":"/manifolds/stable/manifolds/#Manifolds.ProductFVectorDistribution","content":" Manifolds.ProductFVectorDistribution  ‚Äî  Type ProductFVectorDistribution([type::VectorSpaceFiber], [x], distrs...) Generates a random vector at point  x  from vector space (a fiber of a tangent bundle) of type  type  using the product distribution of given distributions. Vector space type and  x  can be automatically inferred from distributions  distrs . source"},{"id":1340,"pagetitle":"Product manifold","title":"Manifolds.ProductPointDistribution","ref":"/manifolds/stable/manifolds/#Manifolds.ProductPointDistribution","content":" Manifolds.ProductPointDistribution  ‚Äî  Type ProductPointDistribution(M::ProductManifold, distributions) Product distribution on manifold  M , combined from  distributions . source"},{"id":1341,"pagetitle":"Product manifold","title":"ManifoldDiff.riemannian_Hessian","ref":"/manifolds/stable/manifolds/#ManifoldDiff.riemannian_Hessian-Tuple{ProductManifold, Vararg{Any, 4}}","content":" ManifoldDiff.riemannian_Hessian  ‚Äî  Method Y = riemannian_Hessian(M::ProductManifold, p, G, H, X)\nriemannian_Hessian!(M::ProductManifold, Y, p, G, H, X) Compute the Riemannian Hessian  $\\operatorname{Hess} f(p)[X]$  given the Euclidean gradient  $‚àá f(\\tilde p)$  in  G  and the Euclidean Hessian  $‚àá^2 f(\\tilde p)[\\tilde X]$  in  H , where  $\\tilde p, \\tilde X$  are the representations of  $p,X$  in the embedding,. On a product manifold, this decouples and can be computed elementwise. source"},{"id":1342,"pagetitle":"Product manifold","title":"Manifolds.flat","ref":"/manifolds/stable/manifolds/#Manifolds.flat-Tuple{ProductManifold, Vararg{Any}}","content":" Manifolds.flat  ‚Äî  Method flat(M::ProductManifold, p, X::FVector{TangentSpaceType}) use the musical isomorphism to transform the tangent vector  X  from the tangent space at  p  on the  ProductManifold M  to a cotangent vector. This can be done elementwise for every entry of  X  (with respect to the corresponding entry in  p ) separately. source"},{"id":1343,"pagetitle":"Product manifold","title":"Manifolds.manifold_volume","ref":"/manifolds/stable/manifolds/#Manifolds.manifold_volume-Tuple{ProductManifold}","content":" Manifolds.manifold_volume  ‚Äî  Method manifold_volume(M::ProductManifold) Return the volume of  ProductManifold M , i.e. product of volumes of the manifolds  M  is constructed from. source"},{"id":1344,"pagetitle":"Product manifold","title":"Manifolds.sharp","ref":"/manifolds/stable/manifolds/#Manifolds.sharp-Tuple{ProductManifold, Vararg{Any}}","content":" Manifolds.sharp  ‚Äî  Method sharp(M::ProductManifold, p, Œæ::FVector{CotangentSpaceType}) Use the musical isomorphism to transform the cotangent vector  Œæ  from the tangent space at  p  on the  ProductManifold M  to a tangent vector. This can be done elementwise for every entry of  Œæ  (and  p ) separately source"},{"id":1345,"pagetitle":"Product manifold","title":"Manifolds.volume_density","ref":"/manifolds/stable/manifolds/#Manifolds.volume_density-Tuple{ProductManifold, Any, Any}","content":" Manifolds.volume_density  ‚Äî  Method volume_density(M::ProductManifold, p, X) Return volume density on the  ProductManifold M , i.e. product of constituent volume densities. source"},{"id":1348,"pagetitle":"Projective space","title":"Projective space","ref":"/manifolds/stable/manifolds/#Projective-space","content":" Projective space"},{"id":1349,"pagetitle":"Projective space","title":"Manifolds.AbstractProjectiveSpace","ref":"/manifolds/stable/manifolds/#Manifolds.AbstractProjectiveSpace","content":" Manifolds.AbstractProjectiveSpace  ‚Äî  Type AbstractProjectiveSpace{ùîΩ} <: AbstractDecoratorManifold{ùîΩ} An abstract type to represent a projective space over  ùîΩ  that is represented isometrically in the embedding. source"},{"id":1350,"pagetitle":"Projective space","title":"Manifolds.ArrayProjectiveSpace","ref":"/manifolds/stable/manifolds/#Manifolds.ArrayProjectiveSpace","content":" Manifolds.ArrayProjectiveSpace  ‚Äî  Type ArrayProjectiveSpace{T<:Tuple,ùîΩ} <: AbstractProjectiveSpace{ùîΩ} The projective space  $ùîΩ‚Ñô^{n‚ÇÅ,n‚ÇÇ,‚Ä¶,n·µ¢}$  is the manifold of all lines in  $ùîΩ^{n‚ÇÅ,n‚ÇÇ,‚Ä¶,n·µ¢}$ . The default representation is in the embedding, i.e. as unit (Frobenius) norm matrices in  $ùîΩ^{n‚ÇÅ,n‚ÇÇ,‚Ä¶,n·µ¢}$ : \\[ùîΩ‚Ñô^{n_1, n_2, ‚Ä¶, n_i} := \\bigl\\{ [p] ‚äÇ ùîΩ^{n_1, n_2, ‚Ä¶, n_i} \\ \\big|\\ \\lVert p \\rVert_{\\mathrm{F}} = 1, Œª ‚àà ùîΩ, |Œª| = 1, p ‚àº p Œª \\bigr\\}.\\] where  $[p]$  is an equivalence class of points  $p$ ,  $‚àº$  indicates equivalence, and  $\\lVert ‚ãÖ \\rVert_{\\mathrm{F}}$  is the Frobenius norm. Note that unlike  ProjectiveSpace , the argument for  ArrayProjectiveSpace  is given by the size of the embedding. This means that  ProjectiveSpace(2)  and  ArrayProjectiveSpace(3)  are the same manifold. Additionally,  ArrayProjectiveSpace(n,1;field=ùîΩ)  and  Grassmann(n,1;field=ùîΩ)  are the same. The tangent space at point  $p$  is given by \\[T_p ùîΩ‚Ñô^{n_1, n_2, ‚Ä¶, n_i} := \\bigl\\{ X ‚àà ùîΩ^{n_1, n_2, ‚Ä¶, n_i}\\ |\\ ‚ü®p,X‚ü©_{\\mathrm{F}} = 0 \\bigr \\},\\] where  $‚ü®‚ãÖ,‚ãÖ‚ü©_{\\mathrm{F}}$  denotes the (Frobenius) inner product in the embedding  $ùîΩ^{n_1, n_2, ‚Ä¶, n_i}$ . Constructor ArrayProjectiveSpace(n‚ÇÅ,n‚ÇÇ,...,n·µ¢; field=‚Ñù) Generate the projective space  $ùîΩ‚Ñô^{n_1, n_2, ‚Ä¶, n_i}$ , defaulting to the real projective space, where  field  can also be used to generate the complex- and right-quaternionic projective spaces. source"},{"id":1351,"pagetitle":"Projective space","title":"Manifolds.ProjectiveSpace","ref":"/manifolds/stable/manifolds/#Manifolds.ProjectiveSpace","content":" Manifolds.ProjectiveSpace  ‚Äî  Type ProjectiveSpace{n,ùîΩ} <: AbstractProjectiveSpace{ùîΩ} The projective space  $ùîΩ‚Ñô^n$  is the manifold of all lines in  $ùîΩ^{n+1}$ . The default representation is in the embedding, i.e. as unit norm vectors in  $ùîΩ^{n+1}$ : \\[ùîΩ‚Ñô^n := \\bigl\\{ [p] ‚äÇ ùîΩ^{n+1} \\ \\big|\\ \\lVert p \\rVert = 1, Œª ‚àà ùîΩ, |Œª| = 1, p ‚àº p Œª \\bigr\\},\\] where  $[p]$  is an equivalence class of points  $p$ , and  $‚àº$  indicates equivalence. For example, the real projective space  $‚Ñù‚Ñô^n$  is represented as the unit sphere  $ùïä^n$ , where antipodal points are considered equivalent. The tangent space at point  $p$  is given by \\[T_p ùîΩ‚Ñô^{n} := \\bigl\\{ X ‚àà ùîΩ^{n+1}\\ \\big|\\ ‚ü®p,X‚ü© = 0 \\bigr \\},\\] where  $‚ü®‚ãÖ,‚ãÖ‚ü©$  denotes the inner product in the embedding  $ùîΩ^{n+1}$ . When  $ùîΩ = ‚Ñç$ , this implementation of  $‚Ñç‚Ñô^n$  is the right-quaternionic projective space. Constructor ProjectiveSpace(n[, field=‚Ñù]) Generate the projective space  $ùîΩ‚Ñô^{n} ‚äÇ ùîΩ^{n+1}$ , defaulting to the real projective space  $‚Ñù‚Ñô^n$ , where  field  can also be used to generate the complex- and right-quaternionic projective spaces. source"},{"id":1352,"pagetitle":"Projective space","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{AbstractProjectiveSpace, Any, Any}","content":" Base.log  ‚Äî  Method log(M::AbstractProjectiveSpace, p, q) Compute the logarithmic map on  AbstractProjectiveSpace M $= ùîΩ‚Ñô^n$ , i.e. the tangent vector whose corresponding  geodesic  starting from  p  reaches  q  after time 1 on  M . The formula reads \\[\\log_p q = (q Œª - \\cos Œ∏ p) \\frac{Œ∏}{\\sin Œ∏},\\] where  $Œ∏ = \\arccos|‚ü®q, p‚ü©_{\\mathrm{F}}|$  is the  distance  between  $p$  and  $q$ ,  $‚ü®‚ãÖ, ‚ãÖ‚ü©_{\\mathrm{F}}$  is the Frobenius inner product, and  $Œª = \\frac{‚ü®q, p‚ü©_{\\mathrm{F}}}{|‚ü®q, p‚ü©_{\\mathrm{F}}|} ‚àà ùîΩ$  is the unit scalar that minimizes  $d_{ùîΩ^{n+1}}(p - q Œª)$ . That is,  $q Œª$  is the member of the equivalence class  $[q]$  that is closest to  $p$  in the embedding. As a result,  $\\exp_p \\circ \\log_p \\colon q ‚Ü¶ q Œª$ . The logarithmic maps for the real  AbstractSphere $ùïä^n$  and the real projective space  $‚Ñù‚Ñô^n$  are identical when  $p$  and  $q$  are in the same hemisphere. source"},{"id":1353,"pagetitle":"Projective space","title":"Manifolds.manifold_volume","ref":"/manifolds/stable/manifolds/#Manifolds.manifold_volume-Tuple{AbstractProjectiveSpace{‚Ñù}}","content":" Manifolds.manifold_volume  ‚Äî  Method manifold_volume(M::AbstractProjectiveSpace{‚Ñù}) Volume of the  $n$ -dimensional  AbstractProjectiveSpace M . The formula reads: \\[\\frac{\\pi^{(n+1)/2}}{Œì((n+1)/2)},\\] where  $Œì$  denotes the  Gamma function . For details see [ BST03 ]. source"},{"id":1354,"pagetitle":"Projective space","title":"Manifolds.uniform_distribution","ref":"/manifolds/stable/manifolds/#Manifolds.uniform_distribution-Tuple{ProjectiveSpace{<:Any, ‚Ñù}, Any}","content":" Manifolds.uniform_distribution  ‚Äî  Method uniform_distribution(M::ProjectiveSpace{<:Any,‚Ñù}, p) Uniform distribution on given  ProjectiveSpace M . Generated points will be of similar type as  p . source"},{"id":1355,"pagetitle":"Projective space","title":"ManifoldsBase._isapprox","ref":"/manifolds/stable/manifolds/#ManifoldsBase._isapprox-Tuple{AbstractProjectiveSpace, Any, Any}","content":" ManifoldsBase._isapprox  ‚Äî  Method isapprox(M::AbstractProjectiveSpace, p, q; kwargs...) Check that points  p  and  q  on the  AbstractProjectiveSpace M $=ùîΩ‚Ñô^n$  are members of the same equivalence class, i.e. that  $p = q Œª$  for some element  $Œª ‚àà ùîΩ$  with unit absolute value, that is,  $|Œª| = 1$ . This is equivalent to the Riemannian  distance  being 0. source"},{"id":1356,"pagetitle":"Projective space","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{AbstractProjectiveSpace, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::AbstractProjectiveSpace, p; kwargs...) Check whether  p  is a valid point on the  AbstractProjectiveSpace M , i.e. that it has the same size as elements of the embedding and has unit Frobenius norm. The tolerance for the norm check can be set using the  kwargs... . source"},{"id":1357,"pagetitle":"Projective space","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Union{Tuple{T}, Tuple{AbstractProjectiveSpace, Any, T}} where T","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::AbstractProjectiveSpace, p, X; kwargs... ) Check whether  X  is a tangent vector in the tangent space of  p  on the  AbstractProjectiveSpace M , i.e. that  X  has the same size as elements of the tangent space of the embedding and that the Frobenius inner product  $‚ü®p, X‚ü©_{\\mathrm{F}} = 0$ . source"},{"id":1358,"pagetitle":"Projective space","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{AbstractProjectiveSpace, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::AbstractProjectiveSpace, p, q) Compute the Riemannian distance on  AbstractProjectiveSpace M $=ùîΩ‚Ñô^n$  between points  p  and  q , i.e. \\[d_{ùîΩ‚Ñô^n}(p, q) = \\arccos\\bigl| ‚ü®p, q‚ü©_{\\mathrm{F}} \\bigr|.\\] Note that this definition is similar to that of the  AbstractSphere . However, the absolute value ensures that all equivalent  p  and  q  have the same pairwise distance. source"},{"id":1359,"pagetitle":"Projective space","title":"ManifoldsBase.get_coordinates","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_coordinates-Tuple{AbstractProjectiveSpace{‚Ñù}, Any, Any, DefaultOrthonormalBasis}","content":" ManifoldsBase.get_coordinates  ‚Äî  Method get_coordinates(M::AbstractProjectiveSpace, p, X, B::DefaultOrthonormalBasis{‚Ñù}) Represent the tangent vector  $X$  at point  $p$  from the  AbstractProjectiveSpace $M = ùîΩ‚Ñô^n$  in an orthonormal basis by unitarily transforming the hyperplane containing  $X$ , whose normal is  $p$ , to the hyperplane whose normal is the  $x$ -axis. Given  $q = p \\overline{Œª} + x$ , where  $Œª = \\frac{‚ü®x, p‚ü©_{\\mathrm{F}}}{|‚ü®x, p‚ü©_{\\mathrm{F}}|}$ ,  $‚ü®‚ãÖ, ‚ãÖ‚ü©_{\\mathrm{F}}$  denotes the Frobenius inner product, and  $\\overline{‚ãÖ}$  denotes complex or quaternionic conjugation, the formula for  $Y$  is \\[\\begin{pmatrix}0 \\\\ Y\\end{pmatrix} = \\left(X - q\\frac{2 ‚ü®q, X‚ü©_{\\mathrm{F}}}{‚ü®q, q‚ü©_{\\mathrm{F}}}\\right)\\overline{Œª}.\\] source"},{"id":1360,"pagetitle":"Projective space","title":"ManifoldsBase.get_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_vector-Tuple{AbstractProjectiveSpace, Any, Any, DefaultOrthonormalBasis{‚Ñù}}","content":" ManifoldsBase.get_vector  ‚Äî  Method get_vector(M::AbstractProjectiveSpace, p, X, B::DefaultOrthonormalBasis{‚Ñù}) Convert a one-dimensional vector of coefficients  $X$  in the basis  B  of the tangent space at  $p$  on the  AbstractProjectiveSpace $M=ùîΩ‚Ñô^n$  to a tangent vector  $Y$  at  $p$  by unitarily transforming the hyperplane containing  $X$ , whose normal is the  $x$ -axis, to the hyperplane whose normal is  $p$ . Given  $q = p \\overline{Œª} + x$ , where  $Œª = \\frac{‚ü®x, p‚ü©_{\\mathrm{F}}}{|‚ü®x, p‚ü©_{\\mathrm{F}}|}$ ,  $‚ü®‚ãÖ, ‚ãÖ‚ü©_{\\mathrm{F}}$  denotes the Frobenius inner product, and  $\\overline{‚ãÖ}$  denotes complex or quaternionic conjugation, the formula for  $Y$  is \\[Y = \\left(X - q\\frac{2 \\left\\langle q, \\begin{pmatrix}0 \\\\ X\\end{pmatrix}\\right\\rangle_{\\mathrm{F}}}{‚ü®q, q‚ü©_{\\mathrm{F}}}\\right) Œª.\\] source"},{"id":1361,"pagetitle":"Projective space","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{AbstractProjectiveSpace, Any, Any, Union{PolarInverseRetraction, ProjectionInverseRetraction, QRInverseRetraction}}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(M::AbstractProjectiveSpace, p, q, method::ProjectionInverseRetraction)\ninverse_retract(M::AbstractProjectiveSpace, p, q, method::PolarInverseRetraction)\ninverse_retract(M::AbstractProjectiveSpace, p, q, method::QRInverseRetraction) Compute the equivalent inverse retraction  ProjectionInverseRetraction ,  PolarInverseRetraction  on the  AbstractProjectiveSpace  manifold  M $=ùîΩ‚Ñô^n$ , i.e. \\[\\operatorname{retr}_p^{-1} q = q \\frac{1}{‚ü®p, q‚ü©_{\\mathrm{F}}} - p,\\] where  $‚ü®‚ãÖ, ‚ãÖ‚ü©_{\\mathrm{F}}$  is the Frobenius inner product. Note that this inverse retraction is equivalent to the three corresponding inverse retractions on  Grassmann(n+1,1,ùîΩ) , where the three inverse retractions in this case coincide. For  $‚Ñù‚Ñô^n$ , it is the same as the  ProjectionInverseRetraction  on the real  Sphere . source"},{"id":1362,"pagetitle":"Projective space","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{AbstractProjectiveSpace}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(M::AbstractProjectiveSpace) Return true if  AbstractProjectiveSpace  is of dimension 1 and false otherwise. source"},{"id":1363,"pagetitle":"Projective space","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Union{Tuple{AbstractProjectiveSpace{ùîΩ}}, Tuple{ùîΩ}} where ùîΩ","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::AbstractProjectiveSpace{ùîΩ}) where {ùîΩ} Return the real dimension of the  AbstractProjectiveSpace M , respectively i.e. the real dimension of the embedding minus the real dimension of the field  ùîΩ . source"},{"id":1364,"pagetitle":"Projective space","title":"ManifoldsBase.parallel_transport_direction","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_direction-Tuple{AbstractProjectiveSpace, Any, Any, Any}","content":" ManifoldsBase.parallel_transport_direction  ‚Äî  Method parallel_transport_direction(M::AbstractProjectiveSpace, p, X, d) Parallel transport a vector  X  from the tangent space at a point  p  on the  AbstractProjectiveSpace M  along the  geodesic  in the direction indicated by the tangent vector  d , i.e. \\[\\mathcal{P}_{\\exp_p (d) ‚Üê p}(X) = X - \\left(p \\frac{\\sin Œ∏}{Œ∏} + d \\frac{1 - \\cos Œ∏}{Œ∏^2}\\right) ‚ü®d, X‚ü©_p,\\] where  $Œ∏ = \\lVert d \\rVert$ , and  $‚ü®‚ãÖ, ‚ãÖ‚ü©_p$  is the  inner  product at the point  $p$ . For the real projective space, this is equivalent to the same vector transport on the real  AbstractSphere . source"},{"id":1365,"pagetitle":"Projective space","title":"ManifoldsBase.parallel_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_to-Tuple{AbstractProjectiveSpace, Any, Any, Any}","content":" ManifoldsBase.parallel_transport_to  ‚Äî  Method parallel_transport_to(M::AbstractProjectiveSpace, p, X, q) Parallel transport a vector  X  from the tangent space at a point  p  on the  AbstractProjectiveSpace M $=ùîΩ‚Ñô^n$  to the tangent space at another point  q . This implementation proceeds by transporting  $X$  to  $T_{q Œª} M$  using the same approach as  parallel_transport_direction , where  $Œª = \\frac{‚ü®q, p‚ü©_{\\mathrm{F}}}{|‚ü®q, p‚ü©_{\\mathrm{F}}|} ‚àà ùîΩ$  is the unit scalar that takes  $q$  to the member  $q Œª$  of its equivalence class  $[q]$  closest to  $p$  in the embedding. It then maps the transported vector from  $T_{q Œª} M$  to  $T_{q} M$ . The resulting transport to  $T_{q} M$  is \\[\\mathcal{P}_{q ‚Üê p}(X) = \\left(X - \\left(p \\frac{\\sin Œ∏}{Œ∏} + d \\frac{1 - \\cos Œ∏}{Œ∏^2}\\right) ‚ü®d, X‚ü©_p\\right) \\overline{Œª},\\] where  $d = \\log_p q$  is the direction of the transport,  $Œ∏ = \\lVert d \\rVert_p$  is the  distance  between  $p$  and  $q$ , and  $\\overline{‚ãÖ}$  denotes complex or quaternionic conjugation. source"},{"id":1366,"pagetitle":"Projective space","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{AbstractProjectiveSpace, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::AbstractProjectiveSpace, p, X) Orthogonally project the point  X  onto the tangent space at  p  on the  AbstractProjectiveSpace M : \\[\\operatorname{proj}_p (X) = X - p‚ü®p, X‚ü©_{\\mathrm{F}},\\] where  $‚ü®‚ãÖ, ‚ãÖ‚ü©_{\\mathrm{F}}$  denotes the Frobenius inner product. For the real  AbstractSphere  and  AbstractProjectiveSpace , this projection is the same. source"},{"id":1367,"pagetitle":"Projective space","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{AbstractProjectiveSpace, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::AbstractProjectiveSpace, p) Orthogonally project the point  p  from the embedding onto the  AbstractProjectiveSpace M : \\[\\operatorname{proj}(p) = \\frac{p}{\\lVert p \\rVert}_{\\mathrm{F}},\\] where  $\\lVert ‚ãÖ \\rVert_{\\mathrm{F}}$  denotes the Frobenius norm. This is identical to projection onto the  AbstractSphere . source"},{"id":1368,"pagetitle":"Projective space","title":"ManifoldsBase.representation_size","ref":"/manifolds/stable/manifolds/#ManifoldsBase.representation_size-Tuple{ArrayProjectiveSpace}","content":" ManifoldsBase.representation_size  ‚Äî  Method representation_size(M::AbstractProjectiveSpace) Return the size points on the  AbstractProjectiveSpace M  are represented as, i.e., the representation size of the embedding. source"},{"id":1369,"pagetitle":"Projective space","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{AbstractProjectiveSpace, Any, Any, Union{PolarRetraction, ProjectionRetraction, QRRetraction}}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::AbstractProjectiveSpace, p, X, method::ProjectionRetraction)\nretract(M::AbstractProjectiveSpace, p, X, method::PolarRetraction)\nretract(M::AbstractProjectiveSpace, p, X, method::QRRetraction) Compute the equivalent retraction  ProjectionRetraction , and  QRRetraction  on the  AbstractProjectiveSpace  manifold  M $=ùîΩ‚Ñô^n$ , i.e. \\[\\operatorname{retr}_p X = \\operatorname{proj}_p(p + X).\\] Note that this retraction is equivalent to the three corresponding retractions on  Grassmann(n+1,1,ùîΩ) , where in this case they coincide. For  $‚Ñù‚Ñô^n$ , it is the same as the  ProjectionRetraction  on the real  Sphere . source"},{"id":1370,"pagetitle":"Projective space","title":"Statistics.mean","ref":"/manifolds/stable/manifolds/#Statistics.mean-Tuple{AbstractProjectiveSpace, Vararg{Any}}","content":" Statistics.mean  ‚Äî  Method mean(\n    M::AbstractProjectiveSpace,\n    x::AbstractVector,\n    [w::AbstractWeights,]\n    method = GeodesicInterpolationWithinRadius(œÄ/4);\n    kwargs...,\n) Compute the Riemannian  mean  of points in vector  x  using  GeodesicInterpolationWithinRadius . source"},{"id":1373,"pagetitle":"Quotient manifold","title":"Quotient manifold","ref":"/manifolds/stable/manifolds/#QuotientManifoldSection","content":" Quotient manifold"},{"id":1374,"pagetitle":"Quotient manifold","title":"Manifolds.IsQuotientManifold","ref":"/manifolds/stable/manifolds/#Manifolds.IsQuotientManifold","content":" Manifolds.IsQuotientManifold  ‚Äî  Type IsQuotientManifold <: AbstractTrait Specify that a certain decorated manifold is a quotient manifold in the sense that it provides implicitly (or explicitly through  QuotientManifold   properties of a quotient manifold. See  QuotientManifold  for more details. source"},{"id":1375,"pagetitle":"Quotient manifold","title":"Manifolds.QuotientManifold","ref":"/manifolds/stable/manifolds/#Manifolds.QuotientManifold","content":" Manifolds.QuotientManifold  ‚Äî  Type QuotientManifold{M <: AbstractManifold{ùîΩ}, N} <: AbstractManifold{ùîΩ} Equip a manifold  $\\mathcal M$  explicitly with the property of being a quotient manifold. A manifold  $\\mathcal M$  is then a a quotient manifold of another manifold  $\\mathcal N$ , i.e. for an  equivalence relation $‚àº$  on  $\\mathcal N$  we have \\[    \\mathcal M = \\mathcal N / ‚àº = \\bigl\\{ [p] : p ‚àà \\mathcal N \\bigr\\},\\] where  $[p] ‚âî \\{ q ‚àà \\mathcal N : q ‚àº p\\}$  denotes the equivalence class containing  $p$ . For more details see Subsection 3.4.1 [ AMS08 ]. This manifold type models an explicit quotient structure. This should be done if either the default implementation of  $\\mathcal M$  uses another representation different from the quotient structure or if it provides a (default) quotient structure that is different from the one introduced here. Fields manifold  ‚Äì the manifold  $\\mathcal M$  in the introduction above. total_space  ‚Äì the manifold  $\\mathcal N$  in the introduction above. Constructor QuotientManifold(M,N) Create a manifold where  M  is the quotient manifold and  N is its total space. source"},{"id":1376,"pagetitle":"Quotient manifold","title":"Provided functions","ref":"/manifolds/stable/manifolds/#Provided-functions","content":" Provided functions"},{"id":1377,"pagetitle":"Quotient manifold","title":"Manifolds.canonical_project!","ref":"/manifolds/stable/manifolds/#Manifolds.canonical_project!-Tuple{AbstractManifold, Any, Any}","content":" Manifolds.canonical_project!  ‚Äî  Method canonical_project!(M, q, p) Compute the canonical projection  $œÄ$  on a manifold  $\\mathcal M$  that  IsQuotientManifold , e.g. a  QuotientManifold  in place of  q . See  canonical_project  for more details. source"},{"id":1378,"pagetitle":"Quotient manifold","title":"Manifolds.canonical_project","ref":"/manifolds/stable/manifolds/#Manifolds.canonical_project-Tuple{AbstractManifold, Any}","content":" Manifolds.canonical_project  ‚Äî  Method canonical_project(M, p) Compute the canonical projection  $œÄ$  on a manifold  $\\mathcal M$  that  IsQuotientManifold , e.g. a  QuotientManifold . The canonical (or natural) projection  $œÄ$  from the total space  $\\mathcal N$  onto  $\\mathcal M$  given by \\[    œÄ = œÄ_{\\mathcal N, \\mathcal M} : \\mathcal N ‚Üí \\mathcal M, p ‚Ü¶ œÄ_{\\mathcal N, \\mathcal M}(p) = [p].\\] in other words, this function implicitly assumes, that the total space  $\\mathcal N$  is given, for example explicitly when  M  is a  QuotientManifold  and  p  is a point on  N . source"},{"id":1379,"pagetitle":"Quotient manifold","title":"Manifolds.differential_canonical_project!","ref":"/manifolds/stable/manifolds/#Manifolds.differential_canonical_project!-Tuple{AbstractManifold, Any, Any}","content":" Manifolds.differential_canonical_project!  ‚Äî  Method differential_canonical_project!(M, Y, p, X) Compute the differential of the canonical projection  $œÄ$  on a manifold  $\\mathcal M$  that  IsQuotientManifold , e.g. a  QuotientManifold . See  differential_canonical_project  for details. source"},{"id":1380,"pagetitle":"Quotient manifold","title":"Manifolds.differential_canonical_project","ref":"/manifolds/stable/manifolds/#Manifolds.differential_canonical_project-Tuple{AbstractManifold, Any, Any}","content":" Manifolds.differential_canonical_project  ‚Äî  Method differential_canonical_project(M, p, X) Compute the differential of the canonical projection  $œÄ$  on a manifold  $\\mathcal M$  that  IsQuotientManifold , e.g. a  QuotientManifold . The canonical (or natural) projection  $œÄ$  from the total space  $\\mathcal N$  onto  $\\mathcal M$ , such that its differential \\[ DœÄ(p) : T_p\\mathcal N ‚Üí T_{œÄ(p)}\\mathcal M\\] where again the total space might be implicitly assumed, or explicitly when using a  QuotientManifold M . So here  p  is a point on  N  and  X  is from  $T_p\\mathcal N$ . source"},{"id":1381,"pagetitle":"Quotient manifold","title":"Manifolds.get_orbit_action","ref":"/manifolds/stable/manifolds/#Manifolds.get_orbit_action-Tuple{AbstractManifold}","content":" Manifolds.get_orbit_action  ‚Äî  Method get_orbit_action(M::AbstractDecoratorManifold) Return the group action that generates the orbit of an equivalence class of the quotient manifold  M  for which equivalence classes are orbits of an action of a Lie group. For the case that \\[\\mathcal M = \\mathcal N / \\mathcal O,\\] where  $\\mathcal O$  is a Lie group with its group action generating the orbit. source"},{"id":1382,"pagetitle":"Quotient manifold","title":"Manifolds.get_total_space","ref":"/manifolds/stable/manifolds/#Manifolds.get_total_space-Tuple{AbstractManifold}","content":" Manifolds.get_total_space  ‚Äî  Method get_total_space(M::AbstractDecoratorManifold) Return the total space of a manifold that  IsQuotientManifold , e.g. a  QuotientManifold . source"},{"id":1383,"pagetitle":"Quotient manifold","title":"Manifolds.horizontal_component","ref":"/manifolds/stable/manifolds/#Manifolds.horizontal_component-Tuple{AbstractManifold, Any, Any}","content":" Manifolds.horizontal_component  ‚Äî  Method horizontal_component(N::AbstractManifold, p, X)\nhorizontal_compontent(QuotientManifold{ùîΩ,M,N}, p, X) Compute the horizontal component of tangent vector  X  at point  p  in the total space of quotient manifold  N . This is often written as the space  $\\mathrm{Hor}_p^œÄ\\mathcal N$ . source"},{"id":1384,"pagetitle":"Quotient manifold","title":"Manifolds.horizontal_lift!","ref":"/manifolds/stable/manifolds/#Manifolds.horizontal_lift!-Tuple{AbstractManifold, Any, Any, Any}","content":" Manifolds.horizontal_lift!  ‚Äî  Method horizontal_lift!(N, Y, q, X)\nhorizontal_lift!(QuotientManifold{ùîΩ,M,N}, Y, p, X) Compute the horizontal lift of  X  from  $T_p\\mathcal M$ ,  $p=œÄ(q)$ . to ` T_q\\mathcal N  in place of  Y . source"},{"id":1385,"pagetitle":"Quotient manifold","title":"Manifolds.horizontal_lift","ref":"/manifolds/stable/manifolds/#Manifolds.horizontal_lift-Tuple{AbstractManifold, Any, Any}","content":" Manifolds.horizontal_lift  ‚Äî  Method horizontal_lift(N::AbstractManifold, q, X)\nhorizontal_lift(::QuotientManifold{ùîΩ,M,N}, p, X) Given a point  q  in total space of quotient manifold  N  such that  $p=œÄ(q)$  is a point on a quotient manifold  M  (implicitly given for the first case) and a tangent vector  X  this method computes a tangent vector  Y  on the horizontal space of  $T_q\\mathcal N$ , i.e. the subspace that is orthogonal to the kernel of  $DœÄ(q)$ . source"},{"id":1386,"pagetitle":"Quotient manifold","title":"Manifolds.vertical_component","ref":"/manifolds/stable/manifolds/#Manifolds.vertical_component-Tuple{AbstractManifold, Any, Any}","content":" Manifolds.vertical_component  ‚Äî  Method vertical_component(N::AbstractManifold, p, X)\nvertical_component(QuotientManifold{ùîΩ,M,N}, p, X) Compute the vertical component of tangent vector  X  at point  p  in the total space of quotient manifold  N . This is often written as the space  $\\mathrm{ver}_p^œÄ\\mathcal N$ . source"},{"id":1389,"pagetitle":"Rotations","title":"Rotations","ref":"/manifolds/stable/manifolds/#Rotations","content":" Rotations The manifold  $\\mathrm{SO}(n)$  of orthogonal matrices with determinant  $+1$  in  $‚Ñù^{n√ón}$ , i.e. \\[\\mathrm{SO}(n) = \\bigl\\{R ‚àà ‚Ñù^{n√ón} \\big| R R^{\\mathrm{T}} =\nR^{\\mathrm{T}}R = I_n, \\det(R) = 1 \\bigr\\}\\] The Lie group  $\\mathrm{SO}(n)$  is a subgroup of the orthogonal group  $\\mathrm{O}(n)$  and also known as the special orthogonal group or the set of rotations group. See also  SpecialOrthogonal , which is this manifold equipped with the group operation. The tangent space to a point  $p ‚àà \\mathrm{SO}(n)$  is given by \\[T_p\\mathrm{SO}(n) = \\{X : X=pY,\\qquad Y=-Y^{\\mathrm{T}}\\},\\] i.e. all vectors that are a product of a skew symmetric matrix multiplied with  $p$ . Since the orthogonal matrices  $\\mathrm{SO}(n)$  are a Lie group, tangent vectors can also be represented by elements of the corresponding Lie algebra, which is the tangent space at the identity element. In the notation above, this means we just store the component  $Y$  of  $X$ . This convention allows for more efficient operations on tangent vectors. Tangent spaces at different points are different vector spaces. Let  $L_R: \\mathrm{SO}(n) ‚Üí \\mathrm{SO}(n)$  where  $R ‚àà \\mathrm{SO}(n)$  be the left-multiplication by  $R$ , that is  $L_R(S) = RS$ . The tangent space at rotation  $R$ ,  $T_R \\mathrm{SO}(n)$ , is related to the tangent space at the identity rotation  $I_n$  by the differential of  $L_R$  at identity,  $(\\mathrm{d}L_R)_{I_n} : T_{I_n} \\mathrm{SO}(n) ‚Üí T_R \\mathrm{SO}(n)$ . To convert the tangent vector representation at the identity rotation  $X ‚àà T_{I_n} \\mathrm{SO}(n)$  (i.e., the default) to the matrix representation of the corresponding tangent vector  $Y$  at a rotation  $R$  use the  embed  which implements the following multiplication:  $Y = RX ‚àà T_R \\mathrm{SO}(n)$ . You can compare the functions  log  and  exp  to see how it works in practice. Several common functions are also implemented together with  orthogonal and unitary matrices ."},{"id":1390,"pagetitle":"Rotations","title":"Manifolds.NormalRotationDistribution","ref":"/manifolds/stable/manifolds/#Manifolds.NormalRotationDistribution","content":" Manifolds.NormalRotationDistribution  ‚Äî  Type NormalRotationDistribution(M::Rotations, d::Distribution, x::TResult) Distribution that returns a random point on the manifold  Rotations M . Random point is generated using base distribution  d  and the type of the result is adjusted to  TResult . See  normal_rotation_distribution  for details. source"},{"id":1391,"pagetitle":"Rotations","title":"Manifolds.Rotations","ref":"/manifolds/stable/manifolds/#Manifolds.Rotations","content":" Manifolds.Rotations  ‚Äî  Type Rotations{T} <: AbstractManifold{‚Ñù} The manifold of rotation matrices of size  $n√ón$ , i.e. real-valued orthogonal matrices with determinant  $+1$ . Constructor Rotations(n::Int; parameter::Symbol=:type) Generate the manifold of  $n√ón$  rotation matrices. source"},{"id":1392,"pagetitle":"Rotations","title":"ManifoldDiff.riemannian_Hessian","ref":"/manifolds/stable/manifolds/#ManifoldDiff.riemannian_Hessian-Tuple{Rotations, Vararg{Any, 4}}","content":" ManifoldDiff.riemannian_Hessian  ‚Äî  Method riemannian_Hessian(M::Rotations, p, G, H, X) The Riemannian Hessian can be computed by adopting Eq. (5.6) [ Ngu23 ], so very similar to the Stiefel manifold. The only difference is, that here the tangent vectors are stored in the Lie algebra, i.e. the update direction is actually  $pX$  instead of just  $X$  (in Stiefel). and that means the inverse has to be appliead to the (Euclidean) Hessian to map it into the Lie algebra. source"},{"id":1393,"pagetitle":"Rotations","title":"Manifolds.angles_4d_skew_sym_matrix","ref":"/manifolds/stable/manifolds/#Manifolds.angles_4d_skew_sym_matrix-Tuple{Any}","content":" Manifolds.angles_4d_skew_sym_matrix  ‚Äî  Method angles_4d_skew_sym_matrix(A) The Lie algebra of  Rotations(4)  in  $‚Ñù^{4√ó4}$ ,  $ùî∞ùî¨(4)$ , consists of  $4√ó4$  skew-symmetric matrices. The unique imaginary components of their eigenvalues are the angles of the two plane rotations. This function computes these more efficiently than  eigvals . By convention, the returned values are sorted in decreasing order (corresponding to the same ordering of  angles  as  cos_angles_4d_rotation_matrix ). source"},{"id":1394,"pagetitle":"Rotations","title":"Manifolds.normal_rotation_distribution","ref":"/manifolds/stable/manifolds/#Manifolds.normal_rotation_distribution-Tuple{Rotations, Any, Real}","content":" Manifolds.normal_rotation_distribution  ‚Äî  Method normal_rotation_distribution(M::Rotations, p, œÉ::Real) Return a random point on the manifold  Rotations M  by generating a (Gaussian) random orthogonal matrix with determinant  $+1$ . Let \\[QR = A\\] be the QR decomposition of a random matrix  $A$ , then the formula reads \\[p = QD\\] where  $D$  is a diagonal matrix with the signs of the diagonal entries of  $R$ , i.e. \\[D_{ij}=\\begin{cases}\n \\operatorname{sgn}(R_{ij}) & \\text{if} \\; i=j \\\\\n 0 & \\, \\text{otherwise}\n\\end{cases}.\\] It can happen that the matrix gets -1 as a determinant. In this case, the first and second columns are swapped. The argument  p  is used to determine the type of returned points. source"},{"id":1395,"pagetitle":"Rotations","title":"ManifoldsBase.Weingarten","ref":"/manifolds/stable/manifolds/#ManifoldsBase.Weingarten-Tuple{Rotations, Any, Any, Any}","content":" ManifoldsBase.Weingarten  ‚Äî  Method Weingarten(M::Rotations, p, X, V) Compute the Weingarten map  $\\mathcal W_p$  at  p  on the  Stiefel M  with respect to the tangent vector  $X \\in T_p\\mathcal M$  and the normal vector  $V \\in N_p\\mathcal M$ . The formula is due to [ AMT13 ] given by \\[\\mathcal W_p(X,V) = -\\frac{1}{2}p\\bigl(V^{\\mathrm{T}}X - X^\\mathrm{T}V\\bigr)\\] source"},{"id":1396,"pagetitle":"Rotations","title":"ManifoldsBase.injectivity_radius","ref":"/manifolds/stable/manifolds/#ManifoldsBase.injectivity_radius-Tuple{Rotations, PolarRetraction}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(M::Rotations, ::PolarRetraction) Return the radius of injectivity for the  PolarRetraction  on the  Rotations M  which is  $\\frac{œÄ}{\\sqrt{2}}$ . source"},{"id":1397,"pagetitle":"Rotations","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{Rotations, Any, Any, PolarInverseRetraction}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(M, p, q, ::PolarInverseRetraction) Compute a vector from the tangent space  $T_p\\mathrm{SO}(n)$  of the point  p  on the  Rotations  manifold  M  with which the point  q  can be reached by the  PolarRetraction  from the point  p  after time 1. The formula reads \\[\\operatorname{retr}^{-1}_p(q)\n= -\\frac{1}{2}(p^{\\mathrm{T}}qs - (p^{\\mathrm{T}}qs)^{\\mathrm{T}})\\] where  $s$  is the solution to the Sylvester equation $p^{\\mathrm{T}}qs + s(p^{\\mathrm{T}}q)^{\\mathrm{T}} + 2I_n = 0.$ source"},{"id":1398,"pagetitle":"Rotations","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{Rotations, Any, Any, QRInverseRetraction}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(M::Rotations, p, q, ::QRInverseRetraction) Compute a vector from the tangent space  $T_p\\mathrm{SO}(n)$  of the point  p  on the  Rotations  manifold  M  with which the point  q  can be reached by the  QRRetraction  from the point  q  after time 1. source"},{"id":1399,"pagetitle":"Rotations","title":"ManifoldsBase.parallel_transport_direction","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_direction-Tuple{Rotations, Any, Any, Any}","content":" ManifoldsBase.parallel_transport_direction  ‚Äî  Method parallel_transport_direction(M::Rotations, p, X, d) Compute parallel transport of vector  X  tangent at  p  on the  Rotations  manifold in the direction  d . The formula, provided in [ Ren11 ], reads: \\[\\mathcal P_{q\\gets p}X = q^\\mathrm{T}p \\operatorname{Exp}(d/2) X \\operatorname{Exp}(d/2)\\] where  $q=\\exp_p d$ . The formula simplifies to identity for 2-D rotations. source"},{"id":1400,"pagetitle":"Rotations","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Rotations, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::Rotations, p; check_det = true) Project  p  to the nearest point on manifold  M . Given the singular value decomposition  $p = U Œ£ V^\\mathrm{T}$ , with the singular values sorted in descending order, the projection is \\[\\operatorname{proj}_{\\mathrm{SO}(n)}(p) =\nU\\operatorname{diag}\\left[1,1,‚Ä¶,\\det(U V^\\mathrm{T})\\right] V^\\mathrm{T}\\] The diagonal matrix ensures that the determinant of the result is  $+1$ . If  p  is expected to be almost special orthogonal, then you may avoid this check with  check_det = false . source"},{"id":1401,"pagetitle":"Rotations","title":"ManifoldsBase.sectional_curvature_max","ref":"/manifolds/stable/manifolds/#ManifoldsBase.sectional_curvature_max-Tuple{Rotations}","content":" ManifoldsBase.sectional_curvature_max  ‚Äî  Method sectional_curvature_max(::Rotations) Sectional curvature of  Rotations M  is equal to 0 for  Rotations(1)  and  Rotations(2) , less than or equal to 1/8 for  Rotations(3)  and less than or equal to 1/4 for higher-dimensional rotations manifolds. For reference, see [ Ge14 ], Lemma 2.5 and [ CE08 ], Corollary 3.19. source"},{"id":1402,"pagetitle":"Rotations","title":"ManifoldsBase.sectional_curvature_min","ref":"/manifolds/stable/manifolds/#ManifoldsBase.sectional_curvature_min-Tuple{Rotations}","content":" ManifoldsBase.sectional_curvature_min  ‚Äî  Method sectional_curvature_min(M::Rotations) Sectional curvature of  Rotations M  is greater than or equal to 0. source"},{"id":1403,"pagetitle":"Rotations","title":"ManifoldsBase.zero_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.zero_vector-Tuple{Rotations, Any}","content":" ManifoldsBase.zero_vector  ‚Äî  Method zero_vector(M::Rotations, p) Return the zero tangent vector from the tangent space art  p  on the  Rotations  as an element of the Lie group, i.e. the zero matrix. source"},{"id":1404,"pagetitle":"Rotations","title":"Literature","ref":"/manifolds/stable/manifolds/#Literature","content":" Literature [AMT13] P.¬†-.-A.¬†Absil, R.¬†Mahony and J.¬†Trumpf.  An Extrinsic Look at the Riemannian Hessian . In:  Geometric Science of Information , edited by F.¬†Nielsen and F.¬†Barbaresco (Springer Berlin Heidelberg, 2013); pp.¬†361‚Äì368. [CE08] J.¬†Cheeger and D.¬†G.¬†Ebin.  Comparison Theorems in Riemannian Geometry  (American Mathematical Society, Providence, R.I, 2008). [Ge14] J.¬†Ge.  DDVV-type inequality for skew-symmetric matrices and Simons-type inequality for Riemannian submersions .  Advances¬†in¬†Mathematics  251 , 62‚Äì86  (2014). [Ngu23] D.¬†Nguyen.  Operator-Valued Formulas for Riemannian Gradient and Hessian and Families of Tractable Metrics in Riemannian Optimization .  Journal¬†of¬†Optimization¬†Theory¬†and¬†Applications  198 , 135‚Äì164  (2023),  arXiv:2009.10159 . [Ren11] Q.¬†Rentmeesters.  A gradient method for geodesic data fitting on some symmetric Riemannian manifolds . In:  IEEE Conference on Decision and Control and European Control Conference  (2011); pp.¬†7141‚Äì7146."},{"id":1407,"pagetitle":"Shape spaces","title":"Shape spaces","ref":"/manifolds/stable/manifolds/#Shape-spaces","content":" Shape spaces Shape spaces are spaces of  $k$  points in  $‚Ñù^n$  up to simultaneous action of a group on all points. The most commonly encountered are Kendall's pre-shape and shape spaces. In the case of the Kendall's pre-shape spaces the action is translation and scaling. In the case of the Kendall's shape spaces the action is translation, scaling and rotation. using Manifolds, Plots\n\nM = KendallsShapeSpace(2, 3)\n# two random point on the shape space\np = [\n    0.4385117672460505 -0.6877826444042382 0.24927087715818771\n    -0.3830259932279294 0.35347460720654283 0.029551386021386548\n]\nq = [\n    -0.42693314765896473 -0.3268567431952937 0.7537898908542584\n    0.3054740561061169 -0.18962848284149897 -0.11584557326461796\n]\n# let's plot them as triples of points on a plane\nfig = scatter(p[1,:], p[2,:], label=\"p\", aspect_ratio=:equal)\nscatter!(fig, q[1,:], q[2,:], label=\"q\")\n\n# aligning q to p\nA = get_orbit_action(M)\na = optimal_alignment(A, p, q)\nrot_q = apply(A, a, q)\nscatter!(fig, rot_q[1,:], rot_q[2,:], label=\"q aligned to p\") A more extensive usage example is available in the  hand_gestures.jl  tutorial."},{"id":1408,"pagetitle":"Shape spaces","title":"Manifolds.KendallsPreShapeSpace","ref":"/manifolds/stable/manifolds/#Manifolds.KendallsPreShapeSpace","content":" Manifolds.KendallsPreShapeSpace  ‚Äî  Type KendallsPreShapeSpace{T} <: AbstractSphere{‚Ñù} Kendall's pre-shape space of  $k$  landmarks in  $‚Ñù^n$  represented by n√ók matrices. In each row the sum of elements of a matrix is equal to 0. The Frobenius norm of the matrix is equal to 1 [ Ken84 ][ Ken89 ]. The space can be interpreted as tuples of  $k$  points in  $‚Ñù^n$  up to simultaneous translation and scaling of all points, so this can be thought of as a quotient manifold. Constructor KendallsPreShapeSpace(n::Int, k::Int; parameter::Symbol=:type) See also KendallsShapeSpace , esp. for the references source"},{"id":1409,"pagetitle":"Shape spaces","title":"Manifolds.KendallsShapeSpace","ref":"/manifolds/stable/manifolds/#Manifolds.KendallsShapeSpace","content":" Manifolds.KendallsShapeSpace  ‚Äî  Type KendallsShapeSpace{T} <: AbstractDecoratorManifold{‚Ñù} Kendall's shape space, defined as quotient of a  KendallsPreShapeSpace  (represented by n√ók matrices) by the action  ColumnwiseMultiplicationAction . The space can be interpreted as tuples of  $k$  points in  $‚Ñù^n$  up to simultaneous translation and scaling and rotation of all points [ Ken84 ][ Ken89 ]. This manifold possesses the  IsQuotientManifold  trait. Constructor KendallsShapeSpace(n::Int, k::Int; parameter::Symbol=:type) References source"},{"id":1410,"pagetitle":"Shape spaces","title":"Provided functions","ref":"/manifolds/stable/manifolds/#Provided-functions","content":" Provided functions"},{"id":1411,"pagetitle":"Shape spaces","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{KendallsPreShapeSpace, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::KendallsPreShapeSpace, p; atol=sqrt(max_eps(X, Y)), kwargs...) Check whether  p  is a valid point on  KendallsPreShapeSpace , i.e. whether each row has zero mean. Other conditions are checked via embedding in  ArraySphere . source"},{"id":1412,"pagetitle":"Shape spaces","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{KendallsPreShapeSpace, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::KendallsPreShapeSpace, p, X; kwargs... ) Check whether  X  is a valid tangent vector on  KendallsPreShapeSpace , i.e. whether each row has zero mean. Other conditions are checked via embedding in  ArraySphere . source"},{"id":1413,"pagetitle":"Shape spaces","title":"ManifoldsBase.get_embedding","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_embedding-Tuple{KendallsPreShapeSpace}","content":" ManifoldsBase.get_embedding  ‚Äî  Method get_embedding(M::KendallsPreShapeSpace) Return the space  KendallsPreShapeSpace M  is embedded in, i.e.  ArraySphere  of matrices of the same shape. source"},{"id":1414,"pagetitle":"Shape spaces","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{KendallsPreShapeSpace}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::KendallsPreShapeSpace) Return the dimension of the  KendallsPreShapeSpace  manifold  M . The dimension is given by  $n(k - 1) - 1$ . source"},{"id":1415,"pagetitle":"Shape spaces","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{KendallsPreShapeSpace, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::KendallsPreShapeSpace, p, X) Project tangent vector  X  at point  p  from the embedding to  KendallsPreShapeSpace  by selecting the right element from the tangent space to orthogonal section representing the quotient manifold  M . See Section 3.7 of [ SK16 ] for details. source"},{"id":1416,"pagetitle":"Shape spaces","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{KendallsPreShapeSpace, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::KendallsPreShapeSpace, p) Project point  p  from the embedding to  KendallsPreShapeSpace  by selecting the right element from the orthogonal section representing the quotient manifold  M . See Section 3.7 of [ SK16 ] for details. The method computes the mean of the landmarks and moves them to make their mean zero; afterwards the Frobenius norm of the landmarks (as a matrix) is normalised to fix the scaling. source"},{"id":1417,"pagetitle":"Shape spaces","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{KendallsShapeSpace, Any, Any}","content":" Base.exp  ‚Äî  Method exp(M::KendallsShapeSpace, p, X) Compute the exponential map on  KendallsShapeSpace M . See [ GMTP21 ] for discussion about its computation. source"},{"id":1418,"pagetitle":"Shape spaces","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{KendallsShapeSpace, Any, Any}","content":" Base.log  ‚Äî  Method log(M::KendallsShapeSpace, p, q) Compute the logarithmic map on  KendallsShapeSpace M . See the [ exp ](@ref exp(::KendallsShapeSpace, ::Any, ::Any)onential map for more details source"},{"id":1419,"pagetitle":"Shape spaces","title":"Base.rand","ref":"/manifolds/stable/manifolds/#Base.rand-Tuple{KendallsShapeSpace}","content":" Base.rand  ‚Äî  Method rand(::KendallsShapeSpace; vector_at=nothing) When  vector_at  is  nothing , return a random point  x  on the  KendallsShapeSpace  manifold  M  by generating a random point in the embedding. When  vector_at  is not  nothing , return a random vector from the tangent space with mean zero and standard deviation  œÉ . source"},{"id":1420,"pagetitle":"Shape spaces","title":"Manifolds.get_total_space","ref":"/manifolds/stable/manifolds/#Manifolds.get_total_space-Tuple{KendallsShapeSpace}","content":" Manifolds.get_total_space  ‚Äî  Method get_total_space(::KendallsShapeSpace) Return the total space of the  KendallsShapeSpace  manifold, which is the  KendallsPreShapeSpace  manifold. source"},{"id":1421,"pagetitle":"Shape spaces","title":"Manifolds.horizontal_component","ref":"/manifolds/stable/manifolds/#Manifolds.horizontal_component-Tuple{KendallsShapeSpace, Any, Any}","content":" Manifolds.horizontal_component  ‚Äî  Method horizontal_component(::KendallsShapeSpace, p, X) Compute the horizontal component of tangent vector  X  at  p  on  KendallsShapeSpace M . See [ GMTP21 ], Section 2.3 for details. source"},{"id":1422,"pagetitle":"Shape spaces","title":"ManifoldsBase.get_embedding","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_embedding-Tuple{KendallsShapeSpace}","content":" ManifoldsBase.get_embedding  ‚Äî  Method get_embedding(M::KendallsShapeSpace) Get the manifold in which  KendallsShapeSpace M  is embedded, i.e.  KendallsPreShapeSpace  of matrices of the same shape. source"},{"id":1423,"pagetitle":"Shape spaces","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{KendallsShapeSpace}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::KendallsShapeSpace) Return false.  KendallsShapeSpace  is not a flat manifold. source"},{"id":1424,"pagetitle":"Shape spaces","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{KendallsShapeSpace}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::KendallsShapeSpace) Return the dimension of the  KendallsShapeSpace  manifold  M . The dimension is given by  $n(k - 1) - 1 - n(n - 1)/2$  in the typical case where  $k \\geq n+1$ , and  $(k + 1)(k - 2) / 2$  otherwise, unless  $k$  is equal to 1, in which case the dimension is 0. See [ Ken84 ] for a discussion of the over-dimensioned case. source"},{"id":1427,"pagetitle":"Skew-Hermitian matrices","title":"Skew-hermitian matrices","ref":"/manifolds/stable/manifolds/#Skew-hermitian-matrices","content":" Skew-hermitian matrices"},{"id":1428,"pagetitle":"Skew-Hermitian matrices","title":"Manifolds.SkewHermitianMatrices","ref":"/manifolds/stable/manifolds/#Manifolds.SkewHermitianMatrices","content":" Manifolds.SkewHermitianMatrices  ‚Äî  Type SkewHermitianMatrices{T,ùîΩ} <: AbstractDecoratorManifold{ùîΩ} The  AbstractManifold $\\operatorname{SkewHerm}(n)$  consisting of the real- or complex-valued skew-hermitian matrices of size  $n√ón$ , i.e. the set \\[\\operatorname{SkewHerm}(n) = \\bigl\\{p  ‚àà ùîΩ^{n√ón}\\ \\big|\\ p^{\\mathrm{H}} = -p \\bigr\\},\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the Hermitian, i.e. complex conjugate transpose, and the field  $ùîΩ ‚àà \\{ ‚Ñù, ‚ÑÇ, ‚Ñç\\}$ . Though it is slightly redundant, usually the matrices are stored as  $n√ón$  arrays. Note that in this representation, the real-valued part of the diagonal must be zero, which is also reflected in the  manifold_dimension . Constructor SkewHermitianMatrices(n::Int, field::AbstractNumbers=‚Ñù; parameter::Symbol=:type) Generate the manifold of  $n√ón$  skew-hermitian matrices. source"},{"id":1429,"pagetitle":"Skew-Hermitian matrices","title":"Manifolds.SkewSymmetricMatrices","ref":"/manifolds/stable/manifolds/#Manifolds.SkewSymmetricMatrices","content":" Manifolds.SkewSymmetricMatrices  ‚Äî  Type SkewSymmetricMatrices{T} Generate the manifold of  $n√ón$  real skew-symmetric matrices. This is equivalent to  SkewHermitianMatrices(n, ‚Ñù) . Constructor SkewSymmetricMatrices(n::Int) source"},{"id":1430,"pagetitle":"Skew-Hermitian matrices","title":"ManifoldsBase.Weingarten","ref":"/manifolds/stable/manifolds/#ManifoldsBase.Weingarten-Tuple{SkewSymmetricMatrices, Any, Any, Any}","content":" ManifoldsBase.Weingarten  ‚Äî  Method Y = Weingarten(M::SkewSymmetricMatrices, p, X, V)\nWeingarten!(M::SkewSymmetricMatrices, Y, p, X, V) Compute the Weingarten map  $\\mathcal W_p$  at  p  on the  SkewSymmetricMatrices M  with respect to the tangent vector  $X \\in T_p\\mathcal M$  and the normal vector  $V \\in N_p\\mathcal M$ . Since this a flat space by itself, the result is always the zero tangent vector. source"},{"id":1431,"pagetitle":"Skew-Hermitian matrices","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Union{Tuple{ùîΩ}, Tuple{SkewHermitianMatrices{<:Any, ùîΩ}, Any}} where ùîΩ","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::SkewHermitianMatrices, p; kwargs...) Check whether  p  is a valid manifold point on the  SkewHermitianMatrices M , i.e. whether  p  is a skew-hermitian matrix of size  (n,n)  with values from the corresponding  AbstractNumbers ùîΩ . The tolerance for the skew-symmetry of  p  can be set using  kwargs... . source"},{"id":1432,"pagetitle":"Skew-Hermitian matrices","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{SkewHermitianMatrices, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::SkewHermitianMatrices, p, X; kwargs... ) Check whether  X  is a tangent vector to manifold point  p  on the  SkewHermitianMatrices M , i.e.  X  must be a skew-hermitian matrix of size  (n,n)  and its values have to be from the correct  AbstractNumbers . The tolerance for the skew-symmetry of  p  and  X  can be set using  kwargs... . source"},{"id":1433,"pagetitle":"Skew-Hermitian matrices","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{SkewHermitianMatrices}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::SkewHermitianMatrices) Return true.  SkewHermitianMatrices  is a flat manifold. source"},{"id":1434,"pagetitle":"Skew-Hermitian matrices","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Union{Tuple{SkewHermitianMatrices{<:Any, ùîΩ}}, Tuple{ùîΩ}} where ùîΩ","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::SkewHermitianMatrices) Return the dimension of the  SkewHermitianMatrices  matrix  M  over the number system  ùîΩ , i.e. \\[\\dim \\mathrm{SkewHerm}(n,‚Ñù) = \\frac{n(n+1)}{2} \\dim_‚Ñù ùîΩ - n,\\] where  $\\dim_‚Ñù ùîΩ$  is the  real_dimension  of  $ùîΩ$ . The first term corresponds to only the upper triangular elements of the matrix being unique, and the second term corresponds to the constraint that the real part of the diagonal be zero. source"},{"id":1435,"pagetitle":"Skew-Hermitian matrices","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{SkewHermitianMatrices, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::SkewHermitianMatrices, p, X) Project the matrix  X  onto the tangent space at  p  on the  SkewHermitianMatrices M , \\[\\operatorname{proj}_p(X) = \\frac{1}{2} \\bigl( X - X^{\\mathrm{H}} \\bigr),\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the Hermitian, i.e. complex conjugate transposed. source"},{"id":1436,"pagetitle":"Skew-Hermitian matrices","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{SkewHermitianMatrices, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::SkewHermitianMatrices, p) Projects  p  from the embedding onto the  SkewHermitianMatrices M , i.e. \\[\\operatorname{proj}_{\\operatorname{SkewHerm}(n)}(p) = \\frac{1}{2} \\bigl( p - p^{\\mathrm{H}} \\bigr),\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the Hermitian, i.e. complex conjugate transposed. source"},{"id":1439,"pagetitle":"SPD, fixed determinant","title":"Symmetric positive definite matrices of fixed determinant","ref":"/manifolds/stable/manifolds/#SPDFixedDeterminantSection","content":" Symmetric positive definite matrices of fixed determinant"},{"id":1440,"pagetitle":"SPD, fixed determinant","title":"Manifolds.SPDFixedDeterminant","ref":"/manifolds/stable/manifolds/#Manifolds.SPDFixedDeterminant","content":" Manifolds.SPDFixedDeterminant  ‚Äî  Type SPDFixedDeterminant{T,D} <: AbstractDecoratorManifold{‚Ñù} The manifold of symmetric positive definite matrices of fixed determinant  $d > 0$ , i.e. \\[\\mathcal P_d(n) =\n\\bigl\\{\np ‚àà ‚Ñù^{n√ón} \\ \\big|\\ a^\\mathrm{T}pa > 0 \\text{ for all } a ‚àà ‚Ñù^{n}\\backslash\\{0\\}\n  \\text{ and } \\det(p) = d\n\\bigr\\}.\\] This manifold is modelled as a submanifold of  SymmetricPositiveDefinite (n) . These matrices are sometimes also called  isochoric , which refers to the interpretation of the matrix representing an ellipsoid. All ellipsoids that represent points on this manifold have the same volume. The tangent space is modelled the same as for  SymmetricPositiveDefinite (n)  and consists of all symmetric matrices with zero trace \\[    T_p\\mathcal P_d(n) =\n    \\bigl\\{\n        X \\in \\mathbb R^{n√ón} \\big|\\ X=X^\\mathrm{T} \\text{ and } \\operatorname{tr}(p) = 0\n    \\bigr\\},\\] since for a constant determinant we require that  0 = D\\det(p)[Z] = \\det(p)\\operatorname{tr}(p^{-1}Z)  for all tangent vectors  $Z$ . Additionally we store the tangent vectors as  X=p^{-1}Z , i.e. symmetric matrices. Constructor SPDFixedDeterminant(n::Int, d::Real=1.0; parameter::Symbol=:type) Generate the manifold  $\\mathcal P_d(n) \\subset \\mathcal P(n)$  of determinant  $d$ , which defaults to 1. parameter : whether a type parameter should be used to store  n . By default size is stored in type. Value can either be  :field  or  :type . source This manifold can is a submanifold of the  symmetric positive definite matrices  and hence inherits most properties therefrom. The differences are the functions"},{"id":1441,"pagetitle":"SPD, fixed determinant","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{SPDFixedDeterminant, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::SPDFixedDeterminant, p; kwargs...) Check whether  p  is a valid manifold point on the  SPDFixedDeterminant (n,d) M , i.e. whether  p  is a  SymmetricPositiveDefinite  matrix of size  (n, n) with determinant  $\\det(p) =$ M.d . The tolerance for the determinant of  p  can be set using  kwargs... . source"},{"id":1442,"pagetitle":"SPD, fixed determinant","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Union{Tuple{T}, Tuple{SPDFixedDeterminant, Any, T}} where T","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::SPDFixedDeterminant, p, X; kwargs... ) Check whether  X  is a tangent vector to manifold point  p  on the  SPDFixedDeterminant M , i.e.  X  has to be a tangent vector on  SymmetricPositiveDefinite , so a symmetric matrix, and additionally fulfill  $\\operatorname{tr}(X) = 0$ . The tolerance for the trace check of  X  can be set using  kwargs... , which influences the  isapprox -check. source"},{"id":1443,"pagetitle":"SPD, fixed determinant","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{SPDFixedDeterminant, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method Y = project(M::SPDFixedDeterminant, p, X)\nproject!(M::SPDFixedDeterminant, Y, p, X) Project the symmetric matrix  X  onto the tangent space at  p  of the (sub-)manifold of s.p.d. matrices of determinant  M.d  (in place of  Y ), by setting its diagonal (and hence its trace) to zero. source"},{"id":1444,"pagetitle":"SPD, fixed determinant","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{SPDFixedDeterminant, Any}","content":" ManifoldsBase.project  ‚Äî  Method q = project(M::SPDFixedDeterminant, p)\nproject!(M::SPDFixedDeterminant, q, p) Project the symmetric positive definite (s.p.d.) matrix  p  from the embedding onto the (sub-)manifold of s.p.d. matrices of determinant  M.d  (in place of  q ). The formula reads \\[q = \\Bigl(\\frac{d}{\\det(p)}\\Bigr)^{\\frac{1}{n}}p\\] source"},{"id":1447,"pagetitle":"Spectrahedron","title":"Spectrahedron","ref":"/manifolds/stable/manifolds/#Spectrahedron","content":" Spectrahedron"},{"id":1448,"pagetitle":"Spectrahedron","title":"Manifolds.Spectrahedron","ref":"/manifolds/stable/manifolds/#Manifolds.Spectrahedron","content":" Manifolds.Spectrahedron  ‚Äî  Type Spectrahedron{T} <: AbstractDecoratorManifold{‚Ñù} The Spectrahedron manifold, also known as the set of correlation matrices (symmetric positive semidefinite matrices) of rank  $k$  with unit trace. \\[\\begin{aligned}\n\\mathcal S(n,k) =\n\\bigl\\{p ‚àà ‚Ñù^{n√ón}\\ \\big|\\ &a^\\mathrm{T}pa \\geq 0 \\text{ for all } a ‚àà ‚Ñù^{n},\\\\\n&\\operatorname{tr}(p) = \\sum_{i=1}^n p_{ii} = 1,\\\\\n&\\text{and } p = qq^{\\mathrm{T}} \\text{ for } q \\in  ‚Ñù^{n√ók}\n\\text{ with } \\operatorname{rank}(p) = \\operatorname{rank}(q) = k\n\\bigr\\}.\n\\end{aligned}\\] This manifold is working solely on the matrices  $q$ . Note that this  $q$  is not unique, indeed for any orthogonal matrix  $A$  we have  $(qA)(qA)^{\\mathrm{T}} = qq^{\\mathrm{T}} = p$ , so the manifold implemented here is the quotient manifold. The unit trace translates to unit frobenius norm of  $q$ . The tangent space at  $p$ , denoted  $T_p\\mathcal E(n,k)$ , is also represented by matrices  $Y\\in ‚Ñù^{n√ók}$  and reads as \\[T_p\\mathcal S(n,k) = \\bigl\\{\nX ‚àà ‚Ñù^{n√ón}\\,|\\,X = qY^{\\mathrm{T}} + Yq^{\\mathrm{T}}\n\\text{ with } \\operatorname{tr}(X) = \\sum_{i=1}^{n}X_{ii} = 0\n\\bigr\\}\\] endowed with the  Euclidean  metric from the embedding, i.e. from the  $‚Ñù^{n√ók}$ This manifold was for example investigated in [ JBAS10 ]. Constructor Spectrahedron(n::Int, k::Int; parameter::Symbol=:type) generates the manifold  $\\mathcal S(n,k) \\subset ‚Ñù^{n√ón}$ . source"},{"id":1449,"pagetitle":"Spectrahedron","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{Spectrahedron, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::Spectrahedron, q; kwargs...) checks, whether  q  is a valid reprsentation of a point  $p=qq^{\\mathrm{T}}$  on the  Spectrahedron M , i.e. is a matrix of size  (N,K) , such that  $p$  is symmetric positive semidefinite and has unit trace, i.e.  $q$  has to have unit frobenius norm. Since by construction  $p$  is symmetric, this is not explicitly checked. Since  $p$  is by construction positive semidefinite, this is not checked. The tolerances for positive semidefiniteness and unit trace can be set using the  kwargs... . source"},{"id":1450,"pagetitle":"Spectrahedron","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Union{Tuple{T}, Tuple{Spectrahedron, Any, T}} where T","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::Spectrahedron, q, Y; kwargs...) Check whether  $X = qY^{\\mathrm{T}} + Yq^{\\mathrm{T}}$  is a tangent vector to  $p=qq^{\\mathrm{T}}$  on the  Spectrahedron M , i.e. atfer  check_point  of  q ,  Y  has to be of same dimension as  q  and a  $X$  has to be a symmetric matrix with trace. The tolerance for the base point check and zero diagonal can be set using the  kwargs... . Note that symmetry of  $X$  holds by construction and is not explicitly checked. source"},{"id":1451,"pagetitle":"Spectrahedron","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{Spectrahedron}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::Spectrahedron) Return false.  Spectrahedron  is not a flat manifold. source"},{"id":1452,"pagetitle":"Spectrahedron","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{Spectrahedron}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::Spectrahedron) returns the dimension of  Spectrahedron M $=\\mathcal S(n,k), n,k ‚àà ‚Ñï$ , i.e. \\[\\dim \\mathcal S(n,k) = nk - 1 - \\frac{k(k-1)}{2}.\\] source"},{"id":1453,"pagetitle":"Spectrahedron","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Spectrahedron, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::Spectrahedron, q) project  q  onto the manifold  Spectrahedron M , by normalizing w.r.t. the Frobenius norm source"},{"id":1454,"pagetitle":"Spectrahedron","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Spectrahedron, Vararg{Any}}","content":" ManifoldsBase.project  ‚Äî  Method project(M::Spectrahedron, q, Y) Project  Y  onto the tangent space at  q , i.e. row-wise onto the Spectrahedron manifold. source"},{"id":1455,"pagetitle":"Spectrahedron","title":"ManifoldsBase.representation_size","ref":"/manifolds/stable/manifolds/#ManifoldsBase.representation_size-Tuple{Spectrahedron}","content":" ManifoldsBase.representation_size  ‚Äî  Method representation_size(M::Spectrahedron) Return the size of an array representing an element on the  Spectrahedron  manifold  M , i.e.  $n√ók$ , the size of such factor of  $p=qq^{\\mathrm{T}}$  on  $\\mathcal M = \\mathcal S(n,k)$ . source"},{"id":1456,"pagetitle":"Spectrahedron","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{Spectrahedron, Any, Any, ProjectionRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::Spectrahedron, q, Y, ::ProjectionRetraction) compute a projection based retraction by projecting  $q+Y$  back onto the manifold. source"},{"id":1457,"pagetitle":"Spectrahedron","title":"ManifoldsBase.vector_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.vector_transport_to-Tuple{Spectrahedron, Any, Any, Any, ProjectionTransport}","content":" ManifoldsBase.vector_transport_to  ‚Äî  Method vector_transport_to(M::Spectrahedron, p, X, q) transport the tangent vector  X  at  p  to  q  by projecting it onto the tangent space at  q . source"},{"id":1458,"pagetitle":"Spectrahedron","title":"ManifoldsBase.zero_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.zero_vector-Tuple{Spectrahedron, Vararg{Any}}","content":" ManifoldsBase.zero_vector  ‚Äî  Method zero_vector(M::Spectrahedron,p) returns the zero tangent vector in the tangent space of the symmetric positive definite matrix  p  on the  Spectrahedron  manifold  M . source"},{"id":1459,"pagetitle":"Spectrahedron","title":"Literature","ref":"/manifolds/stable/manifolds/#Literature","content":" Literature"},{"id":1462,"pagetitle":"Sphere","title":"Sphere and unit norm arrays","ref":"/manifolds/stable/manifolds/#SphereSection","content":" Sphere and unit norm arrays"},{"id":1463,"pagetitle":"Sphere","title":"Manifolds.AbstractSphere","ref":"/manifolds/stable/manifolds/#Manifolds.AbstractSphere","content":" Manifolds.AbstractSphere  ‚Äî  Type AbstractSphere{ùîΩ} <: AbstractDecoratorManifold{ùîΩ} An abstract type to represent a unit sphere that is represented isometrically in the embedding. source The classical sphere, i.e. unit norm (real- or complex-valued) vectors can be generated as usual: to create the 2-dimensional sphere (in  $‚Ñù^3$ ), use  Sphere(2)  and  Sphere(2,‚ÑÇ) , respectively."},{"id":1464,"pagetitle":"Sphere","title":"Manifolds.Sphere","ref":"/manifolds/stable/manifolds/#Manifolds.Sphere","content":" Manifolds.Sphere  ‚Äî  Type Sphere{T,ùîΩ} <: AbstractSphere{ùîΩ} The (unit) sphere manifold  $ùïä^{n}$  is the set of all unit norm vectors in  $ùîΩ^{n+1}$ . The sphere is represented in the embedding, i.e. \\[ùïä^{n} := \\bigl\\{ p \\in ùîΩ^{n+1}\\ \\big|\\ \\lVert p \\rVert = 1 \\bigr\\}\\] where  $ùîΩ\\in\\{‚Ñù,‚ÑÇ,‚Ñç\\}$ . Note that compared to the  ArraySphere , here the argument  n  of the manifold is the dimension of the manifold, i.e.  $ùïä^{n} ‚äÇ ùîΩ^{n+1}$ ,  $n\\in ‚Ñï$ . The tangent space at point  $p$  is given by \\[T_pùïä^{n} := \\bigl\\{ X ‚àà ùîΩ^{n+1}\\ |\\ \\Re(‚ü®p,X‚ü©) = 0 \\bigr \\},\\] where  $ùîΩ\\in\\{‚Ñù,‚ÑÇ,‚Ñç\\}$  and  $‚ü®‚ãÖ,‚ãÖ‚ü©$  denotes the inner product in the embedding  $ùîΩ^{n+1}$ . For  $ùîΩ=‚ÑÇ$ , the manifold is the complex sphere, written  $‚ÑÇùïä^n$ , embedded in  $‚ÑÇ^{n+1}$ .  $‚ÑÇùïä^n$  is the complexification of the real sphere  $ùïä^{2n+1}$ . Likewise, the quaternionic sphere  $‚Ñçùïä^n$  is the quaternionification of the real sphere  $ùïä^{4n+3}$ . Consequently,  $‚ÑÇùïä^0$  is equivalent to  $ùïä^1$  and  Circle , while  $‚ÑÇùïä^1$  and  $‚Ñçùïä^0$  are equivalent to  $ùïä^3$ , though with different default representations. This manifold is modeled as a special case of the more general case, i.e. as an embedded manifold to the  Euclidean , and several functions like the  inner  product and the  zero_vector  are inherited from the embedding. Constructor Sphere(n[, field=‚Ñù]) Generate the (real-valued) sphere  $ùïä^{n} ‚äÇ ‚Ñù^{n+1}$ , where  field  can also be used to generate the complex- and quaternionic-valued sphere. source For the higher-dimensional arrays, for example unit (Frobenius) norm matrices, the manifold is generated using the size of the matrix. To create the unit sphere of  $3√ó2$  real-valued matrices, write  ArraySphere(3,2)  and the complex case is done ‚Äì as for the  Euclidean  case ‚Äì with an keyword argument  ArraySphere(3,2; field=‚ÑÇ) . This case also covers the classical sphere as a special case, but you specify the size of the vectors/embedding instead: The 2-sphere can here be generated  ArraySphere(3) ."},{"id":1465,"pagetitle":"Sphere","title":"Manifolds.ArraySphere","ref":"/manifolds/stable/manifolds/#Manifolds.ArraySphere","content":" Manifolds.ArraySphere  ‚Äî  Type ArraySphere{T<:Tuple,ùîΩ} <: AbstractSphere{ùîΩ} The (unit) sphere manifold  $ùïä^{n‚ÇÅ,n‚ÇÇ,...,n·µ¢}$  is the set of all unit (Frobenius) norm elements of  $ùîΩ^{n‚ÇÅ,n‚ÇÇ,...,n·µ¢}$ , where ``ùîΩ\\in{‚Ñù,‚ÑÇ,‚Ñç}. The generalized sphere is represented in the embedding, and supports arbitrary sized arrays or in other words arbitrary tensors of unit norm. The set formally reads \\[ùïä^{n_1, n_2, ‚Ä¶, n_i} := \\bigl\\{ p \\in ùîΩ^{n_1, n_2, ‚Ä¶, n_i}\\ \\big|\\ \\lVert p \\rVert = 1 \\bigr\\}\\] where  $ùîΩ\\in\\{‚Ñù,‚ÑÇ,‚Ñç\\}$ . Setting  $i=1$  and  $ùîΩ=‚Ñù$   this  simplifies to unit vectors in  $‚Ñù^n$ , see  Sphere  for this special case. Note that compared to this classical case, the argument for the generalized case here is given by the dimension of the embedding. This means that  Sphere(2)  and  ArraySphere(3)  are the same manifold. The tangent space at point  $p$  is given by \\[T_p ùïä^{n_1, n_2, ‚Ä¶, n_i} := \\bigl\\{ X ‚àà ùîΩ^{n_1, n_2, ‚Ä¶, n_i}\\ |\\ \\Re(‚ü®p,X‚ü©) = 0 \\bigr \\},\\] where  $ùîΩ\\in\\{‚Ñù,‚ÑÇ,‚Ñç\\}$  and  $‚ü®‚ãÖ,‚ãÖ‚ü©$  denotes the (Frobenius) inner product in the embedding  $ùîΩ^{n_1, n_2, ‚Ä¶, n_i}$ . This manifold is modeled as an embedded manifold to the  Euclidean , i.e. several functions like the  inner  product and the  zero_vector  are inherited from the embedding. Constructor ArraySphere(n‚ÇÅ,n‚ÇÇ,...,n·µ¢; field=‚Ñù, parameter::Symbol=:type) Generate sphere in  $ùîΩ^{n_1, n_2, ‚Ä¶, n_i}$ , where  $ùîΩ$  defaults to the real-valued case  $‚Ñù$ . source There is also one atlas available on the sphere."},{"id":1466,"pagetitle":"Sphere","title":"Manifolds.StereographicAtlas","ref":"/manifolds/stable/manifolds/#Manifolds.StereographicAtlas","content":" Manifolds.StereographicAtlas  ‚Äî  Type StereographicAtlas() The stereographic atlas of  $S^n$  with two charts: one with the singular point (-1, 0, ..., 0) (called  :north ) and one with the singular point (1, 0, ..., 0) (called  :south ). source"},{"id":1467,"pagetitle":"Sphere","title":"Functions on unit spheres","ref":"/manifolds/stable/manifolds/#Functions-on-unit-spheres","content":" Functions on unit spheres"},{"id":1468,"pagetitle":"Sphere","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{AbstractSphere, Vararg{Any}}","content":" Base.exp  ‚Äî  Method exp(M::AbstractSphere, p, X) Compute the exponential map from  p  in the tangent direction  X  on the  AbstractSphere M  by following the great arc eminating from  p  in direction  X . \\[\\exp_p X = \\cos(\\lVert X \\rVert_p)p + \\sin(\\lVert X \\rVert_p)\\frac{X}{\\lVert X \\rVert_p},\\] where  $\\lVert X \\rVert_p$  is the  norm  on the tangent space at  p  of the  AbstractSphere M . source"},{"id":1469,"pagetitle":"Sphere","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{AbstractSphere, Vararg{Any}}","content":" Base.log  ‚Äî  Method log(M::AbstractSphere, p, q) Compute the logarithmic map on the  AbstractSphere M , i.e. the tangent vector, whose geodesic starting from  p  reaches  q  after time 1. The formula reads for  $x ‚â† -y$ \\[\\log_p q = d_{ùïä}(p,q) \\frac{q-\\Re(‚ü®p,q‚ü©) p}{\\lVert q-\\Re(‚ü®p,q‚ü©) p \\rVert_2},\\] and a deterministic choice from the set of tangent vectors is returned if  $x=-y$ , i.e. for opposite points. source"},{"id":1470,"pagetitle":"Sphere","title":"Manifolds.local_metric","ref":"/manifolds/stable/manifolds/#Manifolds.local_metric-Tuple{Sphere{Tuple{Int64}, ‚Ñù}, Any, DefaultOrthonormalBasis}","content":" Manifolds.local_metric  ‚Äî  Method local_metric(M::Sphere{n}, p, ::DefaultOrthonormalBasis) return the local representation of the metric in a  DefaultOrthonormalBasis , namely the diagonal matrix of size  $n√ón$  with ones on the diagonal, since the metric is obtained from the embedding by restriction to the tangent space  $T_p\\mathcal M$  at  $p$ . source"},{"id":1471,"pagetitle":"Sphere","title":"Manifolds.manifold_volume","ref":"/manifolds/stable/manifolds/#Manifolds.manifold_volume-Tuple{AbstractSphere{‚Ñù}}","content":" Manifolds.manifold_volume  ‚Äî  Method manifold_volume(M::AbstractSphere{‚Ñù}) Volume of the  $n$ -dimensional  Sphere M . The formula reads \\[\\operatorname{Vol}(ùïä^{n}) = \\frac{2\\pi^{(n+1)/2}}{Œì((n+1)/2)},\\] where  $Œì$  denotes the  Gamma function . source"},{"id":1472,"pagetitle":"Sphere","title":"Manifolds.uniform_distribution","ref":"/manifolds/stable/manifolds/#Manifolds.uniform_distribution-Tuple{Sphere{<:Any, ‚Ñù}, Any}","content":" Manifolds.uniform_distribution  ‚Äî  Method uniform_distribution(M::Sphere{n,‚Ñù}, p) where {n} Uniform distribution on given  Sphere M . Generated points will be of similar type as  p . source"},{"id":1473,"pagetitle":"Sphere","title":"Manifolds.volume_density","ref":"/manifolds/stable/manifolds/#Manifolds.volume_density-Tuple{AbstractSphere{‚Ñù}, Any, Any}","content":" Manifolds.volume_density  ‚Äî  Method volume_density(M::AbstractSphere{‚Ñù}, p, X) Compute volume density function of a sphere, i.e. determinant of the differential of exponential map  exp(M, p, X) . The formula reads  $(\\sin(\\lVert X\\rVert)/\\lVert X\\rVert)^(n-1)$  where  n  is the dimension of  M . It is derived from Eq. (4.1) in [ CLLD22 ]. source"},{"id":1474,"pagetitle":"Sphere","title":"ManifoldsBase.Weingarten","ref":"/manifolds/stable/manifolds/#ManifoldsBase.Weingarten-Tuple{Sphere, Any, Any, Any}","content":" ManifoldsBase.Weingarten  ‚Äî  Method Y = Weingarten(M::Sphere, p, X, V)\nWeingarten!(M::Sphere, Y, p, X, V) Compute the Weingarten map  $\\mathcal W_p$  at  p  on the  Sphere M  with respect to the tangent vector  $X \\in T_p\\mathcal M$  and the normal vector  $V \\in N_p\\mathcal M$ . The formula is due to [ AMT13 ] given by \\[\\mathcal W_p(X,V) = -Xp^{\\mathrm{T}}V\\] source"},{"id":1475,"pagetitle":"Sphere","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{AbstractSphere, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::AbstractSphere, p; kwargs...) Check whether  p  is a valid point on the  AbstractSphere M , i.e. is a point in the embedding of unit length. The tolerance for the last test can be set using the  kwargs... . source"},{"id":1476,"pagetitle":"Sphere","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Union{Tuple{T}, Tuple{AbstractSphere, Any, T}} where T","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::AbstractSphere, p, X; kwargs... ) Check whether  X  is a tangent vector to  p  on the  AbstractSphere M , i.e. after  check_point (M,p) ,  X  has to be of same dimension as  p  and orthogonal to  p . The tolerance for the last test can be set using the  kwargs... . source"},{"id":1477,"pagetitle":"Sphere","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{AbstractSphere, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::AbstractSphere, p, q) Compute the geodesic distance betweeen  p  and  q  on the  AbstractSphere M . The formula is given by the (shorter) great arc length on the (or a) great circle both  p  and  q  lie on. \\[d_{ùïä}(p,q) = \\arccos(\\Re(‚ü®p,q‚ü©)).\\] source"},{"id":1478,"pagetitle":"Sphere","title":"ManifoldsBase.get_coordinates","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_coordinates-Tuple{AbstractSphere{‚Ñù}, Any, Any, DefaultOrthonormalBasis}","content":" ManifoldsBase.get_coordinates  ‚Äî  Method get_coordinates(M::AbstractSphere{‚Ñù}, p, X, B::DefaultOrthonormalBasis) Represent the tangent vector  X  at point  p  from the  AbstractSphere M  in an orthonormal basis by rotating the hyperplane containing  X  to a hyperplane whose normal is the  $x$ -axis. Given  $q = p Œª + x$ , where  $Œª = \\operatorname{sgn}(‚ü®x, p‚ü©)$ , and  $‚ü®‚ãÖ, ‚ãÖ‚ü©_{\\mathrm{F}}$  denotes the Frobenius inner product, the formula for  $Y$  is \\[\\begin{pmatrix}0 \\\\ Y\\end{pmatrix} = X - q\\frac{2 ‚ü®q, X‚ü©_{\\mathrm{F}}}{‚ü®q, q‚ü©_{\\mathrm{F}}}.\\] source"},{"id":1479,"pagetitle":"Sphere","title":"ManifoldsBase.get_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_vector-Tuple{AbstractSphere{‚Ñù}, Any, Any, DefaultOrthonormalBasis}","content":" ManifoldsBase.get_vector  ‚Äî  Method get_vector(M::AbstractSphere{‚Ñù}, p, X, B::DefaultOrthonormalBasis) Convert a one-dimensional vector of coefficients  X  in the basis  B  of the tangent space at  p  on the  AbstractSphere M  to a tangent vector  Y  at  p  by rotating the hyperplane containing  X , whose normal is the  $x$ -axis, to the hyperplane whose normal is  p . Given  $q = p Œª + x$ , where  $Œª = \\operatorname{sgn}(‚ü®x, p‚ü©)$ , and  $‚ü®‚ãÖ, ‚ãÖ‚ü©_{\\mathrm{F}}$  denotes the Frobenius inner product, the formula for  $Y$  is \\[Y = X - q\\frac{2 \\left\\langle q, \\begin{pmatrix}0 \\\\ X\\end{pmatrix}\\right\\rangle_{\\mathrm{F}}}{‚ü®q, q‚ü©_{\\mathrm{F}}}.\\] source"},{"id":1480,"pagetitle":"Sphere","title":"ManifoldsBase.injectivity_radius","ref":"/manifolds/stable/manifolds/#ManifoldsBase.injectivity_radius-Tuple{AbstractSphere}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(M::AbstractSphere[, p]) Return the injectivity radius for the  AbstractSphere M , which is globally  $œÄ$ . injectivity_radius(M::Sphere, x, ::ProjectionRetraction) Return the injectivity radius for the  ProjectionRetraction  on the  AbstractSphere , which is globally  $\\frac{œÄ}{2}$ . source"},{"id":1481,"pagetitle":"Sphere","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{AbstractSphere, Any, Any, ProjectionInverseRetraction}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(M::AbstractSphere, p, q, ::ProjectionInverseRetraction) Compute the inverse of the projection based retraction on the  AbstractSphere M , i.e. rearranging  $p+X = q\\lVert p+X\\rVert_2$  yields since  $\\Re(‚ü®p,X‚ü©) = 0$  and when  $d_{ùïä^2}(p,q) ‚â§ \\frac{œÄ}{2}$  that \\[\\operatorname{retr}_p^{-1}(q) = \\frac{q}{\\Re(‚ü®p, q‚ü©)} - p.\\] source"},{"id":1482,"pagetitle":"Sphere","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{AbstractSphere}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(M::AbstractSphere) Return true if  AbstractSphere  is of dimension 1 and false otherwise. source"},{"id":1483,"pagetitle":"Sphere","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{AbstractSphere}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::AbstractSphere) Return the dimension of the  AbstractSphere M , respectively i.e. the dimension of the embedding -1. source"},{"id":1484,"pagetitle":"Sphere","title":"ManifoldsBase.parallel_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_to-Tuple{AbstractSphere, Vararg{Any, 4}}","content":" ManifoldsBase.parallel_transport_to  ‚Äî  Method parallel_transport_to(M::AbstractSphere, p, X, q) Compute the parallel transport on the  Sphere  of the tangent vector  X  at  p  to  q , provided, the  geodesic  between  p  and  q  is unique. The formula reads \\[P_{p‚Üêq}(X) = X - \\frac{\\Re(‚ü®\\log_p q,X‚ü©_p)}{d^2_ùïä(p,q)}\n\\bigl(\\log_p q + \\log_q p \\bigr).\\] source"},{"id":1485,"pagetitle":"Sphere","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{AbstractSphere, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::AbstractSphere, p, X) Project the point  X  onto the tangent space at  p  on the  Sphere M . \\[\\operatorname{proj}_{p}(X) = X - \\Re(‚ü®p, X‚ü©)p\\] source"},{"id":1486,"pagetitle":"Sphere","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{AbstractSphere, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::AbstractSphere, p) Project the point  p  from the embedding onto the  Sphere M . \\[\\operatorname{proj}(p) = \\frac{p}{\\lVert p \\rVert},\\] where  $\\lVert‚ãÖ\\rVert$  denotes the usual 2-norm for vectors if  $m=1$  and the Frobenius norm for the case  $m>1$ . source"},{"id":1487,"pagetitle":"Sphere","title":"ManifoldsBase.representation_size","ref":"/manifolds/stable/manifolds/#ManifoldsBase.representation_size-Tuple{ArraySphere}","content":" ManifoldsBase.representation_size  ‚Äî  Method representation_size(M::AbstractSphere) Return the size points on the  AbstractSphere M  are represented as, i.e., the representation size of the embedding. source"},{"id":1488,"pagetitle":"Sphere","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{AbstractSphere, Any, Any, ProjectionRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::AbstractSphere, p, X, ::ProjectionRetraction) Compute the retraction that is based on projection, i.e. \\[\\operatorname{retr}_p(X) = \\frac{p+X}{\\lVert p+X \\rVert_2}\\] source"},{"id":1489,"pagetitle":"Sphere","title":"ManifoldsBase.riemann_tensor","ref":"/manifolds/stable/manifolds/#ManifoldsBase.riemann_tensor-Tuple{AbstractSphere{‚Ñù}, Vararg{Any, 4}}","content":" ManifoldsBase.riemann_tensor  ‚Äî  Method riemann_tensor(M::AbstractSphere{‚Ñù}, p, X, Y, Z) Compute the Riemann tensor  $R(X,Y)Z$  at point  p  on  AbstractSphere M . The formula reads [ MF12 ] (though note that a different convention is used in that paper than in Manifolds.jl): \\[R(X,Y)Z = \\langle Z, Y \\rangle X - \\langle Z, X \\rangle Y\\] source"},{"id":1490,"pagetitle":"Sphere","title":"ManifoldsBase.sectional_curvature","ref":"/manifolds/stable/manifolds/#ManifoldsBase.sectional_curvature-Tuple{AbstractSphere, Any, Any, Any}","content":" ManifoldsBase.sectional_curvature  ‚Äî  Method sectional_curvature(::AbstractSphere, p, X, Y) Sectional curvature of  AbstractSphere M  is 1 if dimension is greater than 1 and 0 otherwise. source"},{"id":1491,"pagetitle":"Sphere","title":"ManifoldsBase.sectional_curvature_max","ref":"/manifolds/stable/manifolds/#ManifoldsBase.sectional_curvature_max-Tuple{AbstractSphere}","content":" ManifoldsBase.sectional_curvature_max  ‚Äî  Method sectional_curvature_max(::AbstractSphere) Sectional curvature of  AbstractSphere M  is 1 if dimension is greater than 1 and 0 otherwise. source"},{"id":1492,"pagetitle":"Sphere","title":"ManifoldsBase.sectional_curvature_min","ref":"/manifolds/stable/manifolds/#ManifoldsBase.sectional_curvature_min-Tuple{AbstractSphere}","content":" ManifoldsBase.sectional_curvature_min  ‚Äî  Method sectional_curvature_min(M::AbstractSphere) Sectional curvature of  AbstractSphere M  is 1 if dimension is greater than 1 and 0 otherwise. source"},{"id":1493,"pagetitle":"Sphere","title":"Statistics.mean","ref":"/manifolds/stable/manifolds/#Statistics.mean-Tuple{AbstractSphere, Vararg{Any}}","content":" Statistics.mean  ‚Äî  Method mean(\n    S::AbstractSphere,\n    x::AbstractVector,\n    [w::AbstractWeights,]\n    method = GeodesicInterpolationWithinRadius(œÄ/2);\n    kwargs...,\n) Compute the Riemannian  mean  of  x  using  GeodesicInterpolationWithinRadius . source"},{"id":1494,"pagetitle":"Sphere","title":"Visualization on  Sphere{2,‚Ñù}","ref":"/manifolds/stable/manifolds/#Visualization-on-Sphere{2,‚Ñù}","content":" Visualization on  Sphere{2,‚Ñù} You can visualize both points and tangent vectors on the sphere. Note There seems to be no unified way to draw spheres in the backends of  Plots.jl . This recipe currently uses the  seriestype wireframe  and  surface , which does not yet work with the default backend  GR . In general you can plot the surface of the hyperboloid either as wireframe ( wireframe=true ) additionally specifying  wires  (or  wires_x  and  wires_y ) to change the density of the wires and a  wireframe_color  for their color. The same holds for the plot as a  surface  (which is  false  by default) and its  surface_resolution  (or  surface_resolution_lat  or  surface_resolution_lon ) and a  surface_color . using Manifolds, Plots\npythonplot()\nM = Sphere(2)\npts = [ [1.0, 0.0, 0.0], [0.0, -1.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0] ]\nscene = plot(M, pts; wireframe_color=colorant\"#CCCCCC\", markersize=10) which scatters our points. We can also draw connecting geodesics, which here is a geodesic triangle. Here we discretize each geodesic with 100 points along the geodesic. The default value is  geodesic_interpolation=-1  which switches to scatter plot of the data. plot!(scene, M, pts; wireframe=false, geodesic_interpolation=100, linewidth=2) And we can also add tangent vectors, for example tangents pointing towards the geometric center of given points. pts2 =  [ [1.0, 0.0, 0.0], [0.0, -1.0, 0.0], [0.0, 0.0, 1.0] ]\np3 = 1/sqrt(3) .* [1.0, -1.0, 1.0]\nvecs = log.(Ref(M), pts2, Ref(p3))\nplot!(scene, M, pts2, vecs; wireframe = false, linewidth=1.5)"},{"id":1495,"pagetitle":"Sphere","title":"Literature","ref":"/manifolds/stable/manifolds/#Literature","content":" Literature [AMT13] P.¬†-.-A.¬†Absil, R.¬†Mahony and J.¬†Trumpf.  An Extrinsic Look at the Riemannian Hessian . In:  Geometric Science of Information , edited by F.¬†Nielsen and F.¬†Barbaresco (Springer Berlin Heidelberg, 2013); pp.¬†361‚Äì368. [CLLD22] E.¬†Chevallier, D.¬†Li, Y.¬†Lu and D.¬†B.¬†Dunson.  Exponential-wrapped distributions on symmetric spaces . ArXiv¬†Preprint (2022). [MF12] P.¬†Muralidharan and P.¬†T.¬†Fletcher.  Sasaki metrics for analysis of longitudinal data on manifolds . In:  2012 IEEE Conference on Computer Vision and Pattern Recognition  (2012)."},{"id":1498,"pagetitle":"Unit-norm symmetric matrices","title":"Unit-norm symmetric matrices","ref":"/manifolds/stable/manifolds/#Unit-norm-symmetric-matrices","content":" Unit-norm symmetric matrices"},{"id":1499,"pagetitle":"Unit-norm symmetric matrices","title":"Manifolds.SphereSymmetricMatrices","ref":"/manifolds/stable/manifolds/#Manifolds.SphereSymmetricMatrices","content":" Manifolds.SphereSymmetricMatrices  ‚Äî  Type SphereSymmetricMatrices{T,ùîΩ} <: AbstractEmbeddedManifold{‚Ñù,TransparentIsometricEmbedding} The  AbstractManifold   consisting of the  $n√ón$  symmetric matrices of unit Frobenius norm, i.e. \\[\\mathcal{S}_{\\text{sym}} :=\\bigl\\{p  ‚àà ùîΩ^{n√ón}\\ \\big|\\ p^{\\mathrm{H}} = p, \\lVert p \\rVert = 1 \\bigr\\},\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the Hermitian, i.e. complex conjugate transpose, and the field  $ùîΩ ‚àà \\{ ‚Ñù, ‚ÑÇ\\}$ . Constructor SphereSymmetricMatrices(n[, field=‚Ñù]) Generate the manifold of  n -by- n  symmetric matrices of unit Frobenius norm. source"},{"id":1500,"pagetitle":"Unit-norm symmetric matrices","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Union{Tuple{T}, Tuple{SphereSymmetricMatrices, T}} where T","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::SphereSymmetricMatrices, p; kwargs...) Check whether the matrix is a valid point on the  SphereSymmetricMatrices M , i.e. is an  n -by- n  symmetric matrix of unit Frobenius norm. The tolerance for the symmetry of  p  can be set using  kwargs... . source"},{"id":1501,"pagetitle":"Unit-norm symmetric matrices","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Union{Tuple{T}, Tuple{SphereSymmetricMatrices, Any, T}} where T","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::SphereSymmetricMatrices, p, X; kwargs... ) Check whether  X  is a tangent vector to manifold point  p  on the  SphereSymmetricMatrices M , i.e.  X  has to be a symmetric matrix of size  (n,n)  of unit Frobenius norm. The tolerance for the symmetry of  p  and  X  can be set using  kwargs... . source"},{"id":1502,"pagetitle":"Unit-norm symmetric matrices","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{SphereSymmetricMatrices}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::SphereSymmetricMatrices) Return false.  SphereSymmetricMatrices  is not a flat manifold. source"},{"id":1503,"pagetitle":"Unit-norm symmetric matrices","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Union{Tuple{SphereSymmetricMatrices{<:Any, ùîΩ}}, Tuple{ùîΩ}} where ùîΩ","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::SphereSymmetricMatrices{<:Any,ùîΩ}) Return the manifold dimension of the  SphereSymmetricMatrices n -by- n  symmetric matrix  M  of unit Frobenius norm over the number system  ùîΩ , i.e. \\[\\begin{aligned}\n\\dim(\\mathcal{S}_{\\text{sym}})(n,‚Ñù) &= \\frac{n(n+1)}{2} - 1,\\\\\n\\dim(\\mathcal{S}_{\\text{sym}})(n,‚ÑÇ) &= 2\\frac{n(n+1)}{2} - n -1.\n\\end{aligned}\\] source"},{"id":1504,"pagetitle":"Unit-norm symmetric matrices","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{SphereSymmetricMatrices, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::SphereSymmetricMatrices, p, X) Project the matrix  X  onto the tangent space at  p  on the  SphereSymmetricMatrices M , i.e. \\[\\operatorname{proj}_p(X) = \\frac{X + X^{\\mathrm{H}}}{2} - ‚ü®p, \\frac{X + X^{\\mathrm{H}}}{2}‚ü©p,\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the Hermitian, i.e. complex conjugate transposed. source"},{"id":1505,"pagetitle":"Unit-norm symmetric matrices","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{SphereSymmetricMatrices, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::SphereSymmetricMatrices, p) Projects  p  from the embedding onto the  SphereSymmetricMatrices M , i.e. \\[\\operatorname{proj}_{\\mathcal{S}_{\\text{sym}}}(p) = \\frac{1}{2} \\bigl( p + p^{\\mathrm{H}} \\bigr),\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the Hermitian, i.e. complex conjugate transposed. source"},{"id":1508,"pagetitle":"Stiefel","title":"Stiefel","ref":"/manifolds/stable/manifolds/#Stiefel","content":" Stiefel"},{"id":1509,"pagetitle":"Stiefel","title":"Common and metric independent functions","ref":"/manifolds/stable/manifolds/#Common-and-metric-independent-functions","content":" Common and metric independent functions"},{"id":1510,"pagetitle":"Stiefel","title":"Manifolds.Stiefel","ref":"/manifolds/stable/manifolds/#Manifolds.Stiefel","content":" Manifolds.Stiefel  ‚Äî  Type Stiefel{T,ùîΩ} <: AbstractDecoratorManifold{ùîΩ} The Stiefel manifold consists of all  $n√ók$ ,  $n ‚â• k$  unitary matrices, i.e. \\[\\operatorname{St}(n,k) = \\bigl\\{ p ‚àà ùîΩ^{n√ók}\\ \\big|\\ p^{\\mathrm{H}}p = I_k \\bigr\\},\\] where  $ùîΩ ‚àà \\{‚Ñù, ‚ÑÇ\\}$ ,  $‚ãÖ^{\\mathrm{H}}$  denotes the complex conjugate transpose or Hermitian, and  $I_k ‚àà ‚Ñù^{k√ók}$  denotes the  $k√ók$  identity matrix. The tangent space at a point  $p ‚àà \\mathcal M$  is given by \\[T_p \\mathcal M = \\{ X ‚àà ùîΩ^{n√ók} : p^{\\mathrm{H}}X + \\overline{X^{\\mathrm{H}}p} = 0_k\\},\\] where  $0_k$  is the  $k√ók$  zero matrix and  $\\overline{‚ãÖ}$  the (elementwise) complex conjugate. This manifold is modeled as an embedded manifold to the  Euclidean , i.e. several functions like the  inner  product and the  zero_vector  are inherited from the embedding. The manifold is named after  Eduard L. Stiefel  (1909‚Äì1978). Constructor Stiefel(n, k, field=‚Ñù; parameter::Symbol=:type) Generate the (real-valued) Stiefel manifold of  $n√ók$  dimensional orthonormal matrices. source"},{"id":1511,"pagetitle":"Stiefel","title":"Base.rand","ref":"/manifolds/stable/manifolds/#Base.rand-Tuple{Stiefel}","content":" Base.rand  ‚Äî  Method rand(::Stiefel; vector_at=nothing, œÉ::Real=1.0) When  vector_at  is  nothing , return a random (Gaussian) point  x  on the  Stiefel  manifold  M  by generating a (Gaussian) matrix with standard deviation  œÉ  and return the orthogonalized version, i.e. return the Q component of the QR decomposition of the random matrix of size  $n√ók$ . When  vector_at  is not  nothing , return a (Gaussian) random vector from the tangent space  $T_{vector\\_at}\\mathrm{St}(n,k)$  with mean zero and standard deviation  œÉ  by projecting a random Matrix onto the tangent vector at  vector_at . source"},{"id":1512,"pagetitle":"Stiefel","title":"Manifolds.uniform_distribution","ref":"/manifolds/stable/manifolds/#Manifolds.uniform_distribution-Tuple{Stiefel{<:Any, ‚Ñù}, Any}","content":" Manifolds.uniform_distribution  ‚Äî  Method uniform_distribution(M::Stiefel{<:Any,‚Ñù}, p) Uniform distribution on given (real-valued)  Stiefel M . Specifically, this is the normalized Haar and Hausdorff measure on  M . Generated points will be of similar type as  p . The implementation is based on Section 2.5.1 in [ Chi03 ]; see also Theorem 2.2.1(iii) in [ Chi03 ]. source"},{"id":1513,"pagetitle":"Stiefel","title":"ManifoldsBase.change_metric","ref":"/manifolds/stable/manifolds/#ManifoldsBase.change_metric-Tuple{Stiefel, EuclideanMetric, Any, Any}","content":" ManifoldsBase.change_metric  ‚Äî  Method change_metric(M::Stiefel, ::EuclideanMetric, p X) Change  X  to the corresponding vector with respect to the metric of the  Stiefel M , which is just the identity, since the manifold is isometrically embedded. source"},{"id":1514,"pagetitle":"Stiefel","title":"ManifoldsBase.change_representer","ref":"/manifolds/stable/manifolds/#ManifoldsBase.change_representer-Tuple{Stiefel, EuclideanMetric, Any, Any}","content":" ManifoldsBase.change_representer  ‚Äî  Method change_representer(M::Stiefel, ::EuclideanMetric, p, X) Change  X  to the corresponding representer of a cotangent vector at  p . Since the  Stiefel  manifold  M , is isometrically embedded, this is the identity source"},{"id":1515,"pagetitle":"Stiefel","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{Stiefel, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::Stiefel, p; kwargs...) Check whether  p  is a valid point on the  Stiefel M = $\\operatorname{St}(n,k)$ , i.e. that it has the right  AbstractNumbers  type and  $p^{\\mathrm{H}}p$  is (approximately) the identity, where  $‚ãÖ^{\\mathrm{H}}$  is the complex conjugate transpose. The settings for approximately can be set with  kwargs... . source"},{"id":1516,"pagetitle":"Stiefel","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{Stiefel, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::Stiefel, p, X; kwargs...) Checks whether  X  is a valid tangent vector at  p  on the  Stiefel M = $\\operatorname{St}(n,k)$ , i.e. the  AbstractNumbers  fits and it (approximately) holds that  $p^{\\mathrm{H}}X + \\overline{X^{\\mathrm{H}}p} = 0$ , where  $‚ãÖ^{\\mathrm{H}}$  denotes the Hermitian and  $\\overline{‚ãÖ}$  the (elementwise) complex conjugate. The settings for approximately can be set with  kwargs... . source"},{"id":1517,"pagetitle":"Stiefel","title":"ManifoldsBase.default_inverse_retraction_method","ref":"/manifolds/stable/manifolds/#ManifoldsBase.default_inverse_retraction_method-Tuple{Stiefel}","content":" ManifoldsBase.default_inverse_retraction_method  ‚Äî  Method default_inverse_retraction_method(M::Stiefel) Return  PolarInverseRetraction  as the default inverse retraction for the  Stiefel  manifold. source"},{"id":1518,"pagetitle":"Stiefel","title":"ManifoldsBase.default_retraction_method","ref":"/manifolds/stable/manifolds/#ManifoldsBase.default_retraction_method-Tuple{Stiefel}","content":" ManifoldsBase.default_retraction_method  ‚Äî  Method default_retraction_method(M::Stiefel) Return  PolarRetraction  as the default retraction for the  Stiefel  manifold. source"},{"id":1519,"pagetitle":"Stiefel","title":"ManifoldsBase.default_vector_transport_method","ref":"/manifolds/stable/manifolds/#ManifoldsBase.default_vector_transport_method-Tuple{Stiefel}","content":" ManifoldsBase.default_vector_transport_method  ‚Äî  Method default_vector_transport_method(M::Stiefel) Return the  DifferentiatedRetractionVectorTransport  of the [ PolarRetraction ]( PolarRetraction  as the default vector transport method for the  Stiefel  manifold. source"},{"id":1520,"pagetitle":"Stiefel","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{Stiefel, Any, Any, PolarInverseRetraction}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(M::Stiefel, p, q, ::PolarInverseRetraction) Compute the inverse retraction based on a singular value decomposition for two points  p ,  q  on the  Stiefel  manifold  M . This follows the folloing approach: From the Polar retraction we know that \\[\\operatorname{retr}_p^{-1}q = qs - t\\] if such a symmetric positive definite  $k√ók$  matrix exists. Since  $qs - t$  is also a tangent vector at  $p$  we obtain \\[p^{\\mathrm{H}}qs + s(p^{\\mathrm{H}}q)^{\\mathrm{H}} + 2I_k = 0,\\] which can either be solved by a Lyapunov approach or a continuous-time algebraic Riccati equation. This implementation follows the Lyapunov approach. source"},{"id":1521,"pagetitle":"Stiefel","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{Stiefel, Any, Any, QRInverseRetraction}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(M::Stiefel, p, q, ::QRInverseRetraction) Compute the inverse retraction based on a qr decomposition for two points  p ,  q  on the  Stiefel  manifold  M  and return the resulting tangent vector in  X . The computation follows Algorithm 1 in [ KFT13 ]. source"},{"id":1522,"pagetitle":"Stiefel","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{Stiefel}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(M::Stiefel) Return true if  Stiefel M  is one-dimensional. source"},{"id":1523,"pagetitle":"Stiefel","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{Stiefel{<:Any, ‚Ñù}}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::Stiefel) Return the dimension of the  Stiefel  manifold  M = $\\operatorname{St}(n,k,ùîΩ)$ . The dimension is given by \\[\\begin{aligned}\n\\dim \\mathrm{St}(n, k, ‚Ñù) &= nk - \\frac{1}{2}k(k+1)\\\\\n\\dim \\mathrm{St}(n, k, ‚ÑÇ) &= 2nk - k^2\\\\\n\\dim \\mathrm{St}(n, k, ‚Ñç) &= 4nk - k(2k-1)\n\\end{aligned}\\] source"},{"id":1524,"pagetitle":"Stiefel","title":"ManifoldsBase.representation_size","ref":"/manifolds/stable/manifolds/#ManifoldsBase.representation_size-Tuple{Stiefel}","content":" ManifoldsBase.representation_size  ‚Äî  Method representation_size(M::Stiefel) Returns the representation size of the  Stiefel M = $\\operatorname{St}(n,k)$ , i.e.  (n,k) , which is the matrix dimensions. source"},{"id":1525,"pagetitle":"Stiefel","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{Stiefel, Any, Any, CayleyRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(::Stiefel, p, X, ::CayleyRetraction) Compute the retraction on the  Stiefel  that is based on the Cayley transform[ Zhu16 ]. Using \\[  W_{p,X} = \\operatorname{P}_pXp^{\\mathrm{H}} - pX^{\\mathrm{H}}\\operatorname{P_p}\n  \\quad\\text{where}\n  \\operatorname{P}_p = I - \\frac{1}{2}pp^{\\mathrm{H}}\\] the formula reads \\[    \\operatorname{retr}_pX = \\Bigl(I - \\frac{1}{2}W_{p,X}\\Bigr)^{-1}\\Bigl(I + \\frac{1}{2}W_{p,X}\\Bigr)p.\\] It is implemented as the case  $m=1$  of the  PadeRetraction . source"},{"id":1526,"pagetitle":"Stiefel","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{Stiefel, Any, Any, PadeRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::Stiefel, p, X, ::PadeRetraction{m}) Compute the retraction on the  Stiefel  manifold  M  based on the Pad√© approximation of order  $m$  [ ZD18 ]. Let  $p_m$  and  $q_m$  be defined for any matrix  $A ‚àà ‚Ñù^{n√óx}$  as \\[  p_m(A) = \\sum_{k=0}^m \\frac{(2m-k)!m!}{(2m)!(m-k)!}\\frac{A^k}{k!}\\] and \\[  q_m(A) = \\sum_{k=0}^m \\frac{(2m-k)!m!}{(2m)!(m-k)!}\\frac{(-A)^k}{k!}\\] respectively. Then the Pad√© approximation (of the matrix exponential  $\\exp(A)$ ) reads \\[  r_m(A) = q_m(A)^{-1}p_m(A)\\] Defining further \\[  W_{p,X} = \\operatorname{P}_pXp^{\\mathrm{H}} - pX^{\\mathrm{H}}\\operatorname{P_p}\n  \\quad\\text{where }\n  \\operatorname{P}_p = I - \\frac{1}{2}pp^{\\mathrm{H}}\\] the retraction reads \\[  \\operatorname{retr}_pX = r_m(W_{p,X})p\\] source"},{"id":1527,"pagetitle":"Stiefel","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{Stiefel, Any, Any, PolarRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::Stiefel, p, X, ::PolarRetraction) Compute the SVD-based retraction  PolarRetraction  on the  Stiefel  manifold  M . With  $USV = p + X$  the retraction reads \\[\\operatorname{retr}_p X = U\\bar{V}^\\mathrm{H}.\\] source"},{"id":1528,"pagetitle":"Stiefel","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{Stiefel, Any, Any, QRRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::Stiefel, p, X, ::QRRetraction) Compute the QR-based retraction  QRRetraction  on the  Stiefel  manifold  M . With  $QR = p + X$  the retraction reads \\[\\operatorname{retr}_p X = QD,\\] where  $D$  is a  $n√ók$  matrix with \\[D = \\operatorname{diag}\\bigl(\\operatorname{sgn}(R_{ii}+0,5)_{i=1}^k \\bigr),\\] where ``\\operatorname{sgn}(p) = \\begin{cases} 1 & \\text{ for } p > 0,\\\n0 & \\text{ for } p = 0,\\\n-1& \\text{ for } p < 0. \\end{cases}`` source"},{"id":1529,"pagetitle":"Stiefel","title":"ManifoldsBase.vector_transport_direction","ref":"/manifolds/stable/manifolds/#ManifoldsBase.vector_transport_direction-Tuple{Stiefel, Any, Any, Any, DifferentiatedRetractionVectorTransport{CayleyRetraction}}","content":" ManifoldsBase.vector_transport_direction  ‚Äî  Method vector_transport_direction(::Stiefel, p, X, d, ::DifferentiatedRetractionVectorTransport{CayleyRetraction}) Compute the vector transport given by the differentiated retraction of the  CayleyRetraction , cf. [ Zhu16 ] Equation (17). The formula reads \\[\\operatorname{T}_{p,d}(X) =\n\\Bigl(I - \\frac{1}{2}W_{p,d}\\Bigr)^{-1}W_{p,X}\\Bigl(I - \\frac{1}{2}W_{p,d}\\Bigr)^{-1}p,\\] with \\[  W_{p,X} = \\operatorname{P}_pXp^{\\mathrm{H}} - pX^{\\mathrm{H}}\\operatorname{P_p}\n  \\quad\\text{where }\n  \\operatorname{P}_p = I - \\frac{1}{2}pp^{\\mathrm{H}}\\] Since this is the differentiated retraction as a vector transport, the result will be in the tangent space at  $q=\\operatorname{retr}_p(d)$  using the  CayleyRetraction . source"},{"id":1530,"pagetitle":"Stiefel","title":"ManifoldsBase.vector_transport_direction","ref":"/manifolds/stable/manifolds/#ManifoldsBase.vector_transport_direction-Tuple{Stiefel, Any, Any, Any, DifferentiatedRetractionVectorTransport{PolarRetraction}}","content":" ManifoldsBase.vector_transport_direction  ‚Äî  Method vector_transport_direction(M::Stiefel, p, X, d, DifferentiatedRetractionVectorTransport{PolarRetraction}) Compute the vector transport by computing the push forward of  retract(::Stiefel, ::Any, ::Any, ::PolarRetraction)  Section 3.5 of [ Zhu16 ]: \\[T_{p,d}^{\\text{Pol}}(X) = q*Œõ + (I-qq^{\\mathrm{T}})X(1+d^\\mathrm{T}d)^{-\\frac{1}{2}},\\] where  $q = \\operatorname{retr}^{\\mathrm{Pol}}_p(d)$ , and  $Œõ$  is the unique solution of the Sylvester equation \\[    Œõ(I+d^\\mathrm{T}d)^{\\frac{1}{2}} + (I + d^\\mathrm{T}d)^{\\frac{1}{2}} = q^\\mathrm{T}X - X^\\mathrm{T}q\\] source"},{"id":1531,"pagetitle":"Stiefel","title":"ManifoldsBase.vector_transport_direction","ref":"/manifolds/stable/manifolds/#ManifoldsBase.vector_transport_direction-Tuple{Stiefel, Any, Any, Any, DifferentiatedRetractionVectorTransport{QRRetraction}}","content":" ManifoldsBase.vector_transport_direction  ‚Äî  Method vector_transport_direction(M::Stiefel, p, X, d, DifferentiatedRetractionVectorTransport{QRRetraction}) Compute the vector transport by computing the push forward of the  retract(::Stiefel, ::Any, ::Any, ::QRRetraction) , See  [ AMS08 ], p. 173, or Section 3.5 of [ Zhu16 ]. \\[T_{p,d}^{\\text{QR}}(X) = q*\\rho_{\\mathrm{s}}(q^\\mathrm{T}XR^{-1}) + (I-qq^{\\mathrm{T}})XR^{-1},\\] where  $q = \\operatorname{retr}^{\\mathrm{QR}}_p(d)$ ,  $R$  is the  $R$  factor of the QR decomposition of  $p + d$ , and \\[\\bigl( \\rho_{\\mathrm{s}}(A) \\bigr)_{ij}\n= \\begin{cases}\nA_{ij}&\\text{ if } i > j\\\\\n0 \\text{ if } i = j\\\\\n-A_{ji} \\text{ if } i < j.\\\\\n\\end{cases}\\] source"},{"id":1532,"pagetitle":"Stiefel","title":"ManifoldsBase.vector_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.vector_transport_to-Tuple{Stiefel, Any, Any, Any, DifferentiatedRetractionVectorTransport{PolarRetraction}}","content":" ManifoldsBase.vector_transport_to  ‚Äî  Method vector_transport_to(M::Stiefel, p, X, q, DifferentiatedRetractionVectorTransport{PolarRetraction}) Compute the vector transport by computing the push forward of the  retract(M::Stiefel, ::Any, ::Any, ::PolarRetraction) , see Section 4 of [ HGA15 ] or  Section 3.5 of [ Zhu16 ]: \\[T_{q\\gets p}^{\\text{Pol}}(X) = q*Œõ + (I-qq^{\\mathrm{T}})X(1+d^\\mathrm{T}d)^{-\\frac{1}{2}},\\] where  $d = \\bigl( \\operatorname{retr}^{\\mathrm{Pol}}_p\\bigr)^{-1}(q)$ , and  $Œõ$  is the unique solution of the Sylvester equation \\[    Œõ(I+d^\\mathrm{T}d)^{\\frac{1}{2}} + (I + d^\\mathrm{T}d)^{\\frac{1}{2}} = q^\\mathrm{T}X - X^\\mathrm{T}q\\] source"},{"id":1533,"pagetitle":"Stiefel","title":"ManifoldsBase.vector_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.vector_transport_to-Tuple{Stiefel, Any, Any, Any, DifferentiatedRetractionVectorTransport{QRRetraction}}","content":" ManifoldsBase.vector_transport_to  ‚Äî  Method vector_transport_to(M::Stiefel, p, X, q, DifferentiatedRetractionVectorTransport{QRRetraction}) Compute the vector transport by computing the push forward of the  retract(M::Stiefel, ::Any, ::Any, ::QRRetraction) , see  [ AMS08 ], p. 173, or Section 3.5 of [ Zhu16 ]. \\[T_{q \\gets p}^{\\text{QR}}(X) = q*\\rho_{\\mathrm{s}}(q^\\mathrm{T}XR^{-1}) + (I-qq^{\\mathrm{T}})XR^{-1},\\] where  $d = \\bigl(\\operatorname{retr}^{\\mathrm{QR}}\\bigr)^{-1}_p(q)$ ,  $R$  is the  $R$  factor of the QR decomposition of  $p+X$ , and \\[\\bigl( \\rho_{\\mathrm{s}}(A) \\bigr)_{ij}\n= \\begin{cases}\nA_{ij}&\\text{ if } i > j\\\\\n0 \\text{ if } i = j\\\\\n-A_{ji} \\text{ if } i < j.\\\\\n\\end{cases}\\] source"},{"id":1534,"pagetitle":"Stiefel","title":"ManifoldsBase.vector_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.vector_transport_to-Tuple{Stiefel, Any, Any, Any, ProjectionTransport}","content":" ManifoldsBase.vector_transport_to  ‚Äî  Method vector_transport_to(M::Stiefel, p, X, q, ::ProjectionTransport) Compute a vector transport by projection, i.e. project  X  from the tangent space at  p  by projection it onto the tangent space at  q . source"},{"id":1535,"pagetitle":"Stiefel","title":"Default metric: the Euclidean metric","ref":"/manifolds/stable/manifolds/#Default-metric:-the-Euclidean-metric","content":" Default metric: the Euclidean metric The  EuclideanMetric  is obtained from the embedding of the Stiefel manifold in  $‚Ñù^{n,k}$ ."},{"id":1536,"pagetitle":"Stiefel","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{Stiefel, Vararg{Any}}","content":" Base.exp  ‚Äî  Method exp(M::Stiefel, p, X) Compute the exponential map on the  Stiefel {n,k,ùîΩ} () manifold  M  emanating from  p  in tangent direction  X . \\[\\exp_p X = \\begin{pmatrix}\n   p\\\\X\n \\end{pmatrix}\n \\operatorname{Exp}\n \\left(\n \\begin{pmatrix} p^{\\mathrm{H}}X & - X^{\\mathrm{H}}X\\\\\n I_n & p^{\\mathrm{H}}X\\end{pmatrix}\n \\right)\n\\begin{pmatrix}  \\exp( -p^{\\mathrm{H}}X) \\\\ 0_n\\end{pmatrix},\\] where  $\\operatorname{Exp}$  denotes matrix exponential,  $‚ãÖ^{\\mathrm{H}}$  denotes the complex conjugate transpose or Hermitian, and  $I_k$  and  $0_k$  are the identity matrix and the zero matrix of dimension  $k√ók$ , respectively. source"},{"id":1537,"pagetitle":"Stiefel","title":"ManifoldDiff.riemannian_Hessian","ref":"/manifolds/stable/manifolds/#ManifoldDiff.riemannian_Hessian-Tuple{Stiefel, Vararg{Any, 4}}","content":" ManifoldDiff.riemannian_Hessian  ‚Äî  Method Y = riemannian_Hessian(M::Stiefel, p, G, H, X)\nriemannian_Hessian!(M::Stiefel, Y, p, G, H, X) Compute the Riemannian Hessian  $\\operatorname{Hess} f(p)[X]$  given the Euclidean gradient  $‚àá f(\\tilde p)$  in  G  and the Euclidean Hessian  $‚àá^2 f(\\tilde p)[\\tilde X]$  in  H , where  $\\tilde p, \\tilde X$  are the representations of  $p,X$  in the embedding,. Here, we adopt Eq. (5.6) [ Ngu23 ], where we use for the  EuclideanMetric $Œ±_0=Œ±_1=1$  in their formula. Then the formula reads \\[    \\operatorname{Hess}f(p)[X]\n    =\n    \\operatorname{proj}_{T_p\\mathcal M}\\Bigl(\n        ‚àá^2f(p)[X] - \\frac{1}{2} X \\bigl((‚àáf(p))^{\\mathrm{H}}p + p^{\\mathrm{H}}‚àáf(p)\\bigr)\n    \\Bigr).\\] Compared to Eq. (5.6) also the metric conversion simplifies to the identity. source"},{"id":1538,"pagetitle":"Stiefel","title":"ManifoldsBase.Weingarten","ref":"/manifolds/stable/manifolds/#ManifoldsBase.Weingarten-Tuple{Stiefel, Any, Any, Any}","content":" ManifoldsBase.Weingarten  ‚Äî  Method Weingarten(M::Stiefel, p, X, V) Compute the Weingarten map  $\\mathcal W_p$  at  p  on the  Stiefel M  with respect to the tangent vector  $X \\in T_p\\mathcal M$  and the normal vector  $V \\in N_p\\mathcal M$ . The formula is due to [ AMT13 ] given by \\[\\mathcal W_p(X,V) = -Xp^{\\mathrm{H}}V - \\frac{1}{2}p\\bigl(X^\\mathrm{H}V + V^{\\mathrm{H}}X\\bigr)\\] source"},{"id":1539,"pagetitle":"Stiefel","title":"ManifoldsBase.get_basis","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_basis-Tuple{Stiefel{<:Any, ‚Ñù}, Any, DefaultOrthonormalBasis{‚Ñù, TangentSpaceType}}","content":" ManifoldsBase.get_basis  ‚Äî  Method get_basis(M::Stiefel{<:Any,‚Ñù}, p, B::DefaultOrthonormalBasis) Create the default basis using the parametrization for any  $X ‚àà T_p\\mathcal M$ . Set  $p_\\bot \\in ‚Ñù^{n√ó(n-k)}$  the matrix such that the  $n√ón$  matrix of the common columns  $[p\\ p_\\bot]$  is an ONB. For any skew symmetric matrix  $a ‚àà ‚Ñù^{k√ók}$  and any  $b ‚àà ‚Ñù^{(n-k)√ók}$  the matrix \\[X = pa + p_\\bot b ‚àà T_p\\mathcal M\\] and we can use the  $\\frac{1}{2}k(k-1) + (n-k)k = nk-\\frac{1}{2}k(k+1)$  entries of  $a$  and  $b$  to specify a basis for the tangent space. using unit vectors for constructing both the upper matrix of  $a$  to build a skew symmetric matrix and the matrix b, the default basis is constructed. Since  $[p\\ p_‚ä•]$  is an automorphism on  $‚Ñù^{n√óp}$  the elements of  $a$  and  $b$  are orthonormal coordinates for the tangent space. To be precise exactly one element in the upper trangular entries of  $a$  is set to  $1$  its symmetric entry to  $-1$  and we normalize with the factor  $\\frac{1}{\\sqrt{2}}$  and for  $b$  one can just use unit vectors reshaped to a matrix to obtain orthonormal set of parameters. source"},{"id":1540,"pagetitle":"Stiefel","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{Stiefel, Any, Any, ProjectionInverseRetraction}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(M::Stiefel, p, q, method::ProjectionInverseRetraction) Compute a projection-based inverse retraction. The inverse retraction is computed by projecting the logarithm map in the embedding to the tangent space at  $p$ . source"},{"id":1541,"pagetitle":"Stiefel","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Stiefel, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::Stiefel,p) Projects  p  from the embedding onto the  Stiefel M , i.e. compute  q  as the polar decomposition of  $p$  such that  $q^{\\mathrm{H}}q$  is the identity, where  $‚ãÖ^{\\mathrm{H}}$  denotes the hermitian, i.e. complex conjugate transposed. source"},{"id":1542,"pagetitle":"Stiefel","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Stiefel, Vararg{Any}}","content":" ManifoldsBase.project  ‚Äî  Method project(M::Stiefel, p, X) Project  X  onto the tangent space of  p  to the  Stiefel  manifold  M . The formula reads \\[\\operatorname{proj}_{T_p\\mathcal M}(X) = X - p \\operatorname{Sym}(p^{\\mathrm{H}}X),\\] where  $\\operatorname{Sym}(q)$  is the symmetrization of  $q$ , e.g. by  $\\operatorname{Sym}(q) = \\frac{q^{\\mathrm{H}}+q}{2}$ . source"},{"id":1543,"pagetitle":"Stiefel","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{Stiefel, Any, Any, ProjectionRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::Stiefel, p, X, method::ProjectionRetraction) Compute a projection-based retraction. The retraction is computed by projecting the exponential map in the embedding to  M . source"},{"id":1544,"pagetitle":"Stiefel","title":"The canonical metric","ref":"/manifolds/stable/manifolds/#The-canonical-metric","content":" The canonical metric Any  $X‚ààT_p\\mathcal M$ ,  $p‚àà\\mathcal M$ , can be written as \\[X = pA + (I_n-pp^{\\mathrm{T}})B,\n\\quad\nA ‚àà ‚Ñù^{p√óp} \\text{ skew-symmetric},\n\\quad\nB ‚àà ‚Ñù^{n√óp} \\text{ arbitrary.}\\] In the  EuclideanMetric , the elements from  $A$  are counted twice (i.e. weighted with a factor of 2). The canonical metric avoids this."},{"id":1545,"pagetitle":"Stiefel","title":"Manifolds.ApproximateLogarithmicMap","ref":"/manifolds/stable/manifolds/#Manifolds.ApproximateLogarithmicMap","content":" Manifolds.ApproximateLogarithmicMap  ‚Äî  Type ApproximateLogarithmicMap <: ApproximateInverseRetraction An approximate implementation of the logarithmic map, which is an  inverse_retract ion. See  inverse_retract(::MetricManifold{‚Ñù,<:Stiefel{<:Any,‚Ñù},CanonicalMetric}, ::Any, ::Any, ::ApproximateLogarithmicMap)  for a use case. Fields max_iterations  ‚Äì maximal number of iterations used in the approximation tolerance  ‚Äì¬†a tolerance used as a stopping criterion source"},{"id":1546,"pagetitle":"Stiefel","title":"Manifolds.CanonicalMetric","ref":"/manifolds/stable/manifolds/#Manifolds.CanonicalMetric","content":" Manifolds.CanonicalMetric  ‚Äî  Type CanonicalMetric <: AbstractMetric The Canonical Metric refers to a metric for the  Stiefel  manifold, see[ EAS98 ]. source"},{"id":1547,"pagetitle":"Stiefel","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{MetricManifold{‚Ñù, <:Stiefel{<:Any, ‚Ñù}, CanonicalMetric}, Vararg{Any}}","content":" Base.exp  ‚Äî  Method q = exp(M::MetricManifold{‚Ñù,<:Stiefel{<:Any,‚Ñù},CanonicalMetric}, p, X)\nexp!(M::MetricManifold{‚Ñù,<:Stiefel{<:Any,‚Ñù},CanonicalMetric}, q, p, X) Compute the exponential map on the  Stiefel (n, k)  manifold with respect to the  CanonicalMetric . First, decompose The tangent vector  $X$  into its horizontal and vertical component with respect to  $p$ , i.e. \\[X = pp^{\\mathrm{T}}X + (I_n-pp^{\\mathrm{T}})X,\\] where  $I_n$  is the  $n√ón$  identity matrix. We introduce  $A=p^{\\mathrm{T}}X$  and  $QR = (I_n-pp^{\\mathrm{T}})X$  the  qr  decomposition of the vertical component. Then using the matrix exponential  $\\operatorname{Exp}$  we introduce  $B$  and  $C$  as \\[\\begin{pmatrix}\nB\\\\C\n\\end{pmatrix}\n\\coloneqq\n\\operatorname{Exp}\\left(\n\\begin{pmatrix}\nA & -R^{\\mathrm{T}}\\\\ R & 0\n\\end{pmatrix}\n\\right)\n\\begin{pmatrix}I_k\\\\0\\end{pmatrix}\\] the exponential map reads \\[q = \\exp_p X = pC + QB.\\] For more details, see [ EAS98 ][ Zim17 ]. source"},{"id":1548,"pagetitle":"Stiefel","title":"ManifoldDiff.riemannian_Hessian","ref":"/manifolds/stable/manifolds/#ManifoldDiff.riemannian_Hessian-Union{Tuple{ùîΩ}, Tuple{MetricManifold{ùîΩ, Stiefel, CanonicalMetric}, Vararg{Any, 4}}} where ùîΩ","content":" ManifoldDiff.riemannian_Hessian  ‚Äî  Method Y = riemannian_Hessian(M::MetricManifold{‚Ñù, Stiefel, CanonicalMetric}, p, G, H, X)\nriemannian_Hessian!(M::MetricManifold{‚Ñù, Stiefel, CanonicalMetric}, Y, p, G, H, X) Compute the Riemannian Hessian  $\\operatorname{Hess} f(p)[X]$  given the Euclidean gradient  $‚àá f(\\tilde p)$  in  G  and the Euclidean Hessian  $‚àá^2 f(\\tilde p)[\\tilde X]$  in  H , where  $\\tilde p, \\tilde X$  are the representations of  $p,X$  in the embedding,. Here, we adopt Eq. (5.6) [ Ngu23 ], for the  CanonicalMetric $Œ±_0=1, Œ±_1=\\frac{1}{2}$  in their formula. The formula reads \\[    \\operatorname{Hess}f(p)[X]\n    =\n    \\operatorname{proj}_{T_p\\mathcal M}\\Bigl(\n        ‚àá^2f(p)[X] - \\frac{1}{2} X \\bigl( (‚àáf(p))^{\\mathrm{H}}p + p^{\\mathrm{H}}‚àáf(p)\\bigr)\n        - \\frac{1}{2} \\bigl( P ‚àáf(p) p^{\\mathrm{H}} + p ‚àáf(p))^{\\mathrm{H}} P)X\n    \\Bigr),\\] where  $P = I-pp^{\\mathrm{H}}$ . source"},{"id":1549,"pagetitle":"Stiefel","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{MetricManifold{‚Ñù, <:Stiefel{<:Any, ‚Ñù}, CanonicalMetric}, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::MetricManifold{‚Ñù, Stiefel{<:Any,‚Ñù}, X, CanonicalMetric}, p, X, Y) Compute the inner product on the  Stiefel  manifold with respect to the  CanonicalMetric . The formula reads \\[g_p(X,Y) = \\operatorname{tr}\\bigl( X^{\\mathrm{T}}(I_n - \\frac{1}{2}pp^{\\mathrm{T}})Y \\bigr).\\] source"},{"id":1550,"pagetitle":"Stiefel","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{MetricManifold{‚Ñù, <:Stiefel{<:Any, ‚Ñù}, CanonicalMetric}, Any, Any, ApproximateLogarithmicMap}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method X = inverse_retract(M::MetricManifold{‚Ñù, Stiefel{<:Any,‚Ñù}, CanonicalMetric}, p, q, a::ApproximateLogarithmicMap)\ninverse_retract!(M::MetricManifold{‚Ñù, Stiefel{<:Any,‚Ñù}, X, CanonicalMetric}, p, q, a::ApproximateLogarithmicMap) Compute an approximation to the logarithmic map on the  Stiefel (n, k)  manifold with respect to the  CanonicalMetric  using a matrix-algebraic based approach to an iterative inversion of the formula of the  exp . The algorithm is derived in [ Zim17 ] and it uses the  max_iterations  and the  tolerance  field from the  ApproximateLogarithmicMap . source"},{"id":1551,"pagetitle":"Stiefel","title":"The submersion or normal metric","ref":"/manifolds/stable/manifolds/#The-submersion-or-normal-metric","content":" The submersion or normal metric"},{"id":1552,"pagetitle":"Stiefel","title":"Manifolds.StiefelSubmersionMetric","ref":"/manifolds/stable/manifolds/#Manifolds.StiefelSubmersionMetric","content":" Manifolds.StiefelSubmersionMetric  ‚Äî  Type StiefelSubmersionMetric{T<:Real} <: RiemannianMetric The submersion (or normal) metric family on the  Stiefel  manifold. The family, with a single real parameter  $Œ±>-1$ , has two special cases: $Œ± = -\\frac{1}{2}$ :  EuclideanMetric $Œ± = 0$ :  CanonicalMetric The family was described in [ HML21 ]. This implementation follows the description in [ ZH22 ]. Constructor StiefelSubmersionMetric(Œ±) Construct the submersion metric on the Stiefel manifold with the parameter  $Œ±$ . source"},{"id":1553,"pagetitle":"Stiefel","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{MetricManifold{‚Ñù, <:Stiefel{<:Any, ‚Ñù}, <:StiefelSubmersionMetric}, Vararg{Any}}","content":" Base.exp  ‚Äî  Method q = exp(M::MetricManifold{‚Ñù,<:Stiefel{<:Any,‚Ñù},<:StiefelSubmersionMetric}, p, X)\nexp!(M::MetricManifold{‚Ñù,<:Stiefel{<:Any,‚Ñù},<:StiefelSubmersionMetric}, q, p, X) Compute the exponential map on the  Stiefel(n,k)  manifold with respect to the  StiefelSubmersionMetric . The exponential map is given by \\[\\exp_p X = \\operatorname{Exp}\\bigl(\n    -\\frac{2Œ±+1}{Œ±+1} p p^\\mathrm{T} X p^\\mathrm{T} +\n    X p^\\mathrm{T} - p X^\\mathrm{T}\n\\bigr) p \\operatorname{Exp}\\bigl(\\frac{\\alpha}{\\alpha+1} p^\\mathrm{T} X\\bigr)\\] This implementation is based on [ ZH22 ]. For  $k < \\frac{n}{2}$  the exponential is computed more efficiently using  StiefelFactorization . source"},{"id":1554,"pagetitle":"Stiefel","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{MetricManifold{‚Ñù, <:Stiefel{<:Any, ‚Ñù}, <:StiefelSubmersionMetric}, Any, Any}","content":" Base.log  ‚Äî  Method log(M::MetricManifold{‚Ñù,<:Stiefel{<:Any,‚Ñù},<:StiefelSubmersionMetric}, p, q; kwargs...) Compute the logarithmic map on the  Stiefel(n,k)  manifold with respect to the  StiefelSubmersionMetric . The logarithmic map is computed using  ShootingInverseRetraction . For  $k ‚â§ \\lfloor\\frac{n}{2}\\rfloor$ , this is sped up using the  $k$ -shooting method of [ ZH22 ]. Keyword arguments are forwarded to  ShootingInverseRetraction ; see that documentation for details. Their defaults are: num_transport_points=4 tolerance=sqrt(eps()) max_iterations=1_000 source"},{"id":1555,"pagetitle":"Stiefel","title":"ManifoldDiff.riemannian_Hessian","ref":"/manifolds/stable/manifolds/#ManifoldDiff.riemannian_Hessian-Tuple{MetricManifold{‚Ñù, <:Stiefel{<:Any, ‚Ñù}, <:StiefelSubmersionMetric}, Vararg{Any, 4}}","content":" ManifoldDiff.riemannian_Hessian  ‚Äî  Method Y = riemannian_Hessian(M::MetricManifold{‚Ñù,<:Stiefel{<:Any,‚Ñù},StiefelSubmersionMetric}, p, G, H, X)\nriemannian_Hessian!(MetricManifold{‚Ñù,<:Stiefel{<:Any,‚Ñù},StiefelSubmersionMetric}, Y, p, G, H, X) Compute the Riemannian Hessian  $\\operatorname{Hess} f(p)[X]$  given the Euclidean gradient  $‚àá f(\\tilde p)$  in  G  and the Euclidean Hessian  $‚àá^2 f(\\tilde p)[\\tilde X]$  in  H , where  $\\tilde p, \\tilde X$  are the representations of  $p,X$  in the embedding,. Here, we adopt Eq. (5.6) [ Ngu23 ], for the  CanonicalMetric $Œ±_0=1, Œ±_1=\\frac{1}{2}$  in their formula. The formula reads \\[    \\operatorname{Hess}f(p)[X]\n    =\n    \\operatorname{proj}_{T_p\\mathcal M}\\Bigl(\n        ‚àá^2f(p)[X] - \\frac{1}{2} X \\bigl( (‚àáf(p))^{\\mathrm{H}}p + p^{\\mathrm{H}}‚àáf(p)\\bigr)\n        - \\frac{2Œ±+1}{2(Œ±+1)} \\bigl( P ‚àáf(p) p^{\\mathrm{H}} + p ‚àáf(p))^{\\mathrm{H}} P)X\n    \\Bigr),\\] where  $P = I-pp^{\\mathrm{H}}$ . Compared to Eq. (5.6) we have that their  $Œ±_0 = 1$ and  $\\alpha_1 =  \\frac{2Œ±+1}{2(Œ±+1)} + 1$ . source"},{"id":1556,"pagetitle":"Stiefel","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{MetricManifold{‚Ñù, <:Stiefel{<:Any, ‚Ñù}, <:StiefelSubmersionMetric}, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::MetricManifold{‚Ñù,<:Stiefel{<:Any,‚Ñù},<:StiefelSubmersionMetric}, p, X, Y) Compute the inner product on the  Stiefel  manifold with respect to the  StiefelSubmersionMetric . The formula reads \\[g_p(X,Y) = \\operatorname{tr}\\bigl( X^{\\mathrm{T}}(I_n - \\frac{2Œ±+1}{2(Œ±+1)}pp^{\\mathrm{T}})Y \\bigr),\\] where  $Œ±$  is the parameter of the metric. source"},{"id":1557,"pagetitle":"Stiefel","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{MetricManifold{‚Ñù, <:Stiefel, <:StiefelSubmersionMetric}, Any, Any, ShootingInverseRetraction}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(\n    M::MetricManifold{‚Ñù,<:Stiefel{<:Any,‚Ñù},<:StiefelSubmersionMetric},\n    p,\n    q,\n    method::ShootingInverseRetraction,\n) Compute the inverse retraction using  ShootingInverseRetraction . In general the retraction is computed using the generic shooting method. inverse_retract(\n    M::MetricManifold{‚Ñù,<:Stiefel{<:Any,‚Ñù},<:StiefelSubmersionMetric},\n    p,\n    q,\n    method::ShootingInverseRetraction{\n        ExponentialRetraction,\n        ProjectionInverseRetraction,\n        <:Union{ProjectionTransport,ScaledVectorTransport{ProjectionTransport}},\n    },\n) Compute the inverse retraction using  ShootingInverseRetraction  more efficiently. For  $k < \\frac{n}{2}$  the retraction is computed more efficiently using  StiefelFactorization . source"},{"id":1558,"pagetitle":"Stiefel","title":"Internal types and functions","ref":"/manifolds/stable/manifolds/#Internal-types-and-functions","content":" Internal types and functions"},{"id":1559,"pagetitle":"Stiefel","title":"Manifolds.StiefelFactorization","ref":"/manifolds/stable/manifolds/#Manifolds.StiefelFactorization","content":" Manifolds.StiefelFactorization  ‚Äî  Type StiefelFactorization{UT,XT} <: AbstractManifoldPoint Represent points (and vectors) on  Stiefel(n, k)  with  $2k√ók$  factors [ ZH22 ]. Given a point  $p ‚àà \\mathrm{St}(n, k)$  and another matrix  $B ‚àà ‚Ñù^{n√ók}$  for  $k ‚â§ \\lfloor\\frac{n}{2}\\rfloor$  the factorization is \\[\\begin{aligned}\nB &= UZ\\\\\nU &= \\begin{bmatrix}p & Q\\end{bmatrix} ‚àà \\mathrm{St}(n, 2k)\\\\\nZ &= \\begin{bmatrix}Z_1 \\\\ Z_2\\end{bmatrix}, \\quad Z_1,Z_2 ‚àà ‚Ñù^{k√ók}.\n\\end{aligned}\\] If  $B ‚àà \\mathrm{St}(n, k)$ , then  $Z ‚àà \\mathrm{St}(2k, k)$ . Note that not every matrix  $B$  can be factorized in this way. For a fixed  $U$ , if  $r ‚àà \\mathrm{St}(n, k)$  has the factor  $Z_r ‚àà \\mathrm{St}(2k, k)$ , then  $X_r ‚àà T_r \\mathrm{St}(n, k)$  has the factor  $Z_{X_r} ‚àà T_{Z_r} \\mathrm{St}(2k, k)$ . $Q$  is determined by choice of a second matrix  $A ‚àà ‚Ñù^{n√ók}$  with the decomposition \\[\\begin{aligned}\nA &= UZ\\\\\nZ_1 &= p^\\mathrm{T} A \\\\\nQ Z_2 &= (I - p p^\\mathrm{T}) A,\n\\end{aligned}\\] where here  $Q Z_2$  is the any decomposition that produces  $Q ‚àà \\mathrm{St}(n, k)$ , for which we choose the QR decomposition. This factorization is useful because it is closed under addition, subtraction, scaling, projection, and the Riemannian exponential and logarithm under the  StiefelSubmersionMetric . That is, if all matrices involved are factorized to have the same  $U$ , then all of these operations and any algorithm that depends only on them can be performed in terms of the  $2k√ók$  matrices  $Z$ . For  $n ‚â´ k$ , this can be much more efficient than working with the full matrices. Warning This type is intended strictly for internal use and should not be directly used. source"},{"id":1560,"pagetitle":"Stiefel","title":"Manifolds.stiefel_factorization","ref":"/manifolds/stable/manifolds/#Manifolds.stiefel_factorization-Tuple{Any, Any}","content":" Manifolds.stiefel_factorization  ‚Äî  Method stiefel_factorization(p, x) -> StiefelFactorization Compute the  StiefelFactorization  of  $x$  relative to the point  $p$ . source"},{"id":1561,"pagetitle":"Stiefel","title":"Literature","ref":"/manifolds/stable/manifolds/#Literature","content":" Literature [AMT13] P.¬†-.-A.¬†Absil, R.¬†Mahony and J.¬†Trumpf.  An Extrinsic Look at the Riemannian Hessian . In:  Geometric Science of Information , edited by F.¬†Nielsen and F.¬†Barbaresco (Springer Berlin Heidelberg, 2013); pp.¬†361‚Äì368. [AMS08] P.-A.¬†Absil, R.¬†Mahony and R.¬†Sepulchre.  Optimization Algorithms on Matrix Manifolds  (Princeton University Press, 2008), available online at  press.princeton.edu/chapters/absil/ . [Chi03] Y.¬†Chikuse.  Statistics on Special Manifolds  (Springer New York, 2003). [EAS98] A.¬†Edelman, T.¬†A.¬†Arias and S.¬†T.¬†Smith.  The Geometry of Algorithms with Orthogonality Constraints .  SIAM¬†Journal¬†on¬†Matrix¬†Analysis¬†and¬†Applications  20 , 303‚Äì353  (1998),  arXiv:806030 . [HGA15] W.¬†Huang, K.¬†A.¬†Gallivan and P.-A.¬†Absil.  A Broyden Class of Quasi-Newton Methods for Riemannian Optimization .  SIAM¬†Journal¬†on¬†Optimization  25 , 1660‚Äì1685  (2015). [HML21] K.¬†H√ºper, I.¬†Markina and F.¬†S.¬†Leite.  A Lagrangian approach to extremal curves on Stiefel manifolds .  Journal¬†of¬†Geometric¬†Mechanics  13 , 55  (2021). [KFT13] T.¬†Kaneko, S.¬†Fiori and T.¬†Tanaka.  Empirical Arithmetic Averaging Over the Compact Stiefel Manifold .  IEEE¬†Transactions¬†on¬†Signal¬†Processing  61 , 883‚Äì894  (2013). [Ngu23] D.¬†Nguyen.  Operator-Valued Formulas for Riemannian Gradient and Hessian and Families of Tractable Metrics in Riemannian Optimization .  Journal¬†of¬†Optimization¬†Theory¬†and¬†Applications  198 , 135‚Äì164  (2023),  arXiv:2009.10159 . [Zhu16] X.¬†Zhu.  A Riemannian conjugate gradient method for optimization on the Stiefel manifold .  Computational¬†Optimization¬†and¬†Applications  67 , 73‚Äì110  (2016). [ZD18] X.¬†Zhu and C.¬†Duan.  On matrix exponentials and their approximations related to optimization on the Stiefel manifold .  Optimization¬†Letters  13 , 1069‚Äì1083  (2018). [Zim17] R.¬†Zimmermann.  A Matrix-Algebraic Algorithm for the Riemannian Logarithm on the Stiefel Manifold under the Canonical Metric .  SIAM¬†J.¬†Matrix¬†Anal.¬†Appl.  38 , 322‚Äì342  (2017),  arXiv:1604.05054 . [ZH22] R.¬†Zimmermann and K.¬†H√ºper.  Computing the Riemannian Logarithm on the Stiefel Manifold: Metrics, Methods, and Performance .  SIAM¬†Journal¬†on¬†Matrix¬†Analysis¬†and¬†Applications  43 , 953‚Äì980  (2022),  arXiv:2103.12046 ."},{"id":1564,"pagetitle":"Symmetric matrices","title":"Symmetric matrices","ref":"/manifolds/stable/manifolds/#Symmetric-matrices","content":" Symmetric matrices"},{"id":1565,"pagetitle":"Symmetric matrices","title":"Manifolds.SymmetricMatrices","ref":"/manifolds/stable/manifolds/#Manifolds.SymmetricMatrices","content":" Manifolds.SymmetricMatrices  ‚Äî  Type SymmetricMatrices{n,ùîΩ} <: AbstractDecoratorManifold{ùîΩ} The  AbstractManifold $\\operatorname{Sym}(n)$  consisting of the real- or complex-valued symmetric matrices of size  $n√ón$ , i.e. the set \\[\\operatorname{Sym}(n) = \\bigl\\{p  ‚àà ùîΩ^{n√ón}\\ \\big|\\ p^{\\mathrm{H}} = p \\bigr\\},\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the Hermitian, i.e. complex conjugate transpose, and the field  $ùîΩ ‚àà \\{ ‚Ñù, ‚ÑÇ\\}$ . Though it is slightly redundant, usually the matrices are stored as  $n√ón$  arrays. Note that in this representation, the complex valued case has to have a real-valued diagonal, which is also reflected in the  manifold_dimension . Constructor SymmetricMatrices(n::Int, field::AbstractNumbers=‚Ñù) Generate the manifold of  $n√ón$  symmetric matrices. source"},{"id":1566,"pagetitle":"Symmetric matrices","title":"ManifoldsBase.Weingarten","ref":"/manifolds/stable/manifolds/#ManifoldsBase.Weingarten-Tuple{SymmetricMatrices, Any, Any, Any}","content":" ManifoldsBase.Weingarten  ‚Äî  Method Y = Weingarten(M::SymmetricMatrices, p, X, V)\nWeingarten!(M::SymmetricMatrices, Y, p, X, V) Compute the Weingarten map  $\\mathcal W_p$  at  p  on the  SymmetricMatrices M  with respect to the tangent vector  $X \\in T_p\\mathcal M$  and the normal vector  $V \\in N_p\\mathcal M$ . Since this a flat space by itself, the result is always the zero tangent vector. source"},{"id":1567,"pagetitle":"Symmetric matrices","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{SymmetricMatrices, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::SymmetricMatrices{n,ùîΩ}, p; kwargs...) Check whether  p  is a valid manifold point on the  SymmetricMatrices M , i.e. whether  p  is a symmetric matrix of size  (n,n)  with values from the corresponding  AbstractNumbers ùîΩ . The tolerance for the symmetry of  p  can be set using  kwargs... . source"},{"id":1568,"pagetitle":"Symmetric matrices","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{SymmetricMatrices, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::SymmetricMatrices{n,ùîΩ}, p, X; kwargs... ) Check whether  X  is a tangent vector to manifold point  p  on the  SymmetricMatrices M , i.e.  X  has to be a symmetric matrix of size  (n,n)  and its values have to be from the correct  AbstractNumbers . The tolerance for the symmetry of  X  can be set using  kwargs... . source"},{"id":1569,"pagetitle":"Symmetric matrices","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{SymmetricMatrices}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::SymmetricMatrices) Return true.  SymmetricMatrices  is a flat manifold. source"},{"id":1570,"pagetitle":"Symmetric matrices","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Union{Tuple{SymmetricMatrices{<:Any, ùîΩ}}, Tuple{ùîΩ}} where ùîΩ","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::SymmetricMatrices{n,ùîΩ}) Return the dimension of the  SymmetricMatrices  matrix  M  over the number system  ùîΩ , i.e. \\[\\begin{aligned}\n\\dim \\mathrm{Sym}(n,‚Ñù) &= \\frac{n(n+1)}{2},\\\\\n\\dim \\mathrm{Sym}(n,‚ÑÇ) &= 2\\frac{n(n+1)}{2} - n = n^2,\n\\end{aligned}\\] where the last  $-n$  is due to the zero imaginary part for Hermitian matrices source"},{"id":1571,"pagetitle":"Symmetric matrices","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{SymmetricMatrices, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::SymmetricMatrices, p, X) Project the matrix  X  onto the tangent space at  p  on the  SymmetricMatrices M , \\[\\operatorname{proj}_p(X) = \\frac{1}{2} \\bigl( X + X^{\\mathrm{H}} \\bigr),\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the Hermitian, i.e. complex conjugate transposed. source"},{"id":1572,"pagetitle":"Symmetric matrices","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{SymmetricMatrices, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::SymmetricMatrices, p) Projects  p  from the embedding onto the  SymmetricMatrices M , i.e. \\[\\operatorname{proj}_{\\operatorname{Sym}(n)}(p) = \\frac{1}{2} \\bigl( p + p^{\\mathrm{H}} \\bigr),\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the Hermitian, i.e. complex conjugate transposed. source"},{"id":1575,"pagetitle":"Symmetric positive definite","title":"Symmetric positive definite matrices","ref":"/manifolds/stable/manifolds/#SymmetricPositiveDefiniteSection","content":" Symmetric positive definite matrices"},{"id":1576,"pagetitle":"Symmetric positive definite","title":"Manifolds.SymmetricPositiveDefinite","ref":"/manifolds/stable/manifolds/#Manifolds.SymmetricPositiveDefinite","content":" Manifolds.SymmetricPositiveDefinite  ‚Äî  Type SymmetricPositiveDefinite{T} <: AbstractDecoratorManifold{‚Ñù} The manifold of symmetric positive definite matrices, i.e. \\[\\mathcal P(n) =\n\\bigl\\{\np ‚àà ‚Ñù^{n√ón}\\ \\big|\\ a^\\mathrm{T}pa > 0 \\text{ for all } a ‚àà ‚Ñù^{n}\\backslash\\{0\\}\n\\bigr\\}\\] The tangent space at  $T_p\\mathcal P(n)$  reads \\[    T_p\\mathcal P(n) =\n    \\bigl\\{\n        X \\in \\mathbb R^{n√ón} \\big|\\ X=X^\\mathrm{T}\n    \\bigr\\},\\] i.e. the set of symmetric matrices, Constructor SymmetricPositiveDefinite(n; parameter::Symbol=:type) generates the manifold  $\\mathcal P(n) \\subset ‚Ñù^{n√ón}$ source This manifold can ‚Äì for example ‚Äì be illustrated as ellipsoids:  since the eigenvalues are all positive they can be taken as lengths of the axes of an ellipsoids while the directions are given by the eigenvectors. The manifold can be equipped with different metrics"},{"id":1577,"pagetitle":"Symmetric positive definite","title":"Common and metric independent functions","ref":"/manifolds/stable/manifolds/#Common-and-metric-independent-functions","content":" Common and metric independent functions"},{"id":1578,"pagetitle":"Symmetric positive definite","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Tuple{Type{AbstractMatrix}, SPDPoint}","content":" Base.convert  ‚Äî  Method convert(::Type{AbstractMatrix}, p::SPDPoint) return the point  p  as a matrix. The matrix is either stored within the  SPDPoint  or reconstructed from  p.eigen . source"},{"id":1579,"pagetitle":"Symmetric positive definite","title":"Base.rand","ref":"/manifolds/stable/manifolds/#Base.rand-Tuple{SymmetricPositiveDefinite}","content":" Base.rand  ‚Äî  Method rand(M::SymmetricPositiveDefinite; œÉ::Real=1) Generate a random symmetric positive definite matrix on the  SymmetricPositiveDefinite  manifold  M . source"},{"id":1580,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{SymmetricPositiveDefinite, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::SymmetricPositiveDefinite, p; kwargs...) checks, whether  p  is a valid point on the  SymmetricPositiveDefinite M , i.e. is a matrix of size  (N,N) , symmetric and positive definite. The tolerance for the second to last test can be set using the  kwargs... . source"},{"id":1581,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{SymmetricPositiveDefinite, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::SymmetricPositiveDefinite, p, X; kwargs... ) Check whether  X  is a tangent vector to  p  on the  SymmetricPositiveDefinite M , i.e. atfer  check_point (M,p) ,  X  has to be of same dimension as  p  and a symmetric matrix, i.e. this stores tangent vetors as elements of the corresponding Lie group. The tolerance for the last test can be set using the  kwargs... . source"},{"id":1582,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.injectivity_radius","ref":"/manifolds/stable/manifolds/#ManifoldsBase.injectivity_radius-Tuple{SymmetricPositiveDefinite}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(M::SymmetricPositiveDefinite[, p])\ninjectivity_radius(M::MetricManifold{SymmetricPositiveDefinite,AffineInvariantMetric}[, p])\ninjectivity_radius(M::MetricManifold{SymmetricPositiveDefinite,LogCholeskyMetric}[, p]) Return the injectivity radius of the  SymmetricPositiveDefinite . Since  M  is a Hadamard manifold with respect to the  AffineInvariantMetric  and the  LogCholeskyMetric , the injectivity radius is globally  $‚àû$ . source"},{"id":1583,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{SymmetricPositiveDefinite}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::SymmetricPositiveDefinite) Return false.  SymmetricPositiveDefinite  is not a flat manifold. source"},{"id":1584,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{SymmetricPositiveDefinite}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::SymmetricPositiveDefinite) returns the dimension of  SymmetricPositiveDefinite M $=\\mathcal P(n), n ‚àà ‚Ñï$ , i.e. \\[\\dim \\mathcal P(n) = \\frac{n(n+1)}{2}.\\] source"},{"id":1585,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{SymmetricPositiveDefinite, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::SymmetricPositiveDefinite, p, X) project a matrix from the embedding onto the tangent space  $T_p\\mathcal P(n)$  of the  SymmetricPositiveDefinite  matrices, i.e. the set of symmetric matrices. source"},{"id":1586,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.representation_size","ref":"/manifolds/stable/manifolds/#ManifoldsBase.representation_size-Tuple{SymmetricPositiveDefinite}","content":" ManifoldsBase.representation_size  ‚Äî  Method representation_size(M::SymmetricPositiveDefinite) Return the size of an array representing an element on the  SymmetricPositiveDefinite  manifold  M , i.e.  $n√ón$ , the size of such a symmetric positive definite matrix on  $\\mathcal M = \\mathcal P(n)$ . source"},{"id":1587,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.zero_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.zero_vector-Tuple{SymmetricPositiveDefinite, Any}","content":" ManifoldsBase.zero_vector  ‚Äî  Method zero_vector(M::SymmetricPositiveDefinite, p) returns the zero tangent vector in the tangent space of the symmetric positive definite matrix  p  on the  SymmetricPositiveDefinite  manifold  M . source"},{"id":1588,"pagetitle":"Symmetric positive definite","title":"Default metric: the affine invariant metric","ref":"/manifolds/stable/manifolds/#Default-metric:-the-affine-invariant-metric","content":" Default metric: the affine invariant metric"},{"id":1589,"pagetitle":"Symmetric positive definite","title":"Manifolds.AffineInvariantMetric","ref":"/manifolds/stable/manifolds/#Manifolds.AffineInvariantMetric","content":" Manifolds.AffineInvariantMetric  ‚Äî  Type AffineInvariantMetric <: AbstractMetric The linear affine metric is the metric for symmetric positive definite matrices, that employs matrix logarithms and exponentials, which yields a linear and affine metric. source This metric is also the default metric, i.e. any call of the following functions with  P=SymmetricPositiveDefinite(3)  will result in  MetricManifold(P,AffineInvariantMetric()) and hence yield the formulae described in this seciton."},{"id":1590,"pagetitle":"Symmetric positive definite","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{SymmetricPositiveDefinite, Vararg{Any}}","content":" Base.exp  ‚Äî  Method exp(M::SymmetricPositiveDefinite, p, X)\nexp(M::MetricManifold{<:SymmetricPositiveDefinite,AffineInvariantMetric}, p, X) Compute the exponential map from  p  with tangent vector  X  on the  SymmetricPositiveDefinite M  with its default  MetricManifold  having the  AffineInvariantMetric . The formula reads \\[\\exp_p X = p^{\\frac{1}{2}}\\operatorname{Exp}(p^{-\\frac{1}{2}} X p^{-\\frac{1}{2}})p^{\\frac{1}{2}},\\] where  $\\operatorname{Exp}$  denotes to the matrix exponential. source"},{"id":1591,"pagetitle":"Symmetric positive definite","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{SymmetricPositiveDefinite, Vararg{Any}}","content":" Base.log  ‚Äî  Method log(M::SymmetricPositiveDefinite, p, q)\nlog(M::MetricManifold{SymmetricPositiveDefinite,AffineInvariantMetric}, p, q) Compute the logarithmic map from  p  to  q  on the  SymmetricPositiveDefinite  as a  MetricManifold  with  AffineInvariantMetric . The formula reads \\[\\log_p q =\np^{\\frac{1}{2}}\\operatorname{Log}(p^{-\\frac{1}{2}}qp^{-\\frac{1}{2}})p^{\\frac{1}{2}},\\] where  $\\operatorname{Log}$  denotes to the matrix logarithm. source"},{"id":1592,"pagetitle":"Symmetric positive definite","title":"ManifoldDiff.riemannian_Hessian","ref":"/manifolds/stable/manifolds/#ManifoldDiff.riemannian_Hessian-Tuple{SymmetricPositiveDefinite, Vararg{Any, 4}}","content":" ManifoldDiff.riemannian_Hessian  ‚Äî  Method riemannian_Hessian(M::SymmetricPositiveDefinite, p, G, H, X) The Riemannian Hessian can be computed as stated in Eq. (7.3) [ Ngu23 ]. Let  $\\nabla f(p)$  denote the Euclidean gradient  G ,  $\\nabla^2 f(p)[X]$  the Euclidean Hessian  H , and  $\\operatorname{sym}(X) = \\frac{1}{2}\\bigl(X^{\\mathrm{T}}+X\\bigr)$  the symmetrization operator. Then the formula reads \\[    \\operatorname{Hess}f(p)[X]\n    =\n    p\\operatorname{sym}(‚àá^2 f(p)[X])p\n    + \\operatorname{sym}\\bigl( X\\operatorname{sym}\\bigl(‚àá f(p)\\bigr)p)\\] source"},{"id":1593,"pagetitle":"Symmetric positive definite","title":"Manifolds.manifold_volume","ref":"/manifolds/stable/manifolds/#Manifolds.manifold_volume-Tuple{SymmetricPositiveDefinite}","content":" Manifolds.manifold_volume  ‚Äî  Method manifold_volume(::SymmetricPositiveDefinite) Return volume of the  SymmetricPositiveDefinite  manifold, i.e. infinity. source"},{"id":1594,"pagetitle":"Symmetric positive definite","title":"Manifolds.volume_density","ref":"/manifolds/stable/manifolds/#Manifolds.volume_density-Tuple{SymmetricPositiveDefinite, Any, Any}","content":" Manifolds.volume_density  ‚Äî  Method volume_density(::SymmetricPositiveDefinite, p, X) Compute the volume density of the  SymmetricPositiveDefinite  manifold at  p  in direction  X . See [ CKA17 ], Section 6.2 for details. Note that metric in Manifolds.jl has a different scaling factor than the reference. source"},{"id":1595,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.change_metric","ref":"/manifolds/stable/manifolds/#ManifoldsBase.change_metric-Tuple{SymmetricPositiveDefinite, EuclideanMetric, Any, Any}","content":" ManifoldsBase.change_metric  ‚Äî  Method change_metric(M::SymmetricPositiveDefinite, E::EuclideanMetric, p, X) Given a tangent vector  $X ‚àà T_p\\mathcal P(n)$  with respect to the  EuclideanMetric g_E , this function changes into the  AffineInvariantMetric  (default) metric on the  SymmetricPositiveDefinite M . To be precise we are looking for  $c\\colon T_p\\mathcal P(n) ‚Üí T_p\\mathcal P(n)$  such that for all  $Y,Z ‚àà T_p\\mathcal P(n)$ ` it holds \\[‚ü®Y,Z‚ü© = \\operatorname{tr}(YZ) = \\operatorname{tr}(p^{-1}c(Y)p^{-1}c(Z)) = g_p(c(Z),c(Y))\\] and hence  $c(X) = pX$  is computed. source"},{"id":1596,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.change_representer","ref":"/manifolds/stable/manifolds/#ManifoldsBase.change_representer-Tuple{SymmetricPositiveDefinite, EuclideanMetric, Any, Any}","content":" ManifoldsBase.change_representer  ‚Äî  Method change_representer(M::SymmetricPositiveDefinite, E::EuclideanMetric, p, X) Given a tangent vector  $X ‚àà T_p\\mathcal M$  representing a linear function on the tangent space at  p  with respect to the  EuclideanMetric g_E , this is turned into the representer with respect to the (default) metric, the  AffineInvariantMetric  on the  SymmetricPositiveDefinite M . To be precise we are looking for  $Z‚ààT_p\\mathcal P(n)$  such that for all  $Y‚ààT_p\\mathcal P(n)$ ` it holds \\[‚ü®X,Y‚ü© = \\operatorname{tr}(XY) = \\operatorname{tr}(p^{-1}Zp^{-1}Y) = g_p(Z,Y)\\] and hence  $Z = pXp$ . source"},{"id":1597,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{SymmetricPositiveDefinite, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::SymmetricPositiveDefinite, p, q)\ndistance(M::MetricManifold{SymmetricPositiveDefinite,AffineInvariantMetric}, p, q) Compute the distance on the  SymmetricPositiveDefinite  manifold between  p  and  q , as a  MetricManifold  with  AffineInvariantMetric . The formula reads \\[d_{\\mathcal P(n)}(p,q)\n= \\lVert \\operatorname{Log}(p^{-\\frac{1}{2}}qp^{-\\frac{1}{2}})\\rVert_{\\mathrm{F}}.,\\] where  $\\operatorname{Log}$  denotes the matrix logarithm and  $\\lVert‚ãÖ\\rVert_{\\mathrm{F}}$  denotes the matrix Frobenius norm. source"},{"id":1598,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.get_basis","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_basis-Tuple{SymmetricPositiveDefinite, Any, DefaultOrthonormalBasis}","content":" ManifoldsBase.get_basis  ‚Äî  Method [Œû,Œ∫] = get_basis(M::SymmetricPositiveDefinite, p, B::DefaultOrthonormalBasis)\n[Œû,Œ∫] = get_basis(M::MetricManifold{<:SymmetricPositiveDefinite,AffineInvariantMetric}, p, B::DefaultOrthonormalBasis) Return a default ONB for the tangent space  $T_p\\mathcal P(n)$  of the  SymmetricPositiveDefinite  with respect to the  AffineInvariantMetric . \\[    g_p(X,Y) = \\operatorname{tr}(p^{-1} X p^{-1} Y),\\] The basis constructed here is based on the ONB for symmetric matrices constructed as follows. Let \\[\\Delta_{i,j} = (a_{k,l})_{k,l=1}^n \\quad \\text{ with }\na_{k,l} =\n\\begin{cases}\n  1 & \\mbox{ for } k=l \\text{ if } i=j\\\\\n  \\frac{1}{\\sqrt{2}} & \\mbox{ for } k=i, l=j \\text{ or } k=j, l=i\\\\\n  0 & \\text{ else.}\n\\end{cases}\\] which forms an ONB for the space of symmetric matrices. We then form the ONB by \\[   \\Xi_{i,j} = p^{\\frac{1}{2}}\\Delta_{i,j}p^{\\frac{1}{2}},\\qquad i=1,\\ldots,n, j=i,\\ldots,n.\\] source"},{"id":1599,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.get_basis_diagonalizing","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_basis_diagonalizing-Tuple{SymmetricPositiveDefinite, Any, DiagonalizingOrthonormalBasis}","content":" ManifoldsBase.get_basis_diagonalizing  ‚Äî  Method [Œû,Œ∫] = get_basis_diagonalizing(M::SymmetricPositiveDefinite, p, B::DiagonalizingOrthonormalBasis)\n[Œû,Œ∫] = get_basis_diagonalizing(M::MetricManifold{<:SymmetricPositiveDefinite,AffineInvariantMetric}, p, B::DiagonalizingOrthonormalBasis) Return a orthonormal basis  Œû  as a vector of tangent vectors (of length  manifold_dimension  of  M ) in the tangent space of  p  on the  MetricManifold  of  SymmetricPositiveDefinite  manifold  M  with  AffineInvariantMetric  that diagonalizes the curvature tensor  $R(u,v)w$  with eigenvalues  Œ∫  and where the direction  B.frame_direction $V$  has curvature  0 . The construction is based on an ONB for the symmetric matrices similar to  get_basis(::SymmetricPositiveDefinite, p, ::DefaultOrthonormalBasis  just that the ONB here is build from the eigen vectors of  $p^{\\frac{1}{2}}Vp^{\\frac{1}{2}}$ . source"},{"id":1600,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.get_coordinates","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_coordinates-Tuple{SymmetricPositiveDefinite, Any, Any, Any, DefaultOrthonormalBasis}","content":" ManifoldsBase.get_coordinates  ‚Äî  Method get_coordinates(::SymmetricPositiveDefinite, p, X, ::DefaultOrthonormalBasis) Using the basis from  get_basis  the coordinates with respect to this ONB can be simplified to \\[   c_k = \\mathrm{tr}(p^{-\\frac{1}{2}}\\Delta_{i,j} X)\\] where  $k$  is trhe linearized index of the  $i=1,\\ldots,n, j=i,\\ldots,n$ . source"},{"id":1601,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.get_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_vector-Tuple{SymmetricPositiveDefinite, Any, Any, Any, DefaultOrthonormalBasis}","content":" ManifoldsBase.get_vector  ‚Äî  Method get_vector(::SymmetricPositiveDefinite, p, c, ::DefaultOrthonormalBasis) Using the basis from  get_basis  the vector reconstruction with respect to this ONB can be simplified to \\[   X = p^{\\frac{1}{2}} \\Biggl( \\sum_{i=1,j=i}^n c_k \\Delta_{i,j} \\Biggr) p^{\\frac{1}{2}}\\] where  $k$  is the linearized index of the  $i=1,\\ldots,n, j=i,\\ldots,n$ . source"},{"id":1602,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{SymmetricPositiveDefinite, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::SymmetricPositiveDefinite, p, X, Y)\ninner(M::MetricManifold{SymmetricPositiveDefinite,AffineInvariantMetric}, p, X, Y) Compute the inner product of  X ,  Y  in the tangent space of  p  on the  SymmetricPositiveDefinite  manifold  M , as a  MetricManifold  with  AffineInvariantMetric . The formula reads \\[g_p(X,Y) = \\operatorname{tr}(p^{-1} X p^{-1} Y),\\] source"},{"id":1603,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{MetricManifold{‚Ñù, <:SymmetricPositiveDefinite, AffineInvariantMetric}}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::MetricManifold{‚Ñù,<:SymmetricPositiveDefinite,AffineInvariantMetric}) Return false.  SymmetricPositiveDefinite  with  AffineInvariantMetric  is not a flat manifold. source"},{"id":1604,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.parallel_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_to-Tuple{SymmetricPositiveDefinite, Any, Any, Any}","content":" ManifoldsBase.parallel_transport_to  ‚Äî  Method parallel_transport_to(M::SymmetricPositiveDefinite, p, X, q)\nparallel_transport_to(M::MetricManifold{SymmetricPositiveDefinite,AffineInvariantMetric}, p, X, y) Compute the parallel transport of  X  from the tangent space at  p  to the tangent space at  q  on the  SymmetricPositiveDefinite  as a  MetricManifold  with the  AffineInvariantMetric . The formula reads \\[\\mathcal P_{q‚Üêp}X = p^{\\frac{1}{2}}\n\\operatorname{Exp}\\bigl(\n\\frac{1}{2}p^{-\\frac{1}{2}}\\log_p(q)p^{-\\frac{1}{2}}\n\\bigr)\np^{-\\frac{1}{2}}X p^{-\\frac{1}{2}}\n\\operatorname{Exp}\\bigl(\n\\frac{1}{2}p^{-\\frac{1}{2}}\\log_p(q)p^{-\\frac{1}{2}}\n\\bigr)\np^{\\frac{1}{2}},\\] where  $\\operatorname{Exp}$  denotes the matrix exponential and  log  the logarithmic map on  SymmetricPositiveDefinite  (again with respect to the  AffineInvariantMetric ). source"},{"id":1605,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.riemann_tensor","ref":"/manifolds/stable/manifolds/#ManifoldsBase.riemann_tensor-Tuple{SymmetricPositiveDefinite, Vararg{Any, 4}}","content":" ManifoldsBase.riemann_tensor  ‚Äî  Method riemann_tensor(::SymmetricPositiveDefinite, p, X, Y, Z) Compute the value of Riemann tensor on the  SymmetricPositiveDefinite  manifold. The formula reads [ Ren11 ]  $R(X,Y)Z=p^{1/2}R(X_I, Y_I)Z_Ip^{1/2}$ , where  $R_I(X_I, Y_I)Z_I=\\frac{1}{4}[Z_I, [X_I, Y_I]]$ ,   $X_I=p^{-1/2}Xp^{-1/2}$ ,  $Y_I=p^{-1/2}Yp^{-1/2}$  and  $Z_I=p^{-1/2}Zp^{-1/2}$ . source"},{"id":1606,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.sectional_curvature_max","ref":"/manifolds/stable/manifolds/#ManifoldsBase.sectional_curvature_max-Tuple{SymmetricPositiveDefinite}","content":" ManifoldsBase.sectional_curvature_max  ‚Äî  Method sectional_curvature_max(M::SymmetricPositiveDefinite) Return minimum sectional curvature of  SymmetricPositiveDefinite  manifold, that is 0. source"},{"id":1607,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.sectional_curvature_min","ref":"/manifolds/stable/manifolds/#ManifoldsBase.sectional_curvature_min-Tuple{SymmetricPositiveDefinite}","content":" ManifoldsBase.sectional_curvature_min  ‚Äî  Method sectional_curvature_min(M::SymmetricPositiveDefinite) Return minimum sectional curvature of  SymmetricPositiveDefinite  manifold, that is 0 for SPD(1) and SPD(2) and -0.25 otherwise. source"},{"id":1608,"pagetitle":"Symmetric positive definite","title":"Bures-Wasserstein metric","ref":"/manifolds/stable/manifolds/#BuresWassersteinMetricSection","content":" Bures-Wasserstein metric"},{"id":1609,"pagetitle":"Symmetric positive definite","title":"Manifolds.BuresWassersteinMetric","ref":"/manifolds/stable/manifolds/#Manifolds.BuresWassersteinMetric","content":" Manifolds.BuresWassersteinMetric  ‚Äî  Type BurresWassertseinMetric <: AbstractMetric The Bures Wasserstein metric for symmetric positive definite matrices [ MMP18 ] source"},{"id":1610,"pagetitle":"Symmetric positive definite","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{MetricManifold{‚Ñù, <:SymmetricPositiveDefinite, BuresWassersteinMetric}, Any, Any}","content":" Base.exp  ‚Äî  Method exp(::MatricManifold{‚Ñù,SymmetricPositiveDefinite,BuresWassersteinMetric}, p, X) Compute the exponential map on  SymmetricPositiveDefinite  with respect to the  BuresWassersteinMetric  given by \\[    \\exp_p(X) = p+X+L_p(X)pL_p(X)\\] where  $q=L_p(X)$  denotes the Lyapunov operator, i.e. it solves  $pq + qp = X$ . source"},{"id":1611,"pagetitle":"Symmetric positive definite","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{MetricManifold{‚Ñù, <:SymmetricPositiveDefinite, BuresWassersteinMetric}, Any, Any}","content":" Base.log  ‚Äî  Method log(::MatricManifold{SymmetricPositiveDefinite,BuresWassersteinMetric}, p, q) Compute the logarithmic map on  SymmetricPositiveDefinite  with respect to the  BuresWassersteinMetric  given by \\[    \\log_p(q) = (pq)^{\\frac{1}{2}} + (qp)^{\\frac{1}{2}} - 2 p\\] where  $q=L_p(X)$  denotes the Lyapunov operator, i.e. it solves  $pq + qp = X$ . source"},{"id":1612,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.change_representer","ref":"/manifolds/stable/manifolds/#ManifoldsBase.change_representer-Tuple{MetricManifold{‚Ñù, <:SymmetricPositiveDefinite, BuresWassersteinMetric}, EuclideanMetric, Any, Any}","content":" ManifoldsBase.change_representer  ‚Äî  Method change_representer(M::MetricManifold{‚Ñù,<:SymmetricPositiveDefinite,BuresWassersteinMetric}, E::EuclideanMetric, p, X) Given a tangent vector  $X ‚àà T_p\\mathcal M$  representing a linear function on the tangent space at  p  with respect to the  EuclideanMetric g_E , this is turned into the representer with respect to the (default) metric, the  BuresWassersteinMetric  on the  SymmetricPositiveDefinite M . To be precise we are looking for  $Z‚ààT_p\\mathcal P(n)$  such that for all  $Y‚ààT_p\\mathcal P(n)$ ` it holds \\[‚ü®X,Y‚ü© = \\operatorname{tr}(XY) = ‚ü®Z,Y‚ü©_{\\mathrm{BW}}\\] for all  $Y$  and hence we get  $Z$ = 2(A+A^{\\mathrm{T}}) $with$ A=Xp``. source"},{"id":1613,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{MetricManifold{‚Ñù, <:SymmetricPositiveDefinite, BuresWassersteinMetric}, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(::MatricManifold{SymmetricPositiveDefinite,BuresWassersteinMetric}, p, q) Compute the distance with respect to the  BuresWassersteinMetric  on  SymmetricPositiveDefinite  matrices, i.e. \\[d(p,q) =\n    \\operatorname{tr}(p) + \\operatorname{tr}(q) - 2\\operatorname{tr}\\Bigl( (p^{\\frac{1}{2}}qp^{\\frac{1}{2}} \\bigr)^\\frac{1}{2} \\Bigr),\\] where the last trace can be simplified (by rotating the matrix products in the trace) to  $\\operatorname{tr}(pq)$ . source"},{"id":1614,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{MetricManifold{‚Ñù, <:SymmetricPositiveDefinite, BuresWassersteinMetric}, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(::MetricManifold{‚Ñù,SymmetricPositiveDefinite,BuresWassersteinMetric}, p, X, Y) Compute the inner product  SymmetricPositiveDefinite  with respect to the  BuresWassersteinMetric  given by \\[    ‚ü®X,Y‚ü© = \\frac{1}{2}\\operatorname{tr}(L_p(X)Y)\\] where  $q=L_p(X)$  denotes the Lyapunov operator, i.e. it solves  $pq + qp = X$ . source"},{"id":1615,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{MetricManifold{‚Ñù, <:SymmetricPositiveDefinite, BuresWassersteinMetric}}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::MetricManifold{‚Ñù,<:SymmetricPositiveDefinite,BuresWassersteinMetric}) Return false.  SymmetricPositiveDefinite  with  BuresWassersteinMetric  is not a flat manifold. source"},{"id":1616,"pagetitle":"Symmetric positive definite","title":"Generalized Bures-Wasserstein metric","ref":"/manifolds/stable/manifolds/#Generalized-Bures-Wasserstein-metric","content":" Generalized Bures-Wasserstein metric"},{"id":1617,"pagetitle":"Symmetric positive definite","title":"Manifolds.GeneralizedBuresWassersteinMetric","ref":"/manifolds/stable/manifolds/#Manifolds.GeneralizedBuresWassersteinMetric","content":" Manifolds.GeneralizedBuresWassersteinMetric  ‚Äî  Type GeneralizedBurresWassertseinMetric{T<:AbstractMatrix} <: AbstractMetric The generalized Bures Wasserstein metric for symmetric positive definite matrices, see [ HMJG21 ]. This metric internally stores the symmetric positive definite matrix  $M$  to generalise the metric, where the name also follows the mentioned preprint. source"},{"id":1618,"pagetitle":"Symmetric positive definite","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{MetricManifold{‚Ñù, <:SymmetricPositiveDefinite, <:GeneralizedBuresWassersteinMetric}, Any, Any}","content":" Base.exp  ‚Äî  Method exp(::MatricManifold{‚Ñù,<:SymmetricPositiveDefinite,<:GeneralizedBuresWassersteinMetric}, p, X) Compute the exponential map on  SymmetricPositiveDefinite  with respect to the  GeneralizedBuresWassersteinMetric  given by \\[    \\exp_p(X) = p+X+\\mathcal ML_{p,M}(X)pML_{p,M}(X)\\] where  $q=L_{M,p}(X)$  denotes the generalized Lyapunov operator, i.e. it solves  $pqM + Mqp = X$ . source"},{"id":1619,"pagetitle":"Symmetric positive definite","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{MetricManifold{‚Ñù, <:SymmetricPositiveDefinite, <:GeneralizedBuresWassersteinMetric}, Any, Any}","content":" Base.log  ‚Äî  Method log(::MatricManifold{‚Ñù,<:SymmetricPositiveDefinite,<:GeneralizedBuresWassersteinMetric}, p, q) Compute the logarithmic map on  SymmetricPositiveDefinite  with respect to the  BuresWassersteinMetric  given by \\[    \\log_p(q) = M(M^{-1}pM^{-1}q)^{\\frac{1}{2}} + (qM^{-1}pM^{-1})^{\\frac{1}{2}}M - 2 p.\\] source"},{"id":1620,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.change_representer","ref":"/manifolds/stable/manifolds/#ManifoldsBase.change_representer-Tuple{MetricManifold{‚Ñù, <:SymmetricPositiveDefinite, <:GeneralizedBuresWassersteinMetric}, EuclideanMetric, Any, Any}","content":" ManifoldsBase.change_representer  ‚Äî  Method change_representer(M::MetricManifold{‚Ñù,<:SymmetricPositiveDefinite,<:GeneralizedBuresWassersteinMetric}, E::EuclideanMetric, p, X) Given a tangent vector  $X ‚àà T_p\\mathcal M$  representing a linear function on the tangent space at  p  with respect to the  EuclideanMetric g_E , this is turned into the representer with respect to the (default) metric, the  GeneralizedBuresWassersteinMetric  on the  SymmetricPositiveDefinite M . To be precise we are looking for  $Z‚ààT_p\\mathcal P(n)$  such that for all  $Y‚ààT_p\\mathcal P(n)$  it holds \\[‚ü®X,Y‚ü© = \\operatorname{tr}(XY) = ‚ü®Z,Y‚ü©_{\\mathrm{BW}}\\] for all  $Y$  and hence we get  $Z = 2pXM + 2MXp$ . source"},{"id":1621,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{MetricManifold{‚Ñù, <:SymmetricPositiveDefinite, <:GeneralizedBuresWassersteinMetric}, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(::MatricManifold{SymmetricPositiveDefinite,GeneralizedBuresWassersteinMetric}, p, q) Compute the distance with respect to the  BuresWassersteinMetric  on  SymmetricPositiveDefinite  matrices, i.e. \\[d(p,q) = \\operatorname{tr}(M^{-1}p) + \\operatorname{tr}(M^{-1}q)\n       - 2\\operatorname{tr}\\bigl( (p^{\\frac{1}{2}}M^{-1}qM^{-1}p^{\\frac{1}{2}} \\bigr)^{\\frac{1}{2}},\\] source"},{"id":1622,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{MetricManifold{‚Ñù, <:SymmetricPositiveDefinite, <:GeneralizedBuresWassersteinMetric}, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(::MetricManifold{‚Ñù,<:SymmetricPositiveDefinite,<:GeneralizedBuresWassersteinMetric}, p, X, Y) Compute the inner product  SymmetricPositiveDefinite  with respect to the  GeneralizedBuresWassersteinMetric  given by \\[    ‚ü®X,Y‚ü© = \\frac{1}{2}\\operatorname{tr}(L_{p,M}(X)Y)\\] where  $q=L_{M,p}(X)$  denotes the generalized Lyapunov operator, i.e. it solves  $pqM + Mqp = X$ . source"},{"id":1623,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{MetricManifold{‚Ñù, <:SymmetricPositiveDefinite, <:GeneralizedBuresWassersteinMetric}}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::MetricManifold{‚Ñù,<:SymmetricPositiveDefinite,<:GeneralizedBuresWassersteinMetric}) Return false.  SymmetricPositiveDefinite  with  GeneralizedBuresWassersteinMetric  is not a flat manifold. source"},{"id":1624,"pagetitle":"Symmetric positive definite","title":"Log-Euclidean metric","ref":"/manifolds/stable/manifolds/#Log-Euclidean-metric","content":" Log-Euclidean metric"},{"id":1625,"pagetitle":"Symmetric positive definite","title":"Manifolds.LogEuclideanMetric","ref":"/manifolds/stable/manifolds/#Manifolds.LogEuclideanMetric","content":" Manifolds.LogEuclideanMetric  ‚Äî  Type LogEuclideanMetric <: RiemannianMetric The LogEuclidean Metric consists of the Euclidean metric applied to all elements after mapping them into the Lie Algebra, i.e. performing a matrix logarithm beforehand. source"},{"id":1626,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{MetricManifold{‚Ñù, <:SymmetricPositiveDefinite, LogEuclideanMetric}, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::MetricManifold{‚Ñù,<:SymmetricPositiveDefinite,LogEuclideanMetric}, p, q) Compute the distance on the  SymmetricPositiveDefinite  manifold between  p  and  q  as a  MetricManifold  with  LogEuclideanMetric . The formula reads \\[    d_{\\mathcal P(n)}(p,q) = \\lVert \\operatorname{Log} p - \\operatorname{Log} q \\rVert_{\\mathrm{F}}\\] where  $\\operatorname{Log}$  denotes the matrix logarithm and  $\\lVert‚ãÖ\\rVert_{\\mathrm{F}}$  denotes the matrix Frobenius norm. source"},{"id":1627,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{MetricManifold{‚Ñù, <:SymmetricPositiveDefinite, LogEuclideanMetric}}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::MetricManifold{‚Ñù,<:SymmetricPositiveDefinite,LogEuclideanMetric}) Return false.  SymmetricPositiveDefinite  with  LogEuclideanMetric  is not a flat manifold. source"},{"id":1628,"pagetitle":"Symmetric positive definite","title":"Log-Cholesky metric","ref":"/manifolds/stable/manifolds/#Log-Cholesky-metric","content":" Log-Cholesky metric"},{"id":1629,"pagetitle":"Symmetric positive definite","title":"Manifolds.LogCholeskyMetric","ref":"/manifolds/stable/manifolds/#Manifolds.LogCholeskyMetric","content":" Manifolds.LogCholeskyMetric  ‚Äî  Type LogCholeskyMetric <: RiemannianMetric The Log-Cholesky metric imposes a metric based on the Cholesky decomposition as introduced by [ Lin19 ]. source"},{"id":1630,"pagetitle":"Symmetric positive definite","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{MetricManifold{‚Ñù, SymmetricPositiveDefinite, LogCholeskyMetric}, Vararg{Any}}","content":" Base.exp  ‚Äî  Method exp(M::MetricManifold{SymmetricPositiveDefinite,LogCholeskyMetric}, p, X) Compute the exponential map on the  SymmetricPositiveDefinite M  with  LogCholeskyMetric  from  p  into direction  X . The formula reads \\[\\exp_p X = (\\exp_y W)(\\exp_y W)^\\mathrm{T}\\] where  $\\exp_xW$  is the exponential map on  CholeskySpace ,  $y$  is the cholesky decomposition of  $p$ ,  $W = y(y^{-1}Xy^{-\\mathrm{T}})_\\frac{1}{2}$ , and  $(‚ãÖ)_\\frac{1}{2}$  denotes the lower triangular matrix with the diagonal multiplied by  $\\frac{1}{2}$ . source"},{"id":1631,"pagetitle":"Symmetric positive definite","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{MetricManifold{‚Ñù, SymmetricPositiveDefinite, LogCholeskyMetric}, Vararg{Any}}","content":" Base.log  ‚Äî  Method log(M::MetricManifold{‚Ñù,<:SymmetricPositiveDefinite,LogCholeskyMetric}, p, q) Compute the logarithmic map on  SymmetricPositiveDefinite M  with respect to the  LogCholeskyMetric  emanating from  p  to  q . The formula can be adapted from the  CholeskySpace  as \\[\\log_p q = xW^{\\mathrm{T}} + Wx^{\\mathrm{T}},\\] where  $x$  is the cholesky factor of  $p$  and  $W=\\log_x y$  for  $y$  the cholesky factor of  $q$  and the just mentioned logarithmic map is the one on  CholeskySpace . source"},{"id":1632,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{MetricManifold{‚Ñù, <:SymmetricPositiveDefinite, LogCholeskyMetric}, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::MetricManifold{SymmetricPositiveDefinite,LogCholeskyMetric}, p, q) Compute the distance on the manifold of  SymmetricPositiveDefinite  nmatrices, i.e. between two symmetric positive definite matrices  p  and  q  with respect to the  LogCholeskyMetric . The formula reads \\[d_{\\mathcal P(n)}(p,q) = \\sqrt{\n \\lVert ‚åä x ‚åã - ‚åä y ‚åã \\rVert_{\\mathrm{F}}^2\n + \\lVert \\log(\\operatorname{diag}(x)) - \\log(\\operatorname{diag}(y))\\rVert_{\\mathrm{F}}^2 }\\ \\ ,\\] where  $x$  and  $y$  are the cholesky factors of  $p$  and  $q$ , respectively,  $‚åä‚ãÖ‚åã$  denbotes the strictly lower triangular matrix of its argument, and  $\\lVert‚ãÖ\\rVert_{\\mathrm{F}}$  the Frobenius norm. source"},{"id":1633,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{MetricManifold{‚Ñù, <:SymmetricPositiveDefinite, LogCholeskyMetric}, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::MetricManifold{‚Ñù,<:SymmetricPositiveDefinite,LogCholeskyMetric}, p, X, Y) Compute the inner product of two matrices  X ,  Y  in the tangent space of  p  on the  SymmetricPositiveDefinite  manifold  M , as a  MetricManifold  with  LogCholeskyMetric . The formula reads \\[    g_p(X,Y) = ‚ü®a_z(X),a_z(Y)‚ü©_z,\\] where  $‚ü®‚ãÖ,‚ãÖ‚ü©_x$  denotes inner product on the  CholeskySpace ,  $z$  is the cholesky factor of  $p$ ,  $a_z(W) = z (z^{-1}Wz^{-\\mathrm{T}})_{\\frac{1}{2}}$ , and  $(‚ãÖ)_\\frac{1}{2}$  denotes the lower triangular matrix with the diagonal multiplied by  $\\frac{1}{2}$ source"},{"id":1634,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{MetricManifold{‚Ñù, <:SymmetricPositiveDefinite, LogCholeskyMetric}}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::MetricManifold{‚Ñù,<:SymmetricPositiveDefinite,LogCholeskyMetric}) Return true.  SymmetricPositiveDefinite  with  LogCholeskyMetric  is a flat manifold. See Proposition 8 of [ Lin19 ]. source"},{"id":1635,"pagetitle":"Symmetric positive definite","title":"ManifoldsBase.parallel_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.parallel_transport_to-Tuple{MetricManifold{‚Ñù, <:SymmetricPositiveDefinite, LogCholeskyMetric}, Any, Any, Any}","content":" ManifoldsBase.parallel_transport_to  ‚Äî  Method vector_transport_to(\n    M::MetricManifold{‚Ñù,<:SymmetricPositiveDefinite,LogCholeskyMetric},\n    p,\n    X,\n    q,\n    ::ParallelTransport,\n) Parallel transport the tangent vector  X  at  p  along the geodesic to  q  with respect to the  SymmetricPositiveDefinite  manifold  M  and  LogCholeskyMetric . The parallel transport is based on the parallel transport on  CholeskySpace : Let  $x$  and  $y$  denote the cholesky factors of  p  and  q , respectively and  $W = x(x^{-1}Xx^{-\\mathrm{T}})_\\frac{1}{2}$ , where  $(‚ãÖ)_\\frac{1}{2}$  denotes the lower triangular matrix with the diagonal multiplied by  $\\frac{1}{2}$ . With  $V$  the parallel transport on  CholeskySpace  from  $x$  to  $y$ . The formula hear reads \\[\\mathcal P_{q‚Üêp}X = yV^{\\mathrm{T}} + Vy^{\\mathrm{T}}.\\] source"},{"id":1636,"pagetitle":"Symmetric positive definite","title":"Statistics","ref":"/manifolds/stable/manifolds/#Statistics","content":" Statistics"},{"id":1637,"pagetitle":"Symmetric positive definite","title":"Statistics.mean","ref":"/manifolds/stable/manifolds/#Statistics.mean-Tuple{SymmetricPositiveDefinite, Any}","content":" Statistics.mean  ‚Äî  Method mean(\n    M::SymmetricPositiveDefinite,\n    x::AbstractVector,\n    [w::AbstractWeights,]\n    method = GeodesicInterpolation();\n    kwargs...,\n) Compute the Riemannian  mean  of  x  using  GeodesicInterpolation . source"},{"id":1638,"pagetitle":"Symmetric positive definite","title":"Efficient representation","ref":"/manifolds/stable/manifolds/#Efficient-representation","content":" Efficient representation When a point  p  is used in several occasions, it might be beneficial to store the eigenvalues and vectors of  p  and optionally its square root and the inverse of the square root. The  SPDPoint  can be used for exactly that."},{"id":1639,"pagetitle":"Symmetric positive definite","title":"Manifolds.SPDPoint","ref":"/manifolds/stable/manifolds/#Manifolds.SPDPoint","content":" Manifolds.SPDPoint  ‚Äî  Type SPDPoint <: AbstractManifoldsPoint Store the result of  eigen(p)  of an SPD matrix and (optionally)  $p^{1/2}$  and  $p^{-1/2}$  to avoid their repeated computations. This result only has the result of  eigen  as a mandatory storage, the other three can be stored. If they are not stored they are computed and returned (but then still not stored) when required. Constructor SPDPoint(p::AbstractMatrix; store_p=true, store_sqrt=true, store_sqrt_inv=true) Create an SPD point using an symmetric positive defincite matrix  p , where you can optionally store  p ,  sqrt  and  sqrt_inv source and there are three internal functions to be able to use  SPDPoint  interchangeably with the default representation as a matrix."},{"id":1640,"pagetitle":"Symmetric positive definite","title":"Manifolds.spd_sqrt","ref":"/manifolds/stable/manifolds/#Manifolds.spd_sqrt","content":" Manifolds.spd_sqrt  ‚Äî  Function spd_sqrt(p::AbstractMatrix)\nspd_sqrt(p::SPDPoint) return  $p^{\\frac{1}{2}}$  by either computing it (if it is missing or for the  AbstractMatrix ) or returning the stored value from within the  SPDPoint . This method assumes that  p  represents an spd matrix. source"},{"id":1641,"pagetitle":"Symmetric positive definite","title":"Manifolds.spd_sqrt_inv","ref":"/manifolds/stable/manifolds/#Manifolds.spd_sqrt_inv","content":" Manifolds.spd_sqrt_inv  ‚Äî  Function spd_sqrt_inv(p::SPDPoint) return  $p^{-\\frac{1}{2}}$  by either computing it (if it is missing or for the  AbstractMatrix ) or returning the stored value from within the  SPDPoint . This method assumes that  p  represents an spd matrix. source"},{"id":1642,"pagetitle":"Symmetric positive definite","title":"Manifolds.spd_sqrt_and_sqrt_inv","ref":"/manifolds/stable/manifolds/#Manifolds.spd_sqrt_and_sqrt_inv","content":" Manifolds.spd_sqrt_and_sqrt_inv  ‚Äî  Function spd_sqrt_and_sqrt_inv(p::AbstractMatrix)\nspd_sqrt_and_sqrt_inv(p::SPDPoint) return  $p^{\\frac{1}{2}}$  and  $p^{-\\frac{1}{2}}$  by either computing them (if they are missing or for the  AbstractMatrix ) or returning their stored value from within the  SPDPoint . Compared to calling single methods  spd_sqrt  and  spd_sqrt_inv  this method only computes the eigenvectors once for the case of the  AbstractMatrix  or if both are missing. This method assumes that  p  represents an spd matrix. source"},{"id":1643,"pagetitle":"Symmetric positive definite","title":"Literature","ref":"/manifolds/stable/manifolds/#Literature","content":" Literature"},{"id":1646,"pagetitle":"Symmetric positive semidefinite fixed rank","title":"Symmetric Positive Semidefinite Matrices of Fixed Rank","ref":"/manifolds/stable/manifolds/#Symmetric-Positive-Semidefinite-Matrices-of-Fixed-Rank","content":" Symmetric Positive Semidefinite Matrices of Fixed Rank"},{"id":1647,"pagetitle":"Symmetric positive semidefinite fixed rank","title":"Manifolds.SymmetricPositiveSemidefiniteFixedRank","ref":"/manifolds/stable/manifolds/#Manifolds.SymmetricPositiveSemidefiniteFixedRank","content":" Manifolds.SymmetricPositiveSemidefiniteFixedRank  ‚Äî  Type SymmetricPositiveSemidefiniteFixedRank{T,ùîΩ} <: AbstractDecoratorManifold{ùîΩ} The  AbstractManifold $\\operatorname{SPS}_k(n)$  consisting of the real- or complex-valued symmetric positive semidefinite matrices of size  $n√ón$  and rank  $k$ , i.e. the set \\[\\operatorname{SPS}_k(n) = \\bigl\\{\np  ‚àà ùîΩ^{n√ón}\\ \\big|\\ p^{\\mathrm{H}} = p,\napa^{\\mathrm{H}} \\geq 0 \\text{ for all } a ‚àà ùîΩ\n\\text{ and } \\operatorname{rank}(p) = k\\bigr\\},\\] where  $‚ãÖ^{\\mathrm{H}}$  denotes the Hermitian, i.e. complex conjugate transpose, and the field  $ùîΩ ‚àà \\{ ‚Ñù, ‚ÑÇ\\}$ . We sometimes  $\\operatorname{SPS}_{k,ùîΩ}(n)$ , when distinguishing the real- and complex-valued manifold is important. An element is represented by  $q ‚àà ùîΩ^{n√ók}$  from the factorization  $p = qq^{\\mathrm{H}}$ . Note that since for any unitary (orthogonal)  $A ‚àà ùîΩ^{n√ón}$  we have  $(Aq)(Aq)^{\\mathrm{H}} = qq^{\\mathrm{H}} = p$ , the representation is not unique, or in other words, the manifold is a quotient manifold of  $ùîΩ^{n√ók}$ . The tangent space at  $p$ ,  $T_p\\operatorname{SPS}_k(n)$ , is also represented by matrices  $Y ‚àà ùîΩ^{n√ók}$  and reads as \\[T_p\\operatorname{SPS}_k(n) = \\bigl\\{\nX ‚àà ùîΩ^{n√ón}\\,|\\,X = qY^{\\mathrm{H}} + Yq^{\\mathrm{H}}\n\\text{ i.e. } X = X^{\\mathrm{H}}\n\\bigr\\}.\\] Note that the metric used yields a non-complete manifold. The metric was used in [ JBAS10 ][ MA20 ]. Constructor SymmetricPositiveSemidefiniteFixedRank(n::Int, k::Int, field::AbstractNumbers=‚Ñù; parameter::Symbol=:type) Generate the manifold of  $n√ón$  symmetric positive semidefinite matrices of rank  $k$  over the  field  of real numbers  ‚Ñù  or complex numbers  ‚ÑÇ . source"},{"id":1648,"pagetitle":"Symmetric positive semidefinite fixed rank","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{SymmetricPositiveSemidefiniteFixedRank, Any, Any}","content":" Base.exp  ‚Äî  Method exp(M::SymmetricPositiveSemidefiniteFixedRank, q, Y) Compute the exponential map on the  SymmetricPositiveSemidefiniteFixedRank , which just reads \\[    \\exp_q Y = q+Y.\\] Note Since the manifold is represented in the embedding and is a quotient manifold, the exponential and logarithmic map are a bijection only with respect to the equivalence classes. Computing \\[    q_2 = \\exp_p(\\log_pq)\\] might yield a matrix  $q_2\\neq q$ , but they represent the same point on the quotient manifold, i.e.  $d_{\\operatorname{SPS}_k(n)}(q_2,q) = 0$ . source"},{"id":1649,"pagetitle":"Symmetric positive semidefinite fixed rank","title":"Base.log","ref":"/manifolds/stable/manifolds/#Base.log-Tuple{SymmetricPositiveSemidefiniteFixedRank, Any, Any}","content":" Base.log  ‚Äî  Method log(M::SymmetricPositiveSemidefiniteFixedRank, q, p) Compute the logarithmic map on the  SymmetricPositiveSemidefiniteFixedRank  manifold by minimizing  $\\lVert p - qY\\rVert$  with respect to  $Y$ . Note Since the manifold is represented in the embedding and is a quotient manifold, the exponential and logarithmic map are a bijection only with respect to the equivalence classes. Computing \\[    q_2 = \\exp_p(\\log_pq)\\] might yield a matrix  $q_2‚â†q$ , but they represent the same point on the quotient manifold, i.e.  $d_{\\operatorname{SPS}_k(n)}(q_2,q) = 0$ . source"},{"id":1650,"pagetitle":"Symmetric positive semidefinite fixed rank","title":"ManifoldsBase._isapprox","ref":"/manifolds/stable/manifolds/#ManifoldsBase._isapprox-Union{Tuple{T}, Tuple{SymmetricPositiveSemidefiniteFixedRank, T, Any}} where T","content":" ManifoldsBase._isapprox  ‚Äî  Method isapprox(M::SymmetricPositiveSemidefiniteFixedRank, p, q; kwargs...) test, whether two points  p ,  q  are (approximately) nearly the same. Since this is a quotient manifold in the embedding, the test is performed by checking their distance, if they are not the same, i.e. that  $d_{\\mathcal M}(p,q) \\approx 0$ , where the comparison is performed with the classical  isapprox . The  kwargs...  are passed on to this accordingly. source"},{"id":1651,"pagetitle":"Symmetric positive semidefinite fixed rank","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{SymmetricPositiveSemidefiniteFixedRank, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::SymmetricPositiveSemidefiniteFixedRank, q; kwargs...) Check whether  q  is a valid manifold point on the  SymmetricPositiveSemidefiniteFixedRank M , i.e. whether  p=q*q'  is a symmetric matrix of size  (n,n)  with values from the corresponding  AbstractNumbers ùîΩ . The symmetry of  p  is not explicitly checked since by using  q  p is symmetric by construction. The tolerance for the symmetry of  p  can and the rank of  q*q'  be set using  kwargs... . source"},{"id":1652,"pagetitle":"Symmetric positive semidefinite fixed rank","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{SymmetricPositiveSemidefiniteFixedRank, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::SymmetricPositiveSemidefiniteFixedRank, p, X; kwargs... ) Check whether  X  is a tangent vector to manifold point  p  on the  SymmetricPositiveSemidefiniteFixedRank M , i.e.  X  has to be a symmetric matrix of size  (n,n)  and its values have to be from the correct  AbstractNumbers . Due to the reduced representation this is fulfilled as soon as the matrix is of correct size. source"},{"id":1653,"pagetitle":"Symmetric positive semidefinite fixed rank","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{SymmetricPositiveSemidefiniteFixedRank, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::SymmetricPositiveSemidefiniteFixedRank, p, q) Compute the distance between two points  p ,  q  on the  SymmetricPositiveSemidefiniteFixedRank , which is the Frobenius norm of  $Y$  which minimizes  $\\lVert p - qY\\rVert$  with respect to  $Y$ . source"},{"id":1654,"pagetitle":"Symmetric positive semidefinite fixed rank","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{SymmetricPositiveSemidefiniteFixedRank}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::SymmetricPositiveSemidefiniteFixedRank) Return false.  SymmetricPositiveSemidefiniteFixedRank  is not a flat manifold. See Theorem A.18 in [ MA20 ]. source"},{"id":1655,"pagetitle":"Symmetric positive semidefinite fixed rank","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{SymmetricPositiveSemidefiniteFixedRank}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::SymmetricPositiveSemidefiniteFixedRank) Return the dimension of the  SymmetricPositiveSemidefiniteFixedRank  matrix  M  over the number system  ùîΩ , i.e. \\[\\begin{aligned}\n\\dim \\operatorname{SPS}_{k,‚Ñù}(n) &= kn - \\frac{k(k-1)}{2},\\\\\n\\dim \\operatorname{SPS}_{k,‚ÑÇ}(n) &= 2kn - k^2,\n\\end{aligned}\\] where the last  $k^2$  is due to the zero imaginary part for Hermitian matrices diagonal source"},{"id":1656,"pagetitle":"Symmetric positive semidefinite fixed rank","title":"ManifoldsBase.vector_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.vector_transport_to-Tuple{SymmetricPositiveSemidefiniteFixedRank, Any, Any, Any, ProjectionTransport}","content":" ManifoldsBase.vector_transport_to  ‚Äî  Method vector_transport_to(M::SymmetricPositiveSemidefiniteFixedRank, p, X, q) transport the tangent vector  X  at  p  to  q  by projecting it onto the tangent space at  q . source"},{"id":1657,"pagetitle":"Symmetric positive semidefinite fixed rank","title":"ManifoldsBase.zero_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.zero_vector-Tuple{SymmetricPositiveSemidefiniteFixedRank, Vararg{Any}}","content":" ManifoldsBase.zero_vector  ‚Äî  Method  zero_vector(M::SymmetricPositiveSemidefiniteFixedRank, p) returns the zero tangent vector in the tangent space of the symmetric positive definite matrix  p  on the  SymmetricPositiveSemidefiniteFixedRank  manifold  M . source"},{"id":1660,"pagetitle":"Symplectic matrices","title":"Symplectic matrices","ref":"/manifolds/stable/manifolds/#Symplectic-matrices","content":" Symplectic matrices The  SymplecticMatrices  manifold, denoted  $\\operatorname{Sp}(2n, ùîΩ)$ , is a closed, embedded, submanifold of  $ùîΩ^{2n√ó2n}$  that represents transformations into symplectic subspaces which keep the canonical symplectic form over  $ùîΩ^{2n√ó2n}$  invariant under the standard embedding inner product. The canonical symplectic form is a non-degenerate bilinear and skew symmetric map  $\\omega\\colon ùîΩ ùîΩ^{2n}√óùîΩ^{2n} ‚Üí ùîΩ$ , given by  $\\omega(x, y) = x^T Q_{2n} y$  for elements  $x, y \\in ùîΩ^{2n}$ , with \\[    Q_{2n} =\n    \\begin{bmatrix}\n     0_n  &  I_n \\\\\n    -I_n  &  0_n\n    \\end{bmatrix}.\\] That means that an element  $p \\in \\operatorname{Sp}(2n)$  must fulfill the requirement that \\[    \\omega (p x, p y) = x^T(p^TQp)y = x^TQy = \\omega(x, y),\\] leading to the requirement on  $p$  that  $p^TQp = Q$ . The symplectic manifold also forms a group under matrix multiplication, called the  $\\textit{symplectic group}$ . Since all the symplectic matrices necessarily have determinant one, the  symplectic group $\\operatorname{Sp}(2n, ùîΩ)$  is a subgroup of the special linear group,  $\\operatorname{SL}(2n, ùîΩ)$ . When the underlying field is either  $‚Ñù$  or  $‚ÑÇ$  the symplectic group with a manifold structure constitutes a Lie group, with the Lie Algebra \\[    \\mathfrak{sp}(2n,F) = \\{H \\in ùîΩ^{2n√ó2n} \\;|\\; Q H + H^{T} Q = 0\\}.\\] This set is also known as the  Hamiltonian matrices , which have the property that  $(QH)^T = QH$  and are commonly used in physics."},{"id":1661,"pagetitle":"Symplectic matrices","title":"Manifolds.ExtendedSymplecticMetric","ref":"/manifolds/stable/manifolds/#Manifolds.ExtendedSymplecticMetric","content":" Manifolds.ExtendedSymplecticMetric  ‚Äî  Type ExtendedSymplecticMetric <: AbstractMetric The extension of the  RealSymplecticMetric  at a point  p \\in \\mathrm{Sp}(2n)  as an inner product over the embedding space  $‚Ñù^{2n√ó2n}$ , i.e. \\[    ‚ü®x, y‚ü©_p = ‚ü®p^{-1}x, p^{-1}‚ü©_{\\mathrm{Fr}}\n    = \\operatorname{tr}(x^{\\mathrm{T}}(pp^{\\mathrm{T}})^{-1}y), \\text{ for all } x, y \\in ‚Ñù^{2n√ó2n}.\\] source"},{"id":1662,"pagetitle":"Symplectic matrices","title":"Manifolds.RealSymplecticMetric","ref":"/manifolds/stable/manifolds/#Manifolds.RealSymplecticMetric","content":" Manifolds.RealSymplecticMetric  ‚Äî  Type RealSymplecticMetric <: RiemannianMetric The canonical Riemannian metric on the symplectic manifold, defined pointwise for  $p \\in \\mathrm{Sp}(2n)$  by [ Fio11 ]] \\[\\begin{align*}\n  & g_p \\colon T_p\\mathrm{Sp}(2n)√óT_p\\mathrm{Sp}(2n) ‚Üí ‚Ñù, \\\\\n  & g_p(Z_1, Z_2) = \\operatorname{tr}((p^{-1}Z_1)^{\\mathrm{T}} (p^{-1}Z_2)).\n\\end{align*}\\] This metric is also the default metric for the  SymplecticMatrices  manifold. source"},{"id":1663,"pagetitle":"Symplectic matrices","title":"Manifolds.SymplecticElement","ref":"/manifolds/stable/manifolds/#Manifolds.SymplecticElement","content":" Manifolds.SymplecticElement  ‚Äî  Type SymplecticElement{T} A lightweight structure to represent the action of the matrix representation of the canonical symplectic form, \\[J_{2n}(Œª) = Œª\\begin{bmatrix}\n0_n & I_n \\\\\n -I_n & 0_n\n\\end{bmatrix} ‚àà ‚Ñù^{2n√ó2n},\\] where we write  $J_{2n} = J_{2n}(1)$  for short. The canonical symplectic form is represented by \\[\\omega_{2n}(x, y) = x^{\\mathrm{T}}J_{2n}y, \\quad x, y ‚àà ‚Ñù^{2n}.\\] The entire matrix is however not instantiated in memory, instead a scalar  $Œª$  of type  T  is stored, which is used to keep track of scaling and transpose operations applied  to each  SymplecticElement . This type acts similar to  I  from  LinearAlgeba . Constructor SymplecticElement(Œª=1) Generate the sumplectic matrix with scaling  $1$ . source"},{"id":1664,"pagetitle":"Symplectic matrices","title":"Manifolds.SymplecticMatrices","ref":"/manifolds/stable/manifolds/#Manifolds.SymplecticMatrices","content":" Manifolds.SymplecticMatrices  ‚Äî  Type SymplecticMatricesMatrices{T, ùîΩ} <: AbstractEmbeddedManifold{ùîΩ, DefaultIsometricEmbeddingType} The symplectic manifold consists of all  $2n√ó2n$  matrices which preserve the canonical symplectic form over  $ùîΩ^{2n√ó2n}√óùîΩ^{2n√ó2n}$ , \\[  \\omega\\colon ùîΩ^{2n√ó2n}√óùîΩ^{2n√ó2n} ‚Üí ùîΩ,\n  \\quad \\omega(x, y) = p^{\\mathrm{T}} J_{2n} q, \\  x, y \\in ùîΩ^{2n√ó2n},\\] where  $J_{2n} = \\begin{bmatrix} 0_n & I_n \\\\ -I_n & 0_n \\end{bmatrix}$  denotes the  SymplecticElement . The symplectic manifold consists of \\[\\mathrm{Sp}(2n, ‚Ñù) = \\bigl\\{ p ‚àà ‚Ñù^{2n√ó2n} \\, \\big| \\, p^{\\mathrm{T}}J_{2n}p = J_{2n} \\bigr\\},\\] The tangent space at a point  $p$  is given by [ BZ21 ] \\[\\begin{align*}\n  T_p\\mathrm{Sp}(2n)\n    &= \\{X \\in ‚Ñù^{2n√ó2n} \\ |\\ p^{T}J_{2n}X + X^{T}J_{2n}p = 0 \\}, \\\\\n    &= \\{X = pJ_{2n}S \\ \\mid\\ S ‚àà R^{2n√ó2n}, S^{\\mathrm{T}} = S \\}.\n\\end{align*}\\] Constructor SymplecticMatrices(2n, field=‚Ñù; parameter::Symbol=:type) Generate the (real-valued) symplectic manifold of  $2n√ó2n$  symplectic matrices. The constructor for the  SymplecticMatrices  manifold accepts the even column/row embedding dimension  $2n$  for the real symplectic manifold,  $‚Ñù^{2n√ó2n}$ . source"},{"id":1665,"pagetitle":"Symplectic matrices","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{SymplecticMatrices, Vararg{Any}}","content":" Base.exp  ‚Äî  Method exp(M::SymplecticMatrices, p, X)\nexp!(M::SymplecticMatrices, q, p, X) The Exponential mapping on the Symplectic manifold with the  RealSymplecticMetric  Riemannian metric. For the point  $p \\in \\mathrm{Sp}(2n)$  the exponential mapping along the tangent vector  $X \\in T_p\\mathrm{Sp}(2n)$  is computed as [ WSF18 ] \\[    \\operatorname{exp}_p(X) = p \\operatorname{Exp}((p^{-1}X)^{\\mathrm{T}})\n                                \\operatorname{Exp}(p^{-1}X - (p^{-1}X)^{\\mathrm{T}}),\\] where  $\\operatorname{Exp}(‚ãÖ)$  denotes the matrix exponential. source"},{"id":1666,"pagetitle":"Symplectic matrices","title":"Base.inv","ref":"/manifolds/stable/manifolds/#Base.inv-Tuple{SymplecticMatrices{<:Any, ‚Ñù}, Any}","content":" Base.inv  ‚Äî  Method inv(::SymplecticMatrices, A)\ninv!(::SymplecticMatrices, A) Compute the symplectic inverse  $A^+$  of matrix  $A ‚àà ‚Ñù^{2n√ó2n}$ . See  symplectic_inverse  for details. source"},{"id":1667,"pagetitle":"Symplectic matrices","title":"Base.rand","ref":"/manifolds/stable/manifolds/#Base.rand-Tuple{Any}","content":" Base.rand  ‚Äî  Method rand(::SymplecticStiefel; vector_at=nothing, œÉ=1.0) Generate a random point on  $\\mathrm{Sp}(2n)$  or a random tangent vector  $X \\in T_p\\mathrm{Sp}(2n)$  if  vector_at  is set to a point  $p \\in \\mathrm{Sp}(2n)$ . A random point on  $\\mathrm{Sp}(2n)$  is constructed by generating a random Hamiltonian matrix  $Œ© \\in \\mathfrak{sp}(2n,F)$  with norm  œÉ , and then transforming it to a symplectic matrix by applying the Cayley transform \\[  \\operatorname{cay}: \\mathfrak{sp}(2n,F) ‚Üí \\mathrm{Sp}(2n),\n  \\ \\Omega \\mapsto (I - \\Omega)^{-1}(I + \\Omega).\\] To generate a random tangent vector in  $T_p\\mathrm{Sp}(2n)$ , this code employs the second tangent vector space parametrization of  SymplecticMatrices . It first generates a random symmetric matrix  $S$  by  S = randn(2n, 2n)  and then symmetrizes it as  S = S + S' . Then  $S$  is normalized to have Frobenius norm of  œÉ  and  X = pJS  is returned, where  J  is the  SymplecticElement . source"},{"id":1668,"pagetitle":"Symplectic matrices","title":"ManifoldDiff.gradient","ref":"/manifolds/stable/manifolds/#ManifoldDiff.gradient-Tuple{SymplecticMatrices, Any, Any, ManifoldDiff.RiemannianProjectionBackend}","content":" ManifoldDiff.gradient  ‚Äî  Method gradient(M::SymplecticMatrices, f, p, backend::RiemannianProjectionBackend;\n         extended_metric=true)\ngradient!(M::SymplecticMatrices, f, p, backend::RiemannianProjectionBackend;\n         extended_metric=true) Compute the manifold gradient  $\\text{grad}f(p)$  of a scalar function  $f \\colon \\mathrm{Sp}(2n) ‚Üí ‚Ñù$  at  $p \\in \\mathrm{Sp}(2n)$ . The element  $\\text{grad}f(p)$  is found as the Riesz representer of the differential  $\\text{D}f(p) \\colon T_p\\mathrm{Sp}(2n) ‚Üí ‚Ñù$  with respect to the Riemannian metric inner product at  $p$  [ Fio11 ]]. That is,  $\\text{grad}f(p) \\in T_p\\mathrm{Sp}(2n)$  solves the relation \\[    g_p(\\text{grad}f(p), X) = \\text{D}f(p) \\quad\\forall\\; X \\in T_p\\mathrm{Sp}(2n).\\] The default behaviour is to first change the representation of the Euclidean gradient from the Euclidean metric to the  RealSymplecticMetric  at  $p$ , and then we projecting the result onto the correct tangent tangent space  $T_p\\mathrm{Sp}(2n, ‚Ñù)$  w.r.t the Riemannian metric  $g_p$  extended to the entire embedding space. Arguments: extended_metric = true : If  true , compute the gradient  $\\text{grad}f(p)$  by   first changing the representer of the Euclidean gradient of a smooth extension   of  $f$ ,  $‚àáf(p)$ , with respect to the  RealSymplecticMetric  at  $p$    extended to the entire embedding space, before projecting onto the correct   tangent vector space with respect to the same extended metric  $g_p$ .   If  false , compute the gradient by first projecting  $‚àáf(p)$  onto the   tangent vector space, before changing the representer in the tangent   vector space to comply with the  RealSymplecticMetric . source"},{"id":1669,"pagetitle":"Symplectic matrices","title":"ManifoldDiff.riemannian_gradient","ref":"/manifolds/stable/manifolds/#ManifoldDiff.riemannian_gradient-Tuple{SymplecticMatrices, Any, Any}","content":" ManifoldDiff.riemannian_gradient  ‚Äî  Method riemannian_gradient(M::SymplecticMatrices, p, Y) Given a gradient  $Y = \\operatorname{grad} \\tilde f(p)$  in the embedding  $‚Ñù^{2n√ó2n}$  or at least around the  SymplecticMatrices M  where  p  (the embedding of) a point on  M , we restrict  $\\tilde f$  to the manifold and denote that by  $f$ . Then the Riemannian gradient  $X = \\operatorname{grad} f(p)$  is given by \\[  X = Yp^{\\mathrm{T}}p + J_{2n}pY^{\\mathrm{T}}J_{2n}p,\\] where  $J_{2n}$  denotes the  SymplecticElement . source"},{"id":1670,"pagetitle":"Symplectic matrices","title":"Manifolds.inv!","ref":"/manifolds/stable/manifolds/#Manifolds.inv!-Tuple{SymplecticMatrices{<:Any, ‚Ñù}, Any}","content":" Manifolds.inv!  ‚Äî  Method inv!(M::SymplecticMatrices, A) Compute the  symplectic_inverse  of a suqare matrix A inplace of A source"},{"id":1671,"pagetitle":"Symplectic matrices","title":"Manifolds.project_normal!","ref":"/manifolds/stable/manifolds/#Manifolds.project_normal!-Union{Tuple{ùîΩ}, Tuple{MetricManifold{ùîΩ, <:Euclidean, ExtendedSymplecticMetric}, Any, Any, Any}} where ùîΩ","content":" Manifolds.project_normal!  ‚Äî  Method project_normal!(::MetricManifold{ùîΩ,<:Euclidean,ExtendedSymplecticMetric}, Y, p, X) Project onto the normal of the tangent space  $(T_p\\mathrm{Sp}(2n))^{\\perp_g}$  at a point  $p ‚àà \\mathrm{Sp}(2n)$ , relative to the riemannian metric  $g$ RealSymplecticMetric . That is, \\[(T_p\\mathrm{Sp}(2n))^{\\perp_g}\n = \\{Y ‚àà ‚Ñù^{2n√ó2n} : g_p(Y, X) = 0 \\test{ for all } X \\in T_p\\mathrm{Sp}(2n)\\}.\\] The closed form projection operator onto the normal space is given by [ GSAS21 ] \\[\\operatorname{P}^{(T_p\\mathrm{Sp}(2n))\\perp}_{g_p}(X) = pJ_{2n}\\operatorname{skew}(p^{\\mathrm{T}}J_{2n}^{\\mathrm{T}}X),\\] where  $\\operatorname{skew}(A) = \\frac{1}{2}(A - A^{\\mathrm{T}})$  and  $J_{2n} = \\begin{bmatrix} 0_n & I_n \\\\ -I_n & 0_n \\end{bmatrix}$  denotes the  SymplecticElement . This function is not exported. source"},{"id":1672,"pagetitle":"Symplectic matrices","title":"Manifolds.symplectic_inverse","ref":"/manifolds/stable/manifolds/#Manifolds.symplectic_inverse-Tuple{AbstractMatrix}","content":" Manifolds.symplectic_inverse  ‚Äî  Method symplectic_inverse(A) Given a matrix \\[  A ‚àà ‚Ñù^{2n√ó2k},\\quad\n  A =\n  \\begin{bmatrix}\n  A_{1,1} & A_{1,2} \\\\\n  A_{2,1} & A_{2, 2}\n  \\end{bmatrix}\\] the symplectic inverse is defined as: \\[A^{+} := J_{2k}^{\\mathrm{T}} A^{\\mathrm{T}} J_{2n},\\] where  $J_{2n} = \\begin{bmatrix} 0_n & I_n \\\\ -I_n & 0_n \\end{bmatrix}$  denotes the  SymplecticElement . The symplectic inverse of A can be expressed explicitly as: \\[A^{+} =\n  \\begin{bmatrix}\n    A_{2, 2}^{\\mathrm{T}} & -A_{1, 2}^{\\mathrm{T}} \\\\[1.2mm]\n   -A_{2, 1}^{\\mathrm{T}} &  A_{1, 1}^{\\mathrm{T}}\n  \\end{bmatrix}.\\] source"},{"id":1673,"pagetitle":"Symplectic matrices","title":"Manifolds.symplectic_inverse_times","ref":"/manifolds/stable/manifolds/#Manifolds.symplectic_inverse_times-Tuple{SymplecticMatrices, Any, Any}","content":" Manifolds.symplectic_inverse_times  ‚Äî  Method symplectic_inverse_times(::SymplecticMatrices, p, q)\nsymplectic_inverse_times!(::SymplecticMatrices, A, p, q) Directly compute the symplectic inverse of  $p \\in \\mathrm{Sp}(2n)$ , multiplied with  $q \\in \\mathrm{Sp}(2n)$ . That is, this function efficiently computes  $p^+q = (J_{2n}p^{\\mathrm{T}}J_{2n})q ‚àà ‚Ñù^{2n√ó2n}$ , where  $J_{2n} = \\begin{bmatrix} 0_n & I_n \\\\ -I_n & 0_n \\end{bmatrix}$  denotes the  SymplecticElement . source"},{"id":1674,"pagetitle":"Symplectic matrices","title":"ManifoldsBase.change_representer","ref":"/manifolds/stable/manifolds/#ManifoldsBase.change_representer-Tuple{MetricManifold{<:Any, <:Euclidean, ExtendedSymplecticMetric}, EuclideanMetric, Any, Any}","content":" ManifoldsBase.change_representer  ‚Äî  Method change_representer(MetMan::MetricManifold{<:Any, <:Euclidean, ExtendedSymplecticMetric},\n                   EucMet::EuclideanMetric, p, X)\nchange_representer!(MetMan::MetricManifold{<:Any, <:Euclidean, ExtendedSymplecticMetric},\n                    Y, EucMet::EuclideanMetric, p, X) Change the representation of a matrix  $Œæ ‚àà ‚Ñù^{2n√ó2n}$  into the inner product space  $(‚Ñù^{2n√ó2n}, g_p)$  where the inner product is given by  $g_p(Œæ, Œ∑) = \\langle p^{-1}Œæ, p^{-1}Œ∑ \\rangle = \\operatorname{tr}(Œæ^{\\mathrm{T}}(pp^{\\mathrm{T}})^{-1}Œ∑)$ , as the extension of the  RealSymplecticMetric  onto the entire embedding space. By changing the representation we mean to apply a mapping \\[    c_p : ‚Ñù^{2n√ó2n} ‚Üí ‚Ñù^{2n√ó2n},\\] defined by requiring that it satisfy the metric compatibility condition \\[    g_p(c_p(Œæ), Œ∑) = ‚ü®p^{-1}c_p(Œæ), p^{-1}Œ∑‚ü© = ‚ü®Œæ, Œ∑‚ü©^{\\text{Euc}}\n        \\;‚àÄ\\; Œ∑ ‚àà T_p\\mathrm{Sp}(2n, ‚Ñù).\\] In this case, we compute the mapping \\[    c_p(Œæ) = pp^{\\mathrm{T}} Œæ.\\] source"},{"id":1675,"pagetitle":"Symplectic matrices","title":"ManifoldsBase.change_representer","ref":"/manifolds/stable/manifolds/#ManifoldsBase.change_representer-Tuple{SymplecticMatrices, EuclideanMetric, Any, Any}","content":" ManifoldsBase.change_representer  ‚Äî  Method change_representer(::SymplecticMatrices, ::EuclideanMetric, p, X)\nchange_representer!(::SymplecticMatrices, Y, ::EuclideanMetric, p, X) Compute the representation of a tangent vector  $Œæ ‚àà T_p\\mathrm{Sp}(2n, ‚Ñù)$  s.t. \\[  g_p(c_p(Œæ), Œ∑) = ‚ü®Œæ, Œ∑‚ü©^{\\text{Euc}} \\text{for all } Œ∑ ‚àà T_p\\mathrm{Sp}(2n, ‚Ñù).\\] with the conversion function \\[  c_p : T_p\\mathrm{Sp}(2n, ‚Ñù) ‚Üí T_p\\mathrm{Sp}(2n, ‚Ñù), \\quad\n  c_p(Œæ) = \\frac{1}{2} pp^{\\mathrm{T}} Œæ + \\frac{1}{2} pJ_{2n} Œæ^{\\mathrm{T}} pJ_{2n},\\] where  $J_{2n} = \\begin{bmatrix} 0_n & I_n \\\\ -I_n & 0_n \\end{bmatrix}$  denotes the  SymplecticElement . Each of the terms  $c_p^1(Œæ) = p p^{\\mathrm{T}} Œæ$  and  $c_p^2(Œæ) = pJ_{2n} Œæ^{\\mathrm{T}} pJ_{2n}$  from the above definition of  $c_p(Œ∑)$  are themselves metric compatible in the sense that \\[    c_p^i : T_p\\mathrm{Sp}(2n, ‚Ñù) ‚Üí ‚Ñù^{2n√ó2n}\\quad\n    g_p^i(c_p(Œæ), Œ∑) = ‚ü®Œæ, Œ∑‚ü©^{\\text{Euc}} \\;‚àÄ\\; Œ∑ ‚àà T_p\\mathrm{Sp}(2n, ‚Ñù),\\] for  $i \\in {1, 2}$ . However the range of each function alone is not confined to    $T_p\\mathrm{Sp}(2n, ‚Ñù)$ , but the convex combination \\[    c_p(Œæ) = \\frac{1}{2}c_p^1(Œæ) + \\frac{1}{2}c_p^2(Œæ)\\] does have the correct range  $T_p\\mathrm{Sp}(2n, ‚Ñù)$ . source"},{"id":1676,"pagetitle":"Symplectic matrices","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Union{Tuple{T}, Tuple{SymplecticMatrices, T}} where T","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::SymplecticMatrices, p; kwargs...) Check whether  p  is a valid point on the  SymplecticMatrices M = $\\mathrm{Sp}(2n)$ , i.e. that it has the right  AbstractNumbers  type and  $p^{+}p$  is (approximately) the identity, where  $A^+$  denotes the  symplectic_inverse . The tolerance can be set with  kwargs... . source"},{"id":1677,"pagetitle":"Symplectic matrices","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{SymplecticMatrices, Vararg{Any}}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::SymplecticMatrices, p, X; kwargs...) Checks whether  X  is a valid tangent vector at  p  on the  SymplecticMatrices M = $\\mathrm{Sp}(2n)$ , which requires that \\[p^{T}J_{2n}X + X^{T}J_{2n}p = 0\\] holds (approximately), where  $J_{2n} = \\begin{bmatrix} 0_n & I_n \\\\ -I_n & 0_n \\end{bmatrix}$  denotes the  SymplecticElement . The tolerance can be set with  kwargs... source"},{"id":1678,"pagetitle":"Symplectic matrices","title":"ManifoldsBase.distance","ref":"/manifolds/stable/manifolds/#ManifoldsBase.distance-Tuple{SymplecticMatrices, Any, Any}","content":" ManifoldsBase.distance  ‚Äî  Method distance(M::SymplecticMatrices, p, q) Compute an approximate geodesic distance between two Symplectic matrices  $p, q \\in \\mathrm{Sp}(2n)$ , as done in [ WSF18 ]. \\[  \\operatorname{dist}(p, q)\n    ‚âà \\lVert\\operatorname{Log}(p^+q)\\rVert_{\\mathrm{Fr}},\\] where the  $\\operatorname{Log}(‚ãÖ)$  operator is the matrix logarithm. This approximation is justified by first recalling the Baker-Campbell-Hausdorf formula, \\[\\operatorname{Log}(\\operatorname{Exp}(A)\\operatorname{Exp}(B))\n = A + B + \\frac{1}{2}[A, B] + \\frac{1}{12}[A, [A, B]] + \\frac{1}{12}[B, [B, A]]\n    + \\ldots \\;.\\] Then we write the expression for the exponential map from  $p$  to  $q$  as \\[    q =\n    \\operatorname{exp}_p(X)\n    =\n    p \\operatorname{Exp}((p^{+}X)^{\\mathrm{T}})\n    \\operatorname{Exp}([p^{+}X - (p^{+}X)^{\\mathrm{T}}]),\n    X \\in T_p\\mathrm{Sp},\\] and with the geodesic distance between  $p$  and  $q$  given by \\[\\operatorname{dist}(p, q) = \\lVert X \\rVert_p = \\lVert p^+ X \\rVert_{\\mathrm{Fr}}\\] we see that \\[  \\begin{align*}\n   \\lVert\\operatorname{Log}(p^+q)\\rVert_{\\mathrm{Fr}}\n    &=\\Bigl\\lVert\n        \\operatorname{Log}\\bigl(\n            \\operatorname{Exp}((p^{+}X)^{\\mathrm{T}})\n            \\operatorname{Exp}(p^{+}X - (p^{+}X)^{\\mathrm{T}})\n        \\bigr)\n    \\Bigr\\rVert_{\\mathrm{Fr}} \\\\\n    &=\\lVert p^{+}X + \\frac{1}{2}[(p^{+}X)^{\\mathrm{T}}, p^{+}X - (p^{+}X)^{\\mathrm{T}}]\n        + \\ldots\\lVert_{\\mathrm{Fr}} \\\\\n    &‚âà\\lVert p^{+}X\\rVert_{\\mathrm{Fr}} = \\operatorname{dist}(p, q).\n  \\end{align*}\\] source"},{"id":1679,"pagetitle":"Symplectic matrices","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{SymplecticMatrices{<:Any, ‚Ñù}, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(::SymplecticMatrices{<:Any,‚Ñù}, p, X, Y) Compute the canonical Riemannian inner product  RealSymplecticMetric \\[    g_p(X, Y) = \\operatorname{tr}((p^{-1}X)^{\\mathrm{T}} (p^{-1}Y))\\] between the two tangent vectors  $X, Y \\in T_p\\mathrm{Sp}(2n)$ . source"},{"id":1680,"pagetitle":"Symplectic matrices","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{SymplecticMatrices, Any, Any, CayleyInverseRetraction}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(M::SymplecticMatrices, p, q, ::CayleyInverseRetraction) Compute the Cayley Inverse Retraction  $X = \\mathcal{L}_p^{\\mathrm{Sp}}(q)$  such that the Cayley Retraction from  $p$  along  $X$  lands at  $q$ , i.e.  $\\mathcal{R}_p(X) = q$  [ BZ21 ]. For  $p, q ‚àà \\mathrm{Sp}(2n, ‚Ñù)$  then, we can define the inverse cayley retraction as long as the following matrices exist. \\[    U = (I + p^+ q)^{-1}, \\quad V = (I + q^+ p)^{-1},\\] where  $(‚ãÖ)^+$  denotes the  symplectic_inverse . Then inverse cayley retration at  $p$  applied to  $q$  is \\[\\mathcal{L}_p^{\\mathrm{Sp}}(q)\n  = 2p\\bigl(V - U\\bigr) + 2\\bigl((p + q)U - p\\bigr) ‚àà T_p\\mathrm{Sp}(2n).\\] source"},{"id":1681,"pagetitle":"Symplectic matrices","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{SymplecticMatrices}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::SymplecticMatrices) Return false.  SymplecticMatrices  is not a flat manifold. source"},{"id":1682,"pagetitle":"Symplectic matrices","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{SymplecticMatrices}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(::SymplecticMatrices) Returns the dimension of the symplectic manifold embedded in  $‚Ñù^{2n√ó2n}$ , i.e. \\[  \\operatorname{dim}(\\mathrm{Sp}(2n)) = (2n + 1)n.\\] source"},{"id":1683,"pagetitle":"Symplectic matrices","title":"ManifoldsBase.project!","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project!-Tuple{MetricManifold{<:Any, <:Euclidean, ExtendedSymplecticMetric}, Any, Any, Any}","content":" ManifoldsBase.project!  ‚Äî  Method project!(::MetricManifold{ùîΩ,<:Euclidean,ExtendedSymplecticMetric}, Y, p, X) where {ùîΩ} Compute the projection of  $X ‚àà R^{2n√ó2n}$  onto  $T_p\\mathrm{Sp}(2n, ‚Ñù)$  with respect to the  RealSymplecticMetric $g$ . The closed form projection mapping is given by [ GSAS21 ] \\[  \\operatorname{P}^{T_p\\mathrm{Sp}(2n)}_{g_p}(X) = pJ_{2n}\\operatorname{sym}(p^{\\mathrm{T}}J_{2n}^{\\mathrm{T}}X),\\] where  $\\operatorname{sym}(A) = \\frac{1}{2}(A + A^{\\mathrm{T}})$  and and  $J_{2n} = \\begin{bmatrix} 0_n & I_n \\\\ -I_n & 0_n \\end{bmatrix}$  denotes the  SymplecticElement . source"},{"id":1684,"pagetitle":"Symplectic matrices","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{SymplecticMatrices, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(::SymplecticMatrices, p, A)\nproject!(::SymplecticMatrices, Y, p, A) Given a point  $p \\in \\mathrm{Sp}(2n)$ , project an element  $A \\in ‚Ñù^{2n√ó2n}$  onto the tangent space  $T_p\\mathrm{Sp}(2n)$  relative to the euclidean metric of the embedding  $‚Ñù^{2n√ó2n}$ . That is, we find the element  $X \\in T_p\\operatorname{Sp}(2n)$  which solves the constrained optimization problem \\[    \\operatorname{min}_{X \\in ‚Ñù^{2n√ó2n}} \\frac{1}{2}\\lVert X - A\\rVert^2, \\quad\n    \\text{such that}\\;\n    h(X) := X^{\\mathrm{T}} J_{2n} p + p^{\\mathrm{T}} J_{2n} X = 0,\\] where  $h: ‚Ñù^{2n√ó2n} ‚Üí \\operatorname{skew}(2n)$  denotes the restriction of  $X$  onto the tangent space  $T_p\\operatorname{SpSt}(2n, 2k)$  and  $J_{2n} = \\begin{bmatrix} 0_n & I_n \\\\ -I_n & 0_n \\end{bmatrix}$  denotes the  SymplecticElement . source"},{"id":1685,"pagetitle":"Symplectic matrices","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{SymplecticMatrices, Any, Any}","content":" ManifoldsBase.retract  ‚Äî  Method retract(::SymplecticMatrices, p, X, ::CayleyRetraction)\nretract!(::SymplecticMatrices, q, p, X, ::CayleyRetraction) Compute the Cayley retraction on  $p ‚àà \\mathrm{Sp}(2n, ‚Ñù)$  in the direction of tangent vector  $X ‚àà T_p\\mathrm{Sp}(2n, ‚Ñù)$ , as defined in by Birtea et al in proposition 2 [ BCC20 ]. Using the  symplectic_inverse $A^+$  of a matrix  $A \\in ‚Ñù^{2n√ó2n}$  the retraction  $\\mathcal{R}: T\\mathrm{Sp}(2n) ‚Üí \\mathrm{Sp}(2n)$  is defined pointwise as \\[\\begin{align*}\n\\mathcal{R}_p(X) &= p \\operatorname{cay}\\left(\\frac{1}{2}p^{+}X\\right), \\\\\n                 &= p \\operatorname{exp}_{1/1}(p^{+}X), \\\\\n                 &= p (2I - p^{+}X)^{-1}(2I + p^{+}X).\n\\end{align*}\\] Here  $\\operatorname{exp}_{1/1}(z) = (2 - z)^{-1}(2 + z)$  denotes the Pad√© (1, 1) approximation to  $\\operatorname{exp}(z)$ . source"},{"id":1686,"pagetitle":"Symplectic matrices","title":"Literature","ref":"/manifolds/stable/manifolds/#Literature","content":" Literature [BZ21] T.¬†Bendokat and R.¬†Zimmermann.  The real symplectic Stiefel and Grassmann manifolds: metrics, geodesics and applications , arXiv¬†Preprint,¬†2108.12447 (2021),  arXiv:2108.12447 . [BCC20] P.¬†Birtea, I.¬†Ca√ßu and D.¬†ComƒÉnescu.  Optimization on the real symplectic group .  Monatshefte¬†f√ºr¬†Mathematik  191 , 465‚Äì485  (2020). [Fio11] S.¬†Fiori.  Solving Minimal-Distance Problems over the Manifold of Real-Symplectic Matrices .  SIAM¬†Journal¬†on¬†Matrix¬†Analysis¬†and¬†Applications  32 , 938‚Äì968  (2011). [GSAS21] B.¬†Gao, N.¬†T.¬†Son, P.-A.¬†Absil and T.¬†Stykel.  Riemannian Optimization on the Symplectic Stiefel Manifold .  SIAM¬†Journal¬†on¬†Optimization  31 , 1546‚Äì1575  (2021). [WSF18] J.¬†Wang, H.¬†Sun and S.¬†Fiori.  A Riemannian-steepest-descent approach for optimization on the real symplectic group .  Mathematical¬†Methods¬†in¬†the¬†Applied¬†Science  41 , 4273‚Äì4286  (2018)."},{"id":1689,"pagetitle":"Symplectic Grassmann","title":"(Real) Symplectic Grassmann","ref":"/manifolds/stable/manifolds/#(Real)-Symplectic-Grassmann","content":" (Real) Symplectic Grassmann"},{"id":1690,"pagetitle":"Symplectic Grassmann","title":"Manifolds.SymplecticGrassmann","ref":"/manifolds/stable/manifolds/#Manifolds.SymplecticGrassmann","content":" Manifolds.SymplecticGrassmann  ‚Äî  Type SymplecticGrassmann{T,ùîΩ} <: AbstractEmbeddedManifold{ùîΩ, DefaultIsometricEmbeddingType} The symplectic Grassmann manifold consists of all symplectic subspaces of  $‚Ñù^{2n}$  of dimension  $2k$ ,  $n ‚â• k$ . Points on this manifold can be represented as corresponding representers on the  SymplecticStiefel \\[\\operatorname{SpGr}(2n,2k) = \\bigl\\{ \\operatorname{span}(p)\\ \\big| \\ p ‚àà \\operatorname{SpSt}(2n, 2k, ‚Ñù)\\},\\] or as projectors \\[\\operatorname{SpGr}(2n, 2k, ‚Ñù) = \\bigl\\{ p ‚àà ‚Ñù^{2n√ó2n} \\ \\big| \\ p^2 = p, \\operatorname{rank}(p) = 2k, p^+=p \\bigr\\},\\] where  $‚ãÖ^+$  is the  symplectic_inverse . See also  ProjectorPoint  and  StiefelPoint  for these two representations, where arrays are interpreted as those on the Stiefel manifold. With respect to the quotient structure, the canonical projection  $œÄ = œÄ_{\\mathrm{SpSt},\\mathrm{SpGr}}$  is given by \\[œÄ: \\mathrm{SpSt}(2n2k) ‚Üí \\mathrm{SpGr}(2n,2k), p ‚Ü¶ œÄ(p) = pp^+.\\] The tangent space is either the tangent space from the symplectic Stiefel manifold, where tangent vectors are representers of their corresponding congruence classes, or for the representation as projectors, using a  ProjectorTVector  as \\[  T_p\\operatorname{SpGr}(2n, 2k, ‚Ñù) =\n  \\bigl\\{ [X,p] \\ \\mid\\ X ‚àà \\mathfrak{sp}(2n,‚Ñù), Xp+pX = X \\bigr\\},\\] where  $[X,p] = Xp-pX$  denotes the matrix commutator and  $\\mathfrak{sp}(2n,‚Ñù)$  is the Lie algebra of the symplectic group consisting of  HamiltonianMatrices . The first repesentation is in  StiefelPoint s and  StiefelTVector s, which both represent their symplectic Grassmann equivalence class. Arrays are interpreted in this representation as well For the representation in  ProjectorPoint  and  ProjectorTVector s, we use the representation from the surjective submersion \\[œÅ: \\mathrm{SpSt}(2n,2k) ‚Üí \\mathrm{SpGr}(2n,2k),\n\\qquad\nœÅ(p) = pp^+\\] and its differential \\[\\mathrm{d}œÅ(p,X) = Xp^+ + pX^+,\\] respectively. The manifold was first introduced in [ BZ21 ] Constructor SymplecticGrassmann(2n::Int, 2k::Int, field::AbstractNumbers=‚Ñù; parameter::Symbol=:type) Generate the (real-valued) symplectic Grassmann manifold. of   $2k$  dimensional symplectic subspace of  $‚Ñù^{2n}$ . Note that both dimensions passed to this constructor have to be even. source"},{"id":1691,"pagetitle":"Symplectic Grassmann","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{SymplecticGrassmann{<:Any, ‚Ñù}}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(::SymplecticGrassmann) Return the dimension of the  SymplecticGrassmann (2n,2k) , which is \\[\\operatorname{dim}\\operatorname{SpGr}(2n, 2k) = 4(n-k)k,\\] see [ BZ21 ], Section 4. source"},{"id":1692,"pagetitle":"Symplectic Grassmann","title":"The (default) symplectic Stiefel representation","ref":"/manifolds/stable/manifolds/#The-(default)-symplectic-Stiefel-representation","content":" The (default) symplectic Stiefel representation"},{"id":1693,"pagetitle":"Symplectic Grassmann","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{SymplecticGrassmann, Any, Any}","content":" Base.exp  ‚Äî  Method exp(::SymplecticGrassmann, p, X)\nexp!(M::SymplecticGrassmann, q, p, X) Compute the exponential mapping \\[  \\exp\\colon T\\mathrm{SpGr}(2n, 2k) ‚Üí \\mathrm{SpGr}(2n, 2k)\\] when representing points and tangent vectors as symplectic bases and their tangents, i.e. on the  SymplecticStiefel  manifold. Then we can just pass this on to  exp(::SymplecticStiefel, p, X) . source"},{"id":1694,"pagetitle":"Symplectic Grassmann","title":"ManifoldDiff.riemannian_gradient","ref":"/manifolds/stable/manifolds/#ManifoldDiff.riemannian_gradient-Tuple{SymplecticGrassmann, Any, Any}","content":" ManifoldDiff.riemannian_gradient  ‚Äî  Method riemannian_gradient(M::SymplecticGrassmann, p, Y) Given a gradient  $Y = \\operatorname{grad} \\tilde f(p)$  in the embedding  $‚Ñù^{2n√ó2k}$  or at least around the  SymplecticGrassmann M  where  p  (the embedding of) a point on  M , and the restriction  $\\tilde f$  to the  SymplecticStiefel  be invariant for the equivalence classes. In other words  $f(p) = f(qp)$  for  $q \\in \\mathrm{Sp}(2k, ‚Ñù)$ , where  $\\mathrm{Sp}(2k, ‚Ñù)$  denotes the  SymplecticMatrices  manifold. Then the Riemannian gradient  $X = \\operatorname{grad} f(p)$  is given by \\[  X = J_{2n}^THJ_{2k}p^{\\mathrm{T}}p - J_{2n}^TpJ_{2k}H^{\\mathrm{T}}p,\\] where  $J_{2n}$  denotes the  SymplecticElement , and  $H = (I_{2n} - pp^+)J_{2n}^{\\mathrm{T}}YJ$ . source"},{"id":1695,"pagetitle":"Symplectic Grassmann","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{SymplecticGrassmann, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::SymplecticGrassmann, p; kwargs...) Check whether  p  is a valid point on the  SymplecticGrassmann ,  $\\operatorname{SpGr}(2n, 2k)$  manifold by verifying that it is a valid representer of an equivalence class of the corersponding  SymplecticStiefel  manifold. source"},{"id":1696,"pagetitle":"Symplectic Grassmann","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{SymplecticGrassmann, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::SymplecticGrassmann, p, X; kwargs...) Check whether  X  is a valid tangent vector at  p  on the  SymplecticGrassmann ,  $\\operatorname{SpGr}(2n, 2k)$  manifold by verifying that it is a valid representer of an equivalence class of the corersponding  SymplecticStiefel  manifolds tangent space at  p . source"},{"id":1697,"pagetitle":"Symplectic Grassmann","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{SymplecticGrassmann, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(::SymplecticGrassmann, p, X, Y) Compute the Riemannian inner product  $g^{\\mathrm{SpGr}}_p(X,Y)$  on the  SymplecticGrassmann  manifold  \\mathrm{SpGr} `. For the case where  $p$  is represented by a point on the  SymplecticStiefel  manifold acting as a representant of its equivalence class  $[p] \\in \\mathrm{SpGr}$  and the tangent vectors  $X,Y \\in \\mathrm{Hor}_p^œÄ\\operatorname{SpSt}(2n,2k)$  are horizontal tangent vectors. Then the inner product reads according to Proposition Lemma 4.8 [ BZ21 ]. \\[g^{\\mathrm{SpGr}}_p(X,Y) = \\operatorname{tr}\\bigl(\n        (p^{\\mathrm{T}}p)^{-1}X^{\\mathrm{T}}(I_{2n} - pp^+)Y\n    \\bigr),\\] where  $I_{2n}$  denotes the identity matrix and  $(‚ãÖ)^+$  the  symplectic_inverse . source"},{"id":1698,"pagetitle":"Symplectic Grassmann","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{SymplecticGrassmann, Any, Any, CayleyInverseRetraction}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(::SymplecticGrassmann, p, q, ::CayleyInverseRetraction)\ninverse_retract!(::SymplecticGrassmann, q, p, X, ::CayleyInverseRetraction) Compute the Cayley Inverse Retraction on the Symplectic Grassmann manifold, when the points are represented as symplectic bases, i.e. on the  SymplecticStiefel . Here we can directly employ the  CaleyInverseRetraction  on the symplectic Stiefel manifold. source"},{"id":1699,"pagetitle":"Symplectic Grassmann","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{SymplecticGrassmann, Any, Any, CayleyRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(::SymplecticGrassmann, p, X, ::CayleyRetraction)\nretract!(::SymplecticGrassmann, q, p, X, ::CayleyRetraction) Compute the Cayley retraction on the Symplectic Grassmann manifold, when the points are represented as symplectic bases, i.e. on the  SymplecticStiefel . Here we can directly employ the  CaleyRetraction  on the symplectic Stiefel manifold. source"},{"id":1700,"pagetitle":"Symplectic Grassmann","title":"The symplectic projector representation","ref":"/manifolds/stable/manifolds/#The-symplectic-projector-representation","content":" The symplectic projector representation"},{"id":1701,"pagetitle":"Symplectic Grassmann","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{SymplecticGrassmann, ProjectorPoint}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::SymplecticGrassmann, p::ProjectorPoint; kwargs...) Check whether  p  is a valid point on the  SymplecticGrassmann ,  $\\operatorname{SpGr}(2n, 2k)$ , that is a propoer symplectic projection: $p^2 = p$ , that is  $p$  is a projection $\\operatorname{rank}(p) = 2k$ , that is, the supspace projected onto is of right dimension $p^+ = p$  the projection is symplectic. source"},{"id":1702,"pagetitle":"Symplectic Grassmann","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{SymplecticGrassmann, ProjectorPoint, ProjectorTVector}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::SymplecticGrassmann, p::ProjectorPoint, X::ProjectorTVector; kwargs...) Check whether  X  is a valid tangent vector at  p  on the  SymplecticGrassmann ,  $\\operatorname{SpGr}(2n, 2k)$  manifold by verifying that it $X^+ = X$ $X = Xp + pX$ For details see Proposition 4.2 in [ BZ21 ] and the definition of  $\\mathfrak{sp}_P(2n)$  before, especially the  $\\bar{Œ©}$ , which is the representation for  $X$  used here. source"},{"id":1703,"pagetitle":"Symplectic Grassmann","title":"Literature","ref":"/manifolds/stable/manifolds/#Literature","content":" Literature [BZ21] T.¬†Bendokat and R.¬†Zimmermann.  The real symplectic Stiefel and Grassmann manifolds: metrics, geodesics and applications , arXiv¬†Preprint,¬†2108.12447 (2021),  arXiv:2108.12447 ."},{"id":1706,"pagetitle":"Symplectic Stiefel","title":"(Real) Symplectic Stiefel","ref":"/manifolds/stable/manifolds/#(Real)-Symplectic-Stiefel","content":" (Real) Symplectic Stiefel The  SymplecticStiefel  manifold, denoted  $\\operatorname{SpSt}(2n, 2k)$ , represents canonical symplectic bases of  $2k$  dimensonal symplectic subspaces of  $‚Ñù^{2n√ó2n}$ . This means that the columns of each element  $p \\in \\operatorname{SpSt}(2n, 2k) \\subset ‚Ñù^{2n√ó2k}$  constitute a canonical symplectic basis of  $\\operatorname{span}(p)$ . The canonical symplectic form is a non-degenerate, bilinear, and skew symmetric map  $\\omega_{2k}\\colon ùîΩ^{2k}√óùîΩ^{2k} ‚Üí ùîΩ$ , given by  $\\omega_{2k}(x, y) = x^T Q_{2k} y$  for elements  $x, y \\in ùîΩ^{2k}$ , with \\[    Q_{2k} =\n    \\begin{bmatrix}\n     0_k  &  I_k \\\\\n    -I_k  &  0_k\n    \\end{bmatrix}.\\] Specifically given an element  $p \\in \\operatorname{SpSt}(2n, 2k)$  we require that \\[    \\omega_{2n} (p x, p y) = x^T(p^TQ_{2n}p)y = x^TQ_{2k}y = \\omega_{2k}(x, y) \\;\\forall\\; x, y \\in ùîΩ^{2k},\\] leading to the requirement on  $p$  that  $p^TQ_{2n}p = Q_{2k}$ . In the case that  $k = n$ , this manifold reduces to the  SymplecticMatrices  manifold, which is also known as the symplectic group."},{"id":1707,"pagetitle":"Symplectic Stiefel","title":"Manifolds.SymplecticStiefel","ref":"/manifolds/stable/manifolds/#Manifolds.SymplecticStiefel","content":" Manifolds.SymplecticStiefel  ‚Äî  Type SymplecticStiefel{T,ùîΩ} <: AbstractEmbeddedManifold{ùîΩ, DefaultIsometricEmbeddingType} The symplectic Stiefel manifold consists of all  $2n√ó2k, n ‚â• k$  matrices satisfying the requirement \\[\\mathrm{SpSt}(2n, 2k, ‚Ñù)\n    := \\bigl\\{ p ‚àà ‚Ñù^{2n√ó2n} \\ \\big| \\ p^{\\mathrm{T}}J_{2n}p = J_{2k} \\bigr\\},\\] where  $J_{2n}$  denotes the  SymplecticElement \\[J_{2n} = \\begin{bmatrix} 0_n & I_n \\\\ -I_n & 0_n \\end{bmatrix}.\\] The symplectic Stiefel tangent space at  $p$  can be parametrized as [ BZ21 ] \\[\\begin{align*}\n    T_p\\mathrm{SpSt}(2n, 2k)\n    &= \\{X ‚àà ‚Ñù^{2n√ó2k} ‚à£ p^{T}J_{2n}X + X^{T}J_{2n}p = 0 \\}, \\\\\n    &= \\{X = pŒ© + p^sB \\mid\n        Œ© ‚àà ‚Ñù^{2k√ó2k}, Œ©^+ = -Œ©, \\\\\n        &\\quad\\qquad p^s ‚àà \\mathrm{SpSt}(2n, 2(n- k)), B ‚àà ‚Ñù^{2(n-k)√ó2k}, \\},\n\\end{align*}\\] where  $Œ© ‚àà \\mathfrak{sp}(2n,F)$  is  Hamiltonian  and  $p^s$  means the symplectic complement of  $p$  s.t.  $p^{+}p^{s} = 0$ . Here  $p^+$  denotes the  symplectic_inverse . You can also use  StiefelPoint  and  StiefelTVector  with this manifold, they are equivalent to using arrays. Constructor SymplecticStiefel(2n::Int, 2k::Int, field::AbstractNumbers=‚Ñù; parameter::Symbol=:type) Generate the (real-valued) symplectic Stiefel manifold of  $2n√ó2k$  matrices which span a  $2k$  dimensional symplectic subspace of  $‚Ñù^{2n√ó2n}$ . The constructor for the  SymplecticStiefel  manifold accepts the even column dimension  $2n$  and an even number of columns  $2k$  for the real symplectic Stiefel manifold with elements  $p ‚àà ‚Ñù^{2n√ó2k}$ . source"},{"id":1708,"pagetitle":"Symplectic Stiefel","title":"Base.exp","ref":"/manifolds/stable/manifolds/#Base.exp-Tuple{SymplecticStiefel, Any, Any}","content":" Base.exp  ‚Äî  Method exp(::SymplecticStiefel, p, X)\nexp!(M::SymplecticStiefel, q, p, X) Compute the exponential mapping \\[  \\exp\\colon T\\mathrm{SpSt}(2n, 2k) ‚Üí \\mathrm{SpSt}(2n, 2k)\\] at a point  $p ‚àà \\mathrm{SpSt}(2n, 2k)$  in the direction of  $X ‚àà T_p\\mathrm{SpSt}(2n, 2k)$ . The tangent vector  $X$  can be written in the form  $X = \\bar{\\Omega}p$  [ BZ21 ], with \\[  \\bar{\\Omega} = X (p^{\\mathrm{T}}p)^{-1}p^{\\mathrm{T}}\n    + J_{2n}p(p^{\\mathrm{T}}p)^{-1}X^{\\mathrm{T}}(I_{2n}\n    - J_{2n}^{\\mathrm{T}}p(p^{\\mathrm{T}}p)^{-1}p^{\\mathrm{T}}J_{2n})J_{2n}\n    ‚àà ‚Ñù^{2n√ó2n},\\] where  $J_{2n} = \\begin{bmatrix} 0_n & I_n \\\\ -I_n & 0_n \\end{bmatrix}$  denotes the  SymplecticElement . Using this expression for  $X$ , the exponential mapping can be computed as \\[  \\exp_p(X) = \\operatorname{Exp}([\\bar{\\Omega} - \\bar{\\Omega}^{\\mathrm{T}}])\n                             \\operatorname{Exp}(\\bar{\\Omega}^{\\mathrm{T}})p,\\] where  $\\operatorname{Exp}(‚ãÖ)$  denotes the matrix exponential. Computing the above mapping directly however, requires taking matrix exponentials of two  $2n√ó2n$  matrices, which is computationally expensive when  $n$  increases. Therefore we instead follow [ BZ21 ] who express the above exponential mapping in a way which only requires taking matrix exponentials of an  $8k√ó8k$  matrix and a  $4k√ó4k$  matrix. To this end, first define \\[\\bar{A} = J_{2k}p^{\\mathrm{T}}X(p^{\\mathrm{T}}p)^{-1}J_{2k} +\n            (p^{\\mathrm{T}}p)^{-1}X^{\\mathrm{T}}(p - J_{2n}^{\\mathrm{T}}p(p^{\\mathrm{T}}p)^{-1}J_{2k}) ‚àà ‚Ñù^{2k√ó2k},\\] and \\[\\bar{H} = (I_{2n} - pp^+)J_{2n}X(p^{\\mathrm{T}}p)^{-1}J_{2k} ‚àà ‚Ñù^{2n√ó2k}.\\] We then let  $\\bar{\\Delta} = p\\bar{A} + \\bar{H}$ , and define the matrices \\[    Œ≥ = \\left[\\left(I_{2n} - \\frac{1}{2}pp^+\\right)\\bar{\\Delta} \\quad\n              -p \\right] ‚àà ‚Ñù^{2n√ó4k},\\] and \\[    Œª = \\left[J_{2n}^{\\mathrm{T}}pJ_{2k} \\quad\n        \\left(\\bar{\\Delta}^+\\left(I_{2n}\n              - \\frac{1}{2}pp^+\\right)\\right)^{\\mathrm{T}}\\right] ‚àà ‚Ñù^{2n√ó4k}.\\] With the above defined matrices it holds that  $\\bar{\\Omega} = ŒªŒ≥^{\\mathrm{T}}$ .  As a last preliminary step, concatenate  $Œ≥$  and  $Œª$  to define the matrices  $Œì = [Œª \\quad -Œ≥] ‚àà ‚Ñù^{2n√ó8k}$  and  $Œõ = [Œ≥ \\quad Œª] ‚àà ‚Ñù^{2n√ó8k}$ . With these matrix constructions done, we can compute the exponential mapping as \\[  \\exp_p(X) = Œì \\operatorname{Exp}(ŒõŒì^{\\mathrm{T}})\n    \\begin{bmatrix} 0_{4k} \\\\ I_{4k} \\end{bmatrix}\n    \\operatorname{Exp}(ŒªŒ≥^{\\mathrm{T}})\n    \\begin{bmatrix} 0_{2k} \\\\ I_{2k} \\end{bmatrix}.\\] which only requires computing the matrix exponentials of  $ŒõŒì^{\\mathrm{T}} ‚àà ‚Ñù^{8k√ó8k}$  and  $ŒªŒ≥^{\\mathrm{T}} ‚àà ‚Ñù^{4k√ó4k}$ . source"},{"id":1709,"pagetitle":"Symplectic Stiefel","title":"Base.inv","ref":"/manifolds/stable/manifolds/#Base.inv-Tuple{SymplecticStiefel, Any}","content":" Base.inv  ‚Äî  Method inv(::SymplecticStiefel, A)\ninv!(::SymplecticStiefel, q, p) Compute the symplectic inverse  $A^+$  of matrix  $A ‚àà ‚Ñù^{2n√ó2k}$ . Given a matrix \\[A ‚àà ‚Ñù^{2n√ó2k},\\quad\nA =\n\\begin{bmatrix}\nA_{1, 1} & A_{1, 2} \\\\\nA_{2, 1} & A_{2, 2}\n\\end{bmatrix}, \\quad A_{i, j} ‚àà ‚Ñù^{2n√ó2k}\\] the symplectic inverse is defined as: \\[A^{+} := J_{2k}^{\\mathrm{T}} A^{\\mathrm{T}} J_{2n},\\] where  $J_{2n} = \\begin{bmatrix} 0_n & I_n \\\\ -I_n & 0_n \\end{bmatrix}$  denotes the  SymplecticElement . The symplectic inverse of a matrix A can be expressed explicitly as: \\[A^{+} =\n  \\begin{bmatrix}\n    A_{2, 2}^{\\mathrm{T}} & -A_{1, 2}^{\\mathrm{T}} \\\\[1.2mm]\n   -A_{2, 1}^{\\mathrm{T}} &  A_{1, 1}^{\\mathrm{T}}\n  \\end{bmatrix}.\\] source"},{"id":1710,"pagetitle":"Symplectic Stiefel","title":"Base.rand","ref":"/manifolds/stable/manifolds/#Base.rand-Tuple{SymplecticStiefel}","content":" Base.rand  ‚Äî  Method rand(M::SymplecticStiefel; vector_at=nothing, œÉ = 1.0) Generate a random point  $p ‚àà \\mathrm{SpSt}(2n, 2k)$  or a random tangent vector  $X ‚àà T_p\\mathrm{SpSt}(2n, 2k)$  if  vector_at  is set to a point  $p ‚àà \\mathrm{Sp}(2n)$ . A random point on  $\\mathrm{SpSt}(2n, 2k)$  is found by first generating a random point on the symplectic manifold  $\\mathrm{Sp}(2n)$ , and then projecting onto the Symplectic Stiefel manifold using the  canonical_project $œÄ_{\\mathrm{SpSt}(2n, 2k)}$ . That is,  $p = œÄ_{\\mathrm{SpSt}(2n, 2k)}(p_{\\mathrm{Sp}})$ . To generate a random tangent vector in  $T_p\\mathrm{SpSt}(2n, 2k)$  this code exploits the second tangent vector space parametrization of  SymplecticStiefel , that any  $X ‚àà T_p\\mathrm{SpSt}(2n, 2k)$  can be written as  $X = pŒ©_X + p^sB_X$ . To generate random tangent vectors at  $p$  then, this function sets  $B_X = 0$  and generates a random Hamiltonian matrix  $Œ©_X ‚àà \\mathfrak{sp}(2n,F)$  with Frobenius norm of  œÉ  before returning  $X = pŒ©_X$ . source"},{"id":1711,"pagetitle":"Symplectic Stiefel","title":"ManifoldDiff.riemannian_gradient","ref":"/manifolds/stable/manifolds/#ManifoldDiff.riemannian_gradient-Tuple{SymplecticStiefel, Any, Any}","content":" ManifoldDiff.riemannian_gradient  ‚Äî  Method X = riemannian_gradient(::SymplecticStiefel, f, p, Y; embedding_metric::EuclideanMetric=EuclideanMetric())\nriemannian_gradient!(::SymplecticStiefel, f, X, p, Y; embedding_metric::EuclideanMetric=EuclideanMetric()) Compute the riemannian gradient  X  of  f  on  SymplecticStiefel   at a point  p , provided that the gradient of the function  $\\tilde f$ , which is  f  continued into the embedding is given by  Y . The metric in the embedding is the Euclidean metric. The manifold gradient  X  is computed from  Y  as \\[    X = Yp^{\\mathrm{T}}p + J_{2n}pY^{\\mathrm{T}}J_{2n}p,\\] where  $J_{2n} = \\begin{bmatrix} 0_n & I_n \\\\ -I_n & 0_n \\end{bmatrix}$  denotes the  SymplecticElement . source"},{"id":1712,"pagetitle":"Symplectic Stiefel","title":"Manifolds.canonical_project","ref":"/manifolds/stable/manifolds/#Manifolds.canonical_project-Tuple{SymplecticStiefel, Any}","content":" Manifolds.canonical_project  ‚Äî  Method canonical_project(::SymplecticStiefel, p_Sp)\ncanonical_project!(::SymplecticStiefel, p, p_Sp) Define the canonical projection from  $\\mathrm{Sp}(2n, 2n)$  onto  $\\mathrm{SpSt}(2n, 2k)$ , by projecting onto the first  $k$  columns and the  $n + 1$ 'th onto the  $n + k$ 'th columns [ BZ21 ]. It is assumed that the point  $p$  is on  $\\mathrm{Sp}(2n, 2n)$ . source"},{"id":1713,"pagetitle":"Symplectic Stiefel","title":"Manifolds.get_total_space","ref":"/manifolds/stable/manifolds/#Manifolds.get_total_space-Union{Tuple{SymplecticStiefel{ManifoldsBase.TypeParameter{Tuple{n, k}}, ‚Ñù}}, Tuple{k}, Tuple{n}} where {n, k}","content":" Manifolds.get_total_space  ‚Äî  Method get_total_space(::SymplecticStiefel) Return the total space of the  SymplecticStiefel  manifold, which is the corresponding  SymplecticMatrices  manifold. source"},{"id":1714,"pagetitle":"Symplectic Stiefel","title":"Manifolds.symplectic_inverse_times","ref":"/manifolds/stable/manifolds/#Manifolds.symplectic_inverse_times-Tuple{SymplecticStiefel, Any, Any}","content":" Manifolds.symplectic_inverse_times  ‚Äî  Method symplectic_inverse_times(::SymplecticStiefel, p, q)\nsymplectic_inverse_times!(::SymplecticStiefel, A, p, q) Directly compute the symplectic inverse of  $p ‚àà \\mathrm{SpSt}(2n, 2k)$ , multiplied with  $q ‚àà \\mathrm{SpSt}(2n, 2k)$ . That is, this function efficiently computes  $p^+q = (J_{2k}p^{\\mathrm{T}}J_{2n})q ‚àà ‚Ñù^{2k√ó2k}$ , where  $J_{2n}, J_{2k}$  are the  SymplecticElement  of sizes  $2n√ó2n$  and  $2k√ó2k$  respectively. This function performs this common operation without allocating more than a  $2k√ó2k$  matrix to store the result in, or in the case of the in-place function, without allocating memory at all. source"},{"id":1715,"pagetitle":"Symplectic Stiefel","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{SymplecticStiefel{<:Any, ‚Ñù}, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::SymplecticStiefel, p; kwargs...) Check whether  p  is a valid point on the  SymplecticStiefel ,  $\\mathrm{SpSt}(2n, 2k)$  manifold, that is  $p^{+}p$  is the identity,  $(‚ãÖ)^+$  denotes the  symplectic_inverse . source"},{"id":1716,"pagetitle":"Symplectic Stiefel","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{SymplecticStiefel, Vararg{Any}}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::SymplecticMatrices, p, X; kwargs...) Checks whether  X  is a valid tangent vector at  p  on the  SymplecticStiefel ,  $\\mathrm{SpSt}(2n, 2k)$  manifold. The check consists of verifying that  $H = p^{+}X ‚àà ùî§_{2k}$ , where  $ùî§$  is the Lie Algebra of the symplectic group  $\\mathrm{Sp}(2k)$ , that is the set of [ HamiltonianMatrices ])(@ref), where  $(‚ãÖ)^+$  denotes the  symplectic_inverse . source"},{"id":1717,"pagetitle":"Symplectic Stiefel","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{SymplecticStiefel, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::SymplecticStiefel, p, X. Y) Compute the Riemannian inner product  $g^{\\mathrm{SpSt}}$  at  $p ‚àà \\mathrm{SpSt}$  of tangent vectors  $Y, X ‚àà T_p\\mathrm{SpSt}$ . Given by Proposition 3.10 in [ BZ21 ]. \\[g^{\\mathrm{SpSt}}_p(X, Y)\n  = \\operatorname{tr}\\Bigl(\n    X^{\\mathrm{T}}\\bigl(\n      I_{2n} - \\frac{1}{2}J_{2n}^{\\mathrm{T}} p(p^{\\mathrm{T}}p)^{-1}p^{\\mathrm{T}}J_{2n}\n    \\bigr) Y (p^{\\mathrm{T}}p)^{-1}\\Bigr).\\] source"},{"id":1718,"pagetitle":"Symplectic Stiefel","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{SymplecticStiefel, Any, Any, CayleyInverseRetraction}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(::SymplecticStiefel, p, q, ::CayleyInverseRetraction)\ninverse_retract!(::SymplecticStiefel, q, p, X, ::CayleyInverseRetraction) Compute the Cayley Inverse Retraction  $X = \\mathcal{L}_p^{\\mathrm{SpSt}}(q)$  such that the Cayley Retraction from  $p$  along  $X$  lands at  $q$ , i.e.  $\\mathcal{R}_p(X) = q$  [ BZ21 ]. For  $p, q ‚àà \\mathrm{SpSt}(2n, 2k, ‚Ñù)$  we can define the inverse cayley retraction as long as the following matrices exist. \\[    U = (I + p^+ q)^{-1} ‚àà ‚Ñù^{2k√ó2k},\n    \\quad\n    V = (I + q^+ p)^{-1} ‚àà ‚Ñù^{2k√ó2k},\\] where  $(‚ãÖ)^+$  denotes the  symplectic_inverse . THen the inverse retraction reads \\[\\mathcal{L}_p^{\\mathrm{Sp}}(q) = 2p\\bigl(V - U\\bigr) + 2\\bigl((p + q)U - p\\bigr) ‚àà T_p\\mathrm{Sp}(2n).\\] source"},{"id":1719,"pagetitle":"Symplectic Stiefel","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{SymplecticStiefel}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::SymplecticStiefel) Return false.  SymplecticStiefel  is not a flat manifold. source"},{"id":1720,"pagetitle":"Symplectic Stiefel","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{SymplecticStiefel}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(::SymplecticStiefel) Returns the dimension of the symplectic Stiefel manifold embedded in  $‚Ñù^{2n√ó2k}$ , i.e. [ BZ21 ] \\[    \\operatorname{dim}(\\mathrm{SpSt}(2n, 2k)) = (4n - 2k + 1)k.\\] source"},{"id":1721,"pagetitle":"Symplectic Stiefel","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{SymplecticStiefel, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(::SymplecticStiefel, p, A)\nproject!(::SymplecticStiefel, Y, p, A) Given a point  $p ‚àà \\mathrm{SpSt}(2n, 2k)$ , project an element  $A ‚àà ‚Ñù^{2n√ó2k}$  onto the tangent space  $T_p\\mathrm{SpSt}(2n, 2k)$  relative to the euclidean metric of the embedding  $‚Ñù^{2n√ó2k}$ . That is, we find the element  $X ‚àà T_p\\mathrm{SpSt}(2n, 2k)$  which solves the constrained optimization problem \\[    \\displaystyle\\operatorname{min}_{X ‚àà ‚Ñù^{2n√ó2k}} \\frac{1}{2}||X - A||^2, \\quad\n    \\text{s.t.}\\;\n    h(X) := X^{\\mathrm{T}} J p + p^{\\mathrm{T}} J X = 0,\\] where  $h : ‚Ñù^{2n√ó2k} ‚Üí \\operatorname{skew}(2k)$  defines the restriction of  $X$  onto the tangent space  $T_p\\mathrm{SpSt}(2n, 2k)$ . source"},{"id":1722,"pagetitle":"Symplectic Stiefel","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{SymplecticStiefel, Any, Any, CayleyRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(::SymplecticStiefel, p, X, ::CayleyRetraction)\nretract!(::SymplecticStiefel, q, p, X, ::CayleyRetraction) Compute the Cayley retraction on the Symplectic Stiefel manifold, from  p  along  X  (computed inplace of  q ). Given a point  $p ‚àà \\mathrm{SpSt}(2n, 2k)$ , every tangent vector  $X ‚àà T_p\\mathrm{SpSt}(2n, 2k)$  is of the form  $X = \\tilde{\\Omega}p$ , with \\[    \\tilde{\\Omega} = \\left(I_{2n} - \\frac{1}{2}pp^+\\right)Xp^+ -\n                     pX^+\\left(I_{2n} - \\frac{1}{2}pp^+\\right) ‚àà ‚Ñù^{2n√ó2n},\\] as shown in Proposition 3.5 of [ BZ21 ]. Using this representation of  $X$ , the Cayley retraction on  $\\mathrm{SpSt}(2n, 2k)$  is defined pointwise as \\[    \\mathcal{R}_p(X) = \\operatorname{cay}\\left(\\frac{1}{2}\\tilde{\\Omega}\\right)p.\\] The operator  $\\operatorname{cay}(A) = (I - A)^{-1}(I + A)$  is the Cayley transform. However, the computation of an  $2n√ó2n$  matrix inverse in the expression above can be reduced down to inverting a  $2k√ó2k$  matrix due to Proposition 5.2 of [ BZ21 ]. Let  $A = p^+X$  and  $H = X - pA$ . Then an equivalent expression for the Cayley retraction defined pointwise above is \\[  \\mathcal{R}_p(X) = -p + (H + 2p)(H^+H/4 - A/2 + I_{2k})^{-1}.\\] This expression is computed inplace of  q . source"},{"id":1723,"pagetitle":"Symplectic Stiefel","title":"Literature","ref":"/manifolds/stable/manifolds/#Literature","content":" Literature [BZ21] T.¬†Bendokat and R.¬†Zimmermann.  The real symplectic Stiefel and Grassmann manifolds: metrics, geodesics and applications , arXiv¬†Preprint,¬†2108.12447 (2021),  arXiv:2108.12447 ."},{"id":1726,"pagetitle":"Torus","title":"Torus","ref":"/manifolds/stable/manifolds/#Torus","content":" Torus The torus  $ùïã^d ‚âÖ [-œÄ,œÄ)^d$  is modeled as an  AbstractPowerManifold   of the (real-valued)  Circle  and uses  ArrayPowerRepresentation . Points on the torus are hence row vectors,  $x ‚àà ‚Ñù^{d}$ ."},{"id":1727,"pagetitle":"Torus","title":"Example","ref":"/manifolds/stable/manifolds/#Example","content":" Example The following code can be used to make a three-dimensional torus  $ùïã^3$  and compute a tangent vector: using Manifolds\nM = Torus(3)\np = [0.5, 0.0, 0.0]\nq = [0.0, 0.5, 1.0]\nX = log(M, p, q) 3-element Vector{Float64}:\n -0.5\n  0.5\n  1.0"},{"id":1728,"pagetitle":"Torus","title":"Types and functions","ref":"/manifolds/stable/manifolds/#Types-and-functions","content":" Types and functions Most functions are directly implemented for an  AbstractPowerManifold   with  ArrayPowerRepresentation  except the following special cases:"},{"id":1729,"pagetitle":"Torus","title":"Manifolds.Torus","ref":"/manifolds/stable/manifolds/#Manifolds.Torus","content":" Manifolds.Torus  ‚Äî  Type Torus{N} <: AbstractPowerManifold The n-dimensional torus is the  $n$ -dimensional product of the  Circle . The  Circle  is stored internally within  M.manifold , such that all functions of  AbstractPowerManifold   can be used directly. source"},{"id":1730,"pagetitle":"Torus","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{Torus, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::Torus{n},p) Checks whether  p  is a valid point on the  Torus M , i.e. each of its entries is a valid point on the  Circle  and the length of  x  is  n . source"},{"id":1731,"pagetitle":"Torus","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Union{Tuple{N}, Tuple{Torus{N}, Any, Any}} where N","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::Torus{n}, p, X; kwargs...) Checks whether  X  is a valid tangent vector to  p  on the  Torus M . This means, that  p  is valid, that  X  is of correct dimension and elementwise a tangent vector to the elements of  p  on the  Circle . source"},{"id":1732,"pagetitle":"Torus","title":"Embedded Torus","ref":"/manifolds/stable/manifolds/#Embedded-Torus","content":" Embedded Torus Two-dimensional torus embedded in  $‚Ñù^3$ ."},{"id":1733,"pagetitle":"Torus","title":"Manifolds.DefaultTorusAtlas","ref":"/manifolds/stable/manifolds/#Manifolds.DefaultTorusAtlas","content":" Manifolds.DefaultTorusAtlas  ‚Äî  Type DefaultTorusAtlas() Atlas for torus with charts indexed by two angles numbers  $Œ∏‚ÇÄ, œÜ‚ÇÄ ‚àà [-œÄ, œÄ)$ . Inverse of a chart  $(Œ∏‚ÇÄ, œÜ‚ÇÄ)$  is given by \\[x(Œ∏, œÜ) = (R + r\\cos(Œ∏ + Œ∏‚ÇÄ))\\cos(œÜ + œÜ‚ÇÄ) \\\\\ny(Œ∏, œÜ) = (R + r\\cos(Œ∏ + Œ∏‚ÇÄ))\\sin(œÜ + œÜ‚ÇÄ) \\\\\nz(Œ∏, œÜ) = r\\sin(Œ∏ + Œ∏‚ÇÄ)\\] source"},{"id":1734,"pagetitle":"Torus","title":"Manifolds.EmbeddedTorus","ref":"/manifolds/stable/manifolds/#Manifolds.EmbeddedTorus","content":" Manifolds.EmbeddedTorus  ‚Äî  Type EmbeddedTorus{TR<:Real} <: AbstractDecoratorManifold{‚Ñù} Surface in ‚Ñù¬≥ described by parametric equations: \\[x(Œ∏, œÜ) = (R + r\\cos Œ∏)\\cos œÜ \\\\\ny(Œ∏, œÜ) = (R + r\\cos Œ∏)\\sin œÜ \\\\\nz(Œ∏, œÜ) = r\\sin Œ∏\\] for Œ∏, œÜ in  $[-œÄ, œÄ)$ . It is assumed that  $R > r > 0$ . Alternative names include anchor ring, donut and doughnut. Constructor EmbeddedTorus(R, r) source"},{"id":1735,"pagetitle":"Torus","title":"Manifolds.affine_connection","ref":"/manifolds/stable/manifolds/#Manifolds.affine_connection-Tuple{Manifolds.EmbeddedTorus, Manifolds.DefaultTorusAtlas, Vararg{Any, 4}}","content":" Manifolds.affine_connection  ‚Äî  Method affine_connection(M::EmbeddedTorus, A::DefaultTorusAtlas, i, a, Xc, Yc) Affine connection on  EmbeddedTorus M . source"},{"id":1736,"pagetitle":"Torus","title":"Manifolds.check_chart_switch","ref":"/manifolds/stable/manifolds/#Manifolds.check_chart_switch-Tuple{Manifolds.EmbeddedTorus, Manifolds.DefaultTorusAtlas, Any, Any}","content":" Manifolds.check_chart_switch  ‚Äî  Method check_chart_switch(::EmbeddedTorus, A::DefaultTorusAtlas, i, a; œµ = pi/3) Return true if parameters  a  lie closer than  œµ  to chart boundary. source"},{"id":1737,"pagetitle":"Torus","title":"Manifolds.gaussian_curvature","ref":"/manifolds/stable/manifolds/#Manifolds.gaussian_curvature-Tuple{Manifolds.EmbeddedTorus, Any}","content":" Manifolds.gaussian_curvature  ‚Äî  Method gaussian_curvature(M::EmbeddedTorus, p) Gaussian curvature at point  p  from  EmbeddedTorus M . source"},{"id":1738,"pagetitle":"Torus","title":"Manifolds.inverse_chart_injectivity_radius","ref":"/manifolds/stable/manifolds/#Manifolds.inverse_chart_injectivity_radius-Tuple{Manifolds.EmbeddedTorus, Manifolds.DefaultTorusAtlas, Any}","content":" Manifolds.inverse_chart_injectivity_radius  ‚Äî  Method inverse_chart_injectivity_radius(M::AbstractManifold, A::AbstractAtlas, i) Injectivity radius of  get_point  for chart  i  from the  DefaultTorusAtlas A  of the  EmbeddedTorus . source"},{"id":1739,"pagetitle":"Torus","title":"Manifolds.normal_vector","ref":"/manifolds/stable/manifolds/#Manifolds.normal_vector-Tuple{Manifolds.EmbeddedTorus, Any}","content":" Manifolds.normal_vector  ‚Äî  Method normal_vector(M::EmbeddedTorus, p) Outward-pointing normal vector on the  EmbeddedTorus  at the point  p . source"},{"id":1740,"pagetitle":"Torus","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{Manifolds.EmbeddedTorus, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::EmbeddedTorus, p; kwargs...) Check whether  p  is a valid point on the  EmbeddedTorus M . The tolerance for the last test can be set using the  kwargs... . The method checks if  $(p_1^2 + p_2^2 + p_3^2 + R^2 - r^2)^2$  is apprximately equal to  $4R^2(p_1^2 + p_2^2)$ . source"},{"id":1741,"pagetitle":"Torus","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Tuple{Manifolds.EmbeddedTorus, Any, Any}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::EmbeddedTorus, p, X; atol=eps(eltype(p)), kwargs...) Check whether  X  is a valid vector tangent to  p  on the  EmbeddedTorus M . The method checks if the vector  X  is orthogonal to the vector normal to the torus, see  normal_vector . Absolute tolerance can be set using  atol . source"},{"id":1742,"pagetitle":"Torus","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{Manifolds.EmbeddedTorus, Manifolds.DefaultTorusAtlas, Vararg{Any, 4}}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::EmbeddedTorus, ::DefaultTorusAtlas, i, a, Xc, Yc) Inner product on  EmbeddedTorus  in chart  i  in the  DefaultTorusAtlas . between vectors with coordinates  Xc  and  Yc  tangent at point with parameters  a . Vector coordinates must be given in the induced basis. source"},{"id":1743,"pagetitle":"Torus","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{Manifolds.EmbeddedTorus}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::EmbeddedTorus) Return false.  EmbeddedTorus  is not a flat manifold. source"},{"id":1744,"pagetitle":"Torus","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{Manifolds.EmbeddedTorus}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(M::EmbeddedTorus) Return the dimension of the  EmbeddedTorus M  that is 2. source"},{"id":1747,"pagetitle":"Tucker","title":"Tucker manifold","ref":"/manifolds/stable/manifolds/#Tucker","content":" Tucker manifold"},{"id":1748,"pagetitle":"Tucker","title":"Manifolds.Tucker","ref":"/manifolds/stable/manifolds/#Manifolds.Tucker","content":" Manifolds.Tucker  ‚Äî  Type Tucker{T, D, ùîΩ} <: AbstractManifold{ùîΩ} The manifold of  $N_1√ó\\dots√óN_D$  real-valued or complex-valued tensors of fixed multilinear rank  $(R_1, \\dots, R_D)$  . If  $R_1 = \\dots = R_D = 1$ , this is the Segre manifold, i.e., the set of rank-1 tensors. Representation in HOSVD format Let  $ùîΩ$  be the real or complex numbers. Any tensor  $p$  on the Tucker manifold can be represented as a multilinear product in HOSVD [ LMV00 ] form \\[p = (U_1,\\dots,U_D) ‚ãÖ \\mathcal{C}\\] where  $\\mathcal C \\in ùîΩ^{R_1√ó\\dots√óR_D}$  and, for  $d=1,\\dots,D$ , the matrix  $U_d \\in ùîΩ^{N_d√óR_d}$  contains the singular vectors of the  $d$ th unfolding of  $\\mathcal{A}$ Tangent space The tangent space to the Tucker manifold at  $p = (U_1,\\dots,U_D) ‚ãÖ \\mathcal{C}$  is [ KL10 ] \\[T_p \\mathcal{M} =\n\\bigl\\{\n(U_1,\\dots,U_D) ‚ãÖ \\mathcal{C}^\\prime\n+ \\sum_{d=1}^D \\bigl(\n    (U_1, \\dots, U_{d-1}, U_d^\\prime, U_{d+1}, \\dots, U_D)\n    ‚ãÖ \\mathcal{C}\n\\bigr)\n\\bigr\\}\\] where  $\\mathcal{C}^\\prime$  is arbitrary,  $U_d^{\\mathrm{H}}$  is the Hermitian adjoint of  $U_d$ , and  $U_d^{\\mathrm{H}} U_d^\\prime = 0$  for all  $d$ . Constructor Tucker(N::NTuple{D, Int}, R::NTuple{D, Int}[, field=‚Ñù]; parameter::Symbol=:type) Generate the manifold of  field -valued tensors of dimensions   N[1] √ó ‚Ä¶ √ó N[D]  and multilinear rank  R = (R[1], ‚Ä¶, R[D]) . source"},{"id":1749,"pagetitle":"Tucker","title":"Manifolds.TuckerPoint","ref":"/manifolds/stable/manifolds/#Manifolds.TuckerPoint","content":" Manifolds.TuckerPoint  ‚Äî  Type TuckerPoint{T,D} An order  D  tensor of fixed multilinear rank and entries of type  T , which makes it a point on the  Tucker  manifold. The tensor is represented in HOSVD form. Constructors: TuckerPoint(core::AbstractArray{T,D}, factors::Vararg{<:AbstractMatrix{T},D}) where {T,D} Construct an order  D  tensor of element type  T  that can be represented as the multilinear product  (factors[1], ‚Ä¶, factors[D]) ‚ãÖ core . It is assumed that the dimensions of the core are the multilinear rank of the tensor and that the matrices  factors  each have full rank. No further assumptions are made. TuckerPoint(p::AbstractArray{T,D}, mlrank::NTuple{D,Int}) where {T,D} The low-multilinear rank tensor arising from the sequentially truncated the higher-order singular value decomposition of the  D -dimensional array  p  of type  T . The singular values are truncated to get a multilinear rank  mlrank  [ VVM12 ]. source"},{"id":1750,"pagetitle":"Tucker","title":"Manifolds.TuckerTVector","ref":"/manifolds/stable/manifolds/#Manifolds.TuckerTVector","content":" Manifolds.TuckerTVector  ‚Äî  Type TuckerTVector{T, D} <: TVector Tangent vector to the  D -th order  Tucker  manifold at  $p = (U_1,\\dots,U_D) ‚ãÖ \\mathcal{C}$ . The numbers are of type  T  and the vector is represented as \\[X =\n(U_1,\\dots,U_D) ‚ãÖ \\mathcal{C}^\\prime +\n\\sum_{d=1}^D (U_1,\\dots,U_{d-1},U_d^\\prime,U_{d+1},\\dots,U_D) ‚ãÖ \\mathcal{C}\\] where  $U_d^\\mathrm{H} U_d^\\prime = 0$ . Constructor TuckerTVector(C‚Ä≤::Array{T,D}, U‚Ä≤::NTuple{D,Matrix{T}}) where {T,D} Constructs a  D th order  TuckerTVector  of number type  T  with  $C^\\prime$  and  $U^\\prime$ , so that, together with a  TuckerPoint $p$  as above, the tangent vector can be represented as  $X$  in the above expression. source"},{"id":1751,"pagetitle":"Tucker","title":"Base.convert","ref":"/manifolds/stable/manifolds/#Base.convert-Union{Tuple{D}, Tuple{T}, Tuple{ùîΩ}, Tuple{Type{Matrix{T}}, CachedBasis{ùîΩ, DefaultOrthonormalBasis{ùîΩ, TangentSpaceType}, Manifolds.HOSVDBasis{T, D}}}} where {ùîΩ, T, D}","content":" Base.convert  ‚Äî  Method Base.convert(::Type{Matrix{T}}, basis::CachedBasis{ùîΩ,DefaultOrthonormalBasis{ùîΩ, TangentSpaceType},HOSVDBasis{T, D}}) where {ùîΩ, T, D}\nBase.convert(::Type{Matrix}, basis::CachedBasis{ùîΩ,DefaultOrthonormalBasis{ùîΩ, TangentSpaceType},HOSVDBasis{T, D}}) where {ùîΩ, T, D} Convert a HOSVD-derived cached basis from [ DBV21 ] of the  D th order  Tucker  manifold with number type  T  to a matrix. The columns of this matrix are the vectorisations of the  embed dings of the basis vectors. source"},{"id":1752,"pagetitle":"Tucker","title":"Base.foreach","ref":"/manifolds/stable/manifolds/#Base.foreach","content":" Base.foreach  ‚Äî  Function Base.foreach(f, M::Tucker, p::TuckerPoint, basis::AbstractBasis, indices=1:manifold_dimension(M)) Let  basis  be and  AbstractBasis  at a point  p  on  M . Suppose  f  is a function that takes an index and a vector as an argument. This function applies  f  to  i  and the  i th basis vector sequentially for each  i  in  indices . Using a  CachedBasis  may speed up the computation. NOTE : The i'th basis vector is overwritten in each iteration. If any information about the vector is to be stored,  f  must make a copy. source"},{"id":1753,"pagetitle":"Tucker","title":"Base.ndims","ref":"/manifolds/stable/manifolds/#Base.ndims-Union{Tuple{TuckerPoint{T, D}}, Tuple{D}, Tuple{T}} where {T, D}","content":" Base.ndims  ‚Äî  Method Base.ndims(p::TuckerPoint{T,D}) where {T,D} The order of the tensor corresponding to the  TuckerPoint p , i.e.,  D . source"},{"id":1754,"pagetitle":"Tucker","title":"Base.size","ref":"/manifolds/stable/manifolds/#Base.size-Tuple{TuckerPoint}","content":" Base.size  ‚Äî  Method Base.size(p::TuckerPoint) The dimensions of a  TuckerPoint p , when regarded as a full tensor (see  embed ). source"},{"id":1755,"pagetitle":"Tucker","title":"ManifoldsBase.check_point","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_point-Tuple{Tucker, Any}","content":" ManifoldsBase.check_point  ‚Äî  Method check_point(M::Tucker, p; kwargs...) Check whether the multidimensional array or  TuckerPoint p  is a point on the  Tucker  manifold, i.e. it is a  D th order  N[1] √ó ‚Ä¶ √ó N[D]  tensor of multilinear rank  (R[1], ‚Ä¶, R[D]) . The keyword arguments are passed to the matrix rank function applied to the unfoldings. For a  TuckerPoint  it is checked that the point is in correct HOSVD form. source"},{"id":1756,"pagetitle":"Tucker","title":"ManifoldsBase.check_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.check_vector-Union{Tuple{D}, Tuple{T}, Tuple{Tucker{<:Any, D}, TuckerPoint{T, D}, TuckerTVector}} where {T, D}","content":" ManifoldsBase.check_vector  ‚Äî  Method check_vector(M::Tucker{<:Any,D}, p::TuckerPoint{T,D}, X::TuckerTVector) where {T,D} Check whether a  TuckerTVector X  is is in the tangent space to the  D th order  Tucker  manifold  M  at the  D th order  TuckerPoint p . This is the case when the dimensions of the factors in  X  agree with those of  p  and the factor matrices of  X  are in the orthogonal complement of the HOSVD factors of  p . source"},{"id":1757,"pagetitle":"Tucker","title":"ManifoldsBase.embed","ref":"/manifolds/stable/manifolds/#ManifoldsBase.embed-Tuple{Tucker, TuckerPoint, TuckerTVector}","content":" ManifoldsBase.embed  ‚Äî  Method embed(::Tucker, p::TuckerPoint, X::TuckerTVector) Convert a tangent vector  X  with base point  p  on the rank  R Tucker  manifold to a full tensor, represented as an  N[1] √ó ‚Ä¶ √ó N[D] -array. source"},{"id":1758,"pagetitle":"Tucker","title":"ManifoldsBase.embed","ref":"/manifolds/stable/manifolds/#ManifoldsBase.embed-Tuple{Tucker, TuckerPoint}","content":" ManifoldsBase.embed  ‚Äî  Method embed(::Tucker, p::TuckerPoint) Convert a  TuckerPoint p  on the rank  R Tucker  manifold to a full  N[1] √ó ‚Ä¶ √ó N[D] -array by evaluating the Tucker decomposition. source"},{"id":1759,"pagetitle":"Tucker","title":"ManifoldsBase.get_basis","ref":"/manifolds/stable/manifolds/#ManifoldsBase.get_basis-Union{Tuple{ùîΩ}, Tuple{Tucker, TuckerPoint}, Tuple{Tucker, TuckerPoint, DefaultOrthonormalBasis{ùîΩ, TangentSpaceType}}} where ùîΩ","content":" ManifoldsBase.get_basis  ‚Äî  Method get_basis(:: Tucker, p::TuckerPoint, basisType::DefaultOrthonormalBasis{ùîΩ, TangentSpaceType}) where ùîΩ An implicitly stored basis of the tangent space to the Tucker manifold. Assume  $p = (U_1,\\dots,U_D) ‚ãÖ \\mathcal{C}$  is in HOSVD format and that, for  $d=1,\\dots,D$ , the singular values of the  $d$ 'th unfolding are  $\\sigma_{dj}$ , with  $j = 1,\\dots,R_d$ . The basis of the tangent space is as follows: [ DBV21 ] \\[\\bigl\\{\n(U_1,\\dots,U_D) e_i\n\\bigr\\} \\cup \\bigl\\{\n(U_1,\\dots, \\sigma_{dj}^{-1} U_d^{\\perp} e_i e_j^T,\\dots,U_D) ‚ãÖ \\mathcal{C}\n\\bigr\\}\\] for all  $d = 1,\\dots,D$  and all canonical basis vectors  $e_i$  and  $e_j$ . Every  $U_d^\\perp$  is such that  $[U_d \\quad U_d^{\\perp}]$  forms an orthonormal basis of  $‚Ñù^{N_d}$ . source"},{"id":1760,"pagetitle":"Tucker","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{Tucker, TuckerPoint, TuckerTVector, TuckerTVector}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::Tucker, p::TuckerPoint, X::TuckerTVector, Y::TuckerTVector) The Euclidean inner product between tangent vectors  X  and  X  at the point  p  on the Tucker manifold. This is equal to  embed(M, p, X) ‚ãÖ embed(M, p, Y) . inner(::Tucker, A::TuckerPoint, X::TuckerTVector, Y)\ninner(::Tucker, A::TuckerPoint, X, Y::TuckerTVector) The Euclidean inner product between  X  and  Y  where  X  is a vector tangent to the Tucker manifold at  p  and  Y  is a vector in the ambient space or vice versa. The vector in the ambient space is represented as a full tensor, i.e., a multidimensional array. source"},{"id":1761,"pagetitle":"Tucker","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{Tucker, Any, TuckerPoint, TuckerPoint, ProjectionInverseRetraction}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(M::Tucker, p::TuckerPoint, q::TuckerPoint, ::ProjectionInverseRetraction) The projection inverse retraction on the Tucker manifold interprets  q  as a point in the ambient Euclidean space (see  embed ) and projects it onto the tangent space at to  M  at  p . source"},{"id":1762,"pagetitle":"Tucker","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{Tucker}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::Tucker) Return false.  Tucker  is not a flat manifold. source"},{"id":1763,"pagetitle":"Tucker","title":"ManifoldsBase.manifold_dimension","ref":"/manifolds/stable/manifolds/#ManifoldsBase.manifold_dimension-Tuple{Tucker}","content":" ManifoldsBase.manifold_dimension  ‚Äî  Method manifold_dimension(::Tucker) The dimension of the manifold of  $N_1√ó\\dots√óN_D$  tensors of multilinear rank  $(R_1, \\dots, R_D)$ , i.e. \\[\\mathrm{dim}(\\mathcal{M}) = \\prod_{d=1}^D R_d + \\sum_{d=1}^D R_d (N_d - R_d).\\] source"},{"id":1764,"pagetitle":"Tucker","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{Tucker, Any, TuckerPoint, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(M::Tucker, p::TuckerPoint, X) The least-squares projection of a dense tensor  X  onto the tangent space to  M  at  p . source"},{"id":1765,"pagetitle":"Tucker","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{Tucker, Any, Any, PolarRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(::Tucker, p::TuckerPoint, X::TuckerTVector, ::PolarRetraction) The truncated HOSVD-based retraction [ KSV13 ] to the Tucker manifold, i.e. the result is the sequentially tuncated HOSVD approximation of  $p + X$ . In the exceptional case that the multilinear rank of  $p + X$  is lower than that of  $p$ , this retraction produces a boundary point, which is outside the manifold. source"},{"id":1766,"pagetitle":"Tucker","title":"ManifoldsBase.zero_vector","ref":"/manifolds/stable/manifolds/#ManifoldsBase.zero_vector-Tuple{Tucker, TuckerPoint}","content":" ManifoldsBase.zero_vector  ‚Äî  Method zero_vector(::Tucker, p::TuckerPoint) The zero element in the tangent space to  p  on the  Tucker  manifold, represented as a  TuckerTVector . source"},{"id":1767,"pagetitle":"Tucker","title":"Literature","ref":"/manifolds/stable/manifolds/#Literature","content":" Literature [DBV21] N.¬†Dewaele, P.¬†Breiding and N.¬†Vannieuwenhoven.  The condition number of many tensor decompositions is invariant under Tucker compression , arXiv¬†Preprint (2021),  arXiv:2106.13034 . [KL10] O.¬†Koch and C.¬†Lubich.  Dynamical Tensor Approximation .  SIAM¬†Journal¬†on¬†Matrix¬†Analysis¬†and¬†Applications  31 , 2360‚Äì2375  (2010). [KSV13] D.¬†Kressner, M.¬†Steinlechner and B.¬†Vandereycken.  Low-rank tensor completion by Riemannian optimization .  BIT¬†Numerical¬†Mathematics  54 , 447‚Äì468  (2013). [LMV00] L.¬†D.¬†Lathauwer, B.¬†D.¬†Moor and J.¬†Vandewalle.  A Multilinear Singular Value Decomposition .  SIAM¬†Journal¬†on¬†Matrix¬†Analysis¬†and¬†Applications  21 , 1253‚Äì1278  (2000). [VVM12] N.¬†Vannieuwenhoven, R.¬†Vandebril and K.¬†Meerbergen.  A New Truncation Strategy for the Higher-Order Singular Value Decomposition .  SIAM¬†Journal¬†on¬†Scientific¬†Computing  34 , A1027‚ÄìA1052  (2012)."},{"id":1770,"pagetitle":"Vector bundle","title":"Vector bundles","ref":"/manifolds/stable/manifolds/#VectorBundleSection","content":" Vector bundles Vector bundle  $E$  is a special case of a  fiber bundle  where each fiber is a vector space. Tangent bundle is a simple example of a vector bundle, where each fiber is the tangent space at the specified point  $p$ . An object representing a tangent bundle can be obtained using the constructor called  TangentBundle . There is also another type,  VectorSpaceFiber , that represents a specific fiber at a given point. This is also considered a manifold."},{"id":1771,"pagetitle":"Vector bundle","title":"FVector","ref":"/manifolds/stable/manifolds/#FVector","content":" FVector For cases where confusion between different types of vectors is possible, the type  FVector  can be used to express which type of vector space the vector belongs to. It is used for example in musical isomorphisms (the  flat  and  sharp  functions) that are used to go from a tangent space to cotangent space and vice versa."},{"id":1772,"pagetitle":"Vector bundle","title":"Documentation","ref":"/manifolds/stable/manifolds/#Documentation","content":" Documentation"},{"id":1773,"pagetitle":"Vector bundle","title":"Manifolds.TensorProductType","ref":"/manifolds/stable/manifolds/#Manifolds.TensorProductType","content":" Manifolds.TensorProductType  ‚Äî  Type TensorProductType(spaces::VectorSpaceType...) Vector space type corresponding to the tensor product of given vector space types. source"},{"id":1774,"pagetitle":"Vector bundle","title":"Manifolds.TangentBundle","ref":"/manifolds/stable/manifolds/#Manifolds.TangentBundle","content":" Manifolds.TangentBundle  ‚Äî  Type TangentBundle{ùîΩ,M} = VectorBundle{ùîΩ,TangentSpaceType,M} where {ùîΩ,M<:AbstractManifold{ùîΩ}} Tangent bundle for manifold of type  M , as a manifold with the Sasaki metric [ Sas58 ]. Exact retraction and inverse retraction can be approximated using  FiberBundleProductRetraction ,  FiberBundleInverseProductRetraction  and  SasakiRetraction .  FiberBundleProductVectorTransport  can be used as a vector transport. Constructors TangentBundle(M::AbstractManifold)\nTangentBundle(M::AbstractManifold, vtm::FiberBundleProductVectorTransport) source"},{"id":1775,"pagetitle":"Vector bundle","title":"Manifolds.VectorBundle","ref":"/manifolds/stable/manifolds/#Manifolds.VectorBundle","content":" Manifolds.VectorBundle  ‚Äî  Type VectorBundle{ùîΩ,TVS,TM,VTV} = FiberBundle{ùîΩ,TVS,TM,TVT} where {TVS<:VectorSpaceType} Alias for  FiberBundle  when fiber type is a  TVS  of type  VectorSpaceType . VectorSpaceFiberType  is used to encode vector spaces as fiber types. source"},{"id":1776,"pagetitle":"Vector bundle","title":"Manifolds.VectorBundleVectorTransport","ref":"/manifolds/stable/manifolds/#Manifolds.VectorBundleVectorTransport","content":" Manifolds.VectorBundleVectorTransport  ‚Äî  Type const VectorBundleVectorTransport = FiberBundleProductVectorTransport Deprecated: an alias for  FiberBundleProductVectorTransport . source"},{"id":1777,"pagetitle":"Vector bundle","title":"Manifolds.fiber_bundle_transport","ref":"/manifolds/stable/manifolds/#Manifolds.fiber_bundle_transport-Tuple{AbstractManifold, ManifoldsBase.FiberType}","content":" Manifolds.fiber_bundle_transport  ‚Äî  Method fiber_bundle_transport(M::AbstractManifold, fiber::FiberType) Determine the vector transport used for  exp  and  log  maps on a vector bundle with fiber type  fiber  and manifold  M . source"},{"id":1778,"pagetitle":"Vector bundle","title":"ManifoldsBase.injectivity_radius","ref":"/manifolds/stable/manifolds/#ManifoldsBase.injectivity_radius-Tuple{FiberBundle{ùîΩ, TangentSpaceType, M} where {ùîΩ, M<:AbstractManifold{ùîΩ}}}","content":" ManifoldsBase.injectivity_radius  ‚Äî  Method injectivity_radius(M::TangentBundle) Injectivity radius of  TangentBundle  manifold is infinite if the base manifold is flat and 0 otherwise. See  https://mathoverflow.net/questions/94322/injectivity-radius-of-the-sasaki-metric . source"},{"id":1779,"pagetitle":"Vector bundle","title":"ManifoldsBase.inner","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inner-Tuple{FiberBundle, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(B::VectorBundle, p, X, Y) Inner product of tangent vectors  X  and  Y  at point  p  from the vector bundle  B  over manifold  B.fiber  (denoted  $\\mathcal M$ ). Notation: The point  $p = (x_p, V_p)$  where  $x_p ‚àà \\mathcal M$  and  $V_p$  belongs to the fiber  $F=œÄ^{-1}(\\{x_p\\})$  of the vector bundle  $B$  where  $œÄ$  is the canonical projection of that vector bundle  $B$ . The tangent vector  $v = (V_{X,M}, V_{X,F}) ‚àà T_{x}B$  where  $V_{X,M}$  is a tangent vector from the tangent space  $T_{x_p}\\mathcal M$  and  $V_{X,F}$  is a tangent vector from the tangent space  $T_{V_p}F$  (isomorphic to  $F$ ). Similarly for the other tangent vector  $w = (V_{Y,M}, V_{Y,F}) ‚àà T_{x}B$ . The inner product is calculated as $‚ü®X, Y‚ü©_p = ‚ü®V_{X,M}, V_{Y,M}‚ü©_{x_p} + ‚ü®V_{X,F}, V_{Y,F}‚ü©_{V_p}.$ source"},{"id":1780,"pagetitle":"Vector bundle","title":"ManifoldsBase.inverse_retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.inverse_retract-Tuple{VectorBundle{ùîΩ} where ùîΩ, Any, Any, Manifolds.FiberBundleInverseProductRetraction}","content":" ManifoldsBase.inverse_retract  ‚Äî  Method inverse_retract(M::VectorBundle, p, q, ::FiberBundleInverseProductRetraction) Compute the allocating variant of the  FiberBundleInverseProductRetraction , which by default allocates and calls  inverse_retract_product! . source"},{"id":1781,"pagetitle":"Vector bundle","title":"ManifoldsBase.is_flat","ref":"/manifolds/stable/manifolds/#ManifoldsBase.is_flat-Tuple{VectorBundle{ùîΩ} where ùîΩ}","content":" ManifoldsBase.is_flat  ‚Äî  Method is_flat(::VectorBundle) Return true if the underlying manifold of  VectorBundle M  is flat. source"},{"id":1782,"pagetitle":"Vector bundle","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{VectorBundle{ùîΩ} where ùîΩ, Any, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(B::VectorBundle, p, X) Project the element  X  of the ambient space of the tangent space  $T_p B$  to the tangent space  $T_p B$ . Notation: The point  $p = (x_p, V_p)$  where  $x_p ‚àà \\mathcal M$  and  $V_p$  belongs to the fiber  $F=œÄ^{-1}(\\{x_p\\})$  of the vector bundle  $B$  where  $œÄ$  is the canonical projection of that vector bundle  $B$ . The vector  $x = (V_{X,M}, V_{X,F})$  where  $x_p$  belongs to the ambient space of  $T_{x_p}\\mathcal M$  and  $V_{X,F}$  belongs to the ambient space of the fiber  $F=œÄ^{-1}(\\{x_p\\})$  of the vector bundle  $B$  where  $œÄ$  is the canonical projection of that vector bundle  $B$ . The projection is calculated by projecting  $V_{X,M}$  to tangent space  $T_{x_p}\\mathcal M$  and then projecting the vector  $V_{X,F}$  to the fiber  $F$ . source"},{"id":1783,"pagetitle":"Vector bundle","title":"ManifoldsBase.project","ref":"/manifolds/stable/manifolds/#ManifoldsBase.project-Tuple{VectorBundle{ùîΩ} where ùîΩ, Any}","content":" ManifoldsBase.project  ‚Äî  Method project(B::VectorBundle, p) Project the point  p  from the ambient space of the vector bundle  B  over manifold  B.fiber  (denoted  $\\mathcal M$ ) to the vector bundle. Notation: The point  $p = (x_p, V_p)$  where  $x_p$  belongs to the ambient space of  $\\mathcal M$  and  $V_p$  belongs to the ambient space of the fiber  $F=œÄ^{-1}(\\{x_p\\})$  of the vector bundle  $B$  where  $œÄ$  is the canonical projection of that vector bundle  $B$ . The projection is calculated by projecting the point  $x_p$  to the manifold  $\\mathcal M$  and then projecting the vector  $V_p$  to the tangent space  $T_{x_p}\\mathcal M$ . source"},{"id":1784,"pagetitle":"Vector bundle","title":"ManifoldsBase.retract","ref":"/manifolds/stable/manifolds/#ManifoldsBase.retract-Tuple{VectorBundle{ùîΩ} where ùîΩ, Any, Any, Number, Manifolds.FiberBundleProductRetraction}","content":" ManifoldsBase.retract  ‚Äî  Method retract(M::VectorBundle, p, q, t::Number, ::FiberBundleProductRetraction) Compute the allocating variant of the  FiberBundleProductRetraction , which by default allocates and calls  retract_product! . source"},{"id":1785,"pagetitle":"Vector bundle","title":"ManifoldsBase.vector_transport_to","ref":"/manifolds/stable/manifolds/#ManifoldsBase.vector_transport_to-Tuple{VectorBundle{ùîΩ} where ùîΩ, Any, Any, Any, Manifolds.FiberBundleProductVectorTransport}","content":" ManifoldsBase.vector_transport_to  ‚Äî  Method vector_transport_to(M::VectorBundle, p, X, q, m::FiberBundleProductVectorTransport) Compute the vector transport the tangent vector  X at  p  to  q  on the  VectorBundle M  using the  FiberBundleProductVectorTransport m . source"},{"id":1786,"pagetitle":"Vector bundle","title":"Example","ref":"/manifolds/stable/manifolds/#Example","content":" Example The following code defines a point on the tangent bundle of the sphere  $S^2$  and a tangent vector to that point. using Manifolds\nM = Sphere(2)\nTB = TangentBundle(M)\np = ArrayPartition([1.0, 0.0, 0.0], [0.0, 1.0, 3.0])\nX = ArrayPartition([0.0, 1.0, 0.0], [0.0, 0.0, -2.0]) ([0.0, 1.0, 0.0], [0.0, 0.0, -2.0]) An approximation of the exponential in the Sasaki metric using 1000 steps can be calculated as follows. q = retract(TB, p, X, SasakiRetraction(1000))\nprintln(\"Approximation of the exponential map: \", q) Approximation of the exponential map: ArrayPartition{Float64, Tuple{Vector{Float64}, Vector{Float64}}}(([0.6759570857309888, 0.35241486404386485, 0.6472138609849252], [-1.0318269583261073, 0.6273324630574116, 0.7360618920075961]))"},{"id":1789,"pagetitle":"Contributing","title":"Contributing to  Manifolds.jl","ref":"/manifolds/stable/misc/#Contributing-to-Manifolds.jl","content":" Contributing to  Manifolds.jl First, thanks for taking the time to contribute. Any contribution is appreciated and welcome. The following is a set of guidelines to  Manifolds.jl ."},{"id":1790,"pagetitle":"Contributing","title":"Table of Contents","ref":"/manifolds/stable/misc/#Table-of-Contents","content":" Table of Contents Contributing to  Manifolds.jl      -  Table of Contents I just have a question How can I file an issue? How can I contribute? Add a missing method Provide a new manifold Code style"},{"id":1791,"pagetitle":"Contributing","title":"I just have a question","ref":"/manifolds/stable/misc/#I-just-have-a-question","content":" I just have a question The developers can most easily be reached in the Julia Slack channel  #manifolds . You can apply for the Julia Slack workspace  here  if you haven't joined yet. You can also ask your question on  discourse.julialang.org ."},{"id":1792,"pagetitle":"Contributing","title":"How can I file an issue?","ref":"/manifolds/stable/misc/#How-can-I-file-an-issue?","content":" How can I file an issue? If you found a bug or want to propose a feature, we track our issues within the  GitHub repository ."},{"id":1793,"pagetitle":"Contributing","title":"How can I contribute?","ref":"/manifolds/stable/misc/#How-can-I-contribute?","content":" How can I contribute?"},{"id":1794,"pagetitle":"Contributing","title":"Add a missing method","ref":"/manifolds/stable/misc/#Add-a-missing-method","content":" Add a missing method Not all methods from our interface  ManifoldsBase.jl  have been implemented for every manifold. If you notice a method missing and can contribute an implementation, please do so! Even providing a single new method is a good contribution."},{"id":1795,"pagetitle":"Contributing","title":"Provide a new manifold","ref":"/manifolds/stable/misc/#Provide-a-new-manifold","content":" Provide a new manifold A main contribution you can provide is another manifold that is not yet included in the package. A manifold is a concrete type of  AbstractManifold  from  ManifoldsBase.jl . This package also provides the main set of functions a manifold can/should implement. Don't worry if you can only implement some of the functions. If the application you have in mind only requires a subset of these functions, implement those. The  ManifoldsBase.jl  interface  provides concrete error messages for the remaining unimplemented functions. One important detail is that the interface usually provides an in-place as well as a non-mutating variant See for example  exp!  and  exp . The non-mutating one (e.g.  exp ) always falls back to use the in-place one, so in most cases it should suffice to implement the in-place one (e.g.  exp! ). Note that since the first argument is  always  the  AbstractManifold , the mutated argument is always the second one in the signature. In the example we have  exp(M, p, X, t)  for the exponential map and  exp!(M, q, p, X, t)  for the in-place one, which stores the result in  q . On the other hand, the user will most likely look for the documentation of the non-mutating version, so we recommend adding the docstring for the non-mutating one, where all different signatures should be collected in one string when reasonable. This can best be achieved by adding a docstring to the method with a general signature with the first argument being your manifold: struct MyManifold <: AbstractManifold end\n\n@doc raw\"\"\"\n    exp(M::MyManifold, p, X)\n\nDescribe the function.\n\"\"\"\nexp(::MyManifold, ::Any...)"},{"id":1796,"pagetitle":"Contributing","title":"Code style","ref":"/manifolds/stable/misc/#Code-style","content":" Code style We try to follow the  documentation guidelines  from the Julia documentation as well as  Blue Style . We run  JuliaFormatter.jl  on the repo in the way set in the  .JuliaFormatter.toml  file, which enforces a number of conventions consistent with the Blue Style. We also follow a few internal conventions: It is preferred that the  AbstractManifold 's struct contain a reference to the general theory. Any implemented function should be accompanied by its mathematical formulae if a closed form exists. Within the source code of one manifold, the type of the manifold should be the first element of the file, and an alphabetical order of the functions is preferable. The above implies that the in-place variant of a function follows the non-mutating variant. There should be no dangling  =  signs. Always add a newline between things of different types (struct/method/const). Always add a newline between methods for different functions (including in-place/nonmutating variants). Prefer to have no newline between methods for the same function; when reasonable, merge the docstrings. All  import / using / include  should be in the main module file."},{"id":1799,"pagetitle":"Changelog","title":"Changelog","ref":"/manifolds/stable/misc/#Changelog","content":" Changelog All notable changes to this project will be documented in this file. The format is based on  Keep a Changelog , and this project adheres to  Semantic Versioning ."},{"id":1800,"pagetitle":"Changelog","title":"[0.9.16] ‚Äì unreleased","ref":"/manifolds/stable/misc/#[0.9.16]-‚Äì-unreleased","content":" [0.9.16] ‚Äì unreleased"},{"id":1801,"pagetitle":"Changelog","title":"Changed","ref":"/manifolds/stable/misc/#Changed","content":" Changed NonlinearSolve.jl  and  PythonCall.jl  are no longer an upper bounded dependency (bugs were fixed)."},{"id":1802,"pagetitle":"Changelog","title":"[0.9.15] ‚Äì 2024-03-24","ref":"/manifolds/stable/misc/#[0.9.15]-‚Äì-2024-03-24","content":" [0.9.15] ‚Äì 2024-03-24"},{"id":1803,"pagetitle":"Changelog","title":"Added","ref":"/manifolds/stable/misc/#Added","content":" Added using  DocumenterInterLinks  for links to other Julia packages documentation. Implementation of  sectional_curvature ,  sectional_curvature_min  and  sectional_curvature_max  for several manifolds. sectional_curvature_matrix  function and a tutorial on coordinate-free curvature."},{"id":1804,"pagetitle":"Changelog","title":"Changed","ref":"/manifolds/stable/misc/#Changed-2","content":" Changed default_vector_transport_method  for  GeneralUnitaryMatrices  other than  Rotations  was changed to  ProjectionTransport ."},{"id":1805,"pagetitle":"Changelog","title":"Fixed","ref":"/manifolds/stable/misc/#Fixed","content":" Fixed typographical errors in tutorials/working-in-charts.jl. several typographical errors in the docs unifies to use two backticks  ``  for math instead of  $  further in the docs"},{"id":1806,"pagetitle":"Changelog","title":"[0.9.14] ‚Äì 2024-01-31","ref":"/manifolds/stable/misc/#[0.9.14]-‚Äì-2024-01-31","content":" [0.9.14] ‚Äì 2024-01-31"},{"id":1807,"pagetitle":"Changelog","title":"Added","ref":"/manifolds/stable/misc/#Added-2","content":" Added rand  on  UnitaryMatrices rand  on arbitrary  GroupManifold s and manifolds with  IsGroupManifold  trait generating points and elements from the Lie algebra, respectively"},{"id":1808,"pagetitle":"Changelog","title":"[0.9.13] ‚Äì 2024-01-24","ref":"/manifolds/stable/misc/#[0.9.13]-‚Äì-2024-01-24","content":" [0.9.13] ‚Äì 2024-01-24"},{"id":1809,"pagetitle":"Changelog","title":"Added","ref":"/manifolds/stable/misc/#Added-3","content":" Added added the real symplectic Grassmann manifold  SymplecticGrassmann Introduce the manifold of  HamiltonianMatrices  and a wrapper for  Hamiltonian  matrices introduce  rand(:HamiltonianMatrices) extend  rand  to also  rand!  for  HamiltonianMatrices ,  SymplecticMatrices  and  SymplecticStiefel implement  riemannian_gradient  conversion for  SymplecticMatrices  and  SymplecticGrassmann the new manifold of  MultinomialSymmetricPositiveDefinite  matrices rand!  for  MultinomialDoublyStochastic  and  MultinomialSymmetric"},{"id":1810,"pagetitle":"Changelog","title":"Deprecated","ref":"/manifolds/stable/misc/#Deprecated","content":" Deprecated Rename  Symplectic  to  SimplecticMatrices  in order to have a  Symplectic  wrapper for such matrices as well in the future for the next breaking change. Rename  SymplecticMatrix  to  SymplecticElement  to clarify that it is the special matrix  $J_{2n}$  and not an arbitrary symplectic matrix."},{"id":1811,"pagetitle":"Changelog","title":"Fixed","ref":"/manifolds/stable/misc/#Fixed-2","content":" Fixed a bug that cause  project  for tangent vectors to return wrong results on  MultinomialDoublyStochastic"},{"id":1812,"pagetitle":"Changelog","title":"[0.9.12] ‚Äì 2024-01-21","ref":"/manifolds/stable/misc/#[0.9.12]-‚Äì-2024-01-21","content":" [0.9.12] ‚Äì 2024-01-21"},{"id":1813,"pagetitle":"Changelog","title":"Fixed","ref":"/manifolds/stable/misc/#Fixed-3","content":" Fixed Fixed  var  on  TranslationGroup ."},{"id":1814,"pagetitle":"Changelog","title":"[0.9.11] ‚Äì 2023-12-27","ref":"/manifolds/stable/misc/#[0.9.11]-‚Äì-2023-12-27","content":" [0.9.11] ‚Äì 2023-12-27"},{"id":1815,"pagetitle":"Changelog","title":"Fixed","ref":"/manifolds/stable/misc/#Fixed-4","content":" Fixed Fixed mixed array index number in-place  parallel_transport_to!  on zero-index  Euclidean , on Julia 1.6."},{"id":1816,"pagetitle":"Changelog","title":"[0.9.10] ‚Äì 2023-12-27","ref":"/manifolds/stable/misc/#[0.9.10]-‚Äì-2023-12-27","content":" [0.9.10] ‚Äì 2023-12-27"},{"id":1817,"pagetitle":"Changelog","title":"Added","ref":"/manifolds/stable/misc/#Added-4","content":" Added Compatibility with  RecursiveArrayTools  v3."},{"id":1818,"pagetitle":"Changelog","title":"Fixed","ref":"/manifolds/stable/misc/#Fixed-5","content":" Fixed Fixed mixed array index number in-place  parallel_transport_to!  on real  Circle , on Julia 1.6. Violations of MD004 lint rule in this file."},{"id":1819,"pagetitle":"Changelog","title":"[0.9.9] ‚Äì 2023-12-25","ref":"/manifolds/stable/misc/#[0.9.9]-‚Äì-2023-12-25","content":" [0.9.9] ‚Äì 2023-12-25"},{"id":1820,"pagetitle":"Changelog","title":"Fixed","ref":"/manifolds/stable/misc/#Fixed-6","content":" Fixed introduced a nonzero  atol  for all point and vector checks that compre to zero. This makes those checks a bit more relaxed by default and resolves  #630 . default_estimation_method(M, f)  is deprecated, use  default_approximation_method(M, f)  for your specific method  f  on the manifold  M . AbstractEstimationMethod  is deprecated, use  AbstractApproximationMethod  instead."},{"id":1821,"pagetitle":"Changelog","title":"[0.9.8] - 2023-11-17","ref":"/manifolds/stable/misc/#[0.9.8]-2023-11-17","content":" [0.9.8] - 2023-11-17"},{"id":1822,"pagetitle":"Changelog","title":"Fixed","ref":"/manifolds/stable/misc/#Fixed-7","content":" Fixed Improved distribution of random vector generation for rotation matrices and complex circle."},{"id":1823,"pagetitle":"Changelog","title":"[0.9.7] ‚Äì 2023-11-14","ref":"/manifolds/stable/misc/#[0.9.7]-‚Äì-2023-11-14","content":" [0.9.7] ‚Äì 2023-11-14"},{"id":1824,"pagetitle":"Changelog","title":"Fixed","ref":"/manifolds/stable/misc/#Fixed-8","content":" Fixed Fixed  is_flat  for  CholeskySpace  and  SymmetricPositiveDefinite  with  LogCholeskyMetric https://github.com/JuliaManifolds/Manifolds.jl/issues/684 ."},{"id":1825,"pagetitle":"Changelog","title":"[0.9.6] - 2023-11-09","ref":"/manifolds/stable/misc/#[0.9.6]-2023-11-09","content":" [0.9.6] - 2023-11-09"},{"id":1826,"pagetitle":"Changelog","title":"Fixed","ref":"/manifolds/stable/misc/#Fixed-9","content":" Fixed Fixed real coefficient basis for complex circle (an issue exposed by  https://github.com/JuliaManifolds/ManifoldsBase.jl/pull/173 ). Fixed  VeeOrthogonalBasis  test for non-real manifolds."},{"id":1827,"pagetitle":"Changelog","title":"[0.9.5] - 2023-11-08","ref":"/manifolds/stable/misc/#[0.9.5]-2023-11-08","content":" [0.9.5] - 2023-11-08"},{"id":1828,"pagetitle":"Changelog","title":"Changed","ref":"/manifolds/stable/misc/#Changed-3","content":" Changed identity_element  now returns a complex matrix for unitary group. number_of_coordinates  is now exported."},{"id":1829,"pagetitle":"Changelog","title":"[0.9.4] - 2023-11-06","ref":"/manifolds/stable/misc/#[0.9.4]-2023-11-06","content":" [0.9.4] - 2023-11-06"},{"id":1830,"pagetitle":"Changelog","title":"Added","ref":"/manifolds/stable/misc/#Added-5","content":" Added Functions  inv_diff ,  inv_diff! ,  adjoint_inv_diff  and  adjoint_inv_diff!  that correspond to differentials and pullbacks of group inversion. Julia 1.10-rc CI workflow."},{"id":1831,"pagetitle":"Changelog","title":"Changed","ref":"/manifolds/stable/misc/#Changed-4","content":" Changed Documentation project files are marked as compatible with  BoundaryValueDiffEq  v5."},{"id":1832,"pagetitle":"Changelog","title":"Fixed","ref":"/manifolds/stable/misc/#Fixed-10","content":" Fixed Fixed issue with incorrect implementation of  apply_diff_group  in  GroupOperationAction  with left backward and right forward action  #669 ."},{"id":1833,"pagetitle":"Changelog","title":"[0.9.3] - 2023-10-28","ref":"/manifolds/stable/misc/#[0.9.3]-2023-10-28","content":" [0.9.3] - 2023-10-28"},{"id":1834,"pagetitle":"Changelog","title":"Added","ref":"/manifolds/stable/misc/#Added-6","content":" Added Support for  BoundaryValueDiffEq  v5."},{"id":1835,"pagetitle":"Changelog","title":"[0.9.2] - 2023-10-27","ref":"/manifolds/stable/misc/#[0.9.2]-2023-10-27","content":" [0.9.2] - 2023-10-27"},{"id":1836,"pagetitle":"Changelog","title":"Added","ref":"/manifolds/stable/misc/#Added-7","content":" Added rand(G; vector_at=Identity(G))  now works for translation, special orthogonal and special Euclidean groups  G  (issue  #665 ). get_embedding  now works for  GeneralUnitaryMultiplicationGroup . Github action that checks for NEWS.md changes."},{"id":1837,"pagetitle":"Changelog","title":"[0.9.1] - 2023-10-25","ref":"/manifolds/stable/misc/#[0.9.1]-2023-10-25","content":" [0.9.1] - 2023-10-25"},{"id":1838,"pagetitle":"Changelog","title":"Added","ref":"/manifolds/stable/misc/#Added-8","content":" Added a new retraction and its inverse for the fixed Rank Manifolds, the orthographic retraction."},{"id":1839,"pagetitle":"Changelog","title":"[0.9.0] - 2023-10-24","ref":"/manifolds/stable/misc/#[0.9.0]-2023-10-24","content":" [0.9.0] - 2023-10-24"},{"id":1840,"pagetitle":"Changelog","title":"Added","ref":"/manifolds/stable/misc/#Added-9","content":" Added Vector bundles are generalized to fiber bundles. Old  BundleFibers  functionality was reworked to better match mathematical abstractions. Fiber bundle functionality is experimental and minor changes may happen without a breaking release, with the exception of  TangentBundle  which is considered to be stable. RotationTranslationAction  is introduced."},{"id":1841,"pagetitle":"Changelog","title":"Changed","ref":"/manifolds/stable/misc/#Changed-5","content":" Changed Sizes of all manifolds can now be either encoded in type or stored in a field to avoid over-specialization. The default is set to store the size in type parameter (except for  PowerManifold  and its variants), replicating the previous behavior. For field storage, pass the  parameter=:field  keyword argument to manifold constructor. For example statically sized  CenteredMatrices{m,n}  is now  CenteredMatrices{TypeParameter{Tuple{m,n}}} , whereas the type of special Euclidean group with field-stored size is  CenteredMatrices{Tuple{Int,Int}} . Similar change applies to: CenteredMatrices{m,n} , CholeskySpace{N} , Elliptope{N,K} , Euclidean , FixedRankMatrices{m,n,k} , KendallsPreShapeSpace{n,k} , KendallsShapeSpace{n,k} , GeneralLinear{n} , GeneralUnitaryMultiplicationGroup{n} , GeneralizedGrassmann{n,k} , GeneralizedStiefel{n,k} , Grassmann{n,k} , Heisenberg{n} , Hyperbolic{n} , MultinomialMatrices{N,M} , MultinomialDoublyStochastic{n} , MultinomialSymmetric{n} , Orthogonal{n} , PowerManifold , PositiveArrays , PositiveMatrices , PositiveNumbers , ProbabilitySimplex{n} , SPDFixedDeterminant{n} , SpecialLinear{n} , SpecialOrthogonal{n} , SpecialUnitary{n} , SpecialEuclidean{n} , SpecialEuclideanManifold{n} , Spectrahedron{n,k} , SphereSymmetricMatrices{N} , Stiefel{n,k} , SymmetricMatrices{N} , SymmetricPositiveDefinite{n} , SymmetricPositiveSemidefiniteFixedRank{n,k} , Symplectic{n} , SymplecticStiefel{n,k} , TranslationGroup , Tucker . For example function Base.show(io::IO, ::CenteredMatrices{m,n}) where {m,n}\n    return print(io, \"CenteredMatrices($m, $n)\")\nend needs to be replaced with function Base.show(io::IO, ::CenteredMatrices{TypeParameter{Tuple{m,n}}}) where {m,n}\n    return print(io, \"CenteredMatrices($m, $n)\")\nend for statically-sized groups and function Base.show(io::IO, M::CenteredMatrices{Tuple{Int,Int}})\n    m, n = get_parameter(M.size)\n    return print(io, \"CenteredMatrices($m, $n; parameter=:field)\")\nend for groups with size stored in field. Alternatively, you can use a single generic method like this: function Base.show(io::IO, M::CenteredMatrices{T}) where {T}\n    m, n = get_parameter(M)\n    if T <: TypeParameter\n        return print(io, \"CenteredMatrices($m, $n)\")\n    else\n        return print(io, \"CenteredMatrices($m, $n; parameter=:field)\")\n    end\nend Argument order for type aliases  RotationActionOnVector  and  RotationTranslationActionOnVector : most often dispatched on argument is now first. A more consistent handling of action direction was introduced. 4-valued  ActionDirection  was split into 2-valued  ActionDirection  (either left or right action) and  GroupActionSide  (action acting from the left or right side). See  https://github.com/JuliaManifolds/Manifolds.jl/issues/637  for a design discussion."},{"id":1842,"pagetitle":"Changelog","title":"Removed","ref":"/manifolds/stable/misc/#Removed","content":" Removed ProductRepr  is removed; please use  ArrayPartition  instead. Default methods throwing \"not implemented\"  ErrorException  for some group-related operations. Standard  MethodError  is now thrown instead. LinearAffineMetric  was deprecated in a previous release and the symbol is now removed. Please use  AffineInvariantMetric  instead."},{"id":1845,"pagetitle":"About","title":"About  Manifolds.jl","ref":"/manifolds/stable/misc/#About-Manifolds.jl","content":" About  Manifolds.jl"},{"id":1846,"pagetitle":"About","title":"License","ref":"/manifolds/stable/misc/#License","content":" License MIT License"},{"id":1847,"pagetitle":"About","title":"Core Developers","ref":"/manifolds/stable/misc/#Core-Developers","content":" Core Developers Seth Axen Mateusz Baran Ronny Bergmann"},{"id":1848,"pagetitle":"About","title":"Contributors","ref":"/manifolds/stable/misc/#Contributors","content":" Contributors See the  GitHub contributors page . Contributions  are welcome!"},{"id":1851,"pagetitle":"Internals","title":"Internal documentation","ref":"/manifolds/stable/misc/#Internal-documentation","content":" Internal documentation This page documents the internal types and methods of  Manifolds.jl 's that might be of use for writing your own manifold."},{"id":1852,"pagetitle":"Internals","title":"Functions","ref":"/manifolds/stable/misc/#Functions","content":" Functions"},{"id":1853,"pagetitle":"Internals","title":"Manifolds.eigen_safe","ref":"/manifolds/stable/misc/#Manifolds.eigen_safe","content":" Manifolds.eigen_safe  ‚Äî  Function eigen_safe(x) Compute the eigendecomposition of  x . If  x  is a  StaticMatrix , it is converted to a  Matrix  before the decomposition. source"},{"id":1854,"pagetitle":"Internals","title":"Manifolds.isnormal","ref":"/manifolds/stable/misc/#Manifolds.isnormal","content":" Manifolds.isnormal  ‚Äî  Function isnormal(x; kwargs...) -> Bool Check if the matrix or number  x  is normal, that is, if it commutes with its adjoint: \\[x x^\\mathrm{H} = x^\\mathrm{H} x.\\] By default, this is an equality check. Provide  kwargs  for  isapprox  to perform an approximate check. source"},{"id":1855,"pagetitle":"Internals","title":"Manifolds.log_safe","ref":"/manifolds/stable/misc/#Manifolds.log_safe","content":" Manifolds.log_safe  ‚Äî  Function log_safe(x) Compute the matrix logarithm of  x . If  x  is a  StaticMatrix , it is converted to a  Matrix  before computing the log. source"},{"id":1856,"pagetitle":"Internals","title":"Manifolds.log_safe!","ref":"/manifolds/stable/misc/#Manifolds.log_safe!","content":" Manifolds.log_safe!  ‚Äî  Function log_safe!(y, x) Compute the matrix logarithm of  x . If the eltype of  y  is real, then the imaginary part of  x  is ignored, and a  DomainError  is raised if  real(x)  has no real logarithm. source"},{"id":1857,"pagetitle":"Internals","title":"Manifolds.mul!_safe","ref":"/manifolds/stable/misc/#Manifolds.mul!_safe","content":" Manifolds.mul!_safe  ‚Äî  Function mul!_safe(Y, A, B) -> Y Call  mul!  safely, that is,  A  and/or  B  are permitted to alias with  Y . source"},{"id":1858,"pagetitle":"Internals","title":"Manifolds.nzsign","ref":"/manifolds/stable/misc/#Manifolds.nzsign","content":" Manifolds.nzsign  ‚Äî  Function nzsign(z[, absz]) Compute a modified  sign(z)  that is always nonzero, i.e. where \\[\\operatorname(nzsign)(z) = \\begin{cases}\n    1 & \\text{if } z = 0\\\\\n    \\frac{z}{|z|} & \\text{otherwise}\n\\end{cases}\\] source"},{"id":1859,"pagetitle":"Internals","title":"Manifolds.realify","ref":"/manifolds/stable/misc/#Manifolds.realify","content":" Manifolds.realify  ‚Äî  Function realify(X::AbstractMatrix{TùîΩ}, ùîΩ::AbstractNumbers) -> Y::AbstractMatrix{<:Real} Given a matrix  $X ‚àà ùîΩ^{n√ón}$ , compute  $Y ‚àà ‚Ñù^{m√óm}$ , where  $m = n \\operatorname{dim}_ùîΩ$ , and  $\\operatorname{dim}_ùîΩ$  is the  real_dimension  of the number field  $ùîΩ$ , using the map  $œï \\colon X ‚Ü¶ Y$ , that preserves the matrix product, so that for all  $C,D ‚àà ùîΩ^{n√ón}$ , \\[œï(C) œï(D) = œï(CD).\\] See  realify!  for an in-place version, and  unrealify!  to compute the inverse of  $œï$ . source"},{"id":1860,"pagetitle":"Internals","title":"Manifolds.realify!","ref":"/manifolds/stable/misc/#Manifolds.realify!","content":" Manifolds.realify!  ‚Äî  Function realify!(Y::AbstractMatrix{<:Real}, X::AbstractMatrix{TùîΩ}, ùîΩ::AbstractNumbers) In-place version of  realify . source realify!(Y::AbstractMatrix{<:Real}, X::AbstractMatrix{<:Complex}, ::typeof(‚ÑÇ)) Given a complex matrix  $X = A + iB ‚àà ‚ÑÇ^{n√ón}$ , compute its realified matrix  $Y ‚àà ‚Ñù^{2n√ó2n}$ , written where \\[Y = \\begin{pmatrix}A & -B \\\\ B & A \\end{pmatrix}.\\] source"},{"id":1861,"pagetitle":"Internals","title":"Manifolds.symmetrize","ref":"/manifolds/stable/misc/#Manifolds.symmetrize","content":" Manifolds.symmetrize  ‚Äî  Function symmetrize(X) Given a square matrix  X  compute  1/2 .* (X' + X) . source"},{"id":1862,"pagetitle":"Internals","title":"Manifolds.symmetrize!","ref":"/manifolds/stable/misc/#Manifolds.symmetrize!","content":" Manifolds.symmetrize!  ‚Äî  Function symmetrize!(Y, X) Given a square matrix  X  compute  1/2 .* (X' + X)  in place of  Y . source"},{"id":1863,"pagetitle":"Internals","title":"Manifolds.unrealify!","ref":"/manifolds/stable/misc/#Manifolds.unrealify!","content":" Manifolds.unrealify!  ‚Äî  Function unrealify!(X::AbstractMatrix{TùîΩ}, Y::AbstractMatrix{<:Real}, ùîΩ::AbstractNumbers[, n]) Given a real matrix  $Y ‚àà ‚Ñù^{m√óm}$ , where  $m = n \\operatorname{dim}_ùîΩ$ , and  $\\operatorname{dim}_ùîΩ$  is the  real_dimension  of the number field  $ùîΩ$ , compute in-place its equivalent matrix  $X ‚àà ùîΩ^{n√ón}$ . Note that this function does not check that  $Y$  has a valid structure to be un-realified. See  realify!  for the inverse of this function. source"},{"id":1864,"pagetitle":"Internals","title":"Manifolds.usinc","ref":"/manifolds/stable/misc/#Manifolds.usinc","content":" Manifolds.usinc  ‚Äî  Function usinc(Œ∏::Real) Unnormalized version of  sinc  function, i.e.  $\\operatorname{usinc}(Œ∏) = \\frac{\\sin(Œ∏)}{Œ∏}$ . This is equivalent to  sinc(Œ∏/œÄ) . source"},{"id":1865,"pagetitle":"Internals","title":"Manifolds.usinc_from_cos","ref":"/manifolds/stable/misc/#Manifolds.usinc_from_cos","content":" Manifolds.usinc_from_cos  ‚Äî  Function usinc_from_cos(x::Real) Unnormalized version of  sinc  function, i.e.  $\\operatorname{usinc}(Œ∏) = \\frac{\\sin(Œ∏)}{Œ∏}$ , computed from  $x = cos(Œ∏)$ . source"},{"id":1866,"pagetitle":"Internals","title":"Manifolds.vec2skew!","ref":"/manifolds/stable/misc/#Manifolds.vec2skew!","content":" Manifolds.vec2skew!  ‚Äî  Function vec2skew!(X, v, k) Create a skew symmetric matrix in-place in  X  of size  $k√ók$  from a vector  v , for example for  v=[1,2,3]  and  k=3  this yields [  0  1  2;\n  -1  0  3;\n  -2 -3  0\n] source"},{"id":1867,"pagetitle":"Internals","title":"Types in Extensions","ref":"/manifolds/stable/misc/#Types-in-Extensions","content":" Types in Extensions"},{"id":1870,"pagetitle":"Notation","title":"Notation overview","ref":"/manifolds/stable/misc/#Notation-overview","content":" Notation overview Since manifolds include a reasonable amount of elements and functions, the following list tries to keep an overview of used notation throughout  Manifolds.jl . The order is alphabetical by name. They might be used in a plain form within the code or when referring to that code. This is for example the case with the calligraphic symbols. Within the documented functions, the utf8 symbols are used whenever possible, as long as that renders correctly in  $\\TeX$  within this documentation. Symbol Description Also used Comment $\\tau_p$ action map by group element  $p$ $\\mathrm{L}_p$ ,  $\\mathrm{R}_p$ either left or right $\\operatorname{Ad}_p(X)$ adjoint action of element  $p$  of a Lie group on the element  $X$  of the corresponding Lie algebra $√ó$ Cartesian product of two manifolds see  ProductManifold $^{\\wedge}$ (n-ary) Cartesian power of a manifold see  PowerManifold $‚ãÖ^\\mathrm{H}$ conjugate/Hermitian transpose $a$ coordinates of a point in a chart see  get_parameters $\\frac{\\mathrm{D}}{\\mathrm{d}t}$ covariant derivative of a vector field  $X(t)$ $T^*_p \\mathcal M$ the cotangent space at  $p$ $Œæ$ a cotangent vector from  $T^*_p \\mathcal M$ $Œæ_1, Œæ_2,‚Ä¶ ,Œ∑,\\zeta$ sometimes written with base point  $Œæ_p$ . $\\mathrm{d}\\phi_p(q)$ Differential of a map  $\\phi: \\mathcal M ‚Üí \\mathcal N$  with respect to  $p$  at a point  $q$ . For functions of multiple variables, for example  $\\phi(p, p_1)$  where  $p \\in \\mathcal M$  and  $p_1 \\in \\mathcal M_1$ , variable  $p$  is explicitly stated to specify with respect to which argument the differential is calculated. $\\mathrm{d}\\phi_q$ ,  $(\\mathrm{d}\\phi)_q$ ,  $(\\phi_*)_q$ ,  $D_p\\phi(q)$ pushes tangent vectors  $X \\in T_q \\mathcal M$  forward to  $\\mathrm{d}\\phi_p(q)[X] \\in T_{\\phi(q)} \\mathcal N$ $n$ dimension (of a manifold) $n_1,n_2,\\ldots,m, \\dim(\\mathcal M)$ for the real dimension sometimes also  $\\dim_{\\mathbb R}(\\mathcal M)$ $d(‚ãÖ,‚ãÖ)$ (Riemannian) distance $d_{\\mathcal M}(‚ãÖ,‚ãÖ)$ $\\exp_p X$ exponential map at  $p \\in \\mathcal M$  of a vector  $X \\in T_p \\mathcal M$ $\\exp_p(X)$ $F$ a fiber see  Fiber $\\mathbb F$ a field, usually  $\\mathbb F \\in \\{\\mathbb R,\\mathbb C, \\mathbb H\\}$ , i.e. the real, complex, and quaternion numbers, respectively. field a manifold or a basis is based on $\\gamma$ a geodesic $\\gamma_{p;q}$ ,  $\\gamma_{p,X}$ connecting two points  $p,q$  or starting in  $p$  with velocity  $X$ . $\\operatorname{grad} f(p)$ (Riemannian) gradient of function  $f \\colon \\mathcal{M} ‚Üí ‚Ñù$  at  $p \\in \\mathcal{M}$ $\\nabla f(p)$ (Euclidean) gradient of function  $f \\colon \\mathcal{M} ‚Üí ‚Ñù$  at  $p \\in \\mathcal{M}$  but thought of as evaluated in the embedding G $\\circ$ a group operation $‚ãÖ^\\mathrm{H}$ Hermitian or conjugate transposed for both complex or quaternion matrices $\\operatorname{Hess} f(p)$ (Riemannian) Hessian of function  $f \\colon T_p\\mathcal{M} ‚Üí T_p\\mathcal M$  (i.e. the 1-1-tensor form) at  $p \\in \\mathcal{M}$ $\\nabla^2 f(p)$ (Euclidean) Hessian of function  $f$  in the embedding H $e$ identity element of a group $I_k$ identity matrix of size  $k√ók$ $k$ indices $i,j$ $\\langle‚ãÖ,‚ãÖ\\rangle$ inner product (in  $T_p \\mathcal M$ ) $\\langle‚ãÖ,‚ãÖ\\rangle_p, g_p(‚ãÖ,‚ãÖ)$ $\\operatorname{retr}^{-1}_pq$ an inverse retraction $\\mathfrak g$ a Lie algebra $\\mathcal{G}$ a (Lie) group $\\log_p q$ logarithmic map at  $p \\in \\mathcal M$  of a point  $q \\in \\mathcal M$ $\\log_p(q)$ $\\mathcal M$ a manifold $\\mathcal M_1, \\mathcal M_2,\\ldots,\\mathcal N$ $N_p \\mathcal M$ the normal space of the tangent space  $T_p \\mathcal M$  in some embedding  $\\mathcal E$  that should be clear from context $V$ a normal vector from  $N_p \\mathcal M$ $W$ $\\operatorname{Exp}$ the matrix exponential $\\operatorname{Log}$ the matrix logarithm $\\mathcal P_{q\\gets p}X$ parallel transport of the vector  $X$  from  $T_p\\mathcal M$  to  $T_q\\mathcal M$ $\\mathcal P_{p,Y}X$ parallel transport in direction  $Y$ of the vector  $X$  from  $T_p\\mathcal M$  to  $T_q\\mathcal M$ ,  $q = \\exp_pY$ $\\mathcal P_{t_1\\gets t_0}^cX$ parallel transport along the curve  $c$ $\\mathcal P^cX=\\mathcal P_{1\\gets 0}^cX$ of the vector  $X$  from  $p=c(0)$  to  $c(1)$ $p$ a point on  $\\mathcal M$ $p_1, p_2, \\ldots,q$ for 3 points one might use  $x,y,z$ $\\operatorname{retr}_pX$ a retraction $\\kappa_p(X, Y)$ sectional curvature $Œæ$ a set of tangent vectors $\\{X_1,\\ldots,X_n\\}$ $J_{2n} \\in ‚Ñù^{2n√ó2n}$ the  SymplecticElement $T_p \\mathcal M$ the tangent space at  $p$ $X$ a tangent vector from  $T_p \\mathcal M$ $X_1,X_2,\\ldots,Y,Z$ sometimes written with base point  $X_p$ $\\operatorname{tr}$ trace (of a matrix) $‚ãÖ^\\mathrm{T}$ transposed $e_i \\in \\mathbb R^n$ the  $i$ th unit vector $e_i^n$ the space dimension ( $n$ ) is omitted, when clear from context $B$ a vector bundle $\\mathcal T_{q\\gets p}X$ vector transport of the vector  $X$  from  $T_p\\mathcal M$  to  $T_q\\mathcal M$ $\\mathcal T_{p,Y}X$ vector transport in direction  $Y$ of the vector  $X$  from  $T_p\\mathcal M$  to  $T_q\\mathcal M$ , where  $q$  is deretmined by  $Y$ , for example using the exponential map or some retraction. $\\operatorname{Vol}(\\mathcal M)$ volume of manifold  $\\mathcal M$ $\\theta_p(X)$ volume density for vector  $X$  tangent at point  $p$ $\\mathcal W$ the Weingarten map  $\\mathcal W: T_p\\mathcal M √ó N_p\\mathcal M ‚Üí T_p\\mathcal M$ $\\mathcal W_p$ the second notation to emphasize the dependency of the point  $p\\in\\mathcal M$ $0_k$ the  $k√ók$  zero matrix."},{"id":1873,"pagetitle":"References","title":"Literature","ref":"/manifolds/stable/misc/#Literature","content":" Literature We are slowly moving to using  DocumenterCitations.jl . The goal is to have all references used / mentioned in the documentation of Manifolds.jl also listed here. If you notice a reference still defined in a footnote, please change it into a BibTeX reference and  open a PR Usually you will find a small reference section at the end of every documentation page that contains references for just that page. [AMT13] P.¬†-.-A.¬†Absil, R.¬†Mahony and J.¬†Trumpf.  An Extrinsic Look at the Riemannian Hessian . In:  Geometric Science of Information , edited by F.¬†Nielsen and F.¬†Barbaresco (Springer Berlin Heidelberg, 2013); pp.¬†361‚Äì368. [AMS08] P.-A.¬†Absil, R.¬†Mahony and R.¬†Sepulchre.  Optimization Algorithms on Matrix Manifolds  (Princeton University Press, 2008), available online at  press.princeton.edu/chapters/absil/ . [AM12] P.-A.¬†Absil and J.¬†Malick.  Projection-like Retractions on Matrix Manifolds .  SIAM¬†Journal¬†on¬†Optimization  22 , 135‚Äì158  (2012). [AO14] P.-A.¬†Absil and I.¬†V.¬†Oseledets.  Low-rank retractions: a survey and new results .  Computational¬†Optimization¬†and¬†Applications  62 , 5‚Äì29  (2014). [ATV13] B.¬†Afsari, R.¬†Tron and R.¬†Vidal.  On the Convergence of Gradient Descent for Finding the Riemannian Center of Mass .  SIAM¬†Journal¬†on¬†Control¬†and¬†Optimization  51 , 2230‚Äì2260  (2013),  arXiv:1201.0925 . [AR13] D.¬†Andrica and R.-A.¬†Rohan.  Computing the Rodrigues coefficients of the exponential map of the Lie groups of matrices . Balkan¬†Journal¬†of¬†Geometry¬†and¬†Its¬†Applications  18 , 1‚Äì10 (2013). [ALRV14] E.¬†Andruchow, G.¬†Larotonda, L.¬†Recht and A.¬†Varela.  The left invariant metric in the general linear group .  Journal¬†of¬†Geometry¬†and¬†Physics  86 , 241‚Äì257  (2014),  arXiv:1109.0520 . [ABBR23] S.¬†D.¬†Axen, M.¬†Baran, R.¬†Bergmann and K.¬†Rzecki.  Manifolds.Jl: An Extensible Julia Framework for Data Analysis on Manifolds .  ACM¬†Transactions¬†on¬†Mathematical¬†Software  49  (2023). [AJLS17] N.¬†Ay, J.¬†Jost, H.¬†V.¬†L√™ and L.¬†Schwachh√∂fer.  Information Geometry  (Springer Cham, 2017). [Bac14] M.¬†Baƒç√°k.  Computing medians and means in Hadamard spaces .  SIAM¬†Journal¬†on¬†Optimization  24 , 1542‚Äì1566  (2014),  arXiv:1210.2145 . [BZ21] T.¬†Bendokat and R.¬†Zimmermann.  The real symplectic Stiefel and Grassmann manifolds: metrics, geodesics and applications , arXiv¬†Preprint,¬†2108.12447 (2021),  arXiv:2108.12447 . [BZA20] T.¬†Bendokat, R.¬†Zimmermann and P.-A.¬†Absil.  A Grassmann Manifold Handbook: Basic Geometry and Computational Aspects , arXiv¬†Preprint (2020),  arXiv:2011.13699 . [BG18] R.¬†Bergmann and P.-Y.¬†Gousenbourger.  A variational model for data fitting on manifolds by minimizing the acceleration of a B√©zier curve .  Frontiers¬†in¬†Applied¬†Mathematics¬†and¬†Statistics  4  (2018),  arXiv:1807.10090 . [BP08] E.¬†Biny and S.¬†Pods.  The Geometry of Heisenberg Groups: With Applications in Signal Theory, Optics, Quantization, and Field Quantization  (American Mathematical Socienty, 2008). [BCC20] P.¬†Birtea, I.¬†Ca√ßu and D.¬†ComƒÉnescu.  Optimization on the real symplectic group .  Monatshefte¬†f√ºr¬†Mathematik  191 , 465‚Äì485  (2020). [BST03] L.¬†J.¬†Boya, E.¬†Sudarshan and T.¬†Tilma.  Volumes of compact manifolds .  Reports¬†on¬†Mathematical¬†Physics  52 , 401‚Äì422  (2003). [BP19] A.¬†L.¬†Brigant and S.¬†Puechmorel.  Approximation of Densities on Riemannian Manifolds .  Entropy  21 , 43  (2019). [CE08] J.¬†Cheeger and D.¬†G.¬†Ebin.  Comparison Theorems in Riemannian Geometry  (American Mathematical Society, Providence, R.I, 2008). [CLLD22] E.¬†Chevallier, D.¬†Li, Y.¬†Lu and D.¬†B.¬†Dunson.  Exponential-wrapped distributions on symmetric spaces . ArXiv¬†Preprint (2022). [CKA17] E.¬†Chevallier, E.¬†Kalunga and J.¬†Angulo.  Kernel Density Estimation on Spaces of Gaussian Distributions and Symmetric Positive Definite Matrices .  SIAM¬†Journal¬†on¬†Imaging¬†Sciences  10 , 191‚Äì215  (2017). [Chi03] Y.¬†Chikuse.  Statistics on Special Manifolds  (Springer New York, 2003). [Dev86] L.¬†Devroye.  Non-Uniform Random Variate Generation  (Springer New York, NY, 1986). [DBV21] N.¬†Dewaele, P.¬†Breiding and N.¬†Vannieuwenhoven.  The condition number of many tensor decompositions is invariant under Tucker compression , arXiv¬†Preprint (2021),  arXiv:2106.13034 . [DH19] A.¬†Douik and B.¬†Hassibi.  Manifold Optimization Over the Set of Doubly Stochastic Matrices: A Second-Order Geometry .  IEEE¬†Transactions¬†on¬†Signal¬†Processing  67 , 5761‚Äì5774  (2019),  arXiv:1802.02628 . [EAS98] A.¬†Edelman, T.¬†A.¬†Arias and S.¬†T.¬†Smith.  The Geometry of Algorithms with Orthogonality Constraints .  SIAM¬†Journal¬†on¬†Matrix¬†Analysis¬†and¬†Applications  20 , 303‚Äì353  (1998),  arXiv:806030 . [FdHDF19] L.¬†Falorsi, P.¬†de¬†Haan, T.¬†R.¬†Davidson and P.¬†Forr√©.  Reparameterizing Distributions on Lie Groups , arXiv¬†Preprint (2019). [Fio11] S.¬†Fiori.  Solving Minimal-Distance Problems over the Manifold of Real-Symplectic Matrices .  SIAM¬†Journal¬†on¬†Matrix¬†Analysis¬†and¬†Applications  32 , 938‚Äì968  (2011). [FVJ08] P.¬†T.¬†Fletcher, S.¬†Venkatasubramanian and S.¬†Joshi.  Robust statistics on Riemannian manifolds via the geometric median . In:  2008 IEEE Conference on Computer Vision and Pattern Recognition  (2008). [GX02] J.¬†Gallier and D.¬†Xu.  Computing exponentials of skew-symmetric matrices and logarithms of orthogonal matrices . International¬†Journal¬†of¬†Robotics¬†and¬†Automation  17 , 1‚Äì11 (2002). [GSAS21] B.¬†Gao, N.¬†T.¬†Son, P.-A.¬†Absil and T.¬†Stykel.  Riemannian Optimization on the Symplectic Stiefel Manifold .  SIAM¬†Journal¬†on¬†Optimization  31 , 1546‚Äì1575  (2021). [Ge14] J.¬†Ge.  DDVV-type inequality for skew-symmetric matrices and Simons-type inequality for Riemannian submersions .  Advances¬†in¬†Mathematics  251 , 62‚Äì86  (2014). [Gil08] M.¬†B.¬†Giles.  Collected Matrix Derivative Results for Forward and Reverse Mode Algorithmic Differentiation . In:  Advances in Automatic Differentiation ,  Lecture Notes in Computational Science and Engineering , edited by C.¬†H.¬†Bischof, H.¬†M.¬†B√ºcker, P.¬†Hovland, U.¬†Naumann and J.¬†Utke (Springer, Berlin, Heidelberg, 2008); pp.¬†35‚Äì44. [GMTP21] N.¬†Guigui, E.¬†Maignant, A.¬†Trouv√© and X.¬†Pennec.  Parallel Transport on Kendall Shape Spaces . In:  Geometric Science of Information  (SPringer Cham, 2021); pp.¬†103‚Äì110. [HMJG21] A.¬†Han, B.¬†Mushra, P.¬†Jawapanpuria and J.¬†Gao.  Learning with symmetric positive definite matrices via generalized Bures-Wasserstein geometry , arXive¬†preprint (2021),  arXiv:2110.10464 . [HU17] S.¬†Hosseini and A.¬†Uschmajew.  A Riemannian Gradient Sampling Algorithm for Nonsmooth Optimization on Manifolds .  SIAM¬†J.¬†Optim.  27 , 173‚Äì189  (2017). [HGA15] W.¬†Huang, K.¬†A.¬†Gallivan and P.-A.¬†Absil.  A Broyden Class of Quasi-Newton Methods for Riemannian Optimization .  SIAM¬†Journal¬†on¬†Optimization  25 , 1660‚Äì1685  (2015). [HML21] K.¬†H√ºper, I.¬†Markina and F.¬†S.¬†Leite.  A Lagrangian approach to extremal curves on Stiefel manifolds .  Journal¬†of¬†Geometric¬†Mechanics  13 , 55  (2021). [JBAS10] M.¬†Journ√©e, F.¬†Bach, P.-A.¬†Absil and R.¬†Sepulchre.  Low-Rank Optimization on the Cone of Positive Semidefinite Matrices .  SIAM¬†Journal¬†on¬†Optimization  20 , 2327‚Äì2351  (2010),  arXiv:0807.4423 . [KFT13] T.¬†Kaneko, S.¬†Fiori and T.¬†Tanaka.  Empirical Arithmetic Averaging Over the Compact Stiefel Manifold .  IEEE¬†Transactions¬†on¬†Signal¬†Processing  61 , 883‚Äì894  (2013). [Kar77] H.¬†Karcher.  Riemannian center of mass and mollifier smoothing .  Communications¬†on¬†Pure¬†and¬†Applied¬†Mathematics  30 , 509‚Äì541  (1977). [Ken84] D.¬†G.¬†Kendall.  Shape Manifolds, Procrustean Metrics, and Complex Projective Spaces .  Bulletin¬†of¬†the¬†London¬†Mathematical¬†Society  16 , 81‚Äì121  (1984). [Ken89] D.¬†G.¬†Kendall.  A Survey of the Statistical Theory of Shape .  Statistical¬†Sciences  4 , 87‚Äì99  (1989). [KL10] O.¬†Koch and C.¬†Lubich.  Dynamical Tensor Approximation .  SIAM¬†Journal¬†on¬†Matrix¬†Analysis¬†and¬†Applications  31 , 2360‚Äì2375  (2010). [KSV13] D.¬†Kressner, M.¬†Steinlechner and B.¬†Vandereycken.  Low-rank tensor completion by Riemannian optimization .  BIT¬†Numerical¬†Mathematics  54 , 447‚Äì468  (2013). [LW19] N.¬†Langren√© and X.¬†Warin.  Fast and Stable Multivariate Kernel Density Estimation by Fast Sum Updating .  Journal¬†of¬†Computational¬†and¬†Graphical¬†Statistics  28 , 596‚Äì608  (2019). [LMV00] L.¬†D.¬†Lathauwer, B.¬†D.¬†Moor and J.¬†Vandewalle.  A Multilinear Singular Value Decomposition .  SIAM¬†Journal¬†on¬†Matrix¬†Analysis¬†and¬†Applications  21 , 1253‚Äì1278  (2000). [Lee19] J.¬†M.¬†Lee.  Introduction to Riemannian Manifolds  (Springer Cham, 2019). [Lin19] Z.¬†Lin.  Riemannian Geometry of Symmetric Positive Definite Matrices via Cholesky Decomposition .  SIAM¬†Journal¬†on¬†Matrix¬†Analysis¬†and¬†Applications  40 , 1353‚Äì1370  (2019),  arXiv:1908.09326 . [MMP18] L.¬†Malag√≥, L.¬†Montrucchio and G.¬†Pistone.  Wasserstein Riemannian geometry of Gaussian densities .  Information¬†Geometry  1 , 137‚Äì179  (2018). [Mar72] G.¬†Marsaglia.  Choosing a Point from the Surface of a Sphere .  Annals¬†of¬†Mathematical¬†Statistics  43 , 645‚Äì646  (1972). [MA20] E.¬†Massart and P.-A.¬†Absil.  Quotient Geometry with Simple Geodesics for the Manifold of Fixed-Rank Positive-Semidefinite Matrices .  SIAM¬†Journal¬†on¬†Matrix¬†Analysis¬†and¬†Applications  41 , 171‚Äì198  (2020). Preprint:  sites.uclouvain.be/absil/2018.06 . [MF12] P.¬†Muralidharan and P.¬†T.¬†Fletcher.  Sasaki metrics for analysis of longitudinal data on manifolds . In:  2012 IEEE Conference on Computer Vision and Pattern Recognition  (2012). [NM16] P.¬†Neff and R.¬†J.¬†Martin.  Minimal geodesics on GL(n) for left-invariant, right-O(n)-invariant Riemannian metrics .  J.¬†Geom.¬†Mech.  8 , 323‚Äì357  (2016),  arXiv:1409.7849 . [Ngu23] D.¬†Nguyen.  Operator-Valued Formulas for Riemannian Gradient and Hessian and Families of Tractable Metrics in Riemannian Optimization .  Journal¬†of¬†Optimization¬†Theory¬†and¬†Applications  198 , 135‚Äì164  (2023),  arXiv:2009.10159 . [Pen06] X.¬†Pennec.  Intrinsic Statistics on Riemannian Manifolds: Basic Tools for Geometric Measurements .  Journal¬†of¬†Mathematical¬†Imaging¬†and¬†Vision  25 , 127‚Äì154  (2006). [PA12] X.¬†Pennec and V.¬†Arsigny.  Exponential Barycenters of the Canonical Cartan Connection and Invariant Means on Lie Groups . In:  Matrix Information Geometry  (Springer, Berlin, Heidelberg, 2012); pp.¬†123‚Äì166,  arXiv:00699361 . [PL20] X.¬†Pennec and M.¬†Lorenzi.  Beyond Riemannian geometry: The affine connection setting for transformation groups . In:  Riemannian Geometric Statistics in Medical Image Analysis  (Elsevier, 2020); pp.¬†169‚Äì229. [Ren11] Q.¬†Rentmeesters.  A gradient method for geodesic data fitting on some symmetric Riemannian manifolds . In:  IEEE Conference on Decision and Control and European Control Conference  (2011); pp.¬†7141‚Äì7146. [Ric88] J.¬†M.¬†Rico Martinez.  Representations of the Euclidean group and its applications to the kinematics of spatial chains . Ph.D. Thesis, University of FLorida (1988). [Sas58] S.¬†Sasaki.  On the differential geometry of tangent bundles of Riemannian manifolds .  Tohoku¬†Math.¬†J.  10  (1958). [SK16] A.¬†Srivastava and E.¬†P.¬†Klassen.  Functional and Shape Data Analysis  (Springer New York, 2016). [Suh13] E.¬†Suhubi.  Exterior Analysis: Using Applications of Differential Forms  (Academic Press, 2013). [Tor20] S.¬†Tornier.  Haar Measures  (2020). [TD17] R.¬†Tron and K.¬†Daniilidis.  The Space of Essential Matrices as a Riemannian Quotient Manifold .  SIAM¬†J.¬†Imaging¬†Sci.  10 , 1416‚Äì1445  (2017). [Van13] B.¬†Vandereycken.  Low-rank matrix completion by Riemannian optimization .  SIAM¬†Journal¬†on¬†Optimization  23 , 1214‚Äì1236  (2013). [VVM12] N.¬†Vannieuwenhoven, R.¬†Vandebril and K.¬†Meerbergen.  A New Truncation Strategy for the Higher-Order Singular Value Decomposition .  SIAM¬†Journal¬†on¬†Scientific¬†Computing  34 , A1027‚ÄìA1052  (2012). [WSF18] J.¬†Wang, H.¬†Sun and S.¬†Fiori.  A Riemannian-steepest-descent approach for optimization on the real symplectic group .  Mathematical¬†Methods¬†in¬†the¬†Applied¬†Science  41 , 4273‚Äì4286  (2018). [YWL21] K.¬†Ye, K.¬†S.-W.¬†Wong and L.-H.¬†Lim.  Optimization on flag manifolds .  Mathematical¬†Programming  194 , 621‚Äì660  (2021). [Zhu16] X.¬†Zhu.  A Riemannian conjugate gradient method for optimization on the Stiefel manifold .  Computational¬†Optimization¬†and¬†Applications  67 , 73‚Äì110  (2016). [ZD18] X.¬†Zhu and C.¬†Duan.  On matrix exponentials and their approximations related to optimization on the Stiefel manifold .  Optimization¬†Letters  13 , 1069‚Äì1083  (2018). [Zim17] R.¬†Zimmermann.  A Matrix-Algebraic Algorithm for the Riemannian Logarithm on the Stiefel Manifold under the Canonical Metric .  SIAM¬†J.¬†Matrix¬†Anal.¬†Appl.  38 , 322‚Äì342  (2017),  arXiv:1604.05054 . [ZH22] R.¬†Zimmermann and K.¬†H√ºper.  Computing the Riemannian Logarithm on the Stiefel Manifold: Metrics, Methods, and Performance .  SIAM¬†Journal¬†on¬†Matrix¬†Analysis¬†and¬†Applications  43 , 953‚Äì980  (2022),  arXiv:2103.12046 . [APSS17] F.¬†√Östr√∂m, S.¬†Petra, B.¬†Schmitzer and C.¬†Schn√∂rr.  Image Labeling by Assignment .  Journal¬†of¬†Mathematical¬†Imaging¬†and¬†Vision  58 , 211‚Äì238  (2017),  arXiv:1603.05285 ."},{"id":1876,"pagetitle":"explore curvature without coordinates","title":"Exploring curvature without coordinates","ref":"/manifolds/stable/tutorials/#Exploring-curvature-without-coordinates","content":" Exploring curvature without coordinates This part of documentation covers exploration of curvature of manifolds  $\\mathcal{M}$ . There are multiple ways to describe curvature: Christoffel symbols, Riemann tensor, Ricci tensor, sectional curvature, and many other. They are usually considered only in coordinates but there is a way to demonstrate curvature in coordinate-free way."},{"id":1877,"pagetitle":"explore curvature without coordinates","title":"Sectional curvature matrix","ref":"/manifolds/stable/tutorials/#Sectional-curvature-matrix","content":" Sectional curvature matrix Curvature of a manifold can be explored using the  sectional_curvature_matrix  function. Note that Riemann tensor and sectional curvature are equivalently full specifications of curvature in a manifold, see [ CE08 ], Eq. (1.12). Let‚Äôs take the  SymmetricPositiveDefinite  manifold as our first example. It has nonpositive sectional curvature: using Manifolds\nusing LinearAlgebra\nM = SymmetricPositiveDefinite(3)\np = rand(M)\ncm = sectional_curvature_matrix(M, p, DefaultOrthonormalBasis()) 6√ó6 Matrix{Float64}:\n  0.0          -0.25         -0.25         ‚Ä¶   4.25414e-21  -2.97882e-21\n -0.25          0.0          -0.125           -0.125         1.17265e-20\n -0.25         -0.125         0.0             -0.125        -0.25\n -2.80168e-21  -0.25          5.79872e-22     -0.25          5.09261e-21\n  4.25414e-21  -0.125        -0.125            0.0          -0.25\n -2.97882e-21   1.17265e-20  -0.25         ‚Ä¶  -0.25          0.0 We can verify that the curvature is consistent with an approximation based on the Bertrand‚ÄìDiguet‚ÄìPuiseux theorem, which relies only on an ONB, exponential map and distance calculation: cm_bdp = Manifolds.estimated_sectional_curvature_matrix(M, p, DefaultOrthonormalBasis(); r=1e-3, N_pts=100000)\nprintln(norm(cm - cm_bdp)) 0.005328691394037271 This approximation converges quite slowly with  N_pts  and is prone to numerical errors at low values of  r  and large values of  N_pts . You can also take the vectors from the basis and see what kind of planes they correspond to. It may be easier to see for the identity matrix as the base point. p = [1.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 1.0]\nV = get_vectors(M, p, get_basis(M, p, DefaultOrthonormalBasis()))\ncm = sectional_curvature_matrix(M, p, DefaultOrthonormalBasis())\nfor X in V\n    println(exp(M, p, X))\nend [2.718281828459045 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 1.0]\n[1.260591836521356 0.7675231451261162 0.0; 0.7675231451261162 1.2605918365213566 0.0; 0.0 0.0 1.0]\n[1.260591836521356 0.0 0.7675231451261162; 0.0 1.0 0.0; 0.7675231451261162 0.0 1.2605918365213566]\n[1.0 0.0 0.0; 0.0 2.718281828459045 0.0; 0.0 0.0 1.0]\n[1.0 0.0 0.0; 0.0 1.260591836521356 0.7675231451261162; 0.0 0.7675231451261162 1.2605918365213566]\n[1.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 2.718281828459045] The flat planes correspond to directions where the matrix changes independently. In other cases sectional curvature indicates hyperbolic characteristic of a submanifold. Sectional curvature can be either larger or smaller than entries in the matrix on other planes. Consider for example the manifold of rotation matrices in four dimensions, and a function that computes plane of maximum curvature using random search. function max_curvature(M::AbstractManifold, p)\n    mc = -Inf\n    X = zero_vector(M, p)\n    Y = zero_vector(M, p)\n    for _ in 1:10000\n        X_c = rand(M; vector_at=p)\n        Y_c = rand(M; vector_at=p)\n        sc = sectional_curvature(M, p, X_c, Y_c)\n        if sc > mc\n            mc = sc\n            X .= X_c\n            Y .= Y_c\n        end\n    end\n    return mc, X, Y\nend\n\nM = Rotations(4)\np = Matrix(I(4) * 1.0)\nprintln(sectional_curvature_matrix(M, p, DefaultOrthonormalBasis()))\nmc, X, Y = max_curvature(M, p)\nprintln(mc)\nprintln(X)\nprintln(Y) [0.0 0.12500000000000003 0.12500000000000003 0.0 0.12500000000000003 0.12500000000000003; 0.12500000000000003 0.0 0.12500000000000003 0.12500000000000003 0.0 0.12500000000000003; 0.12500000000000003 0.12500000000000003 0.0 0.12500000000000003 0.12500000000000003 0.0; 0.0 0.12500000000000003 0.12500000000000003 0.0 0.12500000000000003 0.12500000000000003; 0.12500000000000003 0.0 0.12500000000000003 0.12500000000000003 0.0 0.12500000000000003; 0.12500000000000003 0.12500000000000003 0.0 0.12500000000000003 0.12500000000000003 0.0]\n0.23763976887464178\n[0.0 0.5665156641128831 -1.925255621999898 0.025735423619253434; -0.5665156641128831 0.0 -0.14229801426871405 -2.093467802847457; 1.925255621999898 0.14229801426871405 0.0 -0.6480651263200445; -0.025735423619253434 2.093467802847457 0.6480651263200445 0.0]\n[0.0 1.4795328370297516 0.13994219455221177 -0.9707549904747508; -1.4795328370297516 0.0 0.8781944378584985 0.2242833550179564; -0.13994219455221177 -0.8781944378584985 0.0 -0.8362824801036352; 0.9707549904747508 -0.2242833550179564 0.8362824801036352 0.0] In the planes corresponding to orthonormal basis, the maximum sectional curvature is 0.125 but the true upper bound is 0.25."},{"id":1878,"pagetitle":"explore curvature without coordinates","title":"Literature","ref":"/manifolds/stable/tutorials/#Literature","content":" Literature [CE08] J.¬†Cheeger and D.¬†G.¬†Ebin.  Comparison Theorems in Riemannian Geometry  (American Mathematical Society, Providence, R.I, 2008)."},{"id":1881,"pagetitle":"üöÄ Get Started with Manifolds.jl","title":"üöÄ Get Started with  Manifolds.jl","ref":"/manifolds/stable/tutorials/#Get-Started-with-Manifolds.jl","content":" üöÄ Get Started with  Manifolds.jl This is a short overview of  Manifolds.jl  and how to get started working with your first Manifold. we first need to install the package, using for example using Pkg; Pkg.add(\"Manifolds\") Then you can load the package with using Manifolds"},{"id":1882,"pagetitle":"üöÄ Get Started with Manifolds.jl","title":"Using the Library of Manifolds","ref":"/manifolds/stable/tutorials/#Using-the-Library-of-Manifolds","content":" Using the Library of Manifolds Manifolds.jl  is first of all a library of manifolds, see the list in the menu  here  under ‚Äúbasic manifolds‚Äù. Let‚Äôs look at three examples together with the first few functions on manifolds."},{"id":1883,"pagetitle":"üöÄ Get Started with Manifolds.jl","title":"1.  The Euclidean space","ref":"/manifolds/stable/tutorials/#1.-[The-Euclidean-space](https://juliamanifolds.github.io/Manifolds.jl/latest/manifolds/euclidean.html)","content":" 1.  The Euclidean space The Euclidean Space  Euclidean  brings us (back) into linear case of vectors, so in terms of manifolds, this is a very simple one. It is often useful to compare to classical algorithms, or implementations. M‚ÇÅ = Euclidean(3) Euclidean(3; field=‚Ñù) Since a manifold is a type in Julia, we write it in CamelCase. Its parameters are first a dimension or size parameter of the manifold, sometimes optional is a field the manifold is defined over. For example the above definition is the same as the real-valued case M‚ÇÅ === Euclidean(3, field=‚Ñù) true But we even introduced a short hand notation, since ‚Ñù is also just a symbol/variable to use‚Äù M‚ÇÅ === ‚Ñù^3 true And similarly here are two ways to create the manifold of vectors of length two with complex entries ‚Äì or mathematically the space  $\\mathbb C^2$ Euclidean(2, field=‚ÑÇ) === ‚ÑÇ^2 true The easiest to check is the dimension of a manifold. Here we have three ‚Äúdirections to walk into‚Äù at every point  $p\\in \\mathbb R ^3$  so  üîó  manifold_dimension  is manifold_dimension(M‚ÇÅ) 3"},{"id":1884,"pagetitle":"üöÄ Get Started with Manifolds.jl","title":"2.  The hyperpolic space","ref":"/manifolds/stable/tutorials/#2.-[The-hyperpolic-space](@ref-HyperbolicSpace)","content":" 2.  The hyperpolic space The  $d$ -dimensional  hyperbolic space  is usually represented in  $\\mathbb R^{d+1}$  as the set of points  $p\\in\\mathbb R^3$  fulfilling \\[p_1^2+p_2^2+‚ãÖs+p_d^2-p_{d+1}^2 = -1.\\] We define the manifold using M‚ÇÇ = Hyperbolic(2) Hyperbolic(2) And we can again just start with looking at the manifold dimension of  M‚ÇÇ manifold_dimension(M‚ÇÇ) 2 A next useful function is to check, whether some  $p‚àà\\mathbb R^3$  is a point on the manifold  M‚ÇÇ . We can check is_point(M‚ÇÇ, [0, 0, 1]) true or is_point(M‚ÇÇ, [1, 0, 1]) false Keyword arguments are passed on to any numerical checks, for example an absolute tolerance when checking the above equiality. But in an interactive session an error message might be helpful. A positional (third) argument is present to activate this. Setting this parameter to true, we obtain an error message that gives insight into why the point is not a point on  M‚ÇÇ . Note that the  LoadError:  is due to quarto, on  REPL  you would just get the  DomainError . is_point(M‚ÇÇ, [0, 0, 1.001]; error=:error) LoadError: DomainError with -1.0020009999999997:\nThe point [0.0, 0.0, 1.001] does not lie on Hyperbolic(2) since its Minkowski inner product is not -1."},{"id":1885,"pagetitle":"üöÄ Get Started with Manifolds.jl","title":"3.  The sphere","ref":"/manifolds/stable/tutorials/#3.-[The-sphere](@ref-SphereSection)","content":" 3.  The sphere The sphere $\\mathbb S^d$  is the  $d$ -dimensional sphere represented in its embedded form, that is unit vectors  $p \\in \\mathbb R^{d+1}$  with unit norm  $\\lVert p \\rVert_2 = 1$ . M‚ÇÉ = Sphere(2) Sphere(2, ‚Ñù) If we only have a point that is approximately on the manifold, we can allow for a tolerance. Usually these are the same values of  atol  and  rtol  alowed in  isapprox , i.e.¬†we get is_point(M‚ÇÉ, [0, 0, 1.001]; atol=1e-3) true Here we can show a last nice check:  üîó  is_vector  to check whether a tangent vector  X  is a representation of a tangent vector  $X‚ààT_p\\mathcal M$  to a point  p  on the manifold. This function has two positional asrguments, the first to again indicate whether to throw an error, the second to disable the check that  p  is a valid point on the manifold. Usually this validity is essential for the tangent check, but if it was for example performed before, it can be turned off to spare time. For example in our first example the point is not of unit norm is_vector(M‚ÇÉ, [2, 0, 0], [0, 1, 1]) false But the orthogonality of  p  and  X  is still valid, we can disable the point check, but even setting the error to true we get here is_vector(M‚ÇÉ, [2, 0, 0], [0, 1, 1], true, false) false But of course it is better to use a valid point in the first place is_vector(M‚ÇÉ, [1, 0, 0], [0, 1, 1]) true and for these we again get informative error messages @expect_error is_vector(M‚ÇÉ, [1, 0, 0], [0.1, 1, 1]; error=:error) DomainError LoadError: LoadError: UndefVarError: `@expect_error` not defined\nin expression starting at In[19]:1 To learn about how to define a manifold youself check out the  üîó How to define your own manifold  tutorial of  üîó  ManifoldsBase.jl .‚Äù"},{"id":1886,"pagetitle":"üöÄ Get Started with Manifolds.jl","title":"Building more advanced manifolds","ref":"/manifolds/stable/tutorials/#Building-more-advanced-manifolds","content":" Building more advanced manifolds Based on these basic manifolds we can directly build more advanced manifolds. The first one concerns vectors or matrices of data on a manifold, the  PowerManifold . M‚ÇÑ = M‚ÇÇ^2 PowerManifold(Hyperbolic(2), 2) Then points are represented by arrays, where the power manifold dimension is added in the end. In other words ‚Äì for the hyperbolic manifold here, we have a matrix with 2 columns, where each column is a valid point on hyperbolic space. p = [0 0; 0 1; 1 sqrt(2)] 3√ó2 Matrix{Float64}:\n 0.0  0.0\n 0.0  1.0\n 1.0  1.41421 [is_point(M‚ÇÇ, p[:, 1]), is_point(M‚ÇÇ, p[:, 2])] 2-element Vector{Bool}:\n 1\n 1 But of course the method we used previously also works for power manifolds: is_point(M‚ÇÑ, p) true Note that nested power manifolds are combined into one as in M‚ÇÑ‚ÇÇ = M‚ÇÑ^4 PowerManifold(Hyperbolic(2), 2, 4) which represents  $2√ó4$  ‚Äì matrices of hyperbolic points represented in  $3√ó2√ó4$  arrays. We can ‚Äì alternatively ‚Äì use a power manifold with nested arrays M‚ÇÖ = PowerManifold(M‚ÇÉ, NestedPowerRepresentation(), 2) PowerManifold(Sphere(2, ‚Ñù), NestedPowerRepresentation(), 2) which emphasizes that we have vectors of length 2 that contain points, so we store them that way. p‚ÇÇ = [[0.0, 0.0, 1.0], [0.0, 1.0, 0.0]] 2-element Vector{Vector{Float64}}:\n [0.0, 0.0, 1.0]\n [0.0, 1.0, 0.0] To unify both representations, elements of the power manifold can also be accessed in the classical indexing fashion, if we start with the corresponding manifold first. This way one can implement algorithms also independent of which representation is used.‚Äù p[M‚ÇÑ, 1] 3-element Vector{Float64}:\n 0.0\n 0.0\n 1.0 p‚ÇÇ[M‚ÇÖ, 2] 3-element Vector{Float64}:\n 0.0\n 1.0\n 0.0 Another construtor is the  ProductManifold  to combine different manifolds. Here of course the order matters. First we construct these using  $√ó$ M‚ÇÜ = M‚ÇÇ √ó M‚ÇÉ ProductManifold with 2 submanifolds:\n Hyperbolic(2)\n Sphere(2, ‚Ñù) Since now the representations might differ from element to element, we have to encapsulate these in their own type. p‚ÇÉ = Manifolds.ArrayPartition([0, 0, 1], [0, 1, 0]) ([0, 0, 1], [0, 1, 0]) Here  ArrayPartition  taken from  üîó  RecursiveArrayTools.jl  to store the point on the product manifold efficiently in one array, still allowing efficient access to the product elements. is_point(M‚ÇÜ, p‚ÇÉ; error=:error) true But accessing single components still works the same.‚Äù p‚ÇÉ[M‚ÇÜ, 1] 3-element Vector{Int64}:\n 0\n 0\n 1 Finally, also the  TangentBundle , the manifold collecting all tangent spaces on a manifold is available as‚Äù M‚Çá = TangentBundle(M‚ÇÉ) TangentBundle(Sphere(2, ‚Ñù))"},{"id":1887,"pagetitle":"üöÄ Get Started with Manifolds.jl","title":"Implementing generic Functions","ref":"/manifolds/stable/tutorials/#Implementing-generic-Functions","content":" Implementing generic Functions In this section we take a look how to implement generic functions on manifolds. For our example here, we want to implement the so-called  üìñ B√©zier curve  using the so-called  üìñ de-Casteljau algorithm . The linked algorithm can easily be generalised to manifolds by replacing lines with geodesics. This was for example used in [ BG18 ] and the following example is an extended version of an example from [ ABBR23 ]. The algorithm works recursively. For the case that we have a B√©zier curve with just two points, the algorithm just evaluates the geodesic connecting both at some time point  $t‚àà[0,1]$ . The function to evaluate a shortest geodesic (it might not be unique, but then a deterministic choice is taken) between two points  p  and  q  on a manifold  M üîó  shortest_geodesic(M, p, q, t) . function de_Casteljau(M::AbstractManifold, t, pts::NTuple{2})\n    return shortest_geodesic(M, pts[1], pts[2], t)\nend de_Casteljau (generic function with 1 method) function de_Casteljau(M::AbstractManifold, t, pts::NTuple)\n    p = de_Casteljau(M, t, pts[1:(end - 1)])\n    q = de_Casteljau(M, t, pts[2:end])\n    return shortest_geodesic(M, p, q, t)\nend de_Casteljau (generic function with 2 methods) Which can now be used on any manifold where the shortest geodesic is implemented Now on several manifolds the  üìñ exponential map  and its (locally defined) inverse, the logarithmic map might not be available in an implementation. So one way to generalise this, is the use of a retraction (see [ AMS08 ], Def. 4.1.1 for details) and its (local) inverse. The function itself is quite similar to the expponential map, just that  üîó  retract(M, p, X, m)  has one further parameter, the type of retraction to take, so  m  is a subtype of  m , the same for the  üîó  inverse_retract(M, p, q, n)  with an  AbstractInverseRetractionMethod n . Thinking of a generic implementation, we would like to have a way to specify one, that is available. This can be done by using  üîó  default_retraction_method  and  üîó  default_inverse_retraction_method , respectively. We implement function generic_de_Casteljau(\n    M::AbstractManifold,\n    t,\n    pts::NTuple{2};\n    m::AbstractRetractionMethod=default_retraction_method(M),\n    n::AbstractInverseRetractionMethod=default_inverse_retraction_method(M),\n)\n    X = inverse_retract(M, pts[1], pts[2], n)\n    return retract(M, pts[1], X, t, m)\nend generic_de_Casteljau (generic function with 1 method) and for the recursion function generic_de_Casteljau(\n    M::AbstractManifold,\n    t,\n    pts::NTuple;\n    m::AbstractRetractionMethod=default_retraction_method(M),\n    n::AbstractInverseRetractionMethod=default_inverse_retraction_method(M),\n)\n    p = generic_de_Casteljau(M, t, pts[1:(end - 1)]; m=m, n=n)\n    q = generic_de_Casteljau(M, t, pts[2:end]; m=m, n=n)\n    X = inverse_retract(M, p, q, n)\n    return retract(M, p, X, t, m)\nend generic_de_Casteljau (generic function with 2 methods) Note that on a manifold  M  where the exponential map is implemented, the  default_retraction_method(M)  returns  üîó  ExponentialRetraction , which yields that the  retract  function falls back to calling  exp . The same mechanism exists for  üîó  parallel_transport_to(M, p, X, q)  and the more general  üîó  vector_transport_to(M, p, X, q, m)  whose  üîó  AbstractVectorTransportMethod m  has a default defined by  üîó  default_vector_transport_method(M) ."},{"id":1888,"pagetitle":"üöÄ Get Started with Manifolds.jl","title":"Allocating and in-place computations","ref":"/manifolds/stable/tutorials/#Allocating-and-in-place-computations","content":" Allocating and in-place computations Memory allocation is a  üîó critical performace issue  when programming in Julia. To take this into account,  Manifolds.jl  provides special functions to reduce the amount of allocations. We again look at the  üìñ exponential map . On a manifold  M  the exponential map needs a point  p  (to start from) and a tangent vector  X , which can be seen as direction to ‚Äúwalk into‚Äù as well as the length to walk into this direction. In  Manifolds.jl  the function can then be called with  q = exp(M, p, X)  (see  üîó  exp(M, p, X) ). This function returns the resulting point  q , which requires to allocate new memory. To avoid this allocation, the function  üîó  exp!(M, q, p, X)  can be called. Here  q  is allocated beforehand and is passed as the memory, where the result is returned in. It might be used even for interims computations, as long as it does not introduce side effects. Thas means that even with  exp!(M, p, p, X)  the result is correct. Let‚Äôs look at an example. We take another look at the  Sphere , but now a high-dimensional one. We can also illustrate how to generate radnom points and tangent vectors. M = Sphere(10000)\np‚ÇÑ = rand(M)\nX = rand(M; vector_at=p‚ÇÑ) Looking at the allocations required we get @allocated exp(M, p‚ÇÑ, X) 8455864 While if we have already allocated memory for the resulting point on the manifold, for example q‚ÇÇ = zero(p‚ÇÑ); There are no new memory allocations necessary if we use the in-place function.‚Äù @allocated exp!(M, q‚ÇÇ, p‚ÇÑ, X) 0 This methodology is used for all functions that compute a new point or tangent vector. By default all allocating functions allocate memory and call the in-place function. This also means that if you implement a new manifold, you just have to implement the in-place version."},{"id":1889,"pagetitle":"üöÄ Get Started with Manifolds.jl","title":"Decorating a manifold","ref":"/manifolds/stable/tutorials/#Decorating-a-manifold","content":" Decorating a manifold As you saw until now, an [üîó  AbstractManifold ]@extref  ManifoldsBase.AbstractManifold ) describes a Riemannian manifold. For completeness, this also includes the chosen  üìñ Riemannian metric tensor  or inner product on the tangent spaces. In  Manifolds.jl  these are assumed to be a ‚Äúreasonable default‚Äù. For example on the  Sphere (n)  we used above, the default metric is the one inherited from restricting the inner product from the embedding space onto each tangent space. Consider a manifold like M‚Çà = SymmetricPositiveDefinite(3) SymmetricPositiveDefinite(3) which is the manifold of  $3√ó3$  matrices that are  symmetric and positive definite . which has a default as well, the affine invariant  AffineInvariantMetric , but also has several different metrics. To switch the metric, we use the idea of a  üìñ decorator pattern  approach. Defining M‚Çà‚ÇÇ = MetricManifold(M‚Çà, BuresWassersteinMetric()) MetricManifold(SymmetricPositiveDefinite(3), BuresWassersteinMetric()) changes the manifold to use the  BuresWassersteinMetric . This changes all functions that depend on the metric, most prominently the Riemannian matric, but also the exponential and logarithmic map and hence also geodesics. All functions that are not dependent on a metric ‚Äì for example the manifold dimension, the tests of points and vectors we already looked at, but also all retractions ‚Äì stay unchanged. This means that for example [manifold_dimension(M‚Çà‚ÇÇ), manifold_dimension(M‚Çà)] 2-element Vector{Int64}:\n 6\n 6 both calls the same underlying function. On the other hand with p‚ÇÖ, X‚ÇÖ = one(zeros(3, 3)), [1.0 0.0 1.0; 0.0 1.0 0.0; 1.0 0.0 1.0] ([1.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 1.0], [1.0 0.0 1.0; 0.0 1.0 0.0; 1.0 0.0 1.0]) but for example the exponential map and the norm yield different results [exp(M‚Çà, p‚ÇÖ, X‚ÇÖ), exp(M‚Çà‚ÇÇ, p‚ÇÖ, X‚ÇÖ)] 2-element Vector{Matrix{Float64}}:\n [4.194528049465325 0.0 3.194528049465325; 0.0 2.718281828459045 0.0; 3.194528049465325 0.0 4.194528049465328]\n [2.5 0.0 1.5; 0.0 2.25 0.0; 1.5 0.0 2.5] [norm(M‚Çà, p‚ÇÖ, X‚ÇÖ), norm(M‚Çà‚ÇÇ, p‚ÇÖ, X‚ÇÖ)] 2-element Vector{Float64}:\n 2.23606797749979\n 1.118033988749895 Technically this done using Traits ‚Äì the trait here is the  IsMetricManifold  trait. Our trait system allows to combine traits but also to inherit properties in a hierarchical way, see  üîó here  for the technical details. The same approach is used for specifying a different  connection specifying a manifold as a certain  quotient manifold specifying a certain  üîó embedding s specify a certain  group action Again, for all of these, the concrete types only have to be used if you want to do a second, different from the details, property, for example a second way to embed a manfiold. If a manifold is (in its usual representation) an embedded manifold, this works with the default manifold type already, since then it is again set as the reasonable default."},{"id":1890,"pagetitle":"üöÄ Get Started with Manifolds.jl","title":"Literature","ref":"/manifolds/stable/tutorials/#Literature","content":" Literature [AMS08] P.-A.¬†Absil, R.¬†Mahony and R.¬†Sepulchre.  Optimization Algorithms on Matrix Manifolds  (Princeton University Press, 2008), available online at  press.princeton.edu/chapters/absil/ . [ABBR23] S.¬†D.¬†Axen, M.¬†Baran, R.¬†Bergmann and K.¬†Rzecki.  Manifolds.Jl: An Extensible Julia Framework for Data Analysis on Manifolds .  ACM¬†Transactions¬†on¬†Mathematical¬†Software  49  (2023). [BG18] R.¬†Bergmann and P.-Y.¬†Gousenbourger.  A variational model for data fitting on manifolds by minimizing the acceleration of a B√©zier curve .  Frontiers¬†in¬†Applied¬†Mathematics¬†and¬†Statistics  4  (2018),  arXiv:1807.10090 ."},{"id":1893,"pagetitle":"perform Hand gesture analysis","title":"Hand gesture analysis","ref":"/manifolds/stable/tutorials/#Hand-gesture-analysis","content":" Hand gesture analysis In this tutorial we will learn how to use Kendall‚Äôs shape space to analyze hand gesture data. Let‚Äôs start by loading libraries required for our work. using Manifolds, CSV, DataFrames, Plots, MultivariateStats Our first function loads dataset of hand gestures, described  here . function load_hands()\n    hands_url = \"https://raw.githubusercontent.com/geomstats/geomstats/master/geomstats/datasets/data/hands/hands.txt\"\n    hand_labels_url = \"https://raw.githubusercontent.com/geomstats/geomstats/master/geomstats/datasets/data/hands/labels.txt\"\n\n    hands = Matrix(CSV.read(download(hands_url), DataFrame, header=false))\n    hands = reshape(hands, size(hands, 1), 3, 22)\n    hand_labels = CSV.read(download(hand_labels_url), DataFrame, header=false).Column1\n    return hands, hand_labels\nend load_hands (generic function with 1 method) The following code plots a sample gesture as a 3D scatter plot of points. hands, hand_labels = load_hands()\nscatter3d(hands[1, 1, :], hands[1, 2, :], hands[1, 3, :]) Each gesture is represented by 22 landmarks in  $‚Ñù¬≥$ , so we use the appropriate Kendall‚Äôs shape space Mshape = KendallsShapeSpace(3, 22) KendallsShapeSpace(3, 22) Hands read from the dataset are projected to the shape space to remove translation and scaling variability. Rotational variability is then handled using the quotient structure of  KendallsShapeSpace hands_projected = [project(Mshape, hands[i, :, :]) for i in axes(hands, 1)] In the next part let‚Äôs do tangent space PCA. This starts with computing a mean point and computing logithmic maps at mean to each point in the dataset. mean_hand = mean(Mshape, hands_projected)\nhand_logs = [log(Mshape, mean_hand, p) for p in hands_projected] For a tangent PCA, we need coordinates in a basis. Some libraries skip this step because the representation of tangent vectors forms a linear subspace of an Euclidean space so PCA automatically detects which directions have no variance but this is a more generic way to solve this issue. B = get_basis(Mshape, mean_hand, ProjectedOrthonormalBasis(:svd))\nhand_log_coordinates = [get_coordinates(Mshape, mean_hand, X, B) for X in hand_logs] This code prepares data for MultivariateStats ‚Äì  mean=0  is set because we‚Äôve centered the data geometrically to  mean_hand  in the code above. red_coords = reduce(hcat, hand_log_coordinates)\nfp = fit(PCA, red_coords; mean=0) PCA(indim = 59, outdim = 19, principalratio = 0.991345477862632)\n\nPattern matrix (unstandardized loadings):\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n             PC1           PC2           PC3           PC4           PC5           PC6           PC7           PC8           PC9          PC10          PC11          PC12          PC13          PC14          PC15          PC16          PC17          PC18          PC19\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n1    0.0225725    -0.025823      0.00247119   -0.00194504    0.011187      0.00865122   -0.00432       0.00232697   -0.00133113   -0.00603743    0.00279173    0.00459607    0.0026104    -0.00194346   -0.0010809     0.00371279   -0.0026941    -0.00336716   -4.78115e-6\n2   -0.0298018     0.012855     -0.0253788    -0.0107526    -0.000642301   0.00243343   -0.0129186     0.0117729     0.0159723     0.00107763   -0.00131555    0.00285026    0.00463989   -0.00216125    0.00161956    0.00105094    0.00029935   -0.000818863   0.000226847\n3   -0.00496432   -0.0149723    -0.00377204    0.0160204    -0.0052388     0.00212934   -0.00568703   -0.00338036    0.000889778  -0.00214546   -0.000896225  -0.00137907   -0.00247179    0.00239153   -0.000377108  -0.00215105    0.0027909     0.000117751  -0.00127213\n4    0.0056335    -0.0129395     0.00752466    0.00555847   -0.00280322    0.00782194    0.00111858    0.0085054    -0.00273334   -0.00581609    0.00450121   -0.00038663    0.00167242    0.00231527    0.000307966  -0.00131181    0.000720744   0.00111114    0.00361935\n5   -0.0113838     0.0232298    -0.00547126   -0.0179074    -0.00225183   -0.0123001    -0.00379069    0.00375553   -0.0110292     0.00304722   -0.00459228   -0.00477702   -0.000442113   0.00166295    0.00238507    0.00489784   -0.00261756    0.00101093   -0.00178457\n6   -0.0345859    -0.0233477     0.0296546     0.00689836    0.003326     -0.00135883   -0.0119614     0.00329535   -0.00698649   -0.00493814    0.00376636    0.000613432  -0.00149234   -0.000250127   0.00623361    0.00254364   -0.000999917   9.66511e-6   -0.000225613\n7   -0.0374342    -0.0209963     0.00235653    0.000683237   0.00758501   -0.00999398    0.00657121    0.00782893   -0.00406903   -0.00581627   -0.00079722    0.0041202     0.00319899    0.00585783   -0.00167581    0.0030249     0.00322473   -0.00108314   -0.00116042\n8    0.02496       0.00943876    0.011668     -0.00772333    0.00960598   -0.00142074    0.00211964   -0.000840499  -0.000234754  -0.000749657   0.000307986   0.0066857    -0.000133384   0.00300887    0.0022704     0.00120301    0.00203841    0.000966472   0.00120561\n9    0.0296003     0.0472131     0.00210213   -0.00393545   -0.00142636   -0.00236192   -0.00533011   -0.00345383   -0.00439341   -0.00852948   -0.000396924  -0.000150678   0.00330386    0.00089967    0.00388721   -0.00199243   -0.00161544    0.00329972   -0.00160867\n10   0.0187554     0.00337061    0.0254247     0.00182716   -0.00726025    0.00345359    0.0118753     0.00392614   -0.00737372   -0.000261283  -0.0044591     0.000623762  -0.00123177   -0.00187434    0.00347221    0.00122414    0.00162647    0.000179093  -0.000639519\n11  -0.0276189    -0.000868697   0.00124921   -0.0271846    -0.0182645    -0.00654734   -0.00377689   -0.00309552    0.00263585    0.0083263     0.0117277    -0.000277824  -0.0013572    -0.00171603   -0.00248708    0.0002054    -0.00129968    0.000538015   0.000635364\n12   0.0742252    -0.0111949    -0.00393113   -0.00375025   -0.00466852    0.00718482   -0.00421926   -0.000133097  -0.00285935    0.00220137   -0.0063239     0.00591546   -0.00391862   -0.00220676   -0.000179801   0.00446115   -0.000848733  -0.00206532    0.00226783\n13   0.0426582     0.00910716    0.0199886     0.00477317    0.000139353   0.00719425   -0.0105414    -0.00511285   -0.00217195    0.0106759    -0.000717452   0.00304458   -0.00227829    0.00118983    0.00302885    0.00259039    0.000590182  -0.00113679   -0.0014884\n14   0.0473028     0.00651493    0.00140138    0.00225381    0.00439764   -0.00750531    0.0193882    -0.00406276    0.0131133    -0.00935677    0.00405362   -0.00109819   -0.000160323   0.00193398    0.00109956    0.000814692   0.000914761   0.00198064    0.00125932\n15   0.0332915     0.0221761     0.0200686    -0.000418236  -0.00238077    0.0136492    -0.00572773   -0.00525892    0.00565712   -0.00186374    0.00193716   -0.00251317    0.00147158   -0.00144082   -0.0036298     0.00233316   -0.000552749  -0.00117945   -0.00143965\n16  -0.019766     -0.0126687    -0.0327939    -0.00786485    0.00374512    0.00537198   -0.0105409    -0.0120939    -4.87631e-5   -0.000200912   0.00649485    0.00341607    0.00856351   -0.000627434   0.00512775    0.00157364    0.0025359    -0.000340485   0.00302362\n17  -0.0163038     0.00392205    0.00368172   -0.00108868   -0.00403097   -0.00250602   -0.00154047   -0.0091664     0.012208     -0.00212529   -0.00249079    0.00425261   -0.0009888     0.000699026   0.00159838    0.00182519   -0.00268461    0.0024567    -0.00287173\n18   0.0315265     0.014339     -0.0281659     0.0188983     0.00116313    0.00517276   -0.012306      0.00964101    0.00378792    0.003776     -0.00471276   -0.00276278    0.00073812   -0.0018049    -0.00110501   -0.00142815   -0.00324852    0.00125496    0.00036833\n19  -0.01342      -0.0266179     0.00692541   -0.00394567    0.00696648    0.00546101    0.0107503     0.00161672    0.00243154    0.0111542    -0.00859616   -0.0022637    -0.00125188   -0.00218111    0.00418941   -0.00245702    0.00109089    0.00262105    0.000894704\n20  -0.000739408   0.00263129    0.00124919    0.000518372  -0.00405283   -0.00980204   -0.00494474   -0.00280603   -0.00543177   -0.00590718    0.00579551    0.00110744   -0.00812888    0.00441085   -0.00391783    0.00174295   -0.000252033  -0.00209523    0.00204457\n21   0.0504932    -0.0110797    -0.0026189    -0.00962761   -0.0153567    -0.00273023    0.00361822    0.00201177   -0.00445139   -0.000379839   0.00688118   -0.000391294  -0.000934333  -0.00118075   -0.00270666   -0.000350291   0.000905076   0.00117337   -0.000755983\n22  -0.046736      0.00232599   -0.0170992    -0.00282647   -0.014517      0.00487345    0.00150701   -0.00101275   -0.00475473    0.00292961    0.00419816    0.0025307     0.00131901    0.00431956   -0.00200533   -0.00153549   -0.000850689  -0.000199973  -0.000797035\n23  -0.0173763    -0.0135675    -0.0235186    -0.00469928   -0.010083      0.00622843    0.00612574    0.000719204  -0.00473516   -0.00170497   -0.0088133    -0.00339875    0.0030805     0.00313125   -0.00334306    0.00617814    0.00103001    0.00544743    0.000548909\n24  -0.00826661    0.0167308     0.00865901   -0.00214922    0.0150335     0.00823526   -0.000297993  -0.00237168   -0.000986393   0.00220198   -0.000681713  -0.000197612   0.000283165   0.00363122    0.000841859  -0.000161184  -0.00456144    0.000377615   0.000890576\n25  -0.00644559    0.010877      0.00278186   -0.00911345   -0.0107489     0.0243946     0.00709473    0.0105892    -0.00627612   -0.00400938    0.00573931   -0.000879342  -0.00421579   -0.00280443    0.00183861   -0.00101372    0.00165889   -0.00303974    0.0016519\n26   0.0441278     0.0158065    -0.00400205   -0.000325081   0.00203837    0.0080049     0.00759341    0.00350391   -0.00106124    0.000470616   0.000231166   0.000781562   0.000640405   0.00106251   -0.00165851    0.0036525     0.00222514   -0.00223304   -0.00322942\n27  -0.0185767     0.0125668     0.0141537     0.0144925     0.00211121   -0.0084411    -0.00693538    0.00588689    0.00509395   -0.000498211  -8.28981e-5   -0.00196856    0.000165433   0.00150428    0.00217742    0.00406355    0.00266332    0.000538881   0.000787166\n28  -0.0288949     0.0285503    -0.00938241    0.00314241    0.00451199   -0.000322886   0.0102419    -0.0057291     0.00452652   -0.00434567    0.00333208    0.000768434   0.000697567  -0.000947317   0.00197396    0.00231527   -0.00262045   -0.0052142    -0.0022789\n29   0.054652      0.016176      0.0233463    -0.00263117    0.0140462    -0.00251733    0.00410277    0.00636276    0.00827887    0.00558304    0.00735049    0.00273341    0.00209918   -0.00136746   -0.00493028    0.0020373     0.00130772    0.00142239   -0.00115467\n30  -0.0234619     0.0175726     0.0109159     0.0120296    -0.00457707   -0.0145693    -7.70199e-5   -0.00427574   -0.00308155    0.0048407    -0.000529341  -0.00208163   -0.00219104   -0.00363319   -0.00608362    0.00641312    7.09267e-5    0.00118223    0.00326152\n31  -0.00743661   -0.0210373    -0.0126597    -0.00541652    0.00933005    0.00815691    0.00468841    0.00631952    0.0111953     0.00090758    0.000217408  -0.0062275    -0.00622832    0.000955856   0.00072591    0.00169066   -0.00115975   -0.00147563   -0.00250162\n32   0.00942946    0.0348065    -0.00344763    0.00870651   -0.0074523    -0.00813785    0.00974278    0.00503949   -0.0115295     0.00778616    0.00187608   -6.06739e-5    0.0101328    -0.00379749    0.00144605   -0.000102658  -0.00132698   -0.00276075    0.00106114\n33   0.0632112    -0.0391171    -0.00200189   -0.0220903    -0.0144734    -0.0113132     0.0077086    -0.000969037   0.00503636    0.00706564    0.00437077    0.00130097    0.00340908    0.0051326     0.00253346    0.000507903  -0.000707207  -0.00056295   -0.00194977\n34   0.0207818    -0.0135932     0.000771381   0.0036835     0.0213596    -0.00486239    0.00157098   -0.00771602   -0.00359822   -0.00378203   -0.0016533    -0.0110685    -0.000753667  -0.00229644   -0.00150167   -0.000303523   0.00158846   -0.000607838   0.000615078\n35  -0.000379201  -0.0120639     0.0297885    -0.00270901    0.00650958   -0.000380978  -0.00121355    0.0101664    -0.00517949   -0.000558258   0.00197674    0.000277632   0.00797185   -0.000760715  -0.00264005   -0.00348748   -0.00231271    0.00137201    0.0015573\n36   0.00115252    0.000667601  -0.000336516   0.0137512    -0.00182112    0.000312716   0.0107091    -0.0131901    -0.000686853   0.00429926   -0.00405865   -0.00152666    0.00779814    0.00289293    0.000712759  -0.00290687    0.000187923  -0.00341138   -0.00143035\n37  -0.0710484    -0.0120054    -0.00742916    0.0315282     0.000899437   0.00447448    0.00873192   -0.00168979    0.00408006    0.0081241     0.0111211    -0.00380385   -0.0027588     0.000382961   0.000901206   0.00209142   -0.00297548    0.000369737   0.000194095\n38   0.0173624    -0.00401998    0.00476487   -0.000229019   0.00277068    0.0121718    -0.00471613   -0.00762391    0.00490114    6.67001e-5   -0.00184396    0.00294105    0.00142187    0.00170863    0.00048986   -0.000522409   0.00089876    0.00154977   -0.00243131\n39  -0.0132061     0.0340923    -0.00256571   -0.00165163   -0.0056104    -0.00854407   -0.00256856    0.00640797    0.00421851    0.00576642   -0.00326446    0.00247372   -0.00086705   -0.003962      0.00141905   -0.000994299   0.00542489    0.000229981  -0.00130346\n40   0.0201995     0.00167282   -0.015568      0.000124091   0.00826228    0.00495587    0.0025755     0.0135085     0.0068398    -0.00135169   -0.000719346  -0.000414134   0.00126898   -0.00109902   -0.00309125    0.00299976   -0.00179919    0.000209681   0.00138728\n41   0.0311951    -0.00349583   -0.000650444   0.00225274   -0.0202231     0.00133542    0.000267878  -0.00500205    0.00441379    4.99341e-6   -0.00226762   -0.00423897   -0.00153824   -0.00378025   -0.00351691   -0.000162936  -0.0024964     0.000454088   0.000183778\n42   0.00295307   -0.00780823    0.00723101    0.0102236    -0.00344839    0.0073579    -0.00253667   -0.00139851   -0.00143191    0.00254803    0.00531096    0.00456018   -0.00235568   -0.00376306   -0.00340022   -0.00172833    0.00121904    0.00142326   -0.000685875\n43   0.0194641    -0.0113322    -0.00277425    0.00886678    0.010623     -0.0172909    -0.00366068    0.00715197    0.00562361    0.00432699    0.00736201    0.00317588   -0.00247544   -0.00147035    0.00388555   -0.00220526    0.00103274    0.00163166    0.000317339\n44  -0.0404226    -0.0150374     0.0122555    -0.00944404    0.0105142     0.000430679  -0.00492254   -0.0094228     0.0056596     0.000305474  -0.00401212    0.00405241    0.00754805   -0.0016228    -0.00720144    0.000628635   0.00159903   -0.00156151    0.00249425\n45   0.019093      0.0161417    -0.0106445     0.00289789   -0.00179217   -0.00983076    0.00218895    0.00481717    0.0085834    -0.00607766    0.000501381  -0.00255306   -0.000130565   0.00217908    0.00346562   -0.000368367   0.00076262   -0.000891547   0.00282931\n46   0.0260759     0.00663921   -0.0162865    -0.000305536   0.011383     -0.00196883   -0.00363319   -0.0036993    -0.00455917   -0.00290846    0.00888095   -0.00789423    0.00304331   -0.00740744    0.00050636   -0.000302411   0.0030843     0.00049445   -0.00284163\n47  -0.0221746    -0.0199404     0.000534764   0.00477627    0.0141621     0.000433482   0.000167613   0.00463961   -0.00399233    0.00393828   -0.000758662  -0.00181117    0.00373518   -0.00279076   -0.000500963   0.00307397    0.0025922    -0.00118273   -0.00313347\n48  -0.0550543     0.0363964    -0.00742737    0.00509457    0.00478327    0.00596863    0.0123141     0.00319395    0.00032336    0.00227062    0.00182639    0.0089813    -0.00131728    0.00282792   -0.00285173    0.000575806   0.000630176   0.00142055   -0.000739086\n49   0.00913939   -0.0112506     0.00275407   -0.000108444   0.0175965    -0.00720219    0.0028736    -0.00852751   -0.00367575    0.00224067    0.00306352    0.00371249   -0.0013583    -0.00438014    0.00156735    0.00259369   -0.00342623    0.00252017   -0.000817948\n50  -0.00233578   -0.0202756     0.0265616     0.0127293    -0.0118266     0.00893602    0.00197975    0.00795907    0.00501867    0.00222461    0.00222965   -0.00193209    0.00671279    0.000512806  -0.000123589   0.00127378   -0.00139443    0.001997     -0.0018316\n51  -0.0153559    -0.0100082     0.0139632     0.00493122   -0.0222626     0.000493596   0.00833022   -0.0038709     0.00743823   -0.00699599   -0.0016895     0.00127742    0.00430974   -0.00836289    0.00714681    0.00356698   -0.000744286   0.000825278   0.00269039\n52   0.0263224    -0.017408     -0.0229181    -0.00281498    0.00866802   -0.0019128     0.00195427    0.00439744   -0.00584011    0.00819845    0.000279562   0.000429365  -0.000174549   0.00240462    0.00358596    0.00083813   -0.00110688   -0.000486164   0.00155618\n53   0.0340365     0.0249426    -0.000528411   0.00975803    0.0137844     0.0129551     0.00420257   -0.00700206   -0.00177581    0.00589381    0.00212311    0.00317137   -0.00186415    0.00236349    0.00271734   -0.000199331   0.000225671   0.00280694    0.00416741\n54  -0.0117798     0.00903529    0.0387701     0.00454727   -0.00907697   -0.00488634   -0.00773384   -6.19644e-6    0.0089247     0.00618783   -0.00347535   -0.00495008   -0.000644665   0.00498122    0.00158708   -0.000299986   0.00137401   -0.00415685    0.00151692\n55   0.040961     -0.0047418    -0.00467653    0.0299573    -0.010076     -0.00532661   -0.00871529    0.0040513    -0.00358455   -0.00462993    0.00250156    0.00223835    0.0054579     0.00519887   -0.000305873   0.000448611  -0.00211423    0.00125517   -0.00247527\n56   0.0102925     0.013984      0.000812639  -0.00373706   -0.00349584    0.0124504    -0.00441857   -0.0044716     0.00140511    0.00328495    0.00684282   -0.00884618    0.0042292     0.00577289   -0.00200728    0.00248224    0.00354552    0.00261187    0.00147238\n57   0.0477407     1.14678e-5   -0.00662024    0.00219729    0.00430952   -0.00449388    0.00119093    0.000191644   0.00325373    0.00379379   -0.000464058  -0.00390622    0.00283012    0.00361447   -0.000321092   0.000398221  -0.00180963   -0.00322221    0.00339463\n58   0.0399973    -0.0189741    -0.0247896     0.0297376    -0.013145     -0.00537322    0.000798352  -0.00376624   -0.00048942    0.0013669    -0.00261489    0.00622029   -0.00186308   -0.00227817   -0.00329716    6.72505e-6    0.00269157   -0.00133317    0.000372921\n59  -0.00330724    0.000903053   0.00809613   -0.00496936    0.00629712   -0.00809498    0.00396068    0.0024341     0.00266899   -0.00182288   -0.00357433    0.00138473    0.00143361   -0.00171682   -0.00717317   -0.00423229   -0.00252162    0.00019209    0.000617265\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nImportance of components:\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n                                 PC1        PC2        PC3         PC4         PC5         PC6         PC7         PC8         PC9        PC10        PC11         PC12         PC13         PC14         PC15         PC16         PC17         PC18        PC19\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nSS Loadings (Eigenvalues)  0.0571665  0.0189413  0.0127985  0.00692343  0.00559569  0.00374975  0.00277789  0.00221675  0.00204783  0.00136863  0.00118197  0.000853869  0.000786129  0.000575358  0.000561562  0.000342726  0.000253164  0.000229252  0.00020354\nVariance explained         0.477945   0.15836    0.107003   0.0578838   0.0467831   0.0313501   0.0232248   0.0185333   0.017121    0.0114425   0.00988197  0.00713883   0.00657249   0.00481032   0.00469498   0.00286538   0.00211659   0.00191668   0.00170171\nCumulative variance        0.477945   0.636305   0.743308   0.801192    0.847975    0.879325    0.90255     0.921083    0.938204    0.949647    0.959528    0.966667     0.97324      0.97805      0.982745     0.98561      0.987727     0.989644     0.991345\nProportion explained       0.482117   0.159743   0.107937   0.0583891   0.0471916   0.0316238   0.0234275   0.0186951   0.0172705   0.0115424   0.00996824  0.00720116   0.00662987   0.00485231   0.00473597   0.0028904    0.00213507   0.00193341   0.00171657\nCumulative proportion      0.482117   0.64186    0.749797   0.808186    0.855378    0.887002    0.910429    0.929124    0.946395    0.957937    0.967905    0.975106     0.981736     0.986589     0.991325     0.994215     0.99635      0.998283     1.0\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Now let‚Äôs show explained variance of each principal component. plot(principalvars(fp), title=\"explained variance\", label=\"Tangent PCA\") The next plot shows how projections on the first two pricipal components look like. fig = plot(; title=\"coordinates per gesture of the first two principal components\")\nfor label_num in [0, 1]\n    mask = hand_labels .== label_num\n    cur_hand_logs = red_coords[:, mask]\n    cur_t = MultivariateStats.transform(fp, cur_hand_logs)\n    scatter!(fig, cur_t[1, :], cur_t[2, :], label=\"gesture \" * string(label_num))\nend\nxlabel!(fig, \"principal component 1\")\nylabel!(fig, \"principal component 2\")\nfig The following heatmap displays pairwise distances between gestures. We can use them for clustering, classification, etc. hand_distances = [\n    distance(Mshape, hands_projected[i], hands_projected[j]) for\n    i in eachindex(hands_projected), j in eachindex(hands_projected)\n]\nheatmap(hand_distances, aspect_ratio=:equal)"},{"id":1896,"pagetitle":"integrate on manifolds and handle probability densities","title":"Integration","ref":"/manifolds/stable/tutorials/#Integration","content":" Integration This part of documentation covers integration of scalar functions defined on manifolds  $f \\colon \\mathcal{M} \\to ‚Ñù$ : \\[\\int_{\\mathcal M} f(p) \\mathrm{d}p\\] The basic concepts are derived from geometric measure theory. In principle, there are many ways in which a manifold can be equipped with a measure that can be later used to define an integral. One of the most popular ways is based on pushing the Lebesgue measure on a tangent space through the exponential map. Any other suitable atlas could be used, not just the one defined by normal coordinates, though each one requires different volume density corrections due to the Jacobian determinant of the pushforward.  Manifolds.jl  provides the function  volume_density  that calculates that quantity, denoted  $\\theta_p(X)$ . See for example [ BP19 ], Definition 11, for a precise description using Jacobi fields. While many sources define volume density as a function of two points,  Manifolds.jl  decided to use the more general point-tangent vector formulation. The two-points variant can be implemented as using Manifolds\nvolume_density_two_points(M::AbstractManifold, p, q) = volume_density(M, p, log(M, p, q)) volume_density_two_points (generic function with 1 method) The simplest way to of integrating a function on a compact manifold is through a  üìñ Monte Carlo integrator . A simple variant can be implemented as follows (assuming uniform distribution of  rand ): using LinearAlgebra, Distributions, SpecialFunctions\nfunction simple_mc_integrate(M::AbstractManifold, f; N::Int = 1000)\n    V = manifold_volume(M)\n    sum = 0.0\n    q = rand(M)\n    for i in 1:N\n        sum += f(M, q)\n        rand!(M, q)\n    end\n    return V * sum/N\nend simple_mc_integrate (generic function with 1 method) We used the function  manifold_volume  to get the volume of the set over which the integration is performed, as described in the linked Wikipedia article."},{"id":1897,"pagetitle":"integrate on manifolds and handle probability densities","title":"Distributions","ref":"/manifolds/stable/tutorials/#Distributions","content":" Distributions We will now try to verify that volume density correction correctly changes probability density of an exponential-wrapped normal distribution.  pdf_tangent_space  (defined in the next code block) represents probability density of a normally distributed random variable  $X_T$  in the tangent space  $T_p \\mathcal{M}$ . Its probability density (with respect to the Lebesgue measure of the tangent space) is  $f_{X_T}\\colon T_p \\mathcal{M} \\to ‚Ñù$ . pdf_manifold  (defined below) refers to the probability density of the distribution  $X_M$  from the tangent space  $T_p \\mathcal{M}$  wrapped using exponential map on the manifold. The formula for probability density with respect to pushforward measure of the Lebesgue measure in the tangent space reads \\[f_{X_M}(q) = \\sum_{X \\in T_p\\mathcal{M}, \\exp_p(X)=q} \\frac{f_{X_T}(X)}{\\theta_p(X)}\\] volume_density  function calculates the correction  $\\theta_p(X)$ . function pdf_tangent_space(M::AbstractManifold, p)\n    return pdf(MvNormal(zeros(manifold_dimension(M)), 0.2*I), p)\nend\n\nfunction pdf_manifold(M::AbstractManifold, q)\n    p = [1.0, 0.0, 0.0]\n    X = log(M, p, q)\n    Xc = get_coordinates(M, p, X, DefaultOrthonormalBasis())\n    vd = abs(volume_density(M, p, X))\n    if vd > eps()\n        return pdf_tangent_space(M, Xc) / vd\n    else\n        return 0.0\n    end\nend\n\nprintln(simple_mc_integrate(Sphere(2), pdf_manifold; N=1000000)) 0.9965059815382356 The function  simple_mc_integrate , defined in the previous section, is used to verify that the density integrates to 1 over the manifold. Note that our  pdf_manifold  implements a simplified version of  $f_{X_M}$  which assumes that the probability mass of  pdf_tangent_space  outside of (local) injectivity radius at  $p$  is negligible. In such case there is only one non-zero summand in the formula for  $f_{X_M}(q)$ , namely  $X=\\log_p(q)$ . Otherwise we would have to consider other vectors  $Y\\in T_p \\mathcal{M}$  such that  $\\exp_p(Y) = q$  in that sum. Remarkably, exponential-wrapped distributions possess three important qualities [ CLLD22 ]: Densities of  $X_M$  are explicit. There is no normalization constant that needs to be computed like in truncated distributions. Sampling from  $X_M$  is easy. It suffices to get a sample from  $X_T$  and pass it to the exponential map. If mean of  $X_T$  is 0, then there is a simple correspondence between moments of  $X_M$  and  $X_T$ , for example  $p$  is the mean of  $X_M$ ."},{"id":1898,"pagetitle":"integrate on manifolds and handle probability densities","title":"Kernel density estimation","ref":"/manifolds/stable/tutorials/#Kernel-density-estimation","content":" Kernel density estimation We can also make a Pelletier‚Äôs isotropic kernel density estimator. Given points  $p_1, p_2, \\dots, p_n$  on  $d$ -dimensional manifold  $\\mathcal M$  the density at point  $q$  is defined as \\[f(q) = \\frac{1}{n h^d} \\sum_{i=1}^n \\frac{1}{\\theta_q(\\log_q(p_i))}K\\left( \\frac{d(q, p_i)}{h} \\right),\\] where  $h$  is the bandwidth, a small positive number less than the injectivity radius of  $\\mathcal M$  and  $K\\colon‚Ñù\\to‚Ñù$  is a kernel function. Note that Pelletier‚Äôs estimator can only use radially-symmetric kernels. The radially symmetric multivariate Epanechnikov kernel used in the example below is described in [ LW19 ]. struct PelletierKDE{TM<:AbstractManifold,TPts<:AbstractVector}\n    M::TM\n    bandwidth::Float64\n    pts::TPts\nend\n\n(kde::PelletierKDE)(::AbstractManifold, p) = kde(p)\nfunction (kde::PelletierKDE)(p)\n    n = length(kde.pts)\n    d = manifold_dimension(kde.M)\n    sum_kde = 0.0\n    function epanechnikov_kernel(x)\n        if x < 1\n            return gamma(2+d/2) * (1-x^2)/(œÄ^(d/2))\n        else\n            return 0.0\n        end\n    end\n    for i in 1:n\n        X = log(kde.M, p, kde.pts[i])\n        Xn = norm(kde.M, p, X)\n        sum_kde += epanechnikov_kernel(Xn / kde.bandwidth) / volume_density(kde.M, p, X)\n    end\n    sum_kde /= n * kde.bandwidth^d\n    return sum_kde\nend\n\nM = Sphere(2)\npts = rand(M, 8)\nkde = PelletierKDE(M, 0.7, pts)\nprintln(simple_mc_integrate(Sphere(2), kde; N=1000000))\nprintln(kde(rand(M))) 1.0000204951428087\n0.0"},{"id":1899,"pagetitle":"integrate on manifolds and handle probability densities","title":"Technical notes","ref":"/manifolds/stable/tutorials/#Technical-notes","content":" Technical notes This section contains a few technical notes that are relevant to the problem of integration on manifolds but can be freely skipped on the first read of the tutorial."},{"id":1900,"pagetitle":"integrate on manifolds and handle probability densities","title":"Conflicting statements about volume of a manifold","ref":"/manifolds/stable/tutorials/#Conflicting-statements-about-volume-of-a-manifold","content":" Conflicting statements about volume of a manifold manifold_volume  and  volume_density  are closely related to each other, though very few sources explore this connection, and some even claiming a certain level of arbitrariness in defining  manifold_volume . Volume is sometimes considered arbitrary because Riemannian metrics on some spaces like the manifold of rotations are defined with arbitrary constants. However, once a constant is picked (and it must be picked before any useful computation can be performed), all geometric operations must follow in a consistent way: inner products, exponential and logarithmic maps, volume densities, etc.  Manifolds.jl  consistently picks such constants and provides a unified framework, though it sometimes results in picking a different constant than what is the most popular in some sub-communities."},{"id":1901,"pagetitle":"integrate on manifolds and handle probability densities","title":"Haar measures","ref":"/manifolds/stable/tutorials/#Haar-measures","content":" Haar measures On Lie groups the situation regarding integration is more complicated. Invariance under left or right group action is a desired property that leads one to consider Haar measures [ Tor20 ]. It is, however, unclear what are the practical benefits of considering Haar measures over the Lebesgue measure of the underlying manifold, which often turns out to be invariant anyway."},{"id":1902,"pagetitle":"integrate on manifolds and handle probability densities","title":"Integration in charts","ref":"/manifolds/stable/tutorials/#Integration-in-charts","content":" Integration in charts Integration through charts is an approach currently not supported by  Manifolds.jl . One has to define a suitable set of disjoint charts covering the entire manifold and use a method for multivariate Euclidean integration. Note that ranges of parameters have to be adjusted for each manifold and scaling based on the metric needs to be applied. See [ BST03 ] for some considerations on symmetric spaces."},{"id":1903,"pagetitle":"integrate on manifolds and handle probability densities","title":"References","ref":"/manifolds/stable/tutorials/#References","content":" References"},{"id":1904,"pagetitle":"integrate on manifolds and handle probability densities","title":"Literature","ref":"/manifolds/stable/tutorials/#Literature","content":" Literature [BST03] L.¬†J.¬†Boya, E.¬†Sudarshan and T.¬†Tilma.  Volumes of compact manifolds .  Reports¬†on¬†Mathematical¬†Physics  52 , 401‚Äì422  (2003). [BP19] A.¬†L.¬†Brigant and S.¬†Puechmorel.  Approximation of Densities on Riemannian Manifolds .  Entropy  21 , 43  (2019). [CLLD22] E.¬†Chevallier, D.¬†Li, Y.¬†Lu and D.¬†B.¬†Dunson.  Exponential-wrapped distributions on symmetric spaces . ArXiv¬†Preprint (2022). [LW19] N.¬†Langren√© and X.¬†Warin.  Fast and Stable Multivariate Kernel Density Estimation by Fast Sum Updating .  Journal¬†of¬†Computational¬†and¬†Graphical¬†Statistics  28 , 596‚Äì608  (2019). [Tor20] S.¬†Tornier.  Haar Measures  (2020)."},{"id":1907,"pagetitle":"work in charts","title":"Working in charts","ref":"/manifolds/stable/tutorials/#Working-in-charts","content":" Working in charts In this tutorial we will learn how to use charts for basic geometric operations like exponential map, logarithmic map and parallel transport. There are two conceptually different approaches to working on a manifold: working in charts and chart-free representations. The first one, widespread in differential geometry textbooks, is based on defining an atlas on the manifold and performing computations in selected charts. This approach, while generic, is not ideally suitable in all circumstances. For example, working in charts that do not cover the entire manifold causes issues with having to switch charts when operating on a manifold. The second one is beneficial if there exists a representation of points and tangent vectors for a manifold which allows for efficient closed-form formulas for standard functions like the exponential map or Riemannian distance in this representation. These computations are then chart-free.  Manifolds.jl  supports both approaches, although the chart-free approach is the main focus of the library. In this tutorial we focus on chart-based computation. using Manifolds, RecursiveArrayTools, OrdinaryDiffEq, DiffEqCallbacks, BoundaryValueDiffEq The manifold we consider is the  M  is the torus in form of the  EmbeddedTorus , that is the representation defined as a surface of revolution of a circle of radius 2 around a circle of radius 3. The atlas we will perform computations in is its  DefaultTorusAtlas A , consistting of a family of charts indexed by two angles, that specify the base point of the chart. We will draw geodesics time between  0  and  t_end , and then sample the solution at multiples of  dt  and draw a line connecting sampled points. M = Manifolds.EmbeddedTorus(3, 2)\nA = Manifolds.DefaultTorusAtlas() Manifolds.DefaultTorusAtlas()"},{"id":1908,"pagetitle":"work in charts","title":"Setup","ref":"/manifolds/stable/tutorials/#Setup","content":" Setup We will first set up our plot with an empty torus.  param_points  are points on the surface of the torus that will be used for basic surface shape in  Makie.jl . The torus will be colored according to its Gaussian curvature stored in  gcs . We later want to have a color scale that has negative curvature blue, zero curvature white and positive curvature red so  gcs_mm  is the largest absolute value of the curvature that will be needed to properly set range of curvature values. In the documentation this tutorial represents a static situation (without interactivity).  Makie.jl  rendering is turned off. # using GLMakie, Makie\n# GLMakie.activate!()\n\n\"\"\"\n    torus_figure()\n\nThis function generates a simple plot of a torus and returns the new figure containing the plot.\n\"\"\"\nfunction torus_figure()\n    fig = Figure(resolution=(1400, 1000), fontsize=16)\n    ax = LScene(fig[1, 1], show_axis=true)\n    œ¥s, œÜs = LinRange(-œÄ, œÄ, 50), LinRange(-œÄ, œÄ, 50)\n    param_points = [Manifolds._torus_param(M, Œ∏, œÜ) for Œ∏ in œ¥s, œÜ in œÜs]\n    X1, Y1, Z1 = [[p[i] for p in param_points] for i in 1:3]\n    gcs = [gaussian_curvature(M, p) for p in param_points]\n    gcs_mm = max(abs(minimum(gcs)), abs(maximum(gcs)))\n    pltobj = surface!(\n        ax,\n        X1,\n        Y1,\n        Z1;\n        shading=true,\n        ambient=Vec3f(0.65, 0.65, 0.65),\n        backlight=1.0f0,\n        color=gcs,\n        colormap=Reverse(:RdBu),\n        colorrange=(-gcs_mm, gcs_mm),\n        transparency=true,\n    )\n    wireframe!(ax, X1, Y1, Z1; transparency=true, color=:gray, linewidth=0.5)\n    zoom!(ax.scene, cameracontrols(ax.scene), 0.98)\n    Colorbar(fig[1, 2], pltobj, height=Relative(0.5), label=\"Gaussian curvature\")\n    return ax, fig\nend torus_figure"},{"id":1909,"pagetitle":"work in charts","title":"Values for the geodesic","ref":"/manifolds/stable/tutorials/#Values-for-the-geodesic","content":" Values for the geodesic solve_for  is a helper function that solves a parallel transport along geodesic problem on the torus  M .  p0x  is the  $(\\theta, \\varphi)$  parametrization of the point from which we will transport the vector. We first calculate the coordinates in the embedding of  p0x  and store it as  p , and then get the initial chart from atlas  A  appropriate for starting working at point  p . The vector we transport has coordinates  Y_transp  in the induced tangent space basis of chart  i_p0x . The function returns the full solution to the parallel transport problem, containing the sequence of charts that was used and solutions of differential equations computed using  OrdinaryDiffEq . bvp_i  is needed later for a different purpose, it is the chart index we will use for solving the logarithmic map boundary value problem in. Next we solve the vector transport problem  solve_for([Œ∏‚Çö, œÜ‚Çö], [Œ∏‚Çì, œÜ‚Çì], [Œ∏y, œÜy]) , sample the result at the selected time steps and store the result in  geo . The solution includes the geodesic which we extract and convert to a sequence of points digestible by  Makie.jl ,  geo_ps .  [Œ∏‚Çö, œÜ‚Çö]  is the parametrization in chart (0, 0) of the starting point of the geodesic. The direction of the geodesic is determined by  [Œ∏‚Çì, œÜ‚Çì] , coordinates of the tangent vector at the starting point expressed in the induced basis of chart  i_p0x  (which depends on the initial point). Finally,  [Œ∏y, œÜy]  are the coordinates of the tangent vector that will be transported along the geodesic, which are also expressed in same basis as  [Œ∏‚Çì, œÜ‚Çì] . We won‚Äôt draw the transported vector at every point as there would be too many arrows, which is why we select every 100th point only for that purpose with  pt_indices . Then,  geo_ps_pt  contains points at which the transported vector is tangent to and  geo_Ys  the transported vector at that point, represented in the embedding. The logarithmic map will be solved between points with parametrization  bvp_a1  and  bvp_a2  in chart  bvp_i . The result is assigned to variable  bvp_sol  and then sampled with time step 0.05. The result of this sampling is converted from parameters in chart  bvp_i  to point in the embedding and stored in  geo_r . function solve_for(p0x, X_p0x, Y_transp, T)\n    p = [Manifolds._torus_param(M, p0x...)...]\n    i_p0x = Manifolds.get_chart_index(M, A, p)\n    p_exp = Manifolds.solve_chart_parallel_transport_ode(\n        M,\n        [0.0, 0.0],\n        X_p0x,\n        A,\n        i_p0x,\n        Y_transp;\n        final_time=T,\n    )\n    return p_exp\nend;"},{"id":1910,"pagetitle":"work in charts","title":"Solving parallel Transport ODE","ref":"/manifolds/stable/tutorials/#Solving-parallel-Transport-ODE","content":" Solving parallel Transport ODE We set the end time  t_end  and time step  dt . t_end = 2.0\ndt = 1e-1 0.1 We also parametrise the start point and direction. Œ∏‚Çö = œÄ/10\nœÜ‚Çö = -œÄ/4\nŒ∏‚Çì = œÄ/2\nœÜ‚Çì = 0.7\nŒ∏y = 0.2\nœÜy = -0.1\n\ngeo = solve_for([Œ∏‚Çö, œÜ‚Çö], [Œ∏‚Çì, œÜ‚Çì], [Œ∏y, œÜy], t_end)(0.0:dt:t_end);\n# geo_ps = [Point3f(s[1]) for s in geo]\n# pt_indices = 1:div(length(geo), 10):length(geo)\n# geo_ps_pt = [Point3f(s[1]) for s in geo[pt_indices]]\n# geo_Ys = [Point3f(s[3]) for s in geo[pt_indices]]\n\n# ax1, fig1 = torus_figure()\n# arrows!(ax1, geo_ps_pt, geo_Ys, linewidth=0.05, color=:blue)\n# lines!(geo_ps; linewidth=4.0, color=:green)\n# fig1 fig-pt"},{"id":1911,"pagetitle":"work in charts","title":"Solving the logarithmic map ODE","ref":"/manifolds/stable/tutorials/#Solving-the-logarithmic-map-ODE","content":" Solving the logarithmic map ODE Œ∏‚ÇÅ=œÄ/2\nœÜ‚ÇÅ=-1.0\nŒ∏‚ÇÇ=-œÄ/8\nœÜ‚ÇÇ=œÄ/2\n\nbvp_i = (0, 0)\nbvp_a1 = [Œ∏‚ÇÅ, œÜ‚ÇÅ]\nbvp_a2 = [Œ∏‚ÇÇ, œÜ‚ÇÇ]\nbvp_sol = Manifolds.solve_chart_log_bvp(M, bvp_a1, bvp_a2, A, bvp_i);\n# geo_r = [Point3f(get_point(M, A, bvp_i, p[1:2])) for p in bvp_sol(0.0:0.05:1.0)]\n\n# ax2, fig2 = torus_figure()\n# lines!(geo_r; linewidth=4.0, color=:green)\n# fig2 fig-geodesic An interactive Pluto version of this tutorial is available in file  tutorials/working-in-charts.jl ."},{"id":1914,"pagetitle":"Home","title":"Welcome to Manopt.jl","ref":"/manopt/stable/#Welcome-to-Manopt.jl","content":" Welcome to Manopt.jl"},{"id":1915,"pagetitle":"Home","title":"Manopt.Manopt","ref":"/manopt/stable/#Manopt.Manopt","content":" Manopt.Manopt  ‚Äî  Module üèîÔ∏è Manopt.jl: optimization on Manifolds in Julia. üìö Documentation:  manoptjl.org üì¶ Repository:  github.com/JuliaManifolds/Manopt.jl üí¨ Discussions:  github.com/JuliaManifolds/Manopt.jl/discussions üéØ Issues:  github.com/JuliaManifolds/Manopt.jl/issues source For a function  $f:\\mathcal M ‚Üí ‚Ñù$  defined on a  Riemannian manifold $\\mathcal M$  algorithms in this package aim to solve \\[\\operatorname*{argmin}_{p ‚àà \\mathcal M} f(p),\\] or in other words: find the point  $p$  on the manifold, where  $f$  reaches its minimal function value. Manopt.jl  provides a framework for optimization on manifolds as well as a Library of optimization algorithms in  Julia . It belongs to the ‚ÄúManopt family‚Äù, which includes  Manopt  (Matlab) and  pymanopt.org  (Python). If you want to delve right into  Manopt.jl  read the  üèîÔ∏è Get started: optimize.  tutorial. Manopt.jl  makes it easy to use an algorithm for your favourite manifold as well as a manifold for your favourite algorithm. It already provides many manifolds and algorithms, which can easily be enhanced, for example to  record  certain data or  debug output  throughout iterations. If you use  Manopt.jl in your work, please cite the following @article{Bergmann2022,\n    Author    = {Ronny Bergmann},\n    Doi       = {10.21105/joss.03866},\n    Journal   = {Journal of Open Source Software},\n    Number    = {70},\n    Pages     = {3866},\n    Publisher = {The Open Journal},\n    Title     = {Manopt.jl: Optimization on Manifolds in {J}ulia},\n    Volume    = {7},\n    Year      = {2022},\n} To refer to a certain version or the source code in general cite for example @software{manoptjl-zenodo-mostrecent,\n    Author    = {Ronny Bergmann},\n    Copyright = {MIT License},\n    Doi       = {10.5281/zenodo.4290905},\n    Publisher = {Zenodo},\n    Title     = {Manopt.jl},\n    Year      = {2024},\n} for the most recent version or a corresponding version specific DOI, see  the list of all versions . If you are also using  Manifolds.jl  please consider to cite @article{AxenBaranBergmannRzecki:2023,\n    AUTHOR    = {Axen, Seth D. and Baran, Mateusz and Bergmann, Ronny and Rzecki, Krzysztof},\n    ARTICLENO = {33},\n    DOI       = {10.1145/3618296},\n    JOURNAL   = {ACM Transactions on Mathematical Software},\n    MONTH     = {dec},\n    NUMBER    = {4},\n    TITLE     = {Manifolds.Jl: An Extensible Julia Framework for Data Analysis on Manifolds},\n    VOLUME    = {49},\n    YEAR      = {2023}\n} Note that both citations are in  BibLaTeX  format."},{"id":1916,"pagetitle":"Home","title":"Main features","ref":"/manopt/stable/#Main-features","content":" Main features"},{"id":1917,"pagetitle":"Home","title":"Optimization algorithms (solvers)","ref":"/manopt/stable/#Optimization-algorithms-(solvers)","content":" Optimization algorithms (solvers) For every optimization algorithm, a  solver  is implemented based on a  AbstractManoptProblem  that describes the problem to solve and its  AbstractManoptSolverState  that set up the solver, and stores values that are required between or for the next iteration. Together they form a  plan ."},{"id":1918,"pagetitle":"Home","title":"Manifolds","ref":"/manopt/stable/#Manifolds","content":" Manifolds This project is build upon  ManifoldsBase.jl , a generic interface to implement manifolds. Certain functions are extended for specific manifolds from  Manifolds.jl , but all other manifolds from that package can be used here, too. The notation in the documentation aims to follow the same  notation  from these packages."},{"id":1919,"pagetitle":"Home","title":"Visualization","ref":"/manopt/stable/#Visualization","content":" Visualization To visualize and interpret results,  Manopt.jl  aims to provide both easy plot functions as well as  exports . Furthermore a system to get  debug  during the iterations of an algorithms as well as  record  capabilities, for example to record a specified tuple of values per iteration, most prominently  RecordCost  and  RecordIterate . Take a look at the  üèîÔ∏è Get started: optimize.  tutorial on how to easily activate this."},{"id":1920,"pagetitle":"Home","title":"Literature","ref":"/manopt/stable/#Literature","content":" Literature If you want to get started with manifolds, one book is [ Car92 ], and if you want do directly dive into optimization on manifolds, good references are [ AMS08 ] and [ Bou23 ], which are both available online for free [AMS08] P.-A.¬†Absil, R.¬†Mahony and R.¬†Sepulchre.  Optimization Algorithms on Matrix Manifolds  (Princeton University Press, 2008), available online at  press.princeton.edu/chapters/absil/ . [Bou23] N.¬†Boumal.  An Introduction to Optimization on Smooth Manifolds . First¬†Edition ( Cambridge University Press, 2023 ). [Car92] M.¬†P.¬†do¬†Carmo.  Riemannian Geometry .  Mathematics: Theory & Applications  (Birkh√§user Boston, Inc., Boston, MA, 1992); p.¬†xiv+300."},{"id":1923,"pagetitle":"About","title":"About","ref":"/manopt/stable/about/#About","content":" About Manopt.jl inherited its name from  Manopt , a Matlab toolbox for optimization on manifolds. This Julia package was started and is currently maintained by  Ronny Bergmann . The following people contributed Constantin Ahlmann-Eltze  implemented the  gradient and differential  check  functions Ren√©e Dornig  implemented the  particle swarm , the  Riemannian Augmented Lagrangian Method , the  Exact Penalty Method , as well as the  NonmonotoneLinesearch Willem Diepeveen  implemented the  primal-dual Riemannian semismooth Newton  solver. Hajg Jasa  implemented the  convex bundle method  and the  proximal bundle method . Even Stephansen Kjems√•s contributed to the implementation of the  Frank Wolfe Method  solver Mathias Ravn Munkvold contributed most of the implementation of the  Adaptive Regularization with Cubics  solver Tom-Christian Riemer  implemented the  trust regions  and  quasi Newton  solvers. Manuel Weiss  implemented most of the  conjugate gradient update rules as well as various  contributors  providing small extensions, finding small bugs and mistakes and fixing them by opening  PR s. If you want to contribute a manifold or algorithm or have any questions, visit the  GitHub repository  to clone/fork the repository or open an issue."},{"id":1924,"pagetitle":"About","title":"further packages","ref":"/manopt/stable/about/#further-packages","content":" further packages Manopt.jl  belongs to the Manopt family: manopt.org  The Matlab version of Manopt, see also their :octocat:  GitHub repository pymanopt.org  The Python version of Manopt providing also several AD backends, see also their :octocat:  GitHub repository but there are also more packages providing tools on manifolds: Jax Geometry  (Python/Jax) for differential geometry and stochastic dynamics with deep learning Geomstats  (Python with several backends) focusing on statistics and machine learning :octocat:  GitHub repository Geoopt  (Python & PyTorch) Riemannian ADAM & SGD. :octocat:  GitHub repository McTorch  (Python & PyToch) Riemannian SGD, Adagrad, ASA & CG. ROPTLIB  (C++) a Riemannian OPTimization LIBrary :octocat:  GitHub repository TF Riemopt  (Python & TensorFlow) Riemannian optimization using TensorFlow"},{"id":1927,"pagetitle":"Changelog","title":"Changelog","ref":"/manopt/stable/changelog/#Changelog","content":" Changelog All notable Changes to the Julia package  Manopt.jl  will be documented in this file. The file was started with Version  0.4 . The format is based on  Keep a Changelog , and this project adheres to  Semantic Versioning ."},{"id":1928,"pagetitle":"Changelog","title":"[0.4.58] - March 18, 2024","ref":"/manopt/stable/changelog/#[0.4.58]-March-18,-2024","content":" [0.4.58] - March 18, 2024"},{"id":1929,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added","content":" Added more advanced methods to add debug to the beginning of an algorithm, a step, or the end of the algorithm with  DebugAction  entries at  :Start ,  :BeforeIteration ,  :Iteration , and  :Stop , respectively. Introduce a Pair-based format to add elements to these hooks, while all others ar now added to :Iteration (no longer to  :All ) (planned) add an easy possibility to also record the initial stage and not only after the first iteration."},{"id":1930,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed","content":" Changed Changed the symbol for the  :Step  dictionary to be  :Iteration , to unify this with the symbols used in recording, and removed the  :All  symbol. On the fine granular scale, all but  :Start  debugs are now reset on init. Since these are merely internal entries in the debug dictionary, this is considered non-breaking. introduce a  StopWhenSwarmVelocityLess  stopping criterion for  particle_swarm  replacing the current default of the swarm change, since this is a bit more effective to compute"},{"id":1931,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed","content":" Fixed fixed the outdated documentation of  TruncatedConjugateGradientState , that now correcly state that  p  is no longer stored, but the algorithm runs on  TpM . implemented the missing  get_iterate  for  TruncatedConjugateGradientState ."},{"id":1932,"pagetitle":"Changelog","title":"[0.4.57] - March 15, 2024","ref":"/manopt/stable/changelog/#[0.4.57]-March-15,-2024","content":" [0.4.57] - March 15, 2024"},{"id":1933,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-2","content":" Changed convex_bundle_method  uses the  sectional_curvature  from  ManifoldsBase.jl . convex_bundle_method  no longer has the unused  k_min  keyword argument. ManifoldsBase.jl  now is running on Documenter 1.3,  Manopt.jl  documentation now uses  DocumenterInterLinks  to refer to sections and functions from  ManifoldsBase.jl"},{"id":1934,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-2","content":" Fixed fixes a type that when passing  sub_kwargs  to  trust_regions  caused an error in the decoration of the sub objective."},{"id":1935,"pagetitle":"Changelog","title":"[0.4.56] - March 4, 2024","ref":"/manopt/stable/changelog/#[0.4.56]-March-4,-2024","content":" [0.4.56] - March 4, 2024"},{"id":1936,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-2","content":" Added The option  :step_towards_negative_gradient  for  nondescent_direction_behavior  in quasi-Newton solvers does no longer emit a warning by default. This has been moved to a  message , that can be accessed/displayed with  DebugMessages DebugMessages  now has a second positional argument, specifying whether all messages, or just the first ( :Once ) should be displayed."},{"id":1937,"pagetitle":"Changelog","title":"[0.4.55] - March 3, 2024","ref":"/manopt/stable/changelog/#[0.4.55]-March-3,-2024","content":" [0.4.55] - March 3, 2024"},{"id":1938,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-3","content":" Added Option  nondescent_direction_behavior  for quasi-Newton solvers. By default it checks for non-descent direction which may not be handled well by some stepsize selection algorithms."},{"id":1939,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-3","content":" Fixed unified documentation, especially function signatures further. fixed a few typos related to math formulae in the doc strings."},{"id":1940,"pagetitle":"Changelog","title":"[0.4.54] - February 28, 2024","ref":"/manopt/stable/changelog/#[0.4.54]-February-28,-2024","content":" [0.4.54] - February 28, 2024"},{"id":1941,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-4","content":" Added convex_bundle_method  optimization algorithm for non-smooth geodesically convex functions proximal_bundle_method  optimization algorithm for non-smooth functions. StopWhenSubgradientNormLess ,  StopWhenLagrangeMultiplierLess , and stopping criteria."},{"id":1942,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-4","content":" Fixed Doc strings now follow a  vale.sh  policy. Though this is not fully working, this PR improves a lot of the doc strings concerning wording and spelling."},{"id":1943,"pagetitle":"Changelog","title":"[0.4.53] - February 13, 2024","ref":"/manopt/stable/changelog/#[0.4.53]-February-13,-2024","content":" [0.4.53] - February 13, 2024"},{"id":1944,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-5","content":" Fixed fixes two storage action defaults, that accidentally still tried to initialize a  :Population  (as modified back to  :Iterate  0.4.49). fix a few typos in the documentation and add a reference for the subgradient menthod."},{"id":1945,"pagetitle":"Changelog","title":"[0.4.52] - February 5, 2024","ref":"/manopt/stable/changelog/#[0.4.52]-February-5,-2024","content":" [0.4.52] - February 5, 2024"},{"id":1946,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-5","content":" Added introduce an environment persistent way of setting global values with the  set_manopt_parameter!  function using  Preferences.jl . introduce such a value named  :Mode  to enable a  \"Tutorial\"  mode that shall often provide more warnings and information for people getting started with optimisation on manifolds"},{"id":1947,"pagetitle":"Changelog","title":"[0.4.51] - January 30, 2024","ref":"/manopt/stable/changelog/#[0.4.51]-January-30,-2024","content":" [0.4.51] - January 30, 2024"},{"id":1948,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-6","content":" Added A  StopWhenSubgradientNormLess  stopping criterion for subgradient-based optimization. Allow the  message=  of the  DebugIfEntry  debug action to contain a format element to print the field in the message as well."},{"id":1949,"pagetitle":"Changelog","title":"[0.4.50] - January 26, 2024","ref":"/manopt/stable/changelog/#[0.4.50]-January-26,-2024","content":" [0.4.50] - January 26, 2024"},{"id":1950,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-6","content":" Fixed Fix Quasi Newton on complex manifolds."},{"id":1951,"pagetitle":"Changelog","title":"[0.4.49] - January 18, 2024","ref":"/manopt/stable/changelog/#[0.4.49]-January-18,-2024","content":" [0.4.49] - January 18, 2024"},{"id":1952,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-7","content":" Added A  StopWhenEntryChangeLess  to be able to stop on arbitrary small changes of specific fields generalises  StopWhenGradientNormLess  to accept arbitrary  norm=  functions refactor the default in  particle_swarm  to no longer ‚Äúmisuse‚Äù the iteration change check, but actually the new one one the  :swarm  entry"},{"id":1953,"pagetitle":"Changelog","title":"[0.4.48] - January 16, 2024","ref":"/manopt/stable/changelog/#[0.4.48]-January-16,-2024","content":" [0.4.48] - January 16, 2024"},{"id":1954,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-7","content":" Fixed fixes an imprecision in the interface of  get_iterate  that sometimes led to the swarm of  particle_swarm  being returned as the iterate. refactor  particle_swarm  in naming and access functions to avoid this also in the future. To access the whole swarm, one now should use  get_manopt_parameter(pss, :Population)"},{"id":1955,"pagetitle":"Changelog","title":"[0.4.47] - January 6, 2024","ref":"/manopt/stable/changelog/#[0.4.47]-January-6,-2024","content":" [0.4.47] - January 6, 2024"},{"id":1956,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-8","content":" Fixed fixed a bug, where the retraction set in  check_Hessian  was not passed on to the optional inner  check_gradient  call, which could lead to unwanted side effects, see  #342 ."},{"id":1957,"pagetitle":"Changelog","title":"[0.4.46] - January 1, 2024","ref":"/manopt/stable/changelog/#[0.4.46]-January-1,-2024","content":" [0.4.46] - January 1, 2024"},{"id":1958,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-3","content":" Changed An error is thrown when a line search from  LineSearches.jl  reports search failure. Changed default stopping criterion in ALM algorithm to mitigate an issue occurring when step size is very small. Default memory length in default ALM subsolver is now capped at manifold dimension. Replaced CI testing on Julia 1.8 with testing on Julia 1.10."},{"id":1959,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-9","content":" Fixed A bug in  LineSearches.jl  extension leading to slower convergence. Fixed a bug in L-BFGS related to memory storage, which caused significantly slower convergence."},{"id":1960,"pagetitle":"Changelog","title":"[0.4.45] - December 28, 2023","ref":"/manopt/stable/changelog/#[0.4.45]-December-28,-2023","content":" [0.4.45] - December 28, 2023"},{"id":1961,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-8","content":" Added Introduce  sub_kwargs  and  sub_stopping_criterion  for  trust_regions  as noticed in  #336"},{"id":1962,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-4","content":" Changed WolfePowellLineSearch ,  ArmijoLineSearch  step sizes now allocate less linesearch_backtrack!  is now available Quasi Newton Updates can work in-place of a direction vector as well. Faster  safe_indices  in L-BFGS."},{"id":1963,"pagetitle":"Changelog","title":"[0.4.44] - December 12, 2023","ref":"/manopt/stable/changelog/#[0.4.44]-December-12,-2023","content":" [0.4.44] - December 12, 2023 Formally one could consider this version breaking, since a few functions have been moved, that in earlier versions (0.3.x) have been used in example scripts. These examples are now available again within  ManoptExamples.jl , and with their ‚Äúreappearance‚Äù the corresponding costs, gradients, differentials, adjoint differentials, and proximal maps have been moved there as well. This is not considered breaking, since the functions were only used in the old, removed examples. Each and every moved function is still documented. They have been partly renamed, and their documentation and testing has been extended."},{"id":1964,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-5","content":" Changed Bumped and added dependencies on all 3 Project.toml files, the main one, the docs/, an the tutorials/ one. artificial_S2_lemniscate  is available as  ManoptExample.Lemniscate  ‚Äì¬†and works on arbitrary manifolds now. artificial_S1_signal  is available as  ManoptExample.artificial_S1_signal artificial_S1_slope_signal  is available as  ManoptExamples.artificial_S1_slope_signal artificial_S2_composite_bezier_curve  is available as  ManoptExamples.artificial_S2_composite_Bezier_curve artificial_S2_rotation_image  is available as  ManoptExamples.artificial_S2_rotation_image artificial_S2_whirl_image  is available as  ManoptExamples.artificial_S2_whirl_image artificial_S2_whirl_patch  is available as  ManoptExamples.artificial_S2_whirl_path artificial_SAR_image  is available as  ManoptExamples.artificial_SAR_image artificial_SPD_image  is available as  ManoptExamples.artificial_SPD_image artificial_SPD_image2  is available as  ManoptExamples.artificial_SPD_image adjoint_differential_forward_logs  is available as  ManoptExamples.adjoint_differential_forward_logs adjoint:differential_bezier_control  is available as  ManoptExamples.adjoint_differential_Bezier_control_points BezierSegment  is available as  ManoptExamples.Bezi√©rSegment cost_acceleration_bezier  is avilable as  ManoptExamples.acceleration_Bezier cost_L2_acceleration_bezier  is available as  ManoptExamples.L2_acceleration_Bezier costIntrICTV12  is available as  ManoptExamples.Intrinsic_infimal_convolution_TV12 costL2TV  is available as  ManoptExamples.L2_Total_Variation costL2TV12  is available as  ManoptExamples.L2_Total_Variation_1_2 costL2TV2  is available as  ManoptExamples.L2_second_order_Total_Variation costTV  is available as  ManoptExamples.Total_Variation costTV2  is available as  ManoptExamples.second_order_Total_Variation de_casteljau  is available as  ManoptExamples.de_Casteljau differential_forward_logs  is available as  ManoptExamples.differential_forward_logs differential_bezier_control  is available as  ManoptExamples.differential_Bezier_control_points forward_logs  is available as  ManoptExamples.forward_logs get_bezier_degree  is available as  ManoptExamples.get_Bezier_degree get_bezier_degrees  is available as  ManoptExamples.get_Bezier_degrees get_Bezier_inner_points  is available as  ManoptExamples.get_Bezier_inner_points get_bezier_junction_tangent_vectors  is available as  ManoptExamples.get_Bezier_junction_tangent_vectors get_bezier_junctions  is available as  ManoptExamples.get_Bezier_junctions get_bezier_points  is available as  ManoptExamples.get_Bezier_points get_bezier_segments  is available as  ManoptExamples.get_Bezier_segments grad_acceleration_bezier  is available as  ManoptExamples.grad_acceleration_Bezier grad_L2_acceleration_bezier  is available as  ManoptExamples.grad_L2_acceleration_Bezier grad_Intrinsic_infimal_convolution_TV12  is available as  ManoptExamples.Intrinsic_infimal_convolution_TV12 ` grad_TV  is available as  ManoptExamples.grad_Total_Variation costIntrICTV12  is available as  ManoptExamples.Intrinsic_infimal_convolution_TV12 project_collaborative_TV  is available as  ManoptExamples.project_collaborative_TV prox_parallel_TV  is available as  ManoptExamples.prox_parallel_TV grad_TV2  is available as  ManoptExamples.prox_second_order_Total_Variation prox_TV  is available as  ManoptExamples.prox_Total_Variation prox_TV2  is available as  ManopExamples.prox_second_order_Total_Variation"},{"id":1965,"pagetitle":"Changelog","title":"[0.4.43] - November 19, 2023","ref":"/manopt/stable/changelog/#[0.4.43]-November-19,-2023","content":" [0.4.43] - November 19, 2023"},{"id":1966,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-9","content":" Added vale.sh as a CI to keep track of a consistent documenttion"},{"id":1967,"pagetitle":"Changelog","title":"[0.4.42] - November 6, 2023","ref":"/manopt/stable/changelog/#[0.4.42]-November-6,-2023","content":" [0.4.42] - November 6, 2023"},{"id":1968,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-10","content":" Added add  Manopt.JuMP_Optimizer  implementing JuMP's solver interface"},{"id":1969,"pagetitle":"Changelog","title":"[0.4.41] - November 2, 2023","ref":"/manopt/stable/changelog/#[0.4.41]-November-2,-2023","content":" [0.4.41] - November 2, 2023"},{"id":1970,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-6","content":" Changed trust_regions  is now more flexible and the sub solver (Steihaug-Toint tCG by default) can now be exchanged. adaptive_regularization_with_cubics  is now more flexible as well, where it previously was a bit too much tightened to the Lanczos solver as well. Unified documentation notation and bumped dependencies to use DocumenterCitations 1.3"},{"id":1971,"pagetitle":"Changelog","title":"[0.4.40] - October 24, 2023","ref":"/manopt/stable/changelog/#[0.4.40]-October-24,-2023","content":" [0.4.40] - October 24, 2023"},{"id":1972,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-11","content":" Added add a  --help  argument to  docs/make.jl  to document all available command line arguments add a  --exclude-tutorials  argument to  docs/make.jl . This way, when quarto is not available on a computer, the docs can still be build with the tutorials not being added to the menu such that documenter does not expect them to exist."},{"id":1973,"pagetitle":"Changelog","title":"Changes","ref":"/manopt/stable/changelog/#Changes","content":" Changes Bump dependencies to  ManifoldsBase.jl  0.15 and  Manifolds.jl  0.9 move the ARC CG subsolver to the main package, since  TangentSpace  is now already available from  ManifoldsBase ."},{"id":1974,"pagetitle":"Changelog","title":"[0.4.39] - October 9, 2023","ref":"/manopt/stable/changelog/#[0.4.39]-October-9,-2023","content":" [0.4.39] - October 9, 2023"},{"id":1975,"pagetitle":"Changelog","title":"Changes","ref":"/manopt/stable/changelog/#Changes-2","content":" Changes also use the pair of a retraction and the inverse retraction (see last update) to perform the relaxation within the Douglas-Rachford algorithm."},{"id":1976,"pagetitle":"Changelog","title":"[0.4.38] - October 8, 2023","ref":"/manopt/stable/changelog/#[0.4.38]-October-8,-2023","content":" [0.4.38] - October 8, 2023"},{"id":1977,"pagetitle":"Changelog","title":"Changes","ref":"/manopt/stable/changelog/#Changes-3","content":" Changes avoid allocations when calling  get_jacobian!  within the Levenberg-Marquard Algorithm."},{"id":1978,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-10","content":" Fixed Fix a lot of typos in the documentation"},{"id":1979,"pagetitle":"Changelog","title":"[0.4.37] - September 28, 2023","ref":"/manopt/stable/changelog/#[0.4.37]-September-28,-2023","content":" [0.4.37] - September 28, 2023"},{"id":1980,"pagetitle":"Changelog","title":"Changes","ref":"/manopt/stable/changelog/#Changes-4","content":" Changes add more of the Riemannian Levenberg-Marquard algorithms parameters as keywords, so they can be changed on call generalize the internal reflection of Douglas-Rachford, such that is also works with an arbitrary pair of a reflection and an inverse reflection."},{"id":1981,"pagetitle":"Changelog","title":"[0.4.36] -  September 20, 2023","ref":"/manopt/stable/changelog/#[0.4.36]-September-20,-2023","content":" [0.4.36] -  September 20, 2023"},{"id":1982,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-11","content":" Fixed Fixed a bug that caused non-matrix points and vectors to fail when working with approximate"},{"id":1983,"pagetitle":"Changelog","title":"[0.4.35] -  September 14, 2023","ref":"/manopt/stable/changelog/#[0.4.35]-September-14,-2023","content":" [0.4.35] -  September 14, 2023"},{"id":1984,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-12","content":" Added The access to functions of the objective is now unified and encapsulated in proper  get_  functions."},{"id":1985,"pagetitle":"Changelog","title":"[0.4.34] -  September 02, 2023","ref":"/manopt/stable/changelog/#[0.4.34]-September-02,-2023","content":" [0.4.34] -  September 02, 2023"},{"id":1986,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-13","content":" Added an  ManifoldEuclideanGradientObjective  to allow the cost, gradient, and Hessian and other first or second derivative based elements to be Euclidean and converted when needed. a keyword  objective_type=:Euclidean  for all solvers, that specifies that an Objective shall be created of the above type"},{"id":1987,"pagetitle":"Changelog","title":"[0.4.33] - August 24, 2023","ref":"/manopt/stable/changelog/#[0.4.33]-August-24,-2023","content":" [0.4.33] - August 24, 2023"},{"id":1988,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-14","content":" Added ConstantStepsize  and  DecreasingStepsize  now have an additional field  type::Symbol  to assess whether the step-size should be relatively (to the gradient norm) or absolutely constant."},{"id":1989,"pagetitle":"Changelog","title":"[0.4.32] - August 23, 2023","ref":"/manopt/stable/changelog/#[0.4.32]-August-23,-2023","content":" [0.4.32] - August 23, 2023"},{"id":1990,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-15","content":" Added The adaptive regularization with cubics (ARC) solver."},{"id":1991,"pagetitle":"Changelog","title":"[0.4.31] - August 14, 2023","ref":"/manopt/stable/changelog/#[0.4.31]-August-14,-2023","content":" [0.4.31] - August 14, 2023"},{"id":1992,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-16","content":" Added A  :Subsolver  keyword in the  debug=  keyword argument, that activates the new  DebugWhenActive to de/activate subsolver debug from the main solvers DebugEvery`."},{"id":1993,"pagetitle":"Changelog","title":"[0.4.30] - August 3, 2023","ref":"/manopt/stable/changelog/#[0.4.30]-August-3,-2023","content":" [0.4.30] - August 3, 2023"},{"id":1994,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-7","content":" Changed References in the documentation are now rendered using  DocumenterCitations.jl Asymptote export now also accepts a size in pixel instead of its default  4cm  size and  render  can be deactivated setting it to  nothing ."},{"id":1995,"pagetitle":"Changelog","title":"[0.4.29] - July 12, 2023","ref":"/manopt/stable/changelog/#[0.4.29]-July-12,-2023","content":" [0.4.29] - July 12, 2023"},{"id":1996,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-12","content":" Fixed fixed a bug, where  cyclic_proximal_point  did not work with decorated objectives."},{"id":1997,"pagetitle":"Changelog","title":"[0.4.28] - June 24, 2023","ref":"/manopt/stable/changelog/#[0.4.28]-June-24,-2023","content":" [0.4.28] - June 24, 2023"},{"id":1998,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-8","content":" Changed max_stepsize  was specialized for  FixedRankManifold  to follow Matlab Manopt."},{"id":1999,"pagetitle":"Changelog","title":"[0.4.27] - June 15, 2023","ref":"/manopt/stable/changelog/#[0.4.27]-June-15,-2023","content":" [0.4.27] - June 15, 2023"},{"id":2000,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-17","content":" Added The  AdaptiveWNGrad  stepsize is available as a new stepsize functor."},{"id":2001,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-13","content":" Fixed Levenberg-Marquardt now possesses its parameters  initial_residual_values  and  initial_jacobian_f  also as keyword arguments, such that their default initialisations can be adapted, if necessary"},{"id":2002,"pagetitle":"Changelog","title":"[0.4.26] - June 11, 2023","ref":"/manopt/stable/changelog/#[0.4.26]-June-11,-2023","content":" [0.4.26] - June 11, 2023"},{"id":2003,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-18","content":" Added simplify usage of gradient descent as sub solver in the DoC solvers. add a  get_state  function document  indicates_convergence ."},{"id":2004,"pagetitle":"Changelog","title":"[0.4.25] - June 5, 2023","ref":"/manopt/stable/changelog/#[0.4.25]-June-5,-2023","content":" [0.4.25] - June 5, 2023"},{"id":2005,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-14","content":" Fixed Fixes an allocation bug in the difference of convex algorithm"},{"id":2006,"pagetitle":"Changelog","title":"[0.4.24] - June 4, 2023","ref":"/manopt/stable/changelog/#[0.4.24]-June-4,-2023","content":" [0.4.24] - June 4, 2023"},{"id":2007,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-19","content":" Added another workflow that deletes old PR renderings from the docs to keep them smaller in overall size."},{"id":2008,"pagetitle":"Changelog","title":"Changes","ref":"/manopt/stable/changelog/#Changes-5","content":" Changes bump dependencies since the extension between Manifolds.jl and ManifoldsDiff.jl has been moved to Manifolds.jl"},{"id":2009,"pagetitle":"Changelog","title":"[0.4.23] - June 4, 2023","ref":"/manopt/stable/changelog/#[0.4.23]-June-4,-2023","content":" [0.4.23] - June 4, 2023"},{"id":2010,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-20","content":" Added More details on the Count and Cache tutorial"},{"id":2011,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-9","content":" Changed loosen constraints slightly"},{"id":2012,"pagetitle":"Changelog","title":"[0.4.22] - May 31, 2023","ref":"/manopt/stable/changelog/#[0.4.22]-May-31,-2023","content":" [0.4.22] - May 31, 2023"},{"id":2013,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-21","content":" Added A tutorial on how to implement a solver"},{"id":2014,"pagetitle":"Changelog","title":"[0.4.21] - May 22, 2023","ref":"/manopt/stable/changelog/#[0.4.21]-May-22,-2023","content":" [0.4.21] - May 22, 2023"},{"id":2015,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-22","content":" Added A  ManifoldCacheObjective  as a decorator for objectives to cache results of calls, using LRU Caches as a weak dependency. For now this works with cost and gradient evaluations A  ManifoldCountObjective  as a decorator for objectives to enable counting of calls to for example the cost and the gradient adds a  return_objective  keyword, that switches the return of a solver to a tuple  (o, s) , where  o  is the (possibly decorated) objective, and  s  is the ‚Äúclassical‚Äù solver return (state or point). This way the counted values can be accessed and the cache can be reused. change solvers on the mid level (form  solver(M, objective, p) ) to also accept decorated objectives"},{"id":2016,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-10","content":" Changed Switch all Requires weak dependencies to actual weak dependencies starting in Julia 1.9"},{"id":2017,"pagetitle":"Changelog","title":"[0.4.20] - May 11, 2023","ref":"/manopt/stable/changelog/#[0.4.20]-May-11,-2023","content":" [0.4.20] - May 11, 2023"},{"id":2018,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-11","content":" Changed the default tolerances for the numerical  check_  functions were loosened a bit, such that  check_vector  can also be changed in its tolerances."},{"id":2019,"pagetitle":"Changelog","title":"[0.4.19] - May 7, 2023","ref":"/manopt/stable/changelog/#[0.4.19]-May-7,-2023","content":" [0.4.19] - May 7, 2023"},{"id":2020,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-23","content":" Added the sub solver for  trust_regions  is now customizable and can now be exchanged."},{"id":2021,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-12","content":" Changed slightly changed the definitions of the solver states for ALM and EPM to be type stable"},{"id":2022,"pagetitle":"Changelog","title":"[0.4.18] - May 4, 2023","ref":"/manopt/stable/changelog/#[0.4.18]-May-4,-2023","content":" [0.4.18] - May 4, 2023"},{"id":2023,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-24","content":" Added A function  check_Hessian(M, f, grad_f, Hess_f)  to numerically check the (Riemannian) Hessian of a function  f"},{"id":2024,"pagetitle":"Changelog","title":"[0.4.17] - April 28, 2023","ref":"/manopt/stable/changelog/#[0.4.17]-April-28,-2023","content":" [0.4.17] - April 28, 2023"},{"id":2025,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-25","content":" Added A new interface of the form  alg(M, objective, p0)  to allow to reuse objectives without creating  AbstractManoptSolverState s and calling  solve! . This especially still allows for any decoration of the objective and/or the state using  debug= , or  record= ."},{"id":2026,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-13","content":" Changed All solvers now have the initial point  p  as an optional parameter making it more accessible to first time users,  gradient_descent(M, f, grad_f)  is equivalent to  gradient_descent(M, f, grad_f, rand(M))"},{"id":2027,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-15","content":" Fixed Unified the framework to work on manifold where points are represented by numbers for several solvers"},{"id":2028,"pagetitle":"Changelog","title":"[0.4.16] - April 18, 2023","ref":"/manopt/stable/changelog/#[0.4.16]-April-18,-2023","content":" [0.4.16] - April 18, 2023"},{"id":2029,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-16","content":" Fixed the inner products used in  truncated_gradient_descent  now also work thoroughly on complex matrix manifolds"},{"id":2030,"pagetitle":"Changelog","title":"[0.4.15] - April 13, 2023","ref":"/manopt/stable/changelog/#[0.4.15]-April-13,-2023","content":" [0.4.15] - April 13, 2023"},{"id":2031,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-14","content":" Changed trust_regions(M, f, grad_f, hess_f, p)  now has the Hessian  hess_f  as well as the start point  p0  as an optional parameter and approximate it otherwise. trust_regions!(M, f, grad_f, hess_f, p)  has the Hessian as an optional parameter and approximate it otherwise."},{"id":2032,"pagetitle":"Changelog","title":"Removed","ref":"/manopt/stable/changelog/#Removed","content":" Removed support for  ManifoldsBase.jl  0.13.x, since with the definition of  copy(M,p::Number) , in 0.14.4, that one is used instead of defining it ourselves."},{"id":2033,"pagetitle":"Changelog","title":"[0.4.14] - April 06, 2023","ref":"/manopt/stable/changelog/#[0.4.14]-April-06,-2023","content":" [0.4.14] - April 06, 2023"},{"id":2034,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-15","content":" Changed particle_swarm  now uses much more in-place operations"},{"id":2035,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-17","content":" Fixed particle_swarm  used quite a few  deepcopy(p)  commands still, which were replaced by  copy(M, p)"},{"id":2036,"pagetitle":"Changelog","title":"[0.4.13] - April 09, 2023","ref":"/manopt/stable/changelog/#[0.4.13]-April-09,-2023","content":" [0.4.13] - April 09, 2023"},{"id":2037,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-26","content":" Added get_message  to obtain messages from sub steps of a solver DebugMessages  to display the new messages in debug safeguards in Armijo line search and L-BFGS against numerical over- and underflow that report in messages"},{"id":2038,"pagetitle":"Changelog","title":"[0.4.12] - April 4, 2023","ref":"/manopt/stable/changelog/#[0.4.12]-April-4,-2023","content":" [0.4.12] - April 4, 2023"},{"id":2039,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-27","content":" Added Introduce the  Difference of Convex Algorithm  (DCA)  difference_of_convex_algorithm(M, f, g, ‚àÇh, p0) Introduce the  Difference of Convex Proximal Point Algorithm  (DCPPA)  difference_of_convex_proximal_point(M, prox_g, grad_h, p0) Introduce a  StopWhenGradientChangeLess  stopping criterion"},{"id":2040,"pagetitle":"Changelog","title":"[0.4.11] - March 27, 2023","ref":"/manopt/stable/changelog/#[0.4.11]-March-27,-2023","content":" [0.4.11] - March 27, 2023"},{"id":2041,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-16","content":" Changed adapt tolerances in tests to the speed/accuracy optimized distance on the sphere in  Manifolds.jl  (part II)"},{"id":2042,"pagetitle":"Changelog","title":"[0.4.10] - March 26, 2023","ref":"/manopt/stable/changelog/#[0.4.10]-March-26,-2023","content":" [0.4.10] - March 26, 2023"},{"id":2043,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-17","content":" Changed adapt tolerances in tests to the speed/accuracy optimized distance on the sphere in  Manifolds.jl"},{"id":2044,"pagetitle":"Changelog","title":"[0.4.9] - March 3, 2023","ref":"/manopt/stable/changelog/#[0.4.9]-March-3,-2023","content":" [0.4.9] - March 3, 2023"},{"id":2045,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-28","content":" Added introduce a wrapper that allows line searches from  LineSearches.jl  to be used within Manopt.jl, introduce the  manoptjl.org/stable/extensions/  page to explain the details."},{"id":2046,"pagetitle":"Changelog","title":"[0.4.8] - February 21, 2023","ref":"/manopt/stable/changelog/#[0.4.8]-February-21,-2023","content":" [0.4.8] - February 21, 2023"},{"id":2047,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-29","content":" Added a  status_summary  that displays the main parameters within several structures of Manopt, most prominently a solver state"},{"id":2048,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-18","content":" Changed Improved storage performance by introducing separate named tuples for points and vectors changed the  show  methods of  AbstractManoptSolverState s to display their `state_summary Move tutorials to be rendered with Quarto into the documentation."},{"id":2049,"pagetitle":"Changelog","title":"[0.4.7] - February 14, 2023","ref":"/manopt/stable/changelog/#[0.4.7]-February-14,-2023","content":" [0.4.7] - February 14, 2023"},{"id":2050,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-19","content":" Changed Bump  [compat]  entry of ManifoldDiff to also include 0.3"},{"id":2051,"pagetitle":"Changelog","title":"[0.4.6] - February 3, 2023","ref":"/manopt/stable/changelog/#[0.4.6]-February-3,-2023","content":" [0.4.6] - February 3, 2023"},{"id":2052,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-18","content":" Fixed Fixed a few stopping criteria even indicated to stop before the algorithm started."},{"id":2053,"pagetitle":"Changelog","title":"[0.4.5] - January 24, 2023","ref":"/manopt/stable/changelog/#[0.4.5]-January-24,-2023","content":" [0.4.5] - January 24, 2023"},{"id":2054,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-20","content":" Changed the new default functions that include  p  are used where possible a first step towards faster storage handling"},{"id":2055,"pagetitle":"Changelog","title":"[0.4.4] - January 20, 2023","ref":"/manopt/stable/changelog/#[0.4.4]-January-20,-2023","content":" [0.4.4] - January 20, 2023"},{"id":2056,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-30","content":" Added Introduce  ConjugateGradientBealeRestart  to allow CG restarts using Beale‚Äòs rule"},{"id":2057,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-19","content":" Fixed fix a type in  HestenesStiefelCoefficient"},{"id":2058,"pagetitle":"Changelog","title":"[0.4.3] - January 17, 2023","ref":"/manopt/stable/changelog/#[0.4.3]-January-17,-2023","content":" [0.4.3] - January 17, 2023"},{"id":2059,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-20","content":" Fixed the CG coefficient  Œ≤  can now be complex fix a bug in  grad_distance"},{"id":2060,"pagetitle":"Changelog","title":"[0.4.2] - January 16, 2023","ref":"/manopt/stable/changelog/#[0.4.2]-January-16,-2023","content":" [0.4.2] - January 16, 2023"},{"id":2061,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-21","content":" Changed the usage of  inner  in line search methods, such that they work well with complex manifolds as well"},{"id":2062,"pagetitle":"Changelog","title":"[0.4.1] - January 15, 2023","ref":"/manopt/stable/changelog/#[0.4.1]-January-15,-2023","content":" [0.4.1] - January 15, 2023"},{"id":2063,"pagetitle":"Changelog","title":"Fixed","ref":"/manopt/stable/changelog/#Fixed-21","content":" Fixed a  max_stepsize  per manifold to avoid leaving the injectivity radius, which it also defaults to"},{"id":2064,"pagetitle":"Changelog","title":"[0.4.0] - January 10, 2023","ref":"/manopt/stable/changelog/#[0.4.0]-January-10,-2023","content":" [0.4.0] - January 10, 2023"},{"id":2065,"pagetitle":"Changelog","title":"Added","ref":"/manopt/stable/changelog/#Added-31","content":" Added Dependency on  ManifoldDiff.jl  and a start of moving actual derivatives, differentials, and gradients there. AbstractManifoldObjective  to store the objective within the  AbstractManoptProblem Introduce a  CostGrad  structure to store a function that computes the cost and gradient within one function."},{"id":2066,"pagetitle":"Changelog","title":"Changed","ref":"/manopt/stable/changelog/#Changed-22","content":" Changed AbstractManoptProblem  replaces  Problem the problem now contains a AbstractManoptSolverState  replaces  Options random_point(M)  is replaced by  rand(M)  from `ManifoldsBase.jl random_tangent(M, p)  is replaced by  rand(M; vector_at=p)"},{"id":2069,"pagetitle":"Contributing to Manopt.jl","title":"Contributing to  Manopt.jl","ref":"/manopt/stable/contributing/#Contributing-to-Manopt.jl","content":" Contributing to  Manopt.jl First, thanks for taking the time to contribute. Any contribution is appreciated and welcome. The following is a set of guidelines to  Manopt.jl ."},{"id":2070,"pagetitle":"Contributing to Manopt.jl","title":"Table of contents","ref":"/manopt/stable/contributing/#Table-of-contents","content":" Table of contents Contributing to  Manopt.jl      -  Table of Contents I just have a question How can I file an issue? How can I contribute? Add a missing method Provide a new algorithm Provide a new example Code style"},{"id":2071,"pagetitle":"Contributing to Manopt.jl","title":"I just have a question","ref":"/manopt/stable/contributing/#I-just-have-a-question","content":" I just have a question The developer can most easily be reached in the Julia Slack channel  #manifolds . You can apply for the Julia Slack workspace  here  if you haven't joined yet. You can also ask your question on  discourse.julialang.org ."},{"id":2072,"pagetitle":"Contributing to Manopt.jl","title":"How can I file an issue?","ref":"/manopt/stable/contributing/#How-can-I-file-an-issue?","content":" How can I file an issue? If you found a bug or want to propose a feature, please open an issue in within the  GitHub repository ."},{"id":2073,"pagetitle":"Contributing to Manopt.jl","title":"How can I contribute?","ref":"/manopt/stable/contributing/#How-can-I-contribute?","content":" How can I contribute?"},{"id":2074,"pagetitle":"Contributing to Manopt.jl","title":"Add a missing method","ref":"/manopt/stable/contributing/#Add-a-missing-method","content":" Add a missing method There is still a lot of methods for within the optimization framework of   Manopt.jl , may it be functions, gradients, differentials, proximal maps, step size rules or stopping criteria. If you notice a method missing and can contribute an implementation, please do so, and the maintainers will try help with the necessary details. Even providing a single new method is a good contribution."},{"id":2075,"pagetitle":"Contributing to Manopt.jl","title":"Provide a new algorithm","ref":"/manopt/stable/contributing/#Provide-a-new-algorithm","content":" Provide a new algorithm A main contribution you can provide is another algorithm that is not yet included in the package. An algorithm is always based on a concrete type of a  AbstractManoptProblem  storing the main information of the task and a concrete type of an  AbstractManoptSolverState  storing all information that needs to be known to the solver in general. The actual algorithm is split into an initialization phase, see  initialize_solver! , and the implementation of the  i th step of the solver itself, see  before the iterative procedure, see  step_solver! . For these two functions, it would be great if a new algorithm uses functions from the  ManifoldsBase.jl  interface as generically as possible. For example, if possible use  retract!(M,q,p,X)  in favor of  exp!(M,q,p,X)  to perform a step starting in  p  in direction  X  (in place of  q ), since the exponential map might be too expensive to evaluate or might not be available on a certain manifold. See  Retractions and inverse retractions  for more details. Further, if possible, prefer  retract!(M,q,p,X)  in favor of  retract(M,p,X) , since a computation in place of a suitable variable  q  reduces memory allocations. Usually, the methods implemented in  Manopt.jl  also have a high-level interface, that is easier to call, creates the necessary problem and options structure and calls the solver. The two technical functions  initialize_solver!  and  step_solver!  should be documented with technical details, while the high level interface should usually provide a general description and some literature references to the algorithm at hand."},{"id":2076,"pagetitle":"Contributing to Manopt.jl","title":"Provide a new example","ref":"/manopt/stable/contributing/#Provide-a-new-example","content":" Provide a new example Example problems are available at  ManoptExamples.jl , where also their reproducible Quarto-Markdown files are stored."},{"id":2077,"pagetitle":"Contributing to Manopt.jl","title":"Code style","ref":"/manopt/stable/contributing/#Code-style","content":" Code style Try to follow the  documentation guidelines  from the Julia documentation as well as  Blue Style . Run  JuliaFormatter.jl  on the repository in the way set in the  .JuliaFormatter.toml  file, which enforces a number of conventions consistent with the Blue Style. Furthermore  vale  is run on both Markdown and code files, affecting documentation and source code comments Please follow a few internal conventions: It is preferred that the  AbstractManoptProblem 's struct contains information about the general structure of the problem. Any implemented function should be accompanied by its mathematical formulae if a closed form exists. AbstractManoptProblem  and helping functions are stored within the  plan/  folder and sorted by properties of the problem and/or solver at hand. the solver state is usually stored with the solver itself Within the source code of one algorithm, following the state, the high level interface should be next, then the initialization, then the step. Otherwise an alphabetical order of functions is preferable. The preceding implies that the mutating variant of a function follows the non-mutating variant. There should be no dangling  =  signs. Always add a newline between things of different types (struct/method/const). Always add a newline between methods for different functions (including mutating/nonmutating variants). Prefer to have no newline between methods for the same function; when reasonable, merge the documentation strings. All  import / using / include  should be in the main module file. Concerning documentation if possible provide both mathematical formulae and literature references using  DocumenterCitations.jl  and BibTeX where possible Always document all input variables and keyword arguments If you implement an algorithm with a certain application in mind, it would be great, if this could be added to the  ManoptExamples.jl  package as well."},{"id":2080,"pagetitle":"Extensions","title":"Extensions","ref":"/manopt/stable/extensions/#Extensions","content":" Extensions"},{"id":2081,"pagetitle":"Extensions","title":"LineSearches.jl","ref":"/manopt/stable/extensions/#LineSearches.jl","content":" LineSearches.jl Manopt can be used with line search algorithms implemented in  LineSearches.jl . This can be illustrated by the following example of optimizing Rosenbrock function constrained to the unit sphere. using Manopt, Manifolds, LineSearches\n\n# define objective function and its gradient\np = [1.0, 100.0]\nfunction rosenbrock(::AbstractManifold, x)\n    val = zero(eltype(x))\n    for i in 1:(length(x) - 1)\n        val += (p[1] - x[i])^2 + p[2] * (x[i + 1] - x[i]^2)^2\n    end\n    return val\nend\nfunction rosenbrock_grad!(M::AbstractManifold, storage, x)\n    storage .= 0.0\n    for i in 1:(length(x) - 1)\n        storage[i] += -2.0 * (p[1] - x[i]) - 4.0 * p[2] * (x[i + 1] - x[i]^2) * x[i]\n        storage[i + 1] += 2.0 * p[2] * (x[i + 1] - x[i]^2)\n    end\n    project!(M, storage, x, storage)\n    return storage\nend\n# define constraint\nn_dims = 5\nM = Manifolds.Sphere(n_dims)\n# set initial point\nx0 = vcat(zeros(n_dims - 1), 1.0)\n# use LineSearches.jl HagerZhang method with Manopt.jl quasiNewton solver\nls_hz = Manopt.LineSearchesStepsize(M, LineSearches.HagerZhang())\nx_opt = quasi_Newton(\n    M,\n    rosenbrock,\n    rosenbrock_grad!,\n    x0;\n    stepsize=ls_hz,\n    evaluation=InplaceEvaluation(),\n    stopping_criterion=StopAfterIteration(1000) | StopWhenGradientNormLess(1e-6),\n    return_state=true,\n) # Solver state for `Manopt.jl`s Quasi Newton Method\nAfter 10 iterations\n\n## Parameters\n* direction update:        limited memory InverseBFGS (size 5), projections, and ParallelTransport() as vector transport.\n* retraction method:       ExponentialRetraction()\n* vector transport method: ParallelTransport()\n\n## Stepsize\nLineSearchesStepsize(HagerZhang{Float64, Base.RefValue{Bool}}\n  delta: Float64 0.1\n  sigma: Float64 0.9\n  alphamax: Float64 Inf\n  rho: Float64 5.0\n  epsilon: Float64 1.0e-6\n  gamma: Float64 0.66\n  linesearchmax: Int64 50\n  psi3: Float64 0.1\n  display: Int64 0\n  mayterminate: Base.RefValue{Bool}\n; retraction_method=ExponentialRetraction(), vector_transport_method=ParallelTransport())\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 1000:\tnot reached\n    |grad f| < 1.0e-6: reached\nOverall: reached\nThis indicates convergence: Yes In general this defines the following new  stepsize"},{"id":2082,"pagetitle":"Extensions","title":"Manopt.LineSearchesStepsize","ref":"/manopt/stable/extensions/#Manopt.LineSearchesStepsize","content":" Manopt.LineSearchesStepsize  ‚Äî  Type LineSearchesStepsize <: Stepsize Wrapper for line searches available in the  LineSearches.jl  library. Constructors LineSearchesStepsize(\n    M::AbstractManifold,\n    linesearch;\n    retraction_method::AbstractRetractionMethod=default_retraction_method(M),\n    vector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M),\n)\nLineSearchesStepsize(\n    linesearch;\n    retraction_method::AbstractRetractionMethod=ExponentialRetraction(),\n    vector_transport_method::AbstractVectorTransportMethod=ParallelTransport(),\n) Wrap  linesearch  (for example  HagerZhang  or  MoreThuente ). The initial step selection from Linesearches.jl is not yet supported and the value 1.0 is used. The retraction used for determining the line along which the search is performed can be  provided as  retraction_method . Gradient vectors are transported between points using  vector_transport_method . source"},{"id":2083,"pagetitle":"Extensions","title":"Manifolds.jl","ref":"/manopt/stable/extensions/#Manifolds.jl","content":" Manifolds.jl Loading  Manifolds.jl  introduces the following additional functions"},{"id":2084,"pagetitle":"Extensions","title":"ManifoldsBase.mid_point","ref":"/manopt/stable/extensions/#ManifoldsBase.mid_point","content":" ManifoldsBase.mid_point  ‚Äî  Function mid_point(M, p, q, x)\nmid_point!(M, y, p, q, x) Compute the mid point between  p  and  q . If there is more than one mid point of (not necessarily minimizing) geodesics (for example on the sphere), the one nearest to  x  is returned (in place of  y ). source"},{"id":2085,"pagetitle":"Extensions","title":"Manopt.max_stepsize","ref":"/manopt/stable/extensions/#Manopt.max_stepsize-Tuple{FiberBundle{ùîΩ, ManifoldsBase.TangentSpaceType, M} where {ùîΩ, M<:AbstractManifold{ùîΩ}}, Any}","content":" Manopt.max_stepsize  ‚Äî  Method max_stepsize(M::TangentBundle, p) Tangent bundle has injectivity radius of either infinity (for flat manifolds) or 0 (for non-flat manifolds). This makes a guess of what a reasonable maximum stepsize on a tangent bundle might be. source"},{"id":2086,"pagetitle":"Extensions","title":"Manopt.max_stepsize","ref":"/manopt/stable/extensions/#Manopt.max_stepsize-Tuple{FixedRankMatrices, Any}","content":" Manopt.max_stepsize  ‚Äî  Method max_stepsize(M::FixedRankMatrices, p) Return a reasonable guess of maximum step size on  FixedRankMatrices  following the choice of typical distance in Matlab Manopt, the dimension of  M . See  this note source"},{"id":2087,"pagetitle":"Extensions","title":"JuMP.jl","ref":"/manopt/stable/extensions/#JuMP.jl","content":" JuMP.jl Manopt can be used using the  JuMP.jl  interface. The manifold is provided in the  @variable  macro. Note that until now, only variables (points on manifolds) are supported, that are arrays, especially structs do not yet work. The algebraic expression of the objective function is specified in the  @objective  macro. The  descent_state_type  attribute specifies the solver. using JuMP, Manopt, Manifolds\nmodel = Model(Manopt.Optimizer)\n# Change the solver with this option, `GradientDescentState` is the default\nset_attribute(\"descent_state_type\", GradientDescentState)\n@variable(model, U[1:2, 1:2] in Stiefel(2, 2), start = 1.0)\n@objective(model, Min, sum((A - U) .^ 2))\noptimize!(model)\nsolution_summary(model)"},{"id":2088,"pagetitle":"Extensions","title":"Interface functions","ref":"/manopt/stable/extensions/#Interface-functions","content":" Interface functions"},{"id":2089,"pagetitle":"Extensions","title":"Manopt.JuMP_ArrayShape","ref":"/manopt/stable/extensions/#Manopt.JuMP_ArrayShape","content":" Manopt.JuMP_ArrayShape  ‚Äî  Type struct ArrayShape{N} <: JuMP.AbstractShape Shape of an  Array{T,N}  of size  size . source"},{"id":2090,"pagetitle":"Extensions","title":"Manopt.JuMP_VectorizedManifold","ref":"/manopt/stable/extensions/#Manopt.JuMP_VectorizedManifold","content":" Manopt.JuMP_VectorizedManifold  ‚Äî  Type struct VectorizedManifold{M} <: MOI.AbstractVectorSet\n    manifold::M\nend Representation of points of  manifold  as a vector of  R^n  where  n  is  MOI.dimension(VectorizedManifold(manifold)) . source"},{"id":2091,"pagetitle":"Extensions","title":"MathOptInterface.dimension","ref":"/manopt/stable/extensions/#MathOptInterface.dimension-Tuple{ManoptJuMPExt.VectorizedManifold}","content":" MathOptInterface.dimension  ‚Äî  Method MOI.dimension(set::VectorizedManifold) Return the representation side of points on the (vectorized in representation) manifold. As the MOI variables are real, this means if the  representation_size  yields (in product)  n , this refers to the vectorized point / tangent vector  from (a subset of  $‚Ñù^n$ ). source"},{"id":2092,"pagetitle":"Extensions","title":"Manopt.JuMP_Optimizer","ref":"/manopt/stable/extensions/#Manopt.JuMP_Optimizer","content":" Manopt.JuMP_Optimizer  ‚Äî  Type Manopt.JuMP_Optimizer() Creates a new optimizer object for the  MathOptInterface  (MOI). An alias  Manopt.JuMP_Optimizer  is defined for convenience. The minimization of a function  f(X)  of an array  X[1:n1,1:n2,...]  over a manifold  M  starting at  X0 , can be modeled as follows: using JuMP\nmodel = Model(Manopt.JuMP_Optimizer)\n@variable(model, X[i1=1:n1,i2=1:n2,...] in M, start = X0[i1,i2,...])\n@objective(model, Min, f(X)) The optimizer assumes that  M  has a  Array  shape described by  ManifoldsBase.representation_size . source"},{"id":2093,"pagetitle":"Extensions","title":"MathOptInterface.empty!","ref":"/manopt/stable/extensions/#MathOptInterface.empty!-Tuple{ManoptJuMPExt.Optimizer}","content":" MathOptInterface.empty!  ‚Äî  Method MOI.empty!(model::ManoptJuMPExt.Optimizer) Clear all model data from  model  but keep the  options  set. source"},{"id":2094,"pagetitle":"Extensions","title":"MathOptInterface.supports","ref":"/manopt/stable/extensions/#MathOptInterface.supports-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.RawOptimizerAttribute}","content":" MathOptInterface.supports  ‚Äî  Method MOI.supports(::Optimizer, attr::MOI.RawOptimizerAttribute) Return a  Bool  indicating whether  attr.name  is a valid option name for  Manopt . source"},{"id":2095,"pagetitle":"Extensions","title":"MathOptInterface.get","ref":"/manopt/stable/extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.RawOptimizerAttribute}","content":" MathOptInterface.get  ‚Äî  Method MOI.get(model::Optimizer, attr::MOI.RawOptimizerAttribute) Return last  value  set by  MOI.set(model, attr, value) . source"},{"id":2096,"pagetitle":"Extensions","title":"MathOptInterface.set","ref":"/manopt/stable/extensions/#MathOptInterface.set-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.RawOptimizerAttribute, Any}","content":" MathOptInterface.set  ‚Äî  Method MOI.get(model::Optimizer, attr::MOI.RawOptimizerAttribute) Set the value for the keyword argument  attr.name  to give for the constructor  model.options[DESCENT_STATE_TYPE] . source"},{"id":2097,"pagetitle":"Extensions","title":"MathOptInterface.supports_incremental_interface","ref":"/manopt/stable/extensions/#MathOptInterface.supports_incremental_interface-Tuple{ManoptJuMPExt.Optimizer}","content":" MathOptInterface.supports_incremental_interface  ‚Äî  Method MOI.supports_incremental_interface(::JuMP_Optimizer) Return  true  indicating that  Manopt.JuMP_Optimizer  implements  MOI.add_constrained_variables  and  MOI.set  for  MOI.ObjectiveFunction  so it can be used with  JuMP.direct_model  and does not require a  MOI.Utilities.CachingOptimizer . See  MOI.supports_incremental_interface . source"},{"id":2098,"pagetitle":"Extensions","title":"MathOptInterface.copy_to","ref":"/manopt/stable/extensions/#MathOptInterface.copy_to-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.ModelLike}","content":" MathOptInterface.copy_to  ‚Äî  Method MOI.copy_to(dest::Optimizer, src::MOI.ModelLike) Because  supports_incremental_interface(dest)  is  true , this simply uses  MOI.Utilities.default_copy_to  and copies the variables with  MOI.add_constrained_variables  and the objective sense with  MOI.set . source"},{"id":2099,"pagetitle":"Extensions","title":"MathOptInterface.supports_add_constrained_variables","ref":"/manopt/stable/extensions/#MathOptInterface.supports_add_constrained_variables-Tuple{ManoptJuMPExt.Optimizer, Type{<:ManoptJuMPExt.VectorizedManifold}}","content":" MathOptInterface.supports_add_constrained_variables  ‚Äî  Method MOI.supports_add_constrained_variables(::JuMP_Optimizer, ::Type{<:VectorizedManifold}) Return  true  indicating that  Manopt.JuMP_Optimizer  support optimization on variables constrained to belong in a vectorized manifold  Manopt.JuMP_VectorizedManifold . source"},{"id":2100,"pagetitle":"Extensions","title":"MathOptInterface.add_constrained_variables","ref":"/manopt/stable/extensions/#MathOptInterface.add_constrained_variables-Tuple{ManoptJuMPExt.Optimizer, ManoptJuMPExt.VectorizedManifold}","content":" MathOptInterface.add_constrained_variables  ‚Äî  Method MOI.add_constrained_variables(model::Optimizer, set::VectorizedManifold) Add  MOI.dimension(set)  variables constrained in  set  and return the list of variable indices that can be used to reference them as well a constraint index for the constraint enforcing the membership of the variables in the  Manopt.JuMP_VectorizedManifold set . source"},{"id":2101,"pagetitle":"Extensions","title":"MathOptInterface.is_valid","ref":"/manopt/stable/extensions/#MathOptInterface.is_valid-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.VariableIndex}","content":" MathOptInterface.is_valid  ‚Äî  Method MOI.is_valid(model::Optimizer, vi::MOI.VariableIndex) Return whether  vi  is a valid variable index. source"},{"id":2102,"pagetitle":"Extensions","title":"MathOptInterface.get","ref":"/manopt/stable/extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.NumberOfVariables}","content":" MathOptInterface.get  ‚Äî  Method MOI.get(model::Optimizer, ::MOI.NumberOfVariables) Return the number of variables added in the model, this corresponds to the  MOI.dimension  of the  Manopt.JuMP_VectorizedManifold . source"},{"id":2103,"pagetitle":"Extensions","title":"MathOptInterface.supports","ref":"/manopt/stable/extensions/#MathOptInterface.supports-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.VariablePrimalStart, Type{MathOptInterface.VariableIndex}}","content":" MathOptInterface.supports  ‚Äî  Method MOI.supports(::Manopt.JuMP_Optimizer, attr::MOI.RawOptimizerAttribute) Return  true  indicating that  Manopt.JuMP_Optimizer  supports starting values for the variables. source"},{"id":2104,"pagetitle":"Extensions","title":"MathOptInterface.set","ref":"/manopt/stable/extensions/#MathOptInterface.set-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.VariablePrimalStart, MathOptInterface.VariableIndex, Union{Nothing, Real}}","content":" MathOptInterface.set  ‚Äî  Method function MOI.set(\n    model::Optimizer,\n    ::MOI.VariablePrimalStart,\n    vi::MOI.VariableIndex,\n    value::Union{Real,Nothing},\n) Set the starting value of the variable of index  vi  to  value . Note that if  value  is  nothing  then it essentially unset any previous starting values set and hence  MOI.optimize!  unless another starting value is set. source"},{"id":2105,"pagetitle":"Extensions","title":"MathOptInterface.set","ref":"/manopt/stable/extensions/#MathOptInterface.set-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.ObjectiveSense, MathOptInterface.OptimizationSense}","content":" MathOptInterface.set  ‚Äî  Method MOI.set(model::Optimizer, ::MOI.ObjectiveSense, sense::MOI.OptimizationSense) Modify the objective sense to either  MOI.MAX_SENSE ,  MOI.MIN_SENSE  or  MOI.FEASIBILITY_SENSE . source"},{"id":2106,"pagetitle":"Extensions","title":"MathOptInterface.set","ref":"/manopt/stable/extensions/#MathOptInterface.set-Union{Tuple{F}, Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.ObjectiveFunction{F}, F}} where F","content":" MathOptInterface.set  ‚Äî  Method MOI.set(model::Optimizer, ::MOI.ObjectiveFunction{F}, func::F) where {F} Set the objective function as  func  for  model . source"},{"id":2107,"pagetitle":"Extensions","title":"MathOptInterface.supports","ref":"/manopt/stable/extensions/#MathOptInterface.supports-Tuple{ManoptJuMPExt.Optimizer, Union{MathOptInterface.ObjectiveSense, MathOptInterface.ObjectiveFunction}}","content":" MathOptInterface.supports  ‚Äî  Method MOI.supports(::Optimizer, ::Union{MOI.ObjectiveSense,MOI.ObjectiveFunction}) Return  true  indicating that  Optimizer  supports being set the objective sense (that is, min, max or feasibility) and the objective function. source"},{"id":2108,"pagetitle":"Extensions","title":"JuMP.build_variable","ref":"/manopt/stable/extensions/#JuMP.build_variable-Tuple{Function, Any, AbstractManifold}","content":" JuMP.build_variable  ‚Äî  Method JuMP.build_variable(::Function, func, m::ManifoldsBase.AbstractManifold) Build a  JuMP.VariablesConstrainedOnCreation  object containing variables and the  Manopt.JuMP_VectorizedManifold  in which they should belong as well as the  shape  that can be used to go from the vectorized MOI representation to the shape of the manifold, that is,  Manopt.JuMP_ArrayShape . source"},{"id":2109,"pagetitle":"Extensions","title":"MathOptInterface.get","ref":"/manopt/stable/extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.ResultCount}","content":" MathOptInterface.get  ‚Äî  Method MOI.get(model::Optimizer, ::MOI.ResultCount) Return  0  if  optimize!  hasn't been called yet and  1  otherwise indicating that one solution is available. source"},{"id":2110,"pagetitle":"Extensions","title":"MathOptInterface.get","ref":"/manopt/stable/extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.SolverName}","content":" MathOptInterface.get  ‚Äî  Method MOI.get(::Optimizer, ::MOI.SolverName) Return the name of the  Optimizer  with the value of the  descent_state_type  option. source"},{"id":2111,"pagetitle":"Extensions","title":"MathOptInterface.get","ref":"/manopt/stable/extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.ObjectiveValue}","content":" MathOptInterface.get  ‚Äî  Method MOI.get(model::Optimizer, attr::MOI.ObjectiveValue) Return the value of the objective function evaluated at the solution. source"},{"id":2112,"pagetitle":"Extensions","title":"MathOptInterface.get","ref":"/manopt/stable/extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.PrimalStatus}","content":" MathOptInterface.get  ‚Äî  Method MOI.get(model::Optimizer, ::MOI.PrimalStatus) Return  MOI.NO_SOLUTION  if  optimize!  hasn't been called yet and  MOI.FEASIBLE_POINT  otherwise indicating that a solution is available to query with  MOI.VariablePrimalStart . source"},{"id":2113,"pagetitle":"Extensions","title":"MathOptInterface.get","ref":"/manopt/stable/extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.DualStatus}","content":" MathOptInterface.get  ‚Äî  Method MOI.get(::Optimizer, ::MOI.DualStatus) Returns  MOI.NO_SOLUTION  indicating that there is no dual solution available. source"},{"id":2114,"pagetitle":"Extensions","title":"MathOptInterface.get","ref":"/manopt/stable/extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.TerminationStatus}","content":" MathOptInterface.get  ‚Äî  Method MOI.get(model::Optimizer, ::MOI.ResultCount) Return  MOI.OPTIMIZE_NOT_CALLED  if  optimize!  hasn't been called yet and  MOI.LOCALLY_SOLVED  otherwise indicating that the solver has solved the problem to local optimality the value of  MOI.RawStatusString  for more details on why the solver stopped. source"},{"id":2115,"pagetitle":"Extensions","title":"MathOptInterface.get","ref":"/manopt/stable/extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.SolverVersion}","content":" MathOptInterface.get  ‚Äî  Method MOI.get(::Optimizer, ::MOI.SolverVersion) Return the version of the Manopt solver, it corresponds to the version of Manopt.jl. source"},{"id":2116,"pagetitle":"Extensions","title":"MathOptInterface.get","ref":"/manopt/stable/extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.ObjectiveSense}","content":" MathOptInterface.get  ‚Äî  Method MOI.set(model::Optimizer, ::MOI.ObjectiveSense, sense::MOI.OptimizationSense) Return the objective sense, defaults to  MOI.FEASIBILITY_SENSE  if no sense has already been set. source"},{"id":2117,"pagetitle":"Extensions","title":"MathOptInterface.get","ref":"/manopt/stable/extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.VariablePrimal, MathOptInterface.VariableIndex}","content":" MathOptInterface.get  ‚Äî  Method MOI.get(model::Optimizer, attr::MOI.VariablePrimal, vi::MOI.VariableIndex) Return the value of the solution for the variable of index  vi . source"},{"id":2118,"pagetitle":"Extensions","title":"MathOptInterface.get","ref":"/manopt/stable/extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.RawStatusString}","content":" MathOptInterface.get  ‚Äî  Method MOI.get(model::Optimizer, ::MOI.RawStatusString) Return a  String  containing  Manopt.get_reason  without the ending newline character. source"},{"id":2121,"pagetitle":"Checks","title":"Verifying gradients and Hessians","ref":"/manopt/stable/helpers/checks/#Verifying-gradients-and-Hessians","content":" Verifying gradients and Hessians If you have computed a gradient or differential and you are not sure whether it is correct."},{"id":2122,"pagetitle":"Checks","title":"Manopt.check_Hessian","ref":"/manopt/stable/helpers/checks/#Manopt.check_Hessian","content":" Manopt.check_Hessian  ‚Äî  Function check_Hessian(M, f, grad_f, Hess_f, p=rand(M), X=rand(M; vector_at=p), Y=rand(M, vector_at=p); kwargs...) Verify numerically whether the Hessian  $\\operatorname{Hess} f(M,p, X)$  of  f(M,p)  is correct. For this either a second-order retraction or a critical point  $p$  of  f  is required. The approximation is then \\[f(\\operatorname{retr}_p(tX)) = f(p) + t‚ü®\\operatorname{grad} f(p), X‚ü© + \\frac{t^2}{2}‚ü®\\operatorname{Hess}f(p)[X], X‚ü© + \\mathcal O(t^3)\\] or in other words, that the error between the function  $f$  and its second order Taylor behaves in error  $\\mathcal O(t^3)$ , which indicates that the Hessian is correct, cf. also [ Bou23 , Section 6.8]. Note that if the errors are below the given tolerance and the method is exact, no plot is generated. Keyword arguments check_grad :       ( true ) verify that  $\\operatorname{grad} f(p) ‚àà T_p\\mathcal M$ . check_linearity :  ( true ) verify that the Hessian is linear, see  is_Hessian_linear  using  a ,  b ,  X , and  Y check_symmetry :   ( true ) verify that the Hessian is symmetric, see  is_Hessian_symmetric check_vector :     ( false ) verify that  $\\operatorname{Hess} f(p)[X] ‚àà T_p\\mathcal M$  using  is_vector . mode :             ( :Default ) specify the mode for the verification; the default assumption is, that the retraction provided is of second order. Otherwise one can also verify the Hessian if the point  p  is a critical point. THen set the mode to  :CritalPoint  to use  gradient_descent  to find a critical point. Note: this requires (and evaluates) new tangent vectors  X  and  Y atol ,  rtol :      (same defaults as  isapprox ) tolerances that are passed down to all checks a ,  b             two real values to verify linearity of the Hessian (if  check_linearity=true ) N :                 ( 101 ) number of points to verify within the  log_range  default range  $[10^{-8},10^{0}]$ exactness_tol :     ( 1e-12 ) if all errors are below this tolerance, the verification is considered to be exact io :                ( nothing ) provide an  IO  to print the result to gradient :          ( grad_f(M, p) ) instead of the gradient function you can also provide the gradient at  p  directly Hessian :           ( Hess_f(M, p, X) ) instead of the Hessian function you can provide the result of  $\\operatorname{Hess} f(p)[X]$  directly. Note that evaluations of the Hessian might still be necessary for checking linearity and symmetry and/or when using  :CriticalPoint  mode. limits :            ( (1e-8,1) ) specify the limits in the  log_range log_range :         ( range(limits[1], limits[2]; length=N) ) specify the range of points (in log scale) to sample the Hessian line N :                 ( 101 ) number of points to use within the  log_range  default range  $[10^{-8},10^{0}]$ plot :              ( false ) whether to plot the resulting verification (requires  Plots.jl  to be loaded). The plot is in log-log-scale. This is returned and can then also be saved. retraction_method : ( default_retraction_method(M, typeof(p)) ) retraction method to use for slope_tol :         ( 0.1 ) tolerance for the slope (global) of the approximation throw_error :       ( false ) throw an error message if the Hessian is wrong window :            ( nothing ) specify window sizes within the  log_range  that are used for the slope estimation. the default is, to use all window sizes  2:N . The  kwargs...  are also passed down to the  check_vector  and the  check_gradient  call, such that tolerances can easily be set. While  check_vector  is also passed to the inner call to  check_gradient  as well as the  retraction_method , this inner  check_gradient  is meant to be just for inner verification, so it does not throw an error nor produce a plot itself. source"},{"id":2123,"pagetitle":"Checks","title":"Manopt.check_differential","ref":"/manopt/stable/helpers/checks/#Manopt.check_differential","content":" Manopt.check_differential  ‚Äî  Function check_differential(M, F, dF, p=rand(M), X=rand(M; vector_at=p); kwargs...) Check numerically whether the differential  dF(M,p,X)  of  F(M,p)  is correct. This implements the method described in [ Bou23 , Section 4.8]. Note that if the errors are below the given tolerance and the method is exact, no plot is generated, Keyword arguments exactness_tol :     ( 1e-12 ) if all errors are below this tolerance, the differential is considered to be exact io :                ( nothing ) provide an  IO  to print the result to limits :            ( (1e-8,1) ) specify the limits in the  log_range log_range :         ( range(limits[1], limits[2]; length=N) ) specify the range of points (in log scale) to sample the differential line N :                 ( 101 ) number of points to verify within the  log_range  default range  $[10^{-8},10^{0}]$ name :              ( \"differential\" ) name to display in the plot plot :              ( false ) whether to plot the result (if  Plots.jl  is loaded). The plot is in log-log-scale. This is returned and can then also be saved. retraction_method : ( default_retraction_method(M, typeof(p)) ) retraction method to use slope_tol :         ( 0.1 ) tolerance for the slope (global) of the approximation throw_error :       ( false ) throw an error message if the differential is wrong window :            ( nothing ) specify window sizes within the  log_range  that are used for the slope estimation. the default is, to use all window sizes  2:N . source"},{"id":2124,"pagetitle":"Checks","title":"Manopt.check_gradient","ref":"/manopt/stable/helpers/checks/#Manopt.check_gradient","content":" Manopt.check_gradient  ‚Äî  Function check_gradient(M, F, gradF, p=rand(M), X=rand(M; vector_at=p); kwargs...) Verify numerically whether the gradient  gradF(M,p)  of  F(M,p)  is correct, that is whether \\[f(\\operatorname{retr}_p(tX)) = f(p) + t‚ü®\\operatorname{grad} f(p), X‚ü© + \\mathcal O(t^2)\\] or in other words, that the error between the function  $f$  and its first order Taylor behaves in error  $\\mathcal O(t^2)$ , which indicates that the gradient is correct, cf. also [ Bou23 , Section 4.8]. Note that if the errors are below the given tolerance and the method is exact, no plot is generated. Keyword arguments check_vector :      ( true ) verify that  $\\operatorname{grad} f(p) ‚àà T_p\\mathcal M$  using  is_vector . exactness_tol :     ( 1e-12 ) if all errors are below this tolerance, the gradient is considered to be exact io :                ( nothing ) provide an  IO  to print the result to gradient :          ( grad_f(M, p) ) instead of the gradient function you can also provide the gradient at  p  directly limits :            ( (1e-8,1) ) specify the limits in the  log_range log_range :         ( range(limits[1], limits[2]; length=N) ) - specify the range of points (in log scale) to sample the gradient line N :                 ( 101 ) number of points to verify within the  log_range  default range  $[10^{-8},10^{0}]$ plot :              ( false ) whether to plot the result (if  Plots.jl  is loaded). The plot is in log-log-scale. This is returned and can then also be saved. retraction_method : ( default_retraction_method(M, typeof(p)) ) retraction method to use slope_tol :         ( 0.1 ) tolerance for the slope (global) of the approximation atol ,  rtol :      (same defaults as  isapprox ) tolerances that are passed down to  is_vector  if  check_vector  is set to  true throw_error :       ( false ) throw an error message if the gradient is wrong window :            ( nothing ) specify window sizes within the  log_range  that are used for the slope estimation. the default is, to use all window sizes  2:N . The remaining keyword arguments are also passed down to the  check_vector  call, such that tolerances can easily be set. source"},{"id":2125,"pagetitle":"Checks","title":"Manopt.find_best_slope_window","ref":"/manopt/stable/helpers/checks/#Manopt.find_best_slope_window","content":" Manopt.find_best_slope_window  ‚Äî  Function (a,b,i,j) = find_best_slope_window(X,Y,window=nothing; slope=2.0, slope_tol=0.1) Check data X,Y for the largest contiguous interval (window) with a regression line fitting ‚Äúbest‚Äù. Among all intervals with a slope within  slope_tol  to  slope  the longest one is taken. If no such interval exists, the one with the slope closest to  slope  is taken. If the window is set to  nothing  (default), all window sizes  2,...,length(X)  are checked. You can also specify a window size or an array of window sizes. For each window size, all its translates in the data is checked. For all these (shifted) windows the regression line is computed (with  a,b  in  a + t*b ) and the best line is computed. From the best line the following data is returned a ,  b  specifying the regression line  a + t*b i ,  j  determining the window, i.e the regression line stems from data  X[i], ..., X[j] source"},{"id":2126,"pagetitle":"Checks","title":"Manopt.is_Hessian_linear","ref":"/manopt/stable/helpers/checks/#Manopt.is_Hessian_linear","content":" Manopt.is_Hessian_linear  ‚Äî  Function is_Hessian_linear(M, Hess_f, p,\n    X=rand(M; vector_at=p), Y=rand(M; vector_at=p), a=randn(), b=randn();\n    throw_error=false, io=nothing, kwargs...\n) Verify whether the Hessian function  Hess_f  fulfills linearity, \\[\\operatorname{Hess} f(p)[aX + bY] = b\\operatorname{Hess} f(p)[X]\n + b\\operatorname{Hess} f(p)[Y]\\] which is checked using  isapprox  and the keyword arguments are passed to this function. Optional arguments throw_error : ( false ) throw an error message if the Hessian is wrong source"},{"id":2127,"pagetitle":"Checks","title":"Manopt.is_Hessian_symmetric","ref":"/manopt/stable/helpers/checks/#Manopt.is_Hessian_symmetric","content":" Manopt.is_Hessian_symmetric  ‚Äî  Function is_Hessian_symmetric(M, Hess_f, p=rand(M), X=rand(M; vector_at=p), Y=rand(M; vector_at=p);\nthrow_error=false, io=nothing, atol::Real=0, rtol::Real=atol>0 ? 0 : ‚àöeps ) Verify whether the Hessian function  Hess_f  fulfills symmetry, which means that \\[‚ü®\\operatorname{Hess} f(p)[X], Y‚ü© = ‚ü®X, \\operatorname{Hess} f(p)[Y]‚ü©\\] which is checked using  isapprox  and the  kwargs...  are passed to this function. Optional arguments atol ,  rtol    with the same defaults as the usual  isapprox throw_error :    ( false ) throw an error message if the Hessian is wrong source"},{"id":2128,"pagetitle":"Checks","title":"Manopt.plot_slope","ref":"/manopt/stable/helpers/checks/#Manopt.plot_slope-Tuple{Any, Any}","content":" Manopt.plot_slope  ‚Äî  Method plot_slope(x, y; slope=2, line_base=0, a=0, b=2.0, i=1,j=length(x)) Plot the result from the verification functions  check_gradient ,  check_differential ,  check_Hessian  on data  x,y  with two comparison lines line_base  + t slope   as the global slope the plot should have a  +  b*t  on the interval [ x[i] ,  x[j] ] for some (best fitting) comparison slope source"},{"id":2129,"pagetitle":"Checks","title":"Manopt.prepare_check_result","ref":"/manopt/stable/helpers/checks/#Manopt.prepare_check_result-Tuple{Any, Any, Any}","content":" Manopt.prepare_check_result  ‚Äî  Method prepare_check_result(log_range, errors, slope) Given a range of values  log_range , with computed  errors , verify whether this yields a slope of  slope  in log-scale Note that if the errors are below the given tolerance and the method is exact, no plot is be generated, Keyword arguments exactness_tol : ( 1e3*eps(eltype(errors)) ) is all errors are below this tolerance, the verification is considered to be exact io :            ( nothing ) provide an  IO  to print the result to name :          ( \"differential\" ) name to display in the plot title plot :          ( false ) whether to plot the result (if  Plots.jl  is loaded). The plot is in log-log-scale. This is returned and can then also be saved. slope_tol :     ( 0.1 ) tolerance for the slope (global) of the approximation throw_error :   ( false ) throw an error message if the gradient or Hessian is wrong source"},{"id":2130,"pagetitle":"Checks","title":"Literature","ref":"/manopt/stable/helpers/checks/#Literature","content":" Literature [Bou23] N.¬†Boumal.  An Introduction to Optimization on Smooth Manifolds . First¬†Edition ( Cambridge University Press, 2023 )."},{"id":2133,"pagetitle":"Exports","title":"Exports","ref":"/manopt/stable/helpers/exports/#sec-exports","content":" Exports Exports aim to provide a consistent generation of images of your results. For example if you  record  the trace your algorithm walks on the  Sphere , you can easily export this trace to a rendered image using  asymptote_export_S2_signals  and render the result with  Asymptote . Despite these, you can always  record  values during your iterations, and export these, for example to  csv ."},{"id":2134,"pagetitle":"Exports","title":"Asymptote","ref":"/manopt/stable/helpers/exports/#Asymptote","content":" Asymptote The following functions provide exports both in graphics and/or raw data using  Asymptote ."},{"id":2135,"pagetitle":"Exports","title":"Manopt.asymptote_export_S2_data","ref":"/manopt/stable/helpers/exports/#Manopt.asymptote_export_S2_data-Tuple{String}","content":" Manopt.asymptote_export_S2_data  ‚Äî  Method asymptote_export_S2_data(filename) Export given  data  as an array of points on the 2-sphere, which might be one-, two- or three-dimensional data with points on the  Sphere $\\mathbb S^2$ . Input filename                 a file to store the Asymptote code in. Optional arguments for the data data                     a point representing the 1D,2D, or 3D array of points elevation_color_scheme   A  ColorScheme  for elevation scale_axes :              ( (1/3,1/3,1/3) ) move spheres closer to each other by a factor per direction Optional arguments for asymptote arrow_head_size :  ( 1.8 ) size of the arrowheads of the vectors (in mm) camera_position   position of the camera scene (default: atop the center of the data in the xy-plane) target            position the camera points at (default: center of xy-plane within data). source"},{"id":2136,"pagetitle":"Exports","title":"Manopt.asymptote_export_S2_signals","ref":"/manopt/stable/helpers/exports/#Manopt.asymptote_export_S2_signals-Tuple{String}","content":" Manopt.asymptote_export_S2_signals  ‚Äî  Method asymptote_export_S2_signals(filename; points, curves, tangent_vectors, colors, options...) Export given  points ,  curves , and  tangent_vectors  on the sphere  $\\mathbb S^2$  to Asymptote. Input filename           a file to store the Asymptote code in. Optional arguments for the data colors             dictionary of color arrays (indexed by symbols  :points ,  :curves  and  :tvector ) where each entry has to provide as least as many colors as the length of the corresponding sets. curves             an  Array  of  Arrays  of points on the sphere, where each inner array is interpreted as a curve and is accompanied by an entry within  colors points             an  Array  of  Arrays  of points on the sphere where each inner array is interpreted as a set of points and is accompanied by an entry within  colors tangent_vectors    an  Array  of  Arrays  of tuples, where the first is a points, the second a tangent vector and each set of vectors is accompanied by an entry from within  colors Optional arguments for asymptote arrow_head_size :   ( 6.0 ) size of the arrowheads of the tangent vectors arrow_head_sizes   overrides the previous value to specify a value per  tVector ` set. camera_position :   ( (1., 1., 0.) ) position of the camera in the Asymptote scene line_width :        ( 1.0 ) size of the lines used to draw the curves. line_widths        overrides the previous value to specify a value per curve and  tVector ` set. dot_size :          ( 1.0 ) size of the dots used to draw the points. dot_sizes          overrides the previous value to specify a value per point set. size :              ( nothing ) a tuple for the image size, otherwise a relative size  4cm  is used. sphere_color :      ( RGBA{Float64}(0.85, 0.85, 0.85, 0.6) ) color of the sphere the data is drawn on sphere_line_color : ( RGBA{Float64}(0.75, 0.75, 0.75, 0.6) ) color of the lines on the sphere sphere_line_width : ( 0.5 ) line width of the lines on the sphere target :            ( (0.,0.,0.) ) position the camera points at source"},{"id":2137,"pagetitle":"Exports","title":"Manopt.asymptote_export_SPD","ref":"/manopt/stable/helpers/exports/#Manopt.asymptote_export_SPD-Tuple{String}","content":" Manopt.asymptote_export_SPD  ‚Äî  Method asymptote_export_SPD(filename) export given  data  as a point on a  Power(SymmetricPOsitiveDefinnite(3))}  manifold of one-, two- or three-dimensional data with points on the manifold of symmetric positive definite matrices. Input filename         a file to store the Asymptote code in. Optional arguments for the data data             a point representing the 1D, 2D, or 3D array of SPD matrices color_scheme     a  ColorScheme  for Geometric Anisotropy Index scale_axes :      ( (1/3,1/3,1/3) ) move symmetric positive definite matrices closer to each other by a factor per direction compared to the distance estimated by the maximal eigenvalue of all involved SPD points Optional arguments for asymptote camera_position   position of the camera scene (default: atop the center of the data in the xy-plane) target            position the camera points at (default: center of xy-plane within data). Both values  camera_position  and  target  are scaled by  scaledAxes*EW , where  EW  is the maximal eigenvalue in the  data . source"},{"id":2138,"pagetitle":"Exports","title":"Manopt.render_asymptote","ref":"/manopt/stable/helpers/exports/#Manopt.render_asymptote-Tuple{Any}","content":" Manopt.render_asymptote  ‚Äî  Method render_asymptote(filename; render=4, format=\"png\", ...) render an exported asymptote file specified in the  filename , which can also be given as a relative or full path Input filename     filename of the exported  asy  and rendered image Keyword arguments the default values are given in brackets render :      ( 4 ) render level of asymptote passed to its  -render  option.  This can be removed from the command by setting it to  nothing . format :      ( \"png\" ) final rendered format passed to the  -f  option export_file : (the filename with format as ending) specify the export filename source"},{"id":2141,"pagetitle":"Notation","title":"Notation","ref":"/manopt/stable/notation/#Notation","content":" Notation In this package,the notation introduced in  Manifolds.jl Notation  is used with the following additional parts. Symbol Description Also used Comment $‚àá$ The  Levi-Cevita connection"},{"id":2144,"pagetitle":"Specify a Solver","title":"Plans for solvers","ref":"/manopt/stable/plans/#sec-plan","content":" Plans for solvers For any optimisation performed in  Manopt.jl  information is required about both the optimisation task or ‚Äúproblem‚Äù at hand as well as the solver and all its parameters. This together is called a  plan  in  Manopt.jl  and it consists of two data structures: The  Manopt Problem  describes all  static  data of a task, most prominently the manifold and the objective. The  Solver State  describes all  varying  data and parameters for the solver that is used. This also means that each solver has its own data structure for the state. By splitting these two parts, one problem can be define an then be solved  using different solvers. Still there might be the need to set certain parameters within any of these structures. For that there is"},{"id":2145,"pagetitle":"Specify a Solver","title":"Manopt.set_manopt_parameter!","ref":"/manopt/stable/plans/#Manopt.set_manopt_parameter!","content":" Manopt.set_manopt_parameter!  ‚Äî  Function set_manopt_parameter!(f, element::Symbol , args...) For any  f  and a  Symbol e , dispatch on its value so by default, to set some  args...  in  f  or one of uts sub elements. source set_manopt_parameter!(element::Symbol, value::Union{String,Bool,<:Number}) Set global  Manopt  parameters addressed by a symbol  element . W This first dispatches on the value of  element . The parameters are stored to the global settings using  Preferences.jl . Passing a  value  of  \"\"  deletes the corresponding entry from the preferences. Whenever the  LocalPreferences.toml  is modified, this is also issued as an  @info . source set_manopt_parameter!(amo::AbstractManifoldObjective, element::Symbol, args...) Set a certain  args...  from the  AbstractManifoldObjective amo  to  value. This function should dispatch on Val(element)`. Currently supported :Cost  passes to the  get_cost_function :Gradient  passes to the  get_gradient_function source set_manopt_parameter!(ams::AbstractManoptProblem, element::Symbol, field::Symbol , value) Set a certain field/element from the  AbstractManoptProblem ams  to  value. This function should dispatch on Val(element)`. By default this passes on to the inner objective, see  set_manopt_parameter! source set_manopt_parameter!(ams::DebugSolverState, ::Val{:Debug}, args...) Set certain values specified by  args...  into the elements of the  debugDictionary source set_manopt_parameter!(ams::AbstractManoptSolverState, element::Symbol, args...) Set a certain field or semantic element from the  AbstractManoptSolverState ams  to  value . This function passes to  Val(element)  and specific setters should dispatch on  Val{element} . By default, this function just does nothing. source set_manopt_parameter!(ams::DebugSolverState, ::Val{:SubProblem}, args...) Set certain values specified by  args...  to the sub problem. source set_manopt_parameter!(ams::DebugSolverState, ::Val{:SubState}, args...) Set certain values specified by  args...  to the sub state. source"},{"id":2146,"pagetitle":"Specify a Solver","title":"Manopt.get_manopt_parameter","ref":"/manopt/stable/plans/#Manopt.get_manopt_parameter","content":" Manopt.get_manopt_parameter  ‚Äî  Function get_manopt_parameter(f, element::Symbol, args...) Access arbitrary parameters from  f  addressed by a symbol  element . For any  f  and a  Symbol e  dispatch on its value by default, to get some element from  f  potentially further qualified by  args... . This functions returns  nothing  if  f  does not have the property  element source get_manopt_parameter(element::Symbol; default=nothing) Access global  Manopt  parameters addressed by a symbol  element . This first dispatches on the value of  element . If the value is not set,  default  is returned. The parameters are queried from the global settings using  Preferences.jl , so they are persistent within your activated Environment. Currently used settings :Mode  the mode can be set to  \"Tutorial\"  to get several hints especially in scenarios, where the optimisation on manifolds is different from the usual ‚Äúexperience‚Äù in (classical, Euclidean) optimization. Any other value has the same effect as not setting it. source"},{"id":2147,"pagetitle":"Specify a Solver","title":"Manopt.status_summary","ref":"/manopt/stable/plans/#Manopt.status_summary","content":" Manopt.status_summary  ‚Äî  Function status_summary(e) Return a string reporting about the current status of  e , where  e  is a type from Manopt. This method is similar to  show  but just returns a string. It might also be more verbose in explaining, or hide internal information. source Where the following Symbols are used The following symbols are used. The column ‚Äúgeneric‚Äù refers to a short hand that might be used¬†for readability if clear from context. | Symbol       | Used in | Description                                                | generic | | :‚Äì‚Äì‚Äì‚Äì‚Äì- | :‚Äì‚Äì‚Äì: | ;‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì | :‚Äì‚Äì‚Äì | |  :active  |  DebugWhenActive  | activity of the debug action stored within |¬†| |  :Basepoint  |  TangentSpace  | the point the tangent space is at           | often  :p  | |  :Cost  | generic |the cost function (within an objective, as pass down) |¬†| |  :Debug  |  DebugSolverState  | the stored  debugDictionary  |¬†| |  :Gradient  | generic | the gradient function (within an objective, as pass down) |¬†| |  :Iterate  | generic | the (current) iterate,¬†similar to  set_iterate! ,¬†within a state |¬†| |  :Manifold  | generic |the manifold (within a problem, as pass down) |¬†| |  :Objective  | generic | the objective (within a problem, as pass down) |¬†| |  :SubProblem  | generic | the sub problem (within a state, as pass down) |¬†| |  :SubState  | generic | the sub state (within a state, as pass down) |¬†| |¬† :Œª  |¬† ProximalDCCost ,  ProximalDCGrad  |¬†set the proximal parameter within the proximal sub objective elements |¬†| |  :Population      |  ParticleSwarmState  | a certain population of points, for example  particle_swarm s swarm |¬†| |  :TrustRegionRadius  |  TrustRegionsState  |¬†the trust region radius |  :œÉ  | |¬† :œÅ ,  :u  |¬† ExactPenaltyCost ,  ExactPenaltyGrad  |¬†Parameters within the exact penalty objective |¬†| |  :œÅ ,  :Œº ,  :Œª  |  AugmentedLagrangianCost  and  AugmentedLagrangianGrad  |¬†Parameters of the Lagrangian function | | Since the iterate is often stored in the states fields  s.p  one  could  access the iterate often also with  :p  and similarly the gradient with  :X . This is discouraged for both readability as well as to star more generic, and it is recommended to use  :Iterate  and  :Gradient  instead in generic settings. You can further activate a ‚ÄúTutorial‚Äù mode by  set_manopt_parameter!(:Mode, \"Tutorial\") . Internally, the following convenience function is available."},{"id":2148,"pagetitle":"Specify a Solver","title":"Manopt.is_tutorial_mode","ref":"/manopt/stable/plans/#Manopt.is_tutorial_mode","content":" Manopt.is_tutorial_mode  ‚Äî  Function is_tutorial_mode() A small internal helper to indicate whether tutorial mode is active. You can set the mode by calling  set_manopt_parameter!(:Mode, \"Tutorial\")  or deactivate it by  set_manopt_parameter!(:Mode, \"\") . source"},{"id":2151,"pagetitle":"Debug Output","title":"Debug output","ref":"/manopt/stable/plans/debug/#sec-debug","content":" Debug output Debug output can easily be added to any solver run. On the high level interfaces, like  gradient_descent , you can just use the  debug=  keyword."},{"id":2152,"pagetitle":"Debug Output","title":"Manopt.DebugAction","ref":"/manopt/stable/plans/debug/#Manopt.DebugAction","content":" Manopt.DebugAction  ‚Äî  Type DebugAction A  DebugAction  is a small functor to print/issue debug output. The usual call is given by  (p::AbstractManoptProblem, s::AbstractManoptSolverState, i) -> s , where  i  is the current iterate. By convention  i=0  is interpreted as \"For Initialization only,\" only debug info that prints initialization reacts,  i<0  triggers updates of variables internally but does not trigger any output. Fields (assumed by subtypes to exist) print  method to perform the actual print. Can for example be set to a file export, or to @info. The default is the  print  function on the default  Base.stdout . source"},{"id":2153,"pagetitle":"Debug Output","title":"Manopt.DebugChange","ref":"/manopt/stable/plans/debug/#Manopt.DebugChange","content":" Manopt.DebugChange  ‚Äî  Type DebugChange(M=DefaultManifold()) debug for the amount of change of the iterate (stored in  get_iterate(o)  of the  AbstractManoptSolverState ) during the last iteration. See  DebugEntryChange  for the general case Keyword parameters storage :                   ( StoreStateAction( [:Gradient] )  storage of the previous action prefix :                    ( \"Last Change:\" ) prefix of the debug output (ignored if you set  format ) io :                        ( stdout ) default stream to print the debug to. format :                    (  \"$prefix %f\" ) format to print the output. inverse_retraction_method : ( default_inverse_retraction_method(M) ) the inverse retraction to be used for approximating distance. source"},{"id":2154,"pagetitle":"Debug Output","title":"Manopt.DebugCost","ref":"/manopt/stable/plans/debug/#Manopt.DebugCost","content":" Manopt.DebugCost  ‚Äî  Type DebugCost <: DebugAction print the current cost function value, see  get_cost . Constructors DebugCost() Parameters format : ( \"$prefix %f\" ) format to print the output io :     ( stdout ) default stream to print the debug to. long :   ( false ) short form to set the format to  f(x):  (default) or  current cost:  and the cost source"},{"id":2155,"pagetitle":"Debug Output","title":"Manopt.DebugDivider","ref":"/manopt/stable/plans/debug/#Manopt.DebugDivider","content":" Manopt.DebugDivider  ‚Äî  Type DebugDivider <: DebugAction print a small divider (default  \" | \" ). Constructor DebugDivider(div,print) source"},{"id":2156,"pagetitle":"Debug Output","title":"Manopt.DebugEntry","ref":"/manopt/stable/plans/debug/#Manopt.DebugEntry","content":" Manopt.DebugEntry  ‚Äî  Type DebugEntry <: DebugAction print a certain fields entry during the iterates, where a  format  can be specified how to print the entry. Additional fields field : symbol the entry can be accessed with within  AbstractManoptSolverState Constructor DebugEntry(f; prefix=\"$f:\", format = \"$prefix %s\", io=stdout) source"},{"id":2157,"pagetitle":"Debug Output","title":"Manopt.DebugEntryChange","ref":"/manopt/stable/plans/debug/#Manopt.DebugEntryChange","content":" Manopt.DebugEntryChange  ‚Äî  Type DebugEntryChange{T} <: DebugAction print a certain entries change during iterates Additional fields print :    ( print ) function to print the result prefix :   ( \"Change of :Iterate\" ) prefix to the print out format :   ( \"$prefix %e\" ) format to print (uses the `prefix by default and scientific notation) field :    Symbol the field can be accessed with within  AbstractManoptSolverState distance : function (p,o,x1,x2) to compute the change/distance between two values of the entry storage :  a  StoreStateAction  to store the previous value of  :f Constructors DebugEntryChange(f,d) Keyword arguments io :             ( stdout ) an  IOStream prefix :         ( \"Change of $f\" ) storage :        ( StoreStateAction((f,)) ) a  StoreStateAction initial_value : an initial value for the change of  o.field . format :         ( \"$prefix %e\" ) format to print the change source"},{"id":2158,"pagetitle":"Debug Output","title":"Manopt.DebugEvery","ref":"/manopt/stable/plans/debug/#Manopt.DebugEvery","content":" Manopt.DebugEvery  ‚Äî  Type DebugEvery <: DebugAction evaluate and print debug only every  $i$ th iteration. Otherwise no print is performed. Whether internal variables are updates is determined by  always_update . This method does not perform any print itself but relies on it's children's print. It also sets the subsolvers active parameter, see | DebugWhenActive }(#ref). Here, the  activattion_offset  can be used to specify whether it refers to  this  iteration, the  i th, when this call is  before  the iteration, then the offset should be 0, for the  next  iteration, that is if this is called  after  an iteration, it has to be set to 1. Since usual debug is happening after the iteration, 1 is the default. Constructor DebugEvery(d::DebugAction, every=1, always_update=true, activation_offset=1) Initialise the DebugEvery. source"},{"id":2159,"pagetitle":"Debug Output","title":"Manopt.DebugGradientChange","ref":"/manopt/stable/plans/debug/#Manopt.DebugGradientChange","content":" Manopt.DebugGradientChange  ‚Äî  Type DebugGradientChange() debug for the amount of change of the gradient (stored in  get_gradient(o)  of the  AbstractManoptSolverState o ) during the last iteration. See  DebugEntryChange  for the general case Keyword parameters storage : ( StoreStateAction( (:Gradient,) ) ) storage of the action for previous data prefix :  ( \"Last Change:\" ) prefix of the debug output (ignored if you set  format ) io :      ( stdout ) default stream to print the debug to. format :  (  \"$prefix %f\" ) format to print the output source"},{"id":2160,"pagetitle":"Debug Output","title":"Manopt.DebugGroup","ref":"/manopt/stable/plans/debug/#Manopt.DebugGroup","content":" Manopt.DebugGroup  ‚Äî  Type DebugGroup <: DebugAction group a set of  DebugAction s into one action, where the internal prints are removed by default and the resulting strings are concatenated Constructor DebugGroup(g) construct a group consisting of an Array of  DebugAction s  g , that are evaluated  en bloque ; the method does not perform any print itself, but relies on the internal prints. It still concatenates the result and returns the complete string source"},{"id":2161,"pagetitle":"Debug Output","title":"Manopt.DebugIfEntry","ref":"/manopt/stable/plans/debug/#Manopt.DebugIfEntry","content":" Manopt.DebugIfEntry  ‚Äî  Type DebugIfEntry <: DebugAction Issue a warning, info, or error if a certain field does  not  pass a the  check . The  message  is printed in this case. If it contains a  @printf  argument identifier, that one is filled with the value of the  field . That way you can print the value in this case as well. Fields io :    an  IO  stream check : a function that takes the value of the  field  as input and returns a boolean field : symbol the entry can be accessed with within  AbstractManoptSolverState msg :   if the  check  fails, this message is displayed type : symbol specifying the type of display, possible values  :print ,  : warn ,  :info ,  :error ,           where  :print  prints to  io . Constructor DebugEntry(field, check=(>(0)); type=:warn, message=\":$f is nonnegative\", io=stdout) source"},{"id":2162,"pagetitle":"Debug Output","title":"Manopt.DebugIterate","ref":"/manopt/stable/plans/debug/#Manopt.DebugIterate","content":" Manopt.DebugIterate  ‚Äî  Type DebugIterate <: DebugAction debug for the current iterate (stored in  get_iterate(o) ). Constructor DebugIterate() Parameters io :        ( stdout ) default stream to print the debug to. format :    ( \"$prefix %s\" ) format how to print the current iterate long :      ( false ) whether to have a long ( \"current iterate:\" ) or a short ( \"p:\" ) prefix prefix      (see  long  for default) set a prefix to be printed before the iterate source"},{"id":2163,"pagetitle":"Debug Output","title":"Manopt.DebugIteration","ref":"/manopt/stable/plans/debug/#Manopt.DebugIteration","content":" Manopt.DebugIteration  ‚Äî  Type DebugIteration <: DebugAction Constructor DebugIteration() Keyword parameters format : ( \"# %-6d\" ) format to print the output io :     ( stdout ) default stream to print the debug to. debug for the current iteration (prefixed with  #  by ) source"},{"id":2164,"pagetitle":"Debug Output","title":"Manopt.DebugMessages","ref":"/manopt/stable/plans/debug/#Manopt.DebugMessages","content":" Manopt.DebugMessages  ‚Äî  Type DebugMessages <: DebugAction An  AbstractManoptSolverState  or one of its sub steps like a  Stepsize  might generate warnings throughout their computations. This debug can be used to  :print  them display them as  :info  or  :warnings  or even  :error , depending on the message type. Constructor DebugMessages(mode=:Info, warn=:Once; io::IO=stdout) Initialize the messages debug to a certain  mode . Available modes are :Error :   issue the messages as an error and hence stop at any issue occurring :Info :    issue the messages as an  @info :Print :   print messages to the steam  io . :Warning : issue the messages as a warning The  warn  level can be set to  :Once  to only display only the first message, to  :Always  to report every message, one can set it to  :No , to deactivate this, then this  DebugAction  is inactive. All other symbols are handled as if they were  :Always: source"},{"id":2165,"pagetitle":"Debug Output","title":"Manopt.DebugSolverState","ref":"/manopt/stable/plans/debug/#Manopt.DebugSolverState","content":" Manopt.DebugSolverState  ‚Äî  Type DebugSolverState <: AbstractManoptSolverState The debug state appends debug to any state, they act as a decorator pattern. Internally a dictionary is kept that stores a  DebugAction  for several occasions using a  Symbol  as reference. The original options can still be accessed using the  get_state  function. Fields options :         the options that are extended by debug information debugDictionary : a  Dict{Symbol,DebugAction}  to keep track of Debug for different actions Constructors DebugSolverState(o,dA) construct debug decorated options, where  dD  can be a  DebugAction , then it is stored within the dictionary at  :Iteration an  Array  of  DebugAction s. a  Dict{Symbol,DebugAction} . an Array of Symbols, String and an Int for the  DebugFactory source"},{"id":2166,"pagetitle":"Debug Output","title":"Manopt.DebugStoppingCriterion","ref":"/manopt/stable/plans/debug/#Manopt.DebugStoppingCriterion","content":" Manopt.DebugStoppingCriterion  ‚Äî  Type DebugStoppingCriterion <: DebugAction print the Reason provided by the stopping criterion. Usually this should be empty, unless the algorithm stops. Fields prefix : ( \"\" ) format to print the output io :     ( stdout ) default stream to print the debug to. Constructor DebugStoppingCriterion(prefix = \"\"; io::IO=stdout) source"},{"id":2167,"pagetitle":"Debug Output","title":"Manopt.DebugTime","ref":"/manopt/stable/plans/debug/#Manopt.DebugTime","content":" Manopt.DebugTime  ‚Äî  Type DebugTime() Measure time and print the intervals. Using  start=true  you can start the timer on construction, for example to measure the runtime of an algorithm overall (adding) The measured time is rounded using the given  time_accuracy  and printed after  canonicalization . Keyword parameters io :            ( stdout ) default stream to print the debug to. format :        (  \"$prefix %s\" ) format to print the output, where  %s  is the canonicalized time`. mode :          ( :cumulative ) whether to display the total time or reset on every call using  :iterative . prefix :        ( \"Last Change:\" ) prefix of the debug output (ignored if you set  format ) start :         ( false ) indicate whether to start the timer on creation or not. Otherwise it might only be started on first call. time_accuracy : ( Millisecond(1) ) round the time to this period before printing the canonicalized time source"},{"id":2168,"pagetitle":"Debug Output","title":"Manopt.DebugWarnIfCostIncreases","ref":"/manopt/stable/plans/debug/#Manopt.DebugWarnIfCostIncreases","content":" Manopt.DebugWarnIfCostIncreases  ‚Äî  Type DebugWarnIfCostIncreases <: DebugAction print a warning if the cost increases. Note that this provides an additional warning for gradient descent with its default constant step size. Constructor DebugWarnIfCostIncreases(warn=:Once; tol=1e-13) Initialize the warning to warning level ( :Once ) and introduce a tolerance for the test of  1e-13 . The  warn  level can be set to  :Once  to only warn the first time the cost increases, to  :Always  to report an increase every time it happens, and it can be set to  :No  to deactivate the warning, then this  DebugAction  is inactive. All other symbols are handled as if they were  :Always: source"},{"id":2169,"pagetitle":"Debug Output","title":"Manopt.DebugWarnIfCostNotFinite","ref":"/manopt/stable/plans/debug/#Manopt.DebugWarnIfCostNotFinite","content":" Manopt.DebugWarnIfCostNotFinite  ‚Äî  Type DebugWarnIfCostNotFinite <: DebugAction A debug to see when a field (value or array within the AbstractManoptSolverState is or contains values that are not finite, for example  Inf  or  Nan . Constructor DebugWarnIfCostNotFinite(field::Symbol, warn=:Once) Initialize the warning to warn  :Once . This can be set to  :Once  to only warn the first time the cost is Nan. It can also be set to  :No  to deactivate the warning, but this makes this Action also useless. All other symbols are handled as if they were  :Always: source"},{"id":2170,"pagetitle":"Debug Output","title":"Manopt.DebugWarnIfFieldNotFinite","ref":"/manopt/stable/plans/debug/#Manopt.DebugWarnIfFieldNotFinite","content":" Manopt.DebugWarnIfFieldNotFinite  ‚Äî  Type DebugWarnIfFieldNotFinite <: DebugAction A debug to see when a field from the options is not finite, for example  Inf  or  Nan Constructor DebugWarnIfFieldNotFinite(field::Symbol, warn=:Once) Initialize the warning to warn  :Once . This can be set to  :Once  to only warn the first time the cost is Nan. It can also be set to  :No  to deactivate the warning, but this makes this Action also useless. All other symbols are handled as if they were  :Always: Example DebugWaranIfFieldNotFinite(:Gradient) Creates a [ DebugAction ] to track whether the gradient does not get  Nan  or  Inf . source"},{"id":2171,"pagetitle":"Debug Output","title":"Manopt.DebugWarnIfGradientNormTooLarge","ref":"/manopt/stable/plans/debug/#Manopt.DebugWarnIfGradientNormTooLarge","content":" Manopt.DebugWarnIfGradientNormTooLarge  ‚Äî  Type DebugWarnIfGradientNormTooLarge{T} <: DebugAction A debug to warn when an evaluated gradient at the current iterate is larger than (a factor times) the maximal (recommended) stepsize at the current iterate. Constructor DebugWarnIfGradientNormTooLarge(factor::T=1.0, warn=:Once) Initialize the warning to warn  :Once . This can be set to  :Once  to only warn the first time the cost is Nan. It can also be set to  :No  to deactivate the warning, but this makes this Action also useless. All other symbols are handled as if they were  :Always: Example DebugWaranIfFieldNotFinite(:Gradient) Creates a [ DebugAction ] to track whether the gradient does not get  Nan  or  Inf . source"},{"id":2172,"pagetitle":"Debug Output","title":"Manopt.DebugWhenActive","ref":"/manopt/stable/plans/debug/#Manopt.DebugWhenActive","content":" Manopt.DebugWhenActive  ‚Äî  Type DebugWhenActive <: DebugAction evaluate and print debug only if the active boolean is set. This can be set from outside and is for example triggered by  DebugEvery  on debugs on the subsolver. This method does not perform any print itself but relies on it's children's prints. For now, the main interaction is with  DebugEvery  which might activate or deactivate this debug Fields active :        a boolean that can (de-)activated from outside to turn on/off debug always_update : whether or not to call the order debugs with iteration  -1  in active state Constructor DebugWhenActive(d::DebugAction, active=true, always_update=true) Initialise the DebugSubsolver. source"},{"id":2173,"pagetitle":"Debug Output","title":"Manopt.DebugActionFactory","ref":"/manopt/stable/plans/debug/#Manopt.DebugActionFactory-Tuple{String}","content":" Manopt.DebugActionFactory  ‚Äî  Method DebugActionFactory(s) create a  DebugAction  where a  String yields the corresponding divider a  DebugAction  is passed through a [ Symbol ] creates  DebugEntry  of that symbol, with the exceptions of  :Change ,  :Iterate ,  :Iteration , and  :Cost . a  Tuple{Symbol,String}  creates a  DebugEntry  of that symbol where the String specifies the format. source"},{"id":2174,"pagetitle":"Debug Output","title":"Manopt.DebugActionFactory","ref":"/manopt/stable/plans/debug/#Manopt.DebugActionFactory-Tuple{Symbol}","content":" Manopt.DebugActionFactory  ‚Äî  Method DebugActionFactory(s::Symbol) Convert certain Symbols in the  debug=[ ... ]  vector to  DebugAction s Currently the following ones are done. Note that the Shortcut symbols should all start with a capital letter. :Cost  creates a  DebugCost :Change  creates a  DebugChange :Gradient  creates a  DebugGradient :GradientChange  creates a  DebugGradientChange :GradientNorm  creates a  DebugGradientNorm :Iterate  creates a  DebugIterate :Iteration  creates a  DebugIteration :IterativeTime  creates a  DebugTime (:Iterative) :Stepsize  creates a  DebugStepsize :Stop  creates a  StoppingCriterion () :WarnCost  creates a  DebugWarnIfCostNotFinite :WarnGradient  creates a  DebugWarnIfFieldNotFinite  for the  ::Gradient . :WarnBundle  creates a  DebugWarnIfLagrangeMultiplierIncreases :Time  creates a  DebugTime :WarningMessages creates a  DebugMessages (:Warning) :InfoMessages creates a  DebugMessages (:Info) :ErrorMessages  creates a  DebugMessages (:Error) :Messages  creates a  DebugMessages ()  (the same as  :InfoMessages ) any other symbol creates a  DebugEntry(s)  to print the entry (o.:s) from the options. source"},{"id":2175,"pagetitle":"Debug Output","title":"Manopt.DebugActionFactory","ref":"/manopt/stable/plans/debug/#Manopt.DebugActionFactory-Tuple{Tuple{Symbol, String}}","content":" Manopt.DebugActionFactory  ‚Äî  Method DebugActionFactory(t::Tuple{Symbol,String) Convert certain Symbols in the  debug=[ ... ]  vector to  DebugAction s Currently the following ones are done, where the string in  t[2]  is passed as the  format  the corresponding debug. Note that the Shortcut symbols  t[1]  should all start with a capital letter. :Change  creates a  DebugChange :Cost  creates a  DebugCost :Gradient  creates a  DebugGradient :GradientChange  creates a  DebugGradientChange :GradientNorm  creates a  DebugGradientNorm :Iterate  creates a  DebugIterate :Iteration  creates a  DebugIteration :Stepsize  creates a  DebugStepsize :Stop  creates a  DebugStoppingCriterion :Time  creates a  DebugTime :IterativeTime  creates a  DebugTime (:Iterative) any other symbol creates a  DebugEntry(s)  to print the entry (o.:s) from the options. source"},{"id":2176,"pagetitle":"Debug Output","title":"Manopt.DebugFactory","ref":"/manopt/stable/plans/debug/#Manopt.DebugFactory-Tuple{Vector}","content":" Manopt.DebugFactory  ‚Äî  Method DebugFactory(a::Vector) Generate a dictionary of  DebugAction s. First all  Symbol s  String ,  DebugAction s and numbers are collected, excluding  :Stop  and  :Subsolver . This collected vector is added to the  :Iteration => [...]  pair.  :Stop  is added as  :StoppingCriterion  to the  :Stop => [...]  pair. If necessary, these pairs are created For each  Pair  of a  Symbol  and a  Vector , the  DebugGroupFactory  is called for the  Vector  and the result is added to the debug dictonaries entry with said symbold. This is wrapped into the  DebugWhenActive , when the  :Subsolver  symbol is present Return value A dictionary for the different enrty points where debug can happen, each containing a  DebugAction  to call. Note that upon the initialisation all dictionaries but the  :StartAlgorithm  one are called with an  i=0  for reset. Examples Providing a simple vector of symbols, numbers and strings like [:Iterate, \" | \", :Cost, :Stop, 10] Adds a group to :Iteration of three actions ( DebugIteration ,  DebugDivider (\" | \"),  and[ DebugCost ](@ref)) as a [ DebugGroup ](@ref) inside an [ DebugEvery ](@ref) to only be executed every 10th iteration. It also adds the [ DebugStoppingCriterion ](@ref) to the :EndAlgorhtm` entry of the dictionary. The same can also be written a bit more precise as DebugFactory([:Iteration => [:Iterate, \" | \", :Cost, 10], :Stop]) We can even make the stoping criterion concrete and pass Actions directly, for example explicitly Making the stop more concrete, we get DebugFactory([:Iteration => [:Iterate, \" | \", DebugCost(), 10], :Stop => [:Stop]]) source"},{"id":2177,"pagetitle":"Debug Output","title":"Manopt.DebugGroupFactory","ref":"/manopt/stable/plans/debug/#Manopt.DebugGroupFactory-Tuple{Vector}","content":" Manopt.DebugGroupFactory  ‚Äî  Method DebugGroupFactory(a::Vector) Generate a [ DebugGroup ] of  DebugAction s. The following rules are used Any  Symbol  is passed to  DebugActionFactory Any  (Symbol, String)  generates similar actions as in 1., but the string is used for  format= `, see  DebugActionFactory Any  String  is passed to  DebugActionFactory(d::String) ](@ref)` Any  DebugAction  is included as is. If this results in more than one  DebugAction  a  DebugGroup  of these is build. If any integers are present, the last of these is used to wrap the group in a  DebugEvery (k) . If  :SubSolver  is present, the resulting Action is wrappedn in  DebugWhenActive , making it deactivatable by its parent solver. source"},{"id":2178,"pagetitle":"Debug Output","title":"Manopt.reset!","ref":"/manopt/stable/plans/debug/#Manopt.reset!-Tuple{DebugTime}","content":" Manopt.reset!  ‚Äî  Method reset!(d::DebugTime) reset the internal time of a  DebugTime , that is start from now again. source"},{"id":2179,"pagetitle":"Debug Output","title":"Manopt.set_manopt_parameter!","ref":"/manopt/stable/plans/debug/#Manopt.set_manopt_parameter!-Tuple{DebugSolverState, Val{:Debug}, Vararg{Any}}","content":" Manopt.set_manopt_parameter!  ‚Äî  Method set_manopt_parameter!(ams::DebugSolverState, ::Val{:Debug}, args...) Set certain values specified by  args...  into the elements of the  debugDictionary source"},{"id":2180,"pagetitle":"Debug Output","title":"Manopt.stop!","ref":"/manopt/stable/plans/debug/#Manopt.stop!-Tuple{DebugTime}","content":" Manopt.stop!  ‚Äî  Method stop!(d::DebugTime) stop the reset the internal time of a  DebugTime , that is set the time to 0 (undefined) source"},{"id":2181,"pagetitle":"Debug Output","title":"Technical details","ref":"/manopt/stable/plans/debug/#Technical-details","content":" Technical details The decorator to print debug during the iterations can be activated by decorating the state of a solver and implementing your own  DebugAction s. For example printing a gradient from the  GradientDescentState  is automatically available, as explained in the  gradient_descent  solver."},{"id":2182,"pagetitle":"Debug Output","title":"Manopt.initialize_solver!","ref":"/manopt/stable/plans/debug/#Manopt.initialize_solver!-Tuple{AbstractManoptProblem, DebugSolverState}","content":" Manopt.initialize_solver!  ‚Äî  Method initialize_solver!(amp::AbstractManoptProblem, dss::DebugSolverState) Extend the initialization of the solver by a hook to run the  DebugAction  that was added to the  :Start  entry of the debug lists. All others are triggered (with iteration number  0 ) to trigger possible resets source"},{"id":2183,"pagetitle":"Debug Output","title":"Manopt.step_solver!","ref":"/manopt/stable/plans/debug/#Manopt.step_solver!-Tuple{AbstractManoptProblem, DebugSolverState, Any}","content":" Manopt.step_solver!  ‚Äî  Method step_solver!(amp::AbstractManoptProblem, dss::DebugSolverState, i) Extend the  i th step of the solver by a hook to run debug prints, that were added to the  :BeforeIteration  and  :Iteration  entries of the debug lists. source"},{"id":2184,"pagetitle":"Debug Output","title":"Manopt.stop_solver!","ref":"/manopt/stable/plans/debug/#Manopt.stop_solver!-Tuple{AbstractManoptProblem, DebugSolverState, Int64}","content":" Manopt.stop_solver!  ‚Äî  Method stop_solver!(amp::AbstractManoptProblem, dss::DebugSolverState, i) Extend the  stop_solver! , whether to stop the solver by a hook to run debug, that were added to the  :Stop  entry of the debug lists. source"},{"id":2187,"pagetitle":"Objective","title":"A manifold objective","ref":"/manopt/stable/plans/objective/#A-manifold-objective","content":" A manifold objective The Objective describes that actual cost function and all its properties."},{"id":2188,"pagetitle":"Objective","title":"Manopt.AbstractManifoldObjective","ref":"/manopt/stable/plans/objective/#Manopt.AbstractManifoldObjective","content":" Manopt.AbstractManifoldObjective  ‚Äî  Type AbstractManifoldObjective{E<:AbstractEvaluationType} Describe the collection of the optimization function ` f:  \\mathcal M ‚Üí \\bbR  (or even a vectorial range) and its corresponding elements, which might for example be a gradient or (one or more) proximal maps. All these elements should usually be implemented as functions  (M, p) -> ... , or  (M, X, p) -> ...  that is the first argument of these functions should be the manifold  M  they are defined on the argument  X  is present, if the computation is performed in-place of  X  (see  InplaceEvaluation ) the argument  p  is the place the function ( $f$  or one of its elements) is evaluated  at . the type  T  indicates the global  AbstractEvaluationType . source"},{"id":2189,"pagetitle":"Objective","title":"Manopt.AbstractDecoratedManifoldObjective","ref":"/manopt/stable/plans/objective/#Manopt.AbstractDecoratedManifoldObjective","content":" Manopt.AbstractDecoratedManifoldObjective  ‚Äî  Type AbstractDecoratedManifoldObjective{E<:AbstractEvaluationType,O<:AbstractManifoldObjective} A common supertype for all decorators of  AbstractManifoldObjective s to simplify dispatch.     The second parameter should refer to the undecorated objective (the most inner one). source Which has two main different possibilities for its containing functions concerning the evaluation mode, not necessarily the cost, but for example gradient in an  AbstractManifoldGradientObjective ."},{"id":2190,"pagetitle":"Objective","title":"Manopt.AbstractEvaluationType","ref":"/manopt/stable/plans/objective/#Manopt.AbstractEvaluationType","content":" Manopt.AbstractEvaluationType  ‚Äî  Type AbstractEvaluationType An abstract type to specify the kind of evaluation a  AbstractManifoldObjective  supports. source"},{"id":2191,"pagetitle":"Objective","title":"Manopt.AllocatingEvaluation","ref":"/manopt/stable/plans/objective/#Manopt.AllocatingEvaluation","content":" Manopt.AllocatingEvaluation  ‚Äî  Type AllocatingEvaluation <: AbstractEvaluationType A parameter for a  AbstractManoptProblem  indicating that the problem uses functions that allocate memory for their result, they work out of place. source"},{"id":2192,"pagetitle":"Objective","title":"Manopt.InplaceEvaluation","ref":"/manopt/stable/plans/objective/#Manopt.InplaceEvaluation","content":" Manopt.InplaceEvaluation  ‚Äî  Type InplaceEvaluation <: AbstractEvaluationType A parameter for a  AbstractManoptProblem  indicating that the problem uses functions that do not allocate memory but work on their input, in place. source"},{"id":2193,"pagetitle":"Objective","title":"Manopt.evaluation_type","ref":"/manopt/stable/plans/objective/#Manopt.evaluation_type","content":" Manopt.evaluation_type  ‚Äî  Function evaluation_type(mp::AbstractManoptProblem) Get the  AbstractEvaluationType  of the objective in  AbstractManoptProblem mp . source evaluation_type(::AbstractManifoldObjective{Teval}) Get the  AbstractEvaluationType  of the objective. source"},{"id":2194,"pagetitle":"Objective","title":"Decorators for objectives","ref":"/manopt/stable/plans/objective/#Decorators-for-objectives","content":" Decorators for objectives An objective can be decorated using the following trait and function to initialize"},{"id":2195,"pagetitle":"Objective","title":"Manopt.dispatch_objective_decorator","ref":"/manopt/stable/plans/objective/#Manopt.dispatch_objective_decorator","content":" Manopt.dispatch_objective_decorator  ‚Äî  Function dispatch_objective_decorator(o::AbstractManoptSolverState) Indicate internally, whether an  AbstractManifoldObjective o  to be of decorating type, it stores (encapsulates) an object in itself, by default in the field  o.objective . Decorators indicate this by returning  Val{true}  for further dispatch. The default is  Val{false} , so by default an state is not decorated. source"},{"id":2196,"pagetitle":"Objective","title":"Manopt.is_objective_decorator","ref":"/manopt/stable/plans/objective/#Manopt.is_objective_decorator","content":" Manopt.is_objective_decorator  ‚Äî  Function is_object_decorator(s::AbstractManifoldObjective) Indicate, whether  AbstractManifoldObjective s  are of decorator type. source"},{"id":2197,"pagetitle":"Objective","title":"Manopt.decorate_objective!","ref":"/manopt/stable/plans/objective/#Manopt.decorate_objective!","content":" Manopt.decorate_objective!  ‚Äî  Function decorate_objective!(M, o::AbstractManifoldObjective) decorate the  AbstractManifoldObjective o  with specific decorators. Optional arguments optional arguments provide necessary details on the decorators. A specific one is used to activate certain decorators. cache :           ( missing ) specify a cache. Currently  :Simple  is supported and  :LRU  if you load  LRUCache.jl . For this case a tuple specifying what to cache and how many can be provided, has to be specified. For example  (:LRU, [:Cost, :Gradient], 10)  states that the last 10 used cost function evaluations and gradient evaluations should be stored. See  objective_cache_factory  for details. count :           ( missing ) specify calls to the objective to be called, see  ManifoldCountObjective  for the full list objective_type :  ( :Riemannian ) specify that an objective is  :Riemannian  or  :Euclidean . The  :Euclidean  symbol is equivalent to specifying it as  :Embedded , since in the end, both refer to converting an objective from the embedding (whether its Euclidean or not) to the Riemannian one. See also objective_cache_factory source"},{"id":2198,"pagetitle":"Objective","title":"Embedded objectives","ref":"/manopt/stable/plans/objective/#subsection-embedded-objectives","content":" Embedded objectives"},{"id":2199,"pagetitle":"Objective","title":"Manopt.EmbeddedManifoldObjective","ref":"/manopt/stable/plans/objective/#Manopt.EmbeddedManifoldObjective","content":" Manopt.EmbeddedManifoldObjective  ‚Äî  Type EmbeddedManifoldObjective{P, T, E, O2, O1<:AbstractManifoldObjective{E}} <:\n   AbstractDecoratedManifoldObjective{O2, O1} Declare an objective to be defined in the embedding. This also declares the gradient to be defined in the embedding, and especially being the Riesz representer with respect to the metric in the embedding. The types can be used to still dispatch on also the undecorated objective type  O2 . Fields objective : the objective that is defined in the embedding p :         ( nothing ) a point in the embedding. X :         ( nothing ) a tangent vector in the embedding When a point in the embedding  p  is provided,  embed!  is used in place of this point to reduce memory allocations. Similarly  X  is used when embedding tangent vectors source"},{"id":2200,"pagetitle":"Objective","title":"Cache objective","ref":"/manopt/stable/plans/objective/#subsection-cache-objective","content":" Cache objective Since single function calls, for example to the cost or the gradient, might be expensive, a simple cache objective exists as a decorator, that caches one cost value or gradient. It can be activated/used with the  cache=  keyword argument available for every solver."},{"id":2201,"pagetitle":"Objective","title":"Manopt.reset_counters!","ref":"/manopt/stable/plans/objective/#Manopt.reset_counters!","content":" Manopt.reset_counters!  ‚Äî  Function reset_counters(co::ManifoldCountObjective, value::Integer=0) Reset all values in the count objective to  value . source"},{"id":2202,"pagetitle":"Objective","title":"Manopt.objective_cache_factory","ref":"/manopt/stable/plans/objective/#Manopt.objective_cache_factory","content":" Manopt.objective_cache_factory  ‚Äî  Function objective_cache_factory(M::AbstractManifold, o::AbstractManifoldObjective, cache::Symbol) Generate a cached variant of the  AbstractManifoldObjective o  on the  AbstractManifold M  based on the symbol  cache . The following caches are available :Simple  generates a  SimpleManifoldCachedObjective :LRU  generates a  ManifoldCachedObjective  where you should use the form  (:LRU, [:Cost, :Gradient])  to specify what should be cached or  (:LRU, [:Cost, :Gradient], 100)  to specify the cache size. Here this variant defaults to  (:LRU, [:Cost, :Gradient], 100) , caching up to 100 cost and gradient values. [1] source objective_cache_factory(M::AbstractManifold, o::AbstractManifoldObjective, cache::Tuple{Symbol, Array, Array})\nobjective_cache_factory(M::AbstractManifold, o::AbstractManifoldObjective, cache::Tuple{Symbol, Array}) Generate a cached variant of the  AbstractManifoldObjective o  on the  AbstractManifold M  based on the symbol  cache[1] , where the second element  cache[2]  are further arguments to the cache and the optional third is passed down as keyword arguments. For all available caches see the simpler variant with symbols. source"},{"id":2203,"pagetitle":"Objective","title":"A simple cache","ref":"/manopt/stable/plans/objective/#A-simple-cache","content":" A simple cache A first generic cache is always available, but it only caches one gradient and one cost function evaluation (for the same point)."},{"id":2204,"pagetitle":"Objective","title":"Manopt.SimpleManifoldCachedObjective","ref":"/manopt/stable/plans/objective/#Manopt.SimpleManifoldCachedObjective","content":" Manopt.SimpleManifoldCachedObjective  ‚Äî  Type  SimpleManifoldCachedObjective{O<:AbstractManifoldGradientObjective{E,TC,TG}, P, T,C} <: AbstractManifoldGradientObjective{E,TC,TG} Provide a simple cache for an  AbstractManifoldGradientObjective  that is for a given point  p  this cache stores a point  p  and a gradient  $\\operatorname{grad} f(p)$  in  X  as well as a cost value  $f(p)$  in  c . Both  X  and  c  are accompanied by booleans to keep track of their validity. Constructor SimpleManifoldCachedObjective(M::AbstractManifold, obj::AbstractManifoldGradientObjective; kwargs...) Keyword p :           ( rand(M) ) a point on the manifold to initialize the cache with X :           ( get_gradient(M, obj, p)  or  zero_vector(M,p) ) a tangent vector to store the gradient in, see also  initialize c :           ( get_cost(M, obj, p)  or  0.0 ) a value to store the cost function in  initialize initialized : ( true ) whether to initialize the cached  X  and  c  or not. source"},{"id":2205,"pagetitle":"Objective","title":"A generic cache","ref":"/manopt/stable/plans/objective/#A-generic-cache","content":" A generic cache For the more advanced cache, you need to implement some type of cache yourself, that provides a  get!  and implement  init_caches . This is for example provided if you load  LRUCache.jl . Then you obtain"},{"id":2206,"pagetitle":"Objective","title":"Manopt.ManifoldCachedObjective","ref":"/manopt/stable/plans/objective/#Manopt.ManifoldCachedObjective","content":" Manopt.ManifoldCachedObjective  ‚Äî  Type ManifoldCachedObjective{E,P,O<:AbstractManifoldObjective{<:E},C<:NamedTuple{}} <: AbstractDecoratedManifoldObjective{E,P} Create a cache for an objective, based on a  NamedTuple  that stores some kind of cache. Constructor ManifoldCachedObjective(M, o::AbstractManifoldObjective, caches::Vector{Symbol}; kwargs...) Create a cache for the  AbstractManifoldObjective  where the Symbols in  caches  indicate, which function evaluations to cache. Supported symbols Symbol Caches calls to (incl.  !  variants) Comment :Constraints get_constraints vector of numbers :Cost get_cost :EqualityConstraint get_equality_constraint numbers per (p,i) :EqualityConstraints get_equality_constraints vector of numbers :GradEqualityConstraint get_grad_equality_constraint tangent vector per (p,i) :GradEqualityConstraints get_grad_equality_constraints vector of tangent vectors :GradInequalityConstraint get_inequality_constraint tangent vector per (p,i) :GradInequalityConstraints get_inequality_constraints vector of tangent vectors :Gradient get_gradient (M,p) tangent vectors :Hessian get_hessian tangent vectors :InequalityConstraint get_inequality_constraint numbers per (p,j) :InequalityConstraints get_inequality_constraints vector of numbers :Preconditioner get_preconditioner tangent vectors :ProximalMap get_proximal_map point per  (p,Œª,i) :StochasticGradients get_gradients vector of tangent vectors :StochasticGradient get_gradient (M, p, i) tangent vector per (p,i) :SubGradient get_subgradient tangent vectors :SubtrahendGradient get_subtrahend_gradient tangent vectors Keyword arguments p :           ( rand(M) ) the type of the keys to be used in the caches. Defaults to the default representation on  M . value :       ( get_cost(M, objective, p) ) the type of values for numeric values in the cache X :           ( zero_vector(M,p) ) the type of values to be cached for gradient and Hessian calls. cache :       ( [:Cost] ) a vector of symbols indicating which function calls should be cached. cache_size :  ( 10 ) number of (least recently used) calls to cache cache_sizes : ( Dict{Symbol,Int}() ) a named tuple or dictionary specifying the sizes individually for each cache. source"},{"id":2207,"pagetitle":"Objective","title":"Manopt.init_caches","ref":"/manopt/stable/plans/objective/#Manopt.init_caches","content":" Manopt.init_caches  ‚Äî  Function init_caches(caches, T::Type{LRU}; kwargs...) Given a vector of symbols  caches , this function sets up the  NamedTuple  of caches, where  T  is the type of cache to use. Keyword arguments p :           ( rand(M) ) a point on a manifold, to both infer its type for keys and initialize caches value :       ( 0.0 ) a value both typing and initialising number-caches, the default is for (Float) values like the cost. X :           ( zero_vector(M, p)  a tangent vector at  p  to both type and initialize tangent vector caches cache_size :  ( 10 )  a default cache size to use cache_sizes : ( Dict{Symbol,Int}() ) a dictionary of sizes for the  caches  to specify different (non-default) sizes source init_caches(M::AbstractManifold, caches, T; kwargs...) Given a vector of symbols  caches , this function sets up the  NamedTuple  of caches for points/vectors on  M , where  T  is the type of cache to use. source"},{"id":2208,"pagetitle":"Objective","title":"Count objective","ref":"/manopt/stable/plans/objective/#subsection-count-objective","content":" Count objective"},{"id":2209,"pagetitle":"Objective","title":"Manopt.ManifoldCountObjective","ref":"/manopt/stable/plans/objective/#Manopt.ManifoldCountObjective","content":" Manopt.ManifoldCountObjective  ‚Äî  Type ManifoldCountObjective{E,P,O<:AbstractManifoldObjective,I<:Integer} <: AbstractDecoratedManifoldObjective{E,P} A wrapper for any  AbstractManifoldObjective  of type  O  to count different calls to parts of the objective. Fields counts  a dictionary of symbols mapping to integers keeping the counted values objective  the wrapped objective Supported symbols Symbol Counts calls to (incl.  !  variants) Comment :Constraints get_constraints :Cost get_cost :EqualityConstraint get_equality_constraint requires vector of counters :EqualityConstraints get_equality_constraints does not count single access :GradEqualityConstraint get_grad_equality_constraint requires vector of counters :GradEqualityConstraints get_grad_equality_constraints does not count single access :GradInequalityConstraint get_inequality_constraint requires vector of counters :GradInequalityConstraints get_inequality_constraints does not count single access :Gradient get_gradient (M,p) :Hessian get_hessian :InequalityConstraint get_inequality_constraint requires vector of counters :InequalityConstraints get_inequality_constraints does not count single access :Preconditioner get_preconditioner :ProximalMap get_proximal_map :StochasticGradients get_gradients :StochasticGradient get_gradient (M, p, i) :SubGradient get_subgradient :SubtrahendGradient get_subtrahend_gradient Constructors ManifoldCountObjective(objective::AbstractManifoldObjective, counts::Dict{Symbol, <:Integer}) Initialise the  ManifoldCountObjective  to wrap  objective  initializing the set of counts ManifoldCountObjective(M::AbtractManifold, objective::AbstractManifoldObjective, count::AbstractVecor{Symbol}, init=0) Count function calls on  objective  using the symbols in  count  initialising all entries to  init . source"},{"id":2210,"pagetitle":"Objective","title":"Internal decorators","ref":"/manopt/stable/plans/objective/#Internal-decorators","content":" Internal decorators"},{"id":2211,"pagetitle":"Objective","title":"Manopt.ReturnManifoldObjective","ref":"/manopt/stable/plans/objective/#Manopt.ReturnManifoldObjective","content":" Manopt.ReturnManifoldObjective  ‚Äî  Type ReturnManifoldObjective{E,O2,O1<:AbstractManifoldObjective{E}} <:\n   AbstractDecoratedManifoldObjective{E,O2} A wrapper to indicate that  get_solver_result  should return the inner objective. The types are such that one can still dispatch on the undecorated type  O2  of the original objective as well. source"},{"id":2212,"pagetitle":"Objective","title":"Specific Objective typed and their access functions","ref":"/manopt/stable/plans/objective/#Specific-Objective-typed-and-their-access-functions","content":" Specific Objective typed and their access functions"},{"id":2213,"pagetitle":"Objective","title":"Cost objective","ref":"/manopt/stable/plans/objective/#Cost-objective","content":" Cost objective"},{"id":2214,"pagetitle":"Objective","title":"Manopt.AbstractManifoldCostObjective","ref":"/manopt/stable/plans/objective/#Manopt.AbstractManifoldCostObjective","content":" Manopt.AbstractManifoldCostObjective  ‚Äî  Type AbstractManifoldCostObjective{T<:AbstractEvaluationType} <: AbstractManifoldObjective{T} Representing objectives on manifolds with a cost function implemented. source"},{"id":2215,"pagetitle":"Objective","title":"Manopt.ManifoldCostObjective","ref":"/manopt/stable/plans/objective/#Manopt.ManifoldCostObjective","content":" Manopt.ManifoldCostObjective  ‚Äî  Type ManifoldCostObjective{T, TC} <: AbstractManifoldCostObjective{T, TC} specify an  AbstractManifoldObjective  that does only have information about the cost function  $f:  \\mathbb M ‚Üí ‚Ñù$  implemented as a function  (M, p) -> c  to compute the cost value  c  at  p  on the manifold  M . cost : a function  $f: \\mathcal M ‚Üí ‚Ñù$  to minimize Constructors ManifoldCostObjective(f) Generate a problem. While this Problem does not have any allocating functions, the type  T  can be set for consistency reasons with other problems. Used with NelderMead ,  particle_swarm source"},{"id":2216,"pagetitle":"Objective","title":"Access functions","ref":"/manopt/stable/plans/objective/#Access-functions","content":" Access functions"},{"id":2217,"pagetitle":"Objective","title":"Manopt.get_cost","ref":"/manopt/stable/plans/objective/#Manopt.get_cost","content":" Manopt.get_cost  ‚Äî  Function get_cost(amp::AbstractManoptProblem, p) evaluate the cost function  f  stored within the  AbstractManifoldObjective  of an  AbstractManoptProblem amp  at the point  p . source get_cost(M::AbstractManifold, obj::AbstractManifoldObjective, p) evaluate the cost function  f  defined on  M  stored within the  AbstractManifoldObjective  at the point  p . source get_cost(M::AbstractManifold, mco::AbstractManifoldCostObjective, p) Evaluate the cost function from within the  AbstractManifoldCostObjective  on  M  at  p . By default this implementation assumed that the cost is stored within  mco.cost . source get_cost(TpM, trmo::TrustRegionModelObjective, X) Evaluate the tangent space  TrustRegionModelObjective \\[m(X) = f(p) + ‚ü®\\operatorname{grad} f(p), X ‚ü©_p + \\frac{1}{2} ‚ü®\\operatorname{Hess} f(p)[X], X‚ü©_p.\\] source get_cost(TpM, trmo::AdaptiveRagularizationWithCubicsModelObjective, X) Evaluate the tangent space  AdaptiveRagularizationWithCubicsModelObjective \\[m(X) = f(p) + ‚ü®\\operatorname{grad} f(p), X ‚ü©_p + \\frac{1}{2} ‚ü®\\operatorname{Hess} f(p)[X], X‚ü©_p\n       +  \\frac{œÉ}{3} \\lVert X \\rVert^3,\\] at  X , cf. Eq. (33) in [ ABBC20 ]. source get_cost(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, p, i) Evaluate the  i th summand of the cost. If you use a single function for the stochastic cost, then only the index  √¨=1 ` is available to evaluate the whole cost. source get_cost(M::AbstractManifold,emo::EmbeddedManifoldObjective, p) Evaluate the cost function of an objective defined in the embedding by first embedding  p  before calling the cost function stored in the  EmbeddedManifoldObjective . source and internally"},{"id":2218,"pagetitle":"Objective","title":"Manopt.get_cost_function","ref":"/manopt/stable/plans/objective/#Manopt.get_cost_function","content":" Manopt.get_cost_function  ‚Äî  Function get_cost_function(amco::AbstractManifoldCostObjective) return the function to evaluate (just) the cost  $f(p)=c$  as a function  (M,p) -> c . source"},{"id":2219,"pagetitle":"Objective","title":"Gradient objectives","ref":"/manopt/stable/plans/objective/#Gradient-objectives","content":" Gradient objectives"},{"id":2220,"pagetitle":"Objective","title":"Manopt.AbstractManifoldGradientObjective","ref":"/manopt/stable/plans/objective/#Manopt.AbstractManifoldGradientObjective","content":" Manopt.AbstractManifoldGradientObjective  ‚Äî  Type AbstractManifoldGradientObjective{E<:AbstractEvaluationType, TC, TG} <: AbstractManifoldCostObjective{E, TC} An abstract type for all objectives that provide a (full) gradient, where  T  is a  AbstractEvaluationType  for the gradient function. source"},{"id":2221,"pagetitle":"Objective","title":"Manopt.ManifoldGradientObjective","ref":"/manopt/stable/plans/objective/#Manopt.ManifoldGradientObjective","content":" Manopt.ManifoldGradientObjective  ‚Äî  Type ManifoldGradientObjective{T<:AbstractEvaluationType} <: AbstractManifoldGradientObjective{T} specify an objective containing a cost and its gradient Fields cost :       a function  $f: \\mathcal M ‚Üí ‚Ñù$ gradient!! : the gradient  $\\operatorname{grad}f: \\mathcal M ‚Üí \\mathcal T\\mathcal M$  of the cost function  $f$ . Depending on the  AbstractEvaluationType T  the gradient can have to forms as a function  (M, p) -> X  that allocates memory for  X , an  AllocatingEvaluation as a function  (M, X, p) -> X  that work in place of  X , an  InplaceEvaluation Constructors ManifoldGradientObjective(cost, gradient; evaluation=AllocatingEvaluation()) Used with gradient_descent ,  conjugate_gradient_descent ,  quasi_Newton source"},{"id":2222,"pagetitle":"Objective","title":"Manopt.ManifoldAlternatingGradientObjective","ref":"/manopt/stable/plans/objective/#Manopt.ManifoldAlternatingGradientObjective","content":" Manopt.ManifoldAlternatingGradientObjective  ‚Äî  Type ManifoldAlternatingGradientObjective{E<:AbstractEvaluationType,TCost,TGradient} <: AbstractManifoldGradientObjective{E} An alternating gradient objective consists of a cost function  $F(x)$ a gradient  $\\operatorname{grad}F$  that is either given as one function  $\\operatorname{grad}F$  returning a tangent vector  X  on  M  or an array of gradient functions  $\\operatorname{grad}F_i$ ,  √¨=1,‚Ä¶,n  s each returning a component of the gradient which might be allocating or mutating variants, but not a mix of both. Note This Objective is usually defined using the  ProductManifold  from  Manifolds.jl , so  Manifolds.jl  to be loaded. Constructors ManifoldAlternatingGradientObjective(F, gradF::Function;\n    evaluation=AllocatingEvaluation()\n)\nManifoldAlternatingGradientObjective(F, gradF::AbstractVector{<:Function};\n    evaluation=AllocatingEvaluation()\n) Create a alternating gradient problem with an optional  cost  and the gradient either as one function (returning an array) or a vector of functions. source"},{"id":2223,"pagetitle":"Objective","title":"Manopt.ManifoldStochasticGradientObjective","ref":"/manopt/stable/plans/objective/#Manopt.ManifoldStochasticGradientObjective","content":" Manopt.ManifoldStochasticGradientObjective  ‚Äî  Type ManifoldStochasticGradientObjective{T<:AbstractEvaluationType} <: AbstractManifoldGradientObjective{T} A stochastic gradient objective consists of a(n optional) cost function ``f(p) = \\displaystyle\\sum {i=1}^n f i(p) an array of gradients,  $\\operatorname{grad}f_i(p), i=1,\\ldots,n$  which can be given in two forms as one single function  $(\\mathcal M, p) ‚Ü¶ (X_1,‚Ä¶,X_n) ‚àà (T_p\\mathcal M)^n$ as a vector of functions  $\\bigl( (\\mathcal M, p) ‚Ü¶ X_1, ‚Ä¶, (\\mathcal M, p) ‚Ü¶ X_n\\bigr)$ . Where both variants can also be provided as  InplaceEvaluation  functions  (M, X, p) -> X , where  X  is the vector of  X1,...Xn  and  (M, X1, p) -> X1, ..., (M, Xn, p) -> Xn , respectively. Constructors ManifoldStochasticGradientObjective(\n    grad_f::Function;\n    cost=Missing(),\n    evaluation=AllocatingEvaluation()\n)\nManifoldStochasticGradientObjective(\n    grad_f::AbstractVector{<:Function};\n    cost=Missing(), evaluation=AllocatingEvaluation()\n) Create a Stochastic gradient problem with the gradient either as one function (returning an array of tangent vectors) or a vector of functions (each returning one tangent vector). The optional cost can also be given as either a single function (returning a number) pr a vector of functions, each returning a value. Used with stochastic_gradient_descent Note that this can also be used with a  gradient_descent , since the (complete) gradient is just the sums of the single gradients. source"},{"id":2224,"pagetitle":"Objective","title":"Manopt.NonlinearLeastSquaresObjective","ref":"/manopt/stable/plans/objective/#Manopt.NonlinearLeastSquaresObjective","content":" Manopt.NonlinearLeastSquaresObjective  ‚Äî  Type NonlinearLeastSquaresObjective{T<:AbstractEvaluationType} <: AbstractManifoldObjective{T} A type for nonlinear least squares problems.  T  is a  AbstractEvaluationType  for the  F  and Jacobian functions. Specify a nonlinear least squares problem Fields f                       a function  $f: \\mathcal M ‚Üí ‚Ñù^d$  to minimize jacobian!!              Jacobian of the function  $f$ jacobian_tangent_basis  the basis of tangent space used for computing the Jacobian. num_components          number of values returned by  f  (equal to  d ). Depending on the  AbstractEvaluationType T  the function  $F$  has to be provided: as a functions  (M::AbstractManifold, p) -> v  that allocates memory for  v  itself for an  AllocatingEvaluation , as a function  (M::AbstractManifold, v, p) -> v  that works in place of  v  for a  InplaceEvaluation . Also the Jacobian  $jacF!!$  is required: as a functions  (M::AbstractManifold, p; basis_domain::AbstractBasis) -> v  that allocates memory for  v  itself for an  AllocatingEvaluation , as a function  (M::AbstractManifold, v, p; basis_domain::AbstractBasis) -> v  that works in place of  v  for an  InplaceEvaluation . Constructors NonlinearLeastSquaresProblem(M, F, jacF, num_components; evaluation=AllocatingEvaluation(), jacobian_tangent_basis=DefaultOrthonormalBasis()) See also LevenbergMarquardt ,  LevenbergMarquardtState source There is also a second variant, if just one function is responsible for computing the cost  and  the gradient"},{"id":2225,"pagetitle":"Objective","title":"Manopt.ManifoldCostGradientObjective","ref":"/manopt/stable/plans/objective/#Manopt.ManifoldCostGradientObjective","content":" Manopt.ManifoldCostGradientObjective  ‚Äî  Type ManifoldCostGradientObjective{T} <: AbstractManifoldObjective{T} specify an objective containing one function to perform a combined computation of cost and its gradient Fields costgrad!! : a function that computes both the cost  $f: \\mathcal M ‚Üí ‚Ñù$  and its gradient  $\\operatorname{grad}f: \\mathcal M ‚Üí \\mathcal T\\mathcal M$ Depending on the  AbstractEvaluationType T  the gradient can have to forms as a function  (M, p) -> (c, X)  that allocates memory for the gradient  X , an  AllocatingEvaluation as a function  (M, X, p) -> (c, X)  that work in place of  X , an  InplaceEvaluation Constructors ManifoldCostGradientObjective(costgrad; evaluation=AllocatingEvaluation()) Used with gradient_descent ,  conjugate_gradient_descent ,  quasi_Newton source"},{"id":2226,"pagetitle":"Objective","title":"Access functions","ref":"/manopt/stable/plans/objective/#Access-functions-2","content":" Access functions"},{"id":2227,"pagetitle":"Objective","title":"Manopt.get_gradient","ref":"/manopt/stable/plans/objective/#Manopt.get_gradient","content":" Manopt.get_gradient  ‚Äî  Function X = get_gradient(M::ProductManifold, ago::ManifoldAlternatingGradientObjective, p)\nget_gradient!(M::ProductManifold, P::ManifoldAlternatingGradientObjective, X, p) Evaluate all summands gradients at a point  p  on the  ProductManifold M  (in place of  X ) source X = get_gradient(M::AbstractManifold, p::ManifoldAlternatingGradientObjective, p, k)\nget_gradient!(M::AbstractManifold, p::ManifoldAlternatingGradientObjective, X, p, k) Evaluate one of the component gradients  $\\operatorname{grad}f_k$ ,  $k‚àà\\{1,‚Ä¶,n\\}$ , at  x  (in place of  Y ). source get_gradient(s::AbstractManoptSolverState) return the (last stored) gradient within  AbstractManoptSolverState s`. By default also undecorates the state beforehand source get_gradient(amp::AbstractManoptProblem, p)\nget_gradient!(amp::AbstractManoptProblem, X, p) evaluate the gradient of an  AbstractManoptProblem amp  at the point  p . The evaluation is done in place of  X  for the  ! -variant. source get_gradient(M::AbstractManifold, mgo::AbstractManifoldGradientObjective{T}, p)\nget_gradient!(M::AbstractManifold, X, mgo::AbstractManifoldGradientObjective{T}, p) evaluate the gradient of a  AbstractManifoldGradientObjective{T} mgo  at  p . The evaluation is done in place of  X  for the  ! -variant. The  T= AllocatingEvaluation  problem might still allocate memory within. When the non-mutating variant is called with a  T= InplaceEvaluation  memory for the result is allocated. Note that the order of parameters follows the philosophy of  Manifolds.jl , namely that even for the mutating variant, the manifold is the first parameter and the (in-place) tangent vector  X  comes second. source get_gradient(agst::AbstractGradientSolverState) return the gradient stored within gradient options. THe default returns  agst.X . source get_gradient(TpM, trmo::TrustRegionModelObjective, X) Evaluate the gradient of the  TrustRegionModelObjective \\[\\operatorname{grad} m(X) = \\operatorname{grad} f(p) + \\operatorname{Hess} f(p)[X].\\] source get_gradient(TpM, trmo::AdaptiveRagularizationWithCubicsModelObjective, X) Evaluate the gradient of the  AdaptiveRagularizationWithCubicsModelObjective \\[\\operatorname{grad} m(X) = \\operatorname{grad} f(p) + \\operatorname{Hess} f(p)[X]\n       + œÉ\\lVert X \\rVert X,\\] at  X , cf. Eq. (37) in [ ABBC20 ]. source get_gradient(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, p, k)\nget_gradient!(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, Y, p, k) Evaluate one of the summands gradients  $\\operatorname{grad}f_k$ ,  $k‚àà\\{1,‚Ä¶,n\\}$ , at  x  (in place of  Y ). If you use a single function for the stochastic gradient, that works in-place, then  get_gradient  is not available, since the length (or number of elements of the gradient required for allocation) can not be determined. source get_gradient(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, p)\nget_gradient!(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, X, p) Evaluate the complete gradient  $\\operatorname{grad} f = \\displaystyle\\sum_{i=1}^n \\operatorname{grad} f_i(p)$  at  p  (in place of  X ). If you use a single function for the stochastic gradient, that works in-place, then  get_gradient  is not available, since the length (or number of elements of the gradient required for allocation) can not be determined. source get_gradient(M::AbstractManifold, emo::EmbeddedManifoldObjective, p)\nget_gradient!(M::AbstractManifold, X, emo::EmbeddedManifoldObjective, p) Evaluate the gradient function of an objective defined in the embedding, that is embed  p  before calling the gradient function stored in the  EmbeddedManifoldObjective . The returned gradient is then converted to a Riemannian gradient calling  riemannian_gradient . source"},{"id":2228,"pagetitle":"Objective","title":"Manopt.get_gradients","ref":"/manopt/stable/plans/objective/#Manopt.get_gradients","content":" Manopt.get_gradients  ‚Äî  Function get_gradients(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, p)\nget_gradients!(M::AbstractManifold, X, sgo::ManifoldStochasticGradientObjective, p) Evaluate all summands gradients  $\\{\\operatorname{grad}f_i\\}_{i=1}^n$  at  p  (in place of  X ). If you use a single function for the stochastic gradient, that works in-place, then  get_gradient  is not available, since the length (or number of elements of the gradient) can not be determined. source and internally"},{"id":2229,"pagetitle":"Objective","title":"Manopt.get_gradient_function","ref":"/manopt/stable/plans/objective/#Manopt.get_gradient_function","content":" Manopt.get_gradient_function  ‚Äî  Function get_gradient_function(amgo::AbstractManifoldGradientObjective, recursive=false) return the function to evaluate (just) the gradient  $\\operatorname{grad} f(p)$ , where either the gradient function using the decorator or without the decorator is used. By default  recursive  is set to  false , since usually to just pass the gradient function somewhere, one still wants for example the cached one or the one that still counts calls. Depending on the  AbstractEvaluationType E  this is a function (M, p) -> X  for the  AllocatingEvaluation  case (M, X, p) -> X  for the  InplaceEvaluation  working in-place of  X . source"},{"id":2230,"pagetitle":"Objective","title":"Internal helpers","ref":"/manopt/stable/plans/objective/#Internal-helpers","content":" Internal helpers"},{"id":2231,"pagetitle":"Objective","title":"Manopt.get_gradient_from_Jacobian!","ref":"/manopt/stable/plans/objective/#Manopt.get_gradient_from_Jacobian!","content":" Manopt.get_gradient_from_Jacobian!  ‚Äî  Function get_gradient_from_Jacobian!(\n    M::AbstractManifold,\n    X,\n    nlso::NonlinearLeastSquaresObjective{InplaceEvaluation},\n    p,\n    Jval=zeros(nlso.num_components, manifold_dimension(M)),\n) Compute gradient of  NonlinearLeastSquaresObjective nlso  at point  p  in place of  X , with temporary Jacobian stored in the optional argument  Jval . source"},{"id":2232,"pagetitle":"Objective","title":"Subgradient objective","ref":"/manopt/stable/plans/objective/#Subgradient-objective","content":" Subgradient objective"},{"id":2233,"pagetitle":"Objective","title":"Manopt.ManifoldSubgradientObjective","ref":"/manopt/stable/plans/objective/#Manopt.ManifoldSubgradientObjective","content":" Manopt.ManifoldSubgradientObjective  ‚Äî  Type ManifoldSubgradientObjective{T<:AbstractEvaluationType,C,S} <:AbstractManifoldCostObjective{T, C} A structure to store information about a objective for a subgradient based optimization problem Fields cost :        the function  $f$  to be minimized subgradient : a function returning a subgradient  $‚àÇf$  of  $f$ Constructor ManifoldSubgradientObjective(f, ‚àÇf) Generate the  ManifoldSubgradientObjective  for a subgradient objective, consisting of a (cost) function  f(M, p)  and a function  ‚àÇf(M, p)  that returns a not necessarily deterministic element from the subdifferential at  p  on a manifold  M . source"},{"id":2234,"pagetitle":"Objective","title":"Access functions","ref":"/manopt/stable/plans/objective/#Access-functions-3","content":" Access functions"},{"id":2235,"pagetitle":"Objective","title":"Manopt.get_subgradient","ref":"/manopt/stable/plans/objective/#Manopt.get_subgradient","content":" Manopt.get_subgradient  ‚Äî  Function get_subgradient(amp::AbstractManoptProblem, p)\nget_subgradient!(amp::AbstractManoptProblem, X, p) evaluate the subgradient of an  AbstractManoptProblem amp  at point  p . The evaluation is done in place of  X  for the  ! -variant. The result might not be deterministic,  one  element of the subdifferential is returned. source X = get_subgradient(M;;AbstractManifold, sgo::ManifoldSubgradientObjective, p)\nget_subgradient!(M;;AbstractManifold, X, sgo::ManifoldSubgradientObjective, p) Evaluate the (sub)gradient of a  ManifoldSubgradientObjective sgo  at the point  p . The evaluation is done in place of  X  for the  ! -variant. The result might not be deterministic,  one  element of the subdifferential is returned. source"},{"id":2236,"pagetitle":"Objective","title":"Proximal map objective","ref":"/manopt/stable/plans/objective/#Proximal-map-objective","content":" Proximal map objective"},{"id":2237,"pagetitle":"Objective","title":"Manopt.ManifoldProximalMapObjective","ref":"/manopt/stable/plans/objective/#Manopt.ManifoldProximalMapObjective","content":" Manopt.ManifoldProximalMapObjective  ‚Äî  Type ManifoldProximalMapObjective{E<:AbstractEvaluationType, TC, TP, V <: Vector{<:Integer}} <: AbstractManifoldCostObjective{E, TC} specify a problem for solvers based on the evaluation of proximal maps. Fields cost  - a function  $F:\\mathcal M‚Üí‚Ñù$  to minimize proxes  - proximal maps  $\\operatorname{prox}_{Œª\\varphi}:\\mathcal M‚Üí\\mathcal M$  as functions  (M, Œª, p) -> q . number_of_proxes  - ( ones(length(proxes)) ` number of proximal maps per function, to specify when one of the maps is a combined one such that the proximal maps functions return more than one entry per function, you have to adapt this value. if not specified, it is set to one prox per function. See also cyclic_proximal_point ,  get_cost ,  get_proximal_map source"},{"id":2238,"pagetitle":"Objective","title":"Access functions","ref":"/manopt/stable/plans/objective/#Access-functions-4","content":" Access functions"},{"id":2239,"pagetitle":"Objective","title":"Manopt.get_proximal_map","ref":"/manopt/stable/plans/objective/#Manopt.get_proximal_map","content":" Manopt.get_proximal_map  ‚Äî  Function q = get_proximal_map(M::AbstractManifold, mpo::ManifoldProximalMapObjective, Œª, p)\nget_proximal_map!(M::AbstractManifold, q, mpo::ManifoldProximalMapObjective, Œª, p)\nq = get_proximal_map(M::AbstractManifold, mpo::ManifoldProximalMapObjective, Œª, p, i)\nget_proximal_map!(M::AbstractManifold, q, mpo::ManifoldProximalMapObjective, Œª, p, i) evaluate the ( i th) proximal map of  ManifoldProximalMapObjective p  at the point  p  of  p.M  with parameter  $Œª>0$ . source"},{"id":2240,"pagetitle":"Objective","title":"Hessian objective","ref":"/manopt/stable/plans/objective/#Hessian-objective","content":" Hessian objective"},{"id":2241,"pagetitle":"Objective","title":"Manopt.AbstractManifoldHessianObjective","ref":"/manopt/stable/plans/objective/#Manopt.AbstractManifoldHessianObjective","content":" Manopt.AbstractManifoldHessianObjective  ‚Äî  Type AbstractManifoldHessianObjective{T<:AbstractEvaluationType,TC,TG,TH} <: AbstractManifoldGradientObjective{T,TC,TG} An abstract type for all objectives that provide a (full) Hessian, where  T  is a  AbstractEvaluationType  for the gradient and Hessian functions. source"},{"id":2242,"pagetitle":"Objective","title":"Manopt.ManifoldHessianObjective","ref":"/manopt/stable/plans/objective/#Manopt.ManifoldHessianObjective","content":" Manopt.ManifoldHessianObjective  ‚Äî  Type ManifoldHessianObjective{T<:AbstractEvaluationType,C,G,H,Pre} <: AbstractManifoldHessianObjective{T,C,G,H} specify a problem for Hessian based algorithms. Fields cost :           a function  $f:\\mathcal M‚Üí‚Ñù$  to minimize gradient :       the gradient  $\\operatorname{grad}f:\\mathcal M ‚Üí \\mathcal T\\mathcal M$  of the cost function  $f$ hessian :        the Hessian  $\\operatorname{Hess}f(x)[‚ãÖ]: \\mathcal T_{x} \\mathcal M ‚Üí \\mathcal T_{x} \\mathcal M$  of the cost function  $f$ preconditioner : the symmetric, positive definite preconditioner as an approximation of the inverse of the Hessian of  $f$ , a map with the same input variables as the  hessian  to numerically stabilize iterations when the Hessian is ill-conditioned Depending on the  AbstractEvaluationType T  the gradient and can have to forms as a function  (M, p) -> X   and  (M, p, X) -> Y , resp., an  AllocatingEvaluation as a function  (M, X, p) -> X  and (M, Y, p, X), resp., an  InplaceEvaluation Constructor ManifoldHessianObjective(f, grad_f, Hess_f, preconditioner = (M, p, X) -> X;\n    evaluation=AllocatingEvaluation()) See also truncated_conjugate_gradient_descent ,  trust_regions source"},{"id":2243,"pagetitle":"Objective","title":"Access functions","ref":"/manopt/stable/plans/objective/#Access-functions-5","content":" Access functions"},{"id":2244,"pagetitle":"Objective","title":"Manopt.get_hessian","ref":"/manopt/stable/plans/objective/#Manopt.get_hessian","content":" Manopt.get_hessian  ‚Äî  Function Y = get_hessian(amp::AbstractManoptProblem{T}, p, X)\nget_hessian!(amp::AbstractManoptProblem{T}, Y, p, X) evaluate the Hessian of an  AbstractManoptProblem amp  at  p  applied to a tangent vector  X , computing  $\\operatorname{Hess}f(q)[X]$ , which can also happen in-place of  Y . source get_hessian(TpM, trmo::TrustRegionModelObjective, X) Evaluate the Hessian of the  TrustRegionModelObjective \\[\\operatorname{Hess} m(X)[Y] = \\operatorname{Hess} f(p)[Y].\\] source get_hessian(M::AbstractManifold, emo::EmbeddedManifoldObjective, p, X)\nget_hessian!(M::AbstractManifold, Y, emo::EmbeddedManifoldObjective, p, X) Evaluate the Hessian of an objective defined in the embedding, that is embed  p  and  X  before calling the Hessian function stored in the  EmbeddedManifoldObjective . The returned Hessian is then converted to a Riemannian Hessian calling   riemannian_Hessian . source"},{"id":2245,"pagetitle":"Objective","title":"Manopt.get_preconditioner","ref":"/manopt/stable/plans/objective/#Manopt.get_preconditioner","content":" Manopt.get_preconditioner  ‚Äî  Function get_preconditioner(amp::AbstractManoptProblem, p, X) evaluate the symmetric, positive definite preconditioner (approximation of the inverse of the Hessian of the cost function  f ) of a  AbstractManoptProblem amp s objective at the point  p  applied to a tangent vector  X . source get_preconditioner(M::AbstractManifold, mho::ManifoldHessianObjective, p, X) evaluate the symmetric, positive definite preconditioner (approximation of the inverse of the Hessian of the cost function  F ) of a  ManifoldHessianObjective mho  at the point  p  applied to a tangent vector  X . source and internally"},{"id":2246,"pagetitle":"Objective","title":"Manopt.get_hessian_function","ref":"/manopt/stable/plans/objective/#Manopt.get_hessian_function","content":" Manopt.get_hessian_function  ‚Äî  Function get_gradient_function(amgo::AbstractManifoldGradientObjective{E<:AbstractEvaluationType}) return the function to evaluate (just) the Hessian  $\\operatorname{Hess} f(p)$ . Depending on the  AbstractEvaluationType E  this is a function (M, p, X) -> Y  for the  AllocatingEvaluation  case (M, Y, p, X) -> X  for the  InplaceEvaluation , working in-place of  Y . source"},{"id":2247,"pagetitle":"Objective","title":"Primal-dual based objectives","ref":"/manopt/stable/plans/objective/#Primal-dual-based-objectives","content":" Primal-dual based objectives"},{"id":2248,"pagetitle":"Objective","title":"Manopt.AbstractPrimalDualManifoldObjective","ref":"/manopt/stable/plans/objective/#Manopt.AbstractPrimalDualManifoldObjective","content":" Manopt.AbstractPrimalDualManifoldObjective  ‚Äî  Type AbstractPrimalDualManifoldObjective{E<:AbstractEvaluationType,C,P} <: AbstractManifoldCostObjective{E,C} A common abstract super type for objectives that consider primal-dual problems. source"},{"id":2249,"pagetitle":"Objective","title":"Manopt.PrimalDualManifoldObjective","ref":"/manopt/stable/plans/objective/#Manopt.PrimalDualManifoldObjective","content":" Manopt.PrimalDualManifoldObjective  ‚Äî  Type PrimalDualManifoldObjective{T<:AbstractEvaluationType} <: AbstractPrimalDualManifoldObjective{T} Describes an Objective linearized or exact Chambolle-Pock algorithm, cf. [ BHS+21 ], [ CP11 ] Fields All fields with  !!  can either be in-place or allocating functions, which should be set depending on the  evaluation=  keyword in the constructor and stored in  T <: AbstractEvaluationType . cost :                           $F + G(Œõ(‚ãÖ))$  to evaluate interim cost function values linearized_forward_operator!! : linearized operator for the forward operation in the algorithm  $DŒõ$ linearized_adjoint_operator!! : the adjoint differential  $(DŒõ)^* : \\mathcal N ‚Üí T\\mathcal M$ prox_f!! :                      the proximal map belonging to  $f$ prox_G_dual!! :                 the proximal map belonging to  $g_n^*$ Œõ!! :                           ( fordward_operator ) the  forward operator (if given)  $Œõ: \\mathcal M ‚Üí \\mathcal N$ Either the linearized operator  $DŒõ$  or  $Œõ$  are required usually. Constructor PrimalDualManifoldObjective(cost, prox_f, prox_G_dual, adjoint_linearized_operator;\n    linearized_forward_operator::Union{Function,Missing}=missing,\n    Œõ::Union{Function,Missing}=missing,\n    evaluation::AbstractEvaluationType=AllocatingEvaluation()\n) The last optional argument can be used to provide the 4 or 5 functions as allocating or mutating (in place computation) ones. Note that the first argument is always the manifold under consideration, the mutated one is the second. source"},{"id":2250,"pagetitle":"Objective","title":"Manopt.PrimalDualManifoldSemismoothNewtonObjective","ref":"/manopt/stable/plans/objective/#Manopt.PrimalDualManifoldSemismoothNewtonObjective","content":" Manopt.PrimalDualManifoldSemismoothNewtonObjective  ‚Äî  Type PrimalDualManifoldSemismoothNewtonObjective{E<:AbstractEvaluationType, TC, LO, ALO, PF, DPF, PG, DPG, L} <: AbstractPrimalDualManifoldObjective{E, TC, PF} Describes a Problem for the Primal-dual Riemannian semismooth Newton algorithm. [ DL21 ] Fields cost :                         $F + G(Œõ(‚ãÖ))$  to evaluate interim cost function values linearized_operator :         the linearization  $DŒõ(‚ãÖ)[‚ãÖ]$  of the operator  $Œõ(‚ãÖ)$ . linearized_adjoint_operator : the adjoint differential  $(DŒõ)^* :  \\mathcal N ‚Üí T\\mathcal M$ prox_F :                      the proximal map belonging to  $F$ diff_prox_F :                 the (Clarke Generalized) differential of the proximal maps of  $F$ prox_G_dual :                 the proximal map belonging to  $g_n^*$ diff_prox_dual_G :            the (Clarke Generalized) differential of the proximal maps of  $G^\\ast_n$ Œõ :                           the exact forward operator. This operator is required if  Œõ(m)=n  does not hold. Constructor PrimalDualManifoldSemismoothNewtonObjective(cost, prox_F, prox_G_dual, forward_operator, adjoint_linearized_operator,Œõ) source"},{"id":2251,"pagetitle":"Objective","title":"Access functions","ref":"/manopt/stable/plans/objective/#Access-functions-6","content":" Access functions"},{"id":2252,"pagetitle":"Objective","title":"Manopt.adjoint_linearized_operator","ref":"/manopt/stable/plans/objective/#Manopt.adjoint_linearized_operator","content":" Manopt.adjoint_linearized_operator  ‚Äî  Function X = adjoint_linearized_operator(N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, m, n, Y)\nadjoint_linearized_operator(N::AbstractManifold, X, apdmo::AbstractPrimalDualManifoldObjective, m, n, Y) Evaluate the adjoint of the linearized forward operator of  $(DŒõ(m))^*[Y]$  stored within the  AbstractPrimalDualManifoldObjective  (in place of  X ). Since  $Y‚ààT_n\\mathcal N$ , both  $m$  and  $n=Œõ(m)$  are necessary arguments, mainly because the forward operator  $Œõ$  might be  missing  in  p . source"},{"id":2253,"pagetitle":"Objective","title":"Manopt.forward_operator","ref":"/manopt/stable/plans/objective/#Manopt.forward_operator","content":" Manopt.forward_operator  ‚Äî  Function q = forward_operator(M::AbstractManifold, N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, p)\nforward_operator!(M::AbstractManifold, N::AbstractManifold, q, apdmo::AbstractPrimalDualManifoldObjective, p) Evaluate the forward operator of  $Œõ(x)$  stored within the  TwoManifoldProblem  (in place of  q ). source"},{"id":2254,"pagetitle":"Objective","title":"Manopt.get_differential_dual_prox","ref":"/manopt/stable/plans/objective/#Manopt.get_differential_dual_prox","content":" Manopt.get_differential_dual_prox  ‚Äî  Function Œ∑ = get_differential_dual_prox(N::AbstractManifold, pdsno::PrimalDualManifoldSemismoothNewtonObjective, n, œÑ, X, Œæ)\nget_differential_dual_prox!(N::AbstractManifold, pdsno::PrimalDualManifoldSemismoothNewtonObjective, Œ∑, n, œÑ, X, Œæ) Evaluate the differential proximal map of  $G_n^*$  stored within  PrimalDualManifoldSemismoothNewtonObjective \\[D\\operatorname{prox}_{œÑG_n^*}(X)[Œæ]\\] which can also be computed in place of  Œ∑ . source"},{"id":2255,"pagetitle":"Objective","title":"Manopt.get_differential_primal_prox","ref":"/manopt/stable/plans/objective/#Manopt.get_differential_primal_prox","content":" Manopt.get_differential_primal_prox  ‚Äî  Function y = get_differential_primal_prox(M::AbstractManifold, pdsno::PrimalDualManifoldSemismoothNewtonObjective œÉ, x)\nget_differential_primal_prox!(p::TwoManifoldProblem, y, œÉ, x) Evaluate the differential proximal map of  $F$  stored within  AbstractPrimalDualManifoldObjective \\[D\\operatorname{prox}_{œÉF}(x)[X]\\] which can also be computed in place of  y . source"},{"id":2256,"pagetitle":"Objective","title":"Manopt.get_dual_prox","ref":"/manopt/stable/plans/objective/#Manopt.get_dual_prox","content":" Manopt.get_dual_prox  ‚Äî  Function Y = get_dual_prox(N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, n, œÑ, X)\nget_dual_prox!(N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, Y, n, œÑ, X) Evaluate the proximal map of  $g_n^*$  stored within  AbstractPrimalDualManifoldObjective \\[  Y = \\operatorname{prox}_{œÑG_n^*}(X)\\] which can also be computed in place of  Y . source"},{"id":2257,"pagetitle":"Objective","title":"Manopt.get_primal_prox","ref":"/manopt/stable/plans/objective/#Manopt.get_primal_prox","content":" Manopt.get_primal_prox  ‚Äî  Function q = get_primal_prox(M::AbstractManifold, p::AbstractPrimalDualManifoldObjective, œÉ, p)\nget_primal_prox!(M::AbstractManifold, p::AbstractPrimalDualManifoldObjective, q, œÉ, p) Evaluate the proximal map of  $F$  stored within  AbstractPrimalDualManifoldObjective \\[\\operatorname{prox}_{œÉF}(x)\\] which can also be computed in place of  y . source"},{"id":2258,"pagetitle":"Objective","title":"Manopt.linearized_forward_operator","ref":"/manopt/stable/plans/objective/#Manopt.linearized_forward_operator","content":" Manopt.linearized_forward_operator  ‚Äî  Function Y = linearized_forward_operator(M::AbstractManifold, N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, m, X, n)\nlinearized_forward_operator!(M::AbstractManifold, N::AbstractManifold, Y, apdmo::AbstractPrimalDualManifoldObjective, m, X, n) Evaluate the linearized operator (differential)  $DŒõ(m)[X]$  stored within the  AbstractPrimalDualManifoldObjective  (in place of  Y ), where  n = Œõ(m) . source"},{"id":2259,"pagetitle":"Objective","title":"Constrained objective","ref":"/manopt/stable/plans/objective/#Constrained-objective","content":" Constrained objective Besides the  AbstractEvaluationType  there is one further property to distinguish among constraint functions, especially the gradients of the constraints."},{"id":2260,"pagetitle":"Objective","title":"Manopt.ConstraintType","ref":"/manopt/stable/plans/objective/#Manopt.ConstraintType","content":" Manopt.ConstraintType  ‚Äî  Type ConstraintType An abstract type to represent different forms of representing constraints source"},{"id":2261,"pagetitle":"Objective","title":"Manopt.FunctionConstraint","ref":"/manopt/stable/plans/objective/#Manopt.FunctionConstraint","content":" Manopt.FunctionConstraint  ‚Äî  Type FunctionConstraint <: ConstraintType A type to indicate that constraints are implemented one whole functions, for example  $g(p) ‚àà ‚Ñù^m$ . source"},{"id":2262,"pagetitle":"Objective","title":"Manopt.VectorConstraint","ref":"/manopt/stable/plans/objective/#Manopt.VectorConstraint","content":" Manopt.VectorConstraint  ‚Äî  Type VectorConstraint <: ConstraintType A type to indicate that constraints are implemented a  vector of functions, for example  $g_i(p) ‚àà ‚Ñù, i=1,‚Ä¶,m$ . source The  ConstraintType  is a parameter of the corresponding Objective."},{"id":2263,"pagetitle":"Objective","title":"Manopt.ConstrainedManifoldObjective","ref":"/manopt/stable/plans/objective/#Manopt.ConstrainedManifoldObjective","content":" Manopt.ConstrainedManifoldObjective  ‚Äî  Type ConstrainedManifoldObjective{T<:AbstractEvaluationType, C <: ConstraintType Manifold} <: AbstractManifoldObjective{T} Describes the constrained objective \\[\\begin{aligned}\n \\operatorname*{arg\\,min}_{p ‚àà\\mathcal{M}} & f(p)\\\\\n \\text{subject to } &g_i(p)\\leq0 \\quad \\text{ for all } i=1,‚Ä¶,m,\\\\\n \\quad &h_j(p)=0 \\quad \\text{ for all } j=1,‚Ä¶,n.\n\\end{aligned}\\] Fields cost  the cost  $f$ ` gradient!!  the gradient of the cost  $f$ ` g  the inequality constraints grad_g!!  the gradient of the inequality constraints h  the equality constraints grad_h!!  the gradient of the equality constraints It consists of an cost function  $f(p)$ the gradient of  $f$ ,  $\\operatorname{grad}f(p)$ inequality constraints  $g(p)$ , either a function  g  returning a vector or a vector  [g1, g2, ..., gm]  of functions. equality constraints  $h(p)$ , either a function  h  returning a vector or a vector  [h1, h2, ..., hn]  of functions. gradients of the inequality constraints  $\\operatorname{grad}g(p) ‚àà (T_p\\mathcal M)^m$ , either a function or a vector of functions. gradients of the equality constraints  $\\operatorname{grad}h(p) ‚àà (T_p\\mathcal M)^n$ , either a function or a vector of functions. There are two ways to specify the constraints  $g$  and  $h$ . as one  Function  returning a vector in  $‚Ñù^m$  and  $‚Ñù^n$  respectively. This might be easier to implement but requires evaluating all constraints even if only one is needed. as a  AbstractVector{<:Function}  where each function returns a real number. This requires each constraint to be implemented as a single function, but it is possible to evaluate also only a single constraint. The gradients  $\\operatorname{grad}g$ ,  $\\operatorname{grad}h$  have to follow the same form. Additionally they can be implemented as in-place functions or as allocating ones. The gradient  $\\operatorname{grad}F$  has to be the same kind. This difference is indicated by the  evaluation  keyword. Constructors ConstrainedManifoldObjective(f, grad_f, g, grad_g, h, grad_h;\n    evaluation=AllocatingEvaluation()\n) Where  f, g, h  describe the cost, inequality and equality constraints, respectively, as described previously and  grad_f, grad_g, grad_h  are the corresponding gradient functions in one of the 4 formats. If the objective does not have inequality constraints, you can set  G  and  gradG  no  nothing . If the problem does not have equality constraints, you can set  H  and  gradH  no  nothing  or leave them out. ConstrainedManifoldObjective(M::AbstractManifold, F, gradF;\n    G=nothing, gradG=nothing, H=nothing, gradH=nothing;\n    evaluation=AllocatingEvaluation()\n) A keyword argument variant of the preceding constructor, where you can leave out either  G  and  gradG  or  H  and  gradH  but not both pairs. source"},{"id":2264,"pagetitle":"Objective","title":"Access functions","ref":"/manopt/stable/plans/objective/#Access-functions-7","content":" Access functions"},{"id":2265,"pagetitle":"Objective","title":"Manopt.get_constraints","ref":"/manopt/stable/plans/objective/#Manopt.get_constraints","content":" Manopt.get_constraints  ‚Äî  Function get_constraints(M::AbstractManifold, co::ConstrainedManifoldObjective, p) Return the vector  $(g_1(p),...g_m(p),h_1(p),...,h_n(p))$  from the  ConstrainedManifoldObjective P  containing the values of all constraints at  p . source get_constraints(M::AbstractManifold, emo::EmbeddedManifoldObjective, p) Return the vector  $(g_1(p),...g_m(p),h_1(p),...,h_n(p))$  defined in the embedding, that is embed  p  before calling the constraint functions stored in the  EmbeddedManifoldObjective . source"},{"id":2266,"pagetitle":"Objective","title":"Manopt.get_equality_constraint","ref":"/manopt/stable/plans/objective/#Manopt.get_equality_constraint","content":" Manopt.get_equality_constraint  ‚Äî  Function get_equality_constraint(M::AbstractManifold, co::ConstrainedManifoldObjective, p, j) evaluate the  j th equality constraint  $(h(p))_j$  or  $h_j(p)$ . Note For the  FunctionConstraint  representation this still evaluates all constraints. source get_equality_constraint(M::AbstractManifold, emo::EmbeddedManifoldObjective, p, j) evaluate the  j s equality constraint  $h_j(p)$  defined in the embedding, that is embed  p  before calling the constraint functions stored in the  EmbeddedManifoldObjective . source"},{"id":2267,"pagetitle":"Objective","title":"Manopt.get_equality_constraints","ref":"/manopt/stable/plans/objective/#Manopt.get_equality_constraints","content":" Manopt.get_equality_constraints  ‚Äî  Function get_equality_constraints(M::AbstractManifold, co::ConstrainedManifoldObjective, p) evaluate all equality constraints  $h(p)$  of  $\\bigl(h_1(p), h_2(p),\\ldots,h_p(p)\\bigr)$  of the  ConstrainedManifoldObjective $P$  at  $p$ . source get_equality_constraints(M::AbstractManifold, emo::EmbeddedManifoldObjective, p) Evaluate all equality constraints  $h(p)$  of  $\\bigl(h_1(p), h_2(p),\\ldots,h_p(p)\\bigr)$  defined in the embedding, that is embed  p  before calling the constraint functions stored in the  EmbeddedManifoldObjective . source"},{"id":2268,"pagetitle":"Objective","title":"Manopt.get_inequality_constraint","ref":"/manopt/stable/plans/objective/#Manopt.get_inequality_constraint","content":" Manopt.get_inequality_constraint  ‚Äî  Function get_inequality_constraint(M::AbstractManifold, co::ConstrainedManifoldObjective, p, i) evaluate one equality constraint  $(g(p))_i$  or  $g_i(p)$ . Note For the  FunctionConstraint  representation this still evaluates all constraints. source get_inequality_constraint(M::AbstractManifold, ems::EmbeddedManifoldObjective, p, i) Evaluate the  i s inequality constraint  $g_i(p)$  defined in the embedding, that is embed  p  before calling the constraint functions stored in the  EmbeddedManifoldObjective . source"},{"id":2269,"pagetitle":"Objective","title":"Manopt.get_inequality_constraints","ref":"/manopt/stable/plans/objective/#Manopt.get_inequality_constraints","content":" Manopt.get_inequality_constraints  ‚Äî  Function get_inequality_constraints(M::AbstractManifold, co::ConstrainedManifoldObjective, p) Evaluate all inequality constraints  $g(p)$  or  $\\bigl(g_1(p), g_2(p),\\ldots,g_m(p)\\bigr)$  of the  ConstrainedManifoldObjective $P$  at  $p$ . source get_inequality_constraints(M::AbstractManifold, ems::EmbeddedManifoldObjective, p) Evaluate all inequality constraints  $g(p)$  of  $\\bigl(g_1(p), g_2(p),\\ldots,g_m(p)\\bigr)$  defined in the embedding, that is embed  p  before calling the constraint functions stored in the  EmbeddedManifoldObjective . source"},{"id":2270,"pagetitle":"Objective","title":"Manopt.get_grad_equality_constraint","ref":"/manopt/stable/plans/objective/#Manopt.get_grad_equality_constraint","content":" Manopt.get_grad_equality_constraint  ‚Äî  Function get_grad_equality_constraint(M::AbstractManifold, co::ConstrainedManifoldObjective, p, j) evaluate the gradient of the  j  th equality constraint  $(\\operatorname{grad} h(p))_j$  or  $\\operatorname{grad} h_j(x)$ . Note For the  FunctionConstraint  variant of the problem, this function still evaluates the full gradient. For the  InplaceEvaluation  and  FunctionConstraint  of the problem, this function currently also calls  get_equality_constraints , since this is the only way to determine the number of constraints. It also allocates a full tangent vector. source X = get_grad_equality_constraint(M::AbstractManifold, emo::EmbeddedManifoldObjective, p, j)\nget_grad_equality_constraint!(M::AbstractManifold, X, emo::EmbeddedManifoldObjective, p, j) evaluate the gradient of the  j th equality constraint  $\\operatorname{grad} h_j(p)$  defined in the embedding, that is embed  p  before calling the gradient function stored in the  EmbeddedManifoldObjective . The returned gradient is then converted to a Riemannian gradient calling  riemannian_gradient . source"},{"id":2271,"pagetitle":"Objective","title":"Manopt.get_grad_equality_constraints","ref":"/manopt/stable/plans/objective/#Manopt.get_grad_equality_constraints","content":" Manopt.get_grad_equality_constraints  ‚Äî  Function get_grad_equality_constraints(M::AbstractManifold, co::ConstrainedManifoldObjective, p) evaluate all gradients of the equality constraints  $\\operatorname{grad} h(x)$  or  $\\bigl(\\operatorname{grad} h_1(x), \\operatorname{grad} h_2(x),\\ldots, \\operatorname{grad}h_n(x)\\bigr)$  of the  ConstrainedManifoldObjective P  at  p . Note For the  InplaceEvaluation  and  FunctionConstraint  variant of the problem, this function currently also calls  get_equality_constraints , since this is the only way to determine the number of constraints. source X = get_grad_equality_constraints(M::AbstractManifold, emo::EmbeddedManifoldObjective, p)\nget_grad_equality_constraints!(M::AbstractManifold, X, emo::EmbeddedManifoldObjective, p) evaluate the gradients of theequality constraints  $\\operatorname{grad} h(p)$  defined in the embedding, that is embed  p  before calling the gradient function stored in the  EmbeddedManifoldObjective . The returned gradients are then converted to a Riemannian gradient calling  riemannian_gradient . source"},{"id":2272,"pagetitle":"Objective","title":"Manopt.get_grad_equality_constraints!","ref":"/manopt/stable/plans/objective/#Manopt.get_grad_equality_constraints!","content":" Manopt.get_grad_equality_constraints!  ‚Äî  Function get_grad_equality_constraints!(M::AbstractManifold, X, co::ConstrainedManifoldObjective, p) evaluate all gradients of the equality constraints  $\\operatorname{grad} h(p)$  or  $\\bigl(\\operatorname{grad} h_1(p), \\operatorname{grad} h_2(p),\\ldots,\\operatorname{grad} h_n(p)\\bigr)$  of the  ConstrainedManifoldObjective $P$  at  $p$  in place of  X , which is a vector of n ` tangent vectors. source"},{"id":2273,"pagetitle":"Objective","title":"Manopt.get_grad_equality_constraint!","ref":"/manopt/stable/plans/objective/#Manopt.get_grad_equality_constraint!","content":" Manopt.get_grad_equality_constraint!  ‚Äî  Function get_grad_equality_constraint!(M::AbstractManifold, X, co::ConstrainedManifoldObjective, p, j) Evaluate the gradient of the  j th equality constraint  $(\\operatorname{grad} h(x))_j$  or  $\\operatorname{grad} h_j(x)$  in place of  $X$ Note For the  FunctionConstraint  variant of the problem, this function still evaluates the full gradient. For the  InplaceEvaluation  of the  FunctionConstraint  of the problem, this function currently also calls  get_inequality_constraints , since this is the only way to determine the number of constraints and allocates a full vector of tangent vectors source"},{"id":2274,"pagetitle":"Objective","title":"Manopt.get_grad_inequality_constraint","ref":"/manopt/stable/plans/objective/#Manopt.get_grad_inequality_constraint","content":" Manopt.get_grad_inequality_constraint  ‚Äî  Function get_grad_inequality_constraint(M::AbstractManifold, co::ConstrainedManifoldObjective, p, i) Evaluate the gradient of the  i  th inequality constraints  $(\\operatorname{grad} g(x))_i$  or  $\\operatorname{grad} g_i(x)$ . Note For the  FunctionConstraint  variant of the problem, this function still evaluates the full gradient. For the  InplaceEvaluation  and  FunctionConstraint  of the problem, this function currently also calls  get_inequality_constraints , since this is the only way to determine the number of constraints. source X = get_grad_inequality_constraint(M::AbstractManifold, emo::EmbeddedManifoldObjective, p, i)\nget_grad_inequality_constraint!(M::AbstractManifold, X, emo::EmbeddedManifoldObjective, p, i) evaluate the gradient of the  i th inequality constraint  $\\operatorname{grad} g_i(p)$  defined in the embedding, that is embed  p  before calling the gradient function stored in the  EmbeddedManifoldObjective . The returned gradient is then converted to a Riemannian gradient calling  riemannian_gradient . source"},{"id":2275,"pagetitle":"Objective","title":"Manopt.get_grad_inequality_constraint!","ref":"/manopt/stable/plans/objective/#Manopt.get_grad_inequality_constraint!","content":" Manopt.get_grad_inequality_constraint!  ‚Äî  Function get_grad_inequality_constraint!(P, X, p, i) Evaluate the gradient of the  i th inequality constraints  $(\\operatorname{grad} g(x))_i$  or  $\\operatorname{grad} g_i(x)$  of the  ConstrainedManifoldObjective P  in place of  $X$ Note For the  FunctionConstraint  variant of the problem, this function still evaluates the full gradient. For the  InplaceEvaluation  and  FunctionConstraint  of the problem, this function currently also calls  get_inequality_constraints , since this is the only way to determine the number of constraints. evaluate all gradients of the inequality constraints  $\\operatorname{grad} h(x)$  or  $\\bigl(g_1(x), g_2(x),\\ldots,g_m(x)\\bigr)$  of the  ConstrainedManifoldObjective $p$  at  $x$  in place of  X , which is a vector of m ` tangent vectors . source"},{"id":2276,"pagetitle":"Objective","title":"Manopt.get_grad_inequality_constraints","ref":"/manopt/stable/plans/objective/#Manopt.get_grad_inequality_constraints","content":" Manopt.get_grad_inequality_constraints  ‚Äî  Function get_grad_inequality_constraints(M::AbstractManifold, co::ConstrainedManifoldObjective, p) evaluate all gradients of the inequality constraints  $\\operatorname{grad} g(p)$  or  $\\bigl(\\operatorname{grad} g_1(p), \\operatorname{grad} g_2(p),‚Ä¶,\\operatorname{grad} g_m(p)\\bigr)$  of the  ConstrainedManifoldObjective $P$  at  $p$ . Note for the  InplaceEvaluation  and  FunctionConstraint  variant of the problem,    this function currently also calls  get_equality_constraints ,    since this is the only way to determine the number of constraints. source X = get_grad_inequality_constraints(M::AbstractManifold, emo::EmbeddedManifoldObjective, p)\nget_grad_inequality_constraints!(M::AbstractManifold, X, emo::EmbeddedManifoldObjective, p) evaluate the gradients of theinequality constraints  $\\operatorname{grad} g(p)$  defined in the embedding, that is embed  p  before calling the gradient function stored in the  EmbeddedManifoldObjective . The returned gradients are then converted to a Riemannian gradient calling  riemannian_gradient . source"},{"id":2277,"pagetitle":"Objective","title":"Manopt.get_grad_inequality_constraints!","ref":"/manopt/stable/plans/objective/#Manopt.get_grad_inequality_constraints!","content":" Manopt.get_grad_inequality_constraints!  ‚Äî  Function get_grad_inequality_constraints!(M::AbstractManifold, X, co::ConstrainedManifoldObjective, p) evaluate all gradients of the inequality constraints  $\\operatorname{grad} g(x)$  or  $\\bigl(\\operatorname{grad} g_1(x), \\operatorname{grad} g_2(x),\\ldots,\\operatorname{grad} g_m(x)\\bigr)$  of the  ConstrainedManifoldObjective P  at  p  in place of  X , which is a vector of  $m$  tangent vectors. source"},{"id":2278,"pagetitle":"Objective","title":"Subproblem objective","ref":"/manopt/stable/plans/objective/#Subproblem-objective","content":" Subproblem objective This objective can be use when the objective of a sub problem solver still needs access to the (outer/main) objective."},{"id":2279,"pagetitle":"Objective","title":"Manopt.AbstractManifoldSubObjective","ref":"/manopt/stable/plans/objective/#Manopt.AbstractManifoldSubObjective","content":" Manopt.AbstractManifoldSubObjective  ‚Äî  Type AbstractManifoldSubObjective{O<:AbstractManifoldObjective} <: AbstractManifoldObjective An abstract type for objectives of sub problems within a solver but still store the original objective internally to generate generic objectives for sub solvers. source"},{"id":2280,"pagetitle":"Objective","title":"Access functions","ref":"/manopt/stable/plans/objective/#Access-functions-8","content":" Access functions"},{"id":2281,"pagetitle":"Objective","title":"Manopt.get_objective_cost","ref":"/manopt/stable/plans/objective/#Manopt.get_objective_cost","content":" Manopt.get_objective_cost  ‚Äî  Function get_objective_cost(M, amso::AbstractManifoldSubObjective, p) Evaluate the cost of the (original) objective stored within the sub objective. source"},{"id":2282,"pagetitle":"Objective","title":"Manopt.get_objective_gradient","ref":"/manopt/stable/plans/objective/#Manopt.get_objective_gradient","content":" Manopt.get_objective_gradient  ‚Äî  Function X = get_objective_gradient(M, amso::AbstractManifoldSubObjective, p)\nget_objective_gradient!(M, X, amso::AbstractManifoldSubObjective, p) Evaluate the gradient of the (original) objective stored within the sub objective  amso . source"},{"id":2283,"pagetitle":"Objective","title":"Manopt.get_objective_hessian","ref":"/manopt/stable/plans/objective/#Manopt.get_objective_hessian","content":" Manopt.get_objective_hessian  ‚Äî  Function Y = get_objective_Hessian(M, amso::AbstractManifoldSubObjective, p, X)\nget_objective_Hessian!(M, Y, amso::AbstractManifoldSubObjective, p, X) Evaluate the Hessian of the (original) objective stored within the sub objective  amso . source"},{"id":2284,"pagetitle":"Objective","title":"Manopt.get_objective_preconditioner","ref":"/manopt/stable/plans/objective/#Manopt.get_objective_preconditioner","content":" Manopt.get_objective_preconditioner  ‚Äî  Function Y = get_objective_preconditioner(M, amso::AbstractManifoldSubObjective, p, X)\nget_objective_preconditioner(M, Y, amso::AbstractManifoldSubObjective, p, X) Evaluate the Hessian of the (original) objective stored within the sub objective  amso . source 1 This cache requires  LRUCache.jl  to be loaded as well."},{"id":2287,"pagetitle":"Problem","title":"A Manopt problem","ref":"/manopt/stable/plans/problem/#sec-problem","content":" A Manopt problem A problem describes all static data of an optimisation task and has as a super type"},{"id":2288,"pagetitle":"Problem","title":"Manopt.AbstractManoptProblem","ref":"/manopt/stable/plans/problem/#Manopt.AbstractManoptProblem","content":" Manopt.AbstractManoptProblem  ‚Äî  Type AbstractManoptProblem{M<:AbstractManifold} Describe a Riemannian optimization problem with all static (not-changing) properties. The most prominent features that should always be stated here are the  AbstractManifold $\\mathcal M$ the cost function  $f:  \\mathcal M ‚Üí ‚Ñù$ Usually the cost should be within an  AbstractManifoldObjective . source"},{"id":2289,"pagetitle":"Problem","title":"Manopt.get_objective","ref":"/manopt/stable/plans/problem/#Manopt.get_objective","content":" Manopt.get_objective  ‚Äî  Function get_objective(o::AbstractManifoldObjective, recursive=true) return the (one step) undecorated  AbstractManifoldObjective  of the (possibly) decorated  o . As long as your decorated objective stores the objective within  o.objective  and the  dispatch_objective_decorator  is set to  Val{true} , the internal state are extracted automatically. By default the objective that is stored within a decorated objective is assumed to be at  o.objective . Overwrite  _get_objective(o, ::Val{true}, recursive) to change this behaviour for your objective o` for both the recursive and the direct case. If  recursive  is set to  false , only the most outer decorator is taken away instead of all. source get_objective(mp::AbstractManoptProblem, recursive=false) return the objective  AbstractManifoldObjective  stored within an  AbstractManoptProblem . If  recursive is set to true, it additionally unwraps all decorators of the objective source get_objective(amso::AbstractManifoldSubObjective) Return the (original) objective stored the sub objective is build on. source"},{"id":2290,"pagetitle":"Problem","title":"Manopt.get_manifold","ref":"/manopt/stable/plans/problem/#Manopt.get_manifold","content":" Manopt.get_manifold  ‚Äî  Function get_manifold(amp::AbstractManoptProblem) return the manifold stored within an  AbstractManoptProblem source Usually, such a problem is determined by the manifold or domain of the optimisation and the objective with all its properties used within an algorithm, see  The Objective . For that one can just use"},{"id":2291,"pagetitle":"Problem","title":"Manopt.DefaultManoptProblem","ref":"/manopt/stable/plans/problem/#Manopt.DefaultManoptProblem","content":" Manopt.DefaultManoptProblem  ‚Äî  Type DefaultManoptProblem{TM <: AbstractManifold, Objective <: AbstractManifoldObjective} Model a default manifold problem, that (just) consists of the domain of optimisation, that is an  AbstractManifold  and an  AbstractManifoldObjective source The exception to these are the primal dual-based solvers ( Chambolle-Pock  and the  PD Semi-smooth Newton ), which both need two manifolds as their domains, hence there also exists a"},{"id":2292,"pagetitle":"Problem","title":"Manopt.TwoManifoldProblem","ref":"/manopt/stable/plans/problem/#Manopt.TwoManifoldProblem","content":" Manopt.TwoManifoldProblem  ‚Äî  Type TwoManifoldProblem{\n    MT<:AbstractManifold,NT<:AbstractManifold,O<:AbstractManifoldObjective\n} <: AbstractManoptProblem{MT} An abstract type for primal-dual-based problems. source From the two ingredients here, you can find more information about the  ManifoldsBase.AbstractManifold  in  ManifoldsBase.jl the  AbstractManifoldObjective  on the  page about the objective ."},{"id":2295,"pagetitle":"Recording values","title":"Record values","ref":"/manopt/stable/plans/record/#sec-record","content":" Record values To record values during the iterations of a solver run, there are in general two possibilities. On the one hand, the high-level interfaces provide a  record=  keyword, that accepts several different inputs. For more details see  How to record . For example recording the gradient from the  GradientDescentState  is automatically available, as explained in the  gradient_descent  solver."},{"id":2296,"pagetitle":"Recording values","title":"Record solver states","ref":"/manopt/stable/plans/record/#subsec-record-states","content":" Record solver states"},{"id":2297,"pagetitle":"Recording values","title":"Manopt.RecordAction","ref":"/manopt/stable/plans/record/#Manopt.RecordAction","content":" Manopt.RecordAction  ‚Äî  Type RecordAction A  RecordAction  is a small functor to record values. The usual call is given by  (amp::AbstractManoptProblem, ams::AbstractManoptSolverState, i) -> s  that performs the record, where  i  is the current iteration. By convention  i<=0  is interpreted as \"For Initialization only,\" so only initialize internal values, but not trigger any record, that the record is called from within  stop_solver!  which returns true afterwards. Fields (assumed by subtypes to exist) recorded_values  an  Array  of the recorded values. source"},{"id":2298,"pagetitle":"Recording values","title":"Manopt.RecordChange","ref":"/manopt/stable/plans/record/#Manopt.RecordChange","content":" Manopt.RecordChange  ‚Äî  Type RecordChange <: RecordAction debug for the amount of change of the iterate (stored in  o.x  of the  AbstractManoptSolverState ) during the last iteration. Additional fields storage  a  StoreStateAction  to store (at least)  o.x  to use this as the last value (to compute the change inverse_retraction_method  - ( default_inverse_retraction_method(manifold, p) ) the inverse retraction to be used for approximating distance. Constructor RecordChange(M=DefaultManifold();) with the preceding fields as keywords. For the  DefaultManifold  only the field storage is used. Providing the actual manifold moves the default storage to the efficient point storage. source"},{"id":2299,"pagetitle":"Recording values","title":"Manopt.RecordCost","ref":"/manopt/stable/plans/record/#Manopt.RecordCost","content":" Manopt.RecordCost  ‚Äî  Type RecordCost <: RecordAction Record the current cost function value, see  get_cost . source"},{"id":2300,"pagetitle":"Recording values","title":"Manopt.RecordEntry","ref":"/manopt/stable/plans/record/#Manopt.RecordEntry","content":" Manopt.RecordEntry  ‚Äî  Type RecordEntry{T} <: RecordAction record a certain fields entry of type {T} during the iterates Fields recorded_values  the recorded Iterates field            Symbol the entry can be accessed with within  AbstractManoptSolverState source"},{"id":2301,"pagetitle":"Recording values","title":"Manopt.RecordEntryChange","ref":"/manopt/stable/plans/record/#Manopt.RecordEntryChange","content":" Manopt.RecordEntryChange  ‚Äî  Type RecordEntryChange{T} <: RecordAction record a certain entries change during iterates Additional fields recorded_values  the recorded Iterates field            Symbol the field can be accessed with within  AbstractManoptSolverState distance         function (p,o,x1,x2) to compute the change/distance between two values of the entry storage          a  StoreStateAction  to store (at least)  getproperty(o, d.field) source"},{"id":2302,"pagetitle":"Recording values","title":"Manopt.RecordEvery","ref":"/manopt/stable/plans/record/#Manopt.RecordEvery","content":" Manopt.RecordEvery  ‚Äî  Type RecordEvery <: RecordAction record only every  $i$ th iteration. Otherwise (optionally, but activated by default) just update internal tracking values. This method does not perform any record itself but relies on it's children's methods source"},{"id":2303,"pagetitle":"Recording values","title":"Manopt.RecordGroup","ref":"/manopt/stable/plans/record/#Manopt.RecordGroup","content":" Manopt.RecordGroup  ‚Äî  Type RecordGroup <: RecordAction group a set of  RecordAction s into one action, where the internal  RecordAction s act independently, but the results can be collected in a grouped fashion, a tuple per calls of this group. The entries can be later addressed either by index or semantic Symbols Constructors RecordGroup(g::Array{<:RecordAction, 1}) construct a group consisting of an Array of  RecordAction s  g , RecordGroup(g, symbols) Examples r = RecordGroup([RecordIteration(), RecordCost()]) A RecordGroup to record the current iteration and the cost. The cost can then be accessed using  get_record(r,2)  or  r[2] . r = RecordGroup([RecordIteration(), RecordCost()], Dict(:Cost => 2)) A RecordGroup to record the current iteration and the cost, which can then be accessed using  get_record(:Cost)  or  r[:Cost] . r = RecordGroup([RecordIteration(), :Cost => RecordCost()]) A RecordGroup identical to the previous constructor, just a little easier to use. source"},{"id":2304,"pagetitle":"Recording values","title":"Manopt.RecordIterate","ref":"/manopt/stable/plans/record/#Manopt.RecordIterate","content":" Manopt.RecordIterate  ‚Äî  Type RecordIterate <: RecordAction record the iterate Constructors RecordIterate(x0) initialize the iterate record array to the type of  x0 , which indicates the kind of iterate RecordIterate(P) initialize the iterate record array to the data type  T . source"},{"id":2305,"pagetitle":"Recording values","title":"Manopt.RecordIteration","ref":"/manopt/stable/plans/record/#Manopt.RecordIteration","content":" Manopt.RecordIteration  ‚Äî  Type RecordIteration <: RecordAction record the current iteration source"},{"id":2306,"pagetitle":"Recording values","title":"Manopt.RecordSolverState","ref":"/manopt/stable/plans/record/#Manopt.RecordSolverState","content":" Manopt.RecordSolverState  ‚Äî  Type RecordSolverState <: AbstractManoptSolverState append to any  AbstractManoptSolverState  the decorator with record capability, Internally a dictionary is kept that stores a  RecordAction  for several concurrent modes using a  Symbol  as reference. The default mode is  :Iteration , which is used to store information that is recorded during the iterations. RecordActions might be added to  :Start  or  :Stop  to record values at the beginning or for the stopping time point, respectively The original options can still be accessed using the  get_state  function. Fields options           the options that are extended by debug information recordDictionary  a  Dict{Symbol,RecordAction}  to keep track of all different recorded values Constructors RecordSolverState(o,dR) construct record decorated  AbstractManoptSolverState , where  dR  can be a  RecordAction , then it is stored within the dictionary at  :Iteration an  Array  of  RecordAction s, then it is stored as a  recordDictionary (@ref). a  Dict{Symbol,RecordAction} . source"},{"id":2307,"pagetitle":"Recording values","title":"Manopt.RecordTime","ref":"/manopt/stable/plans/record/#Manopt.RecordTime","content":" Manopt.RecordTime  ‚Äî  Type RecordTime <: RecordAction record the time elapsed during the current iteration. The three possible modes are :cumulative  record times without resetting the timer :iterative  record times with resetting the timer :total  record a time only at the end of an algorithm (see  stop_solver! ) The default is  :cumulative , and any non-listed symbol default to using this mode. Constructor RecordTime(; mode::Symbol=:cumulative) source"},{"id":2308,"pagetitle":"Recording values","title":"Base.getindex","ref":"/manopt/stable/plans/record/#Base.getindex-Tuple{RecordGroup, Vararg{Any}}","content":" Base.getindex  ‚Äî  Method getindex(r::RecordGroup, s::Symbol)\nr[s]\ngetindex(r::RecordGroup, sT::NTuple{N,Symbol})\nr[sT]\ngetindex(r::RecordGroup, i)\nr[i] return an array of recorded values with respect to the  s , the symbols from the tuple  sT  or the index  i . See  get_record  for details. source"},{"id":2309,"pagetitle":"Recording values","title":"Base.getindex","ref":"/manopt/stable/plans/record/#Base.getindex-Tuple{RecordSolverState, Symbol}","content":" Base.getindex  ‚Äî  Method get_index(rs::RecordSolverState, s::Symbol)\nro[s] Get the recorded values for recorded type  s , see  get_record  for details. get_index(rs::RecordSolverState, s::Symbol, i...)\nro[s, i...] Access the recording type of type  s  and call its  RecordAction  with  [i...] . source"},{"id":2310,"pagetitle":"Recording values","title":"Manopt.RecordActionFactory","ref":"/manopt/stable/plans/record/#Manopt.RecordActionFactory-Tuple{AbstractManoptSolverState, RecordAction}","content":" Manopt.RecordActionFactory  ‚Äî  Method RecordActionFactory(s) create a  RecordAction  where a  RecordAction  is passed through a [ Symbol ] creates  RecordEntry  of that symbol, with the exceptions of :Change         to record the change of the iterates in  o.x ` :Iterate        to record the iterate :Iteration      to record the current iteration number :Cost           to record the current cost function value :Time           to record the total time taken after every iteration :IterativeTime  to record the times taken for each iteration. source"},{"id":2311,"pagetitle":"Recording values","title":"Manopt.RecordFactory","ref":"/manopt/stable/plans/record/#Manopt.RecordFactory-Tuple{AbstractManoptSolverState, Vector}","content":" Manopt.RecordFactory  ‚Äî  Method RecordFactory(s::AbstractManoptSolverState, a) given an array of  Symbol s and  RecordAction s and  Ints The symbol  :Cost  creates a  RecordCost The symbol  :iteration  creates a  RecordIteration The symbol  :Change  creates a  RecordChange any other symbol creates a  RecordEntry  of the corresponding field in  AbstractManoptSolverState any  RecordAction  is directly included an semantic pair  :symbol => RecordAction  is directly included an Integer  k  introduces that record is only performed every  k th iteration source"},{"id":2312,"pagetitle":"Recording values","title":"Manopt.get_record","ref":"/manopt/stable/plans/record/#Manopt.get_record","content":" Manopt.get_record  ‚Äî  Function get_record(s::AbstractManoptSolverState, [,symbol=:Iteration])\nget_record(s::RecordSolverState, [,symbol=:Iteration]) return the recorded values from within the  RecordSolverState s  that where recorded with respect to the  Symbol symbol  as an  Array . The default refers to any recordings during an  :Iteration . When called with arbitrary  AbstractManoptSolverState , this method looks for the  RecordSolverState  decorator and calls  get_record  on the decorator. source"},{"id":2313,"pagetitle":"Recording values","title":"Manopt.get_record","ref":"/manopt/stable/plans/record/#Manopt.get_record-Tuple{RecordAction, Any}","content":" Manopt.get_record  ‚Äî  Method get_record(r::RecordAction) return the recorded values stored within a  RecordAction r . source"},{"id":2314,"pagetitle":"Recording values","title":"Manopt.get_record","ref":"/manopt/stable/plans/record/#Manopt.get_record-Tuple{RecordGroup}","content":" Manopt.get_record  ‚Äî  Method get_record(r::RecordGroup) return an array of tuples, where each tuple is a recorded set per iteration or record call. get_record(r::RecordGruop, i::Int) return an array of values corresponding to the  i th entry in this record group get_record(r::RecordGruop, s::Symbol) return an array of recorded values with respect to the  s , see  RecordGroup . get_record(r::RecordGroup, s1::Symbol, s2::Symbol,...) return an array of tuples, where each tuple is a recorded set corresponding to the symbols  s1, s2,...  per iteration / record call. source"},{"id":2315,"pagetitle":"Recording values","title":"Manopt.get_record_action","ref":"/manopt/stable/plans/record/#Manopt.get_record_action","content":" Manopt.get_record_action  ‚Äî  Function get_record_action(s::AbstractManoptSolverState, s::Symbol) return the action contained in the (first)  RecordSolverState  decorator within the  AbstractManoptSolverState o . source"},{"id":2316,"pagetitle":"Recording values","title":"Manopt.get_record_state","ref":"/manopt/stable/plans/record/#Manopt.get_record_state-Tuple{AbstractManoptSolverState}","content":" Manopt.get_record_state  ‚Äî  Method get_record_state(s::AbstractManoptSolverState) return the  RecordSolverState  among the decorators from the  AbstractManoptSolverState o source"},{"id":2317,"pagetitle":"Recording values","title":"Manopt.has_record","ref":"/manopt/stable/plans/record/#Manopt.has_record-Tuple{RecordSolverState}","content":" Manopt.has_record  ‚Äî  Method has_record(s::AbstractManoptSolverState) Indicate whether the  AbstractManoptSolverState s  are decorated with  RecordSolverState source"},{"id":2318,"pagetitle":"Recording values","title":"Manopt.record_or_reset!","ref":"/manopt/stable/plans/record/#Manopt.record_or_reset!-Tuple{RecordAction, Any, Int64}","content":" Manopt.record_or_reset!  ‚Äî  Method record_or_reset!(r,v,i) either record ( i>0  and not  Inf ) the value  v  within the  RecordAction r  or reset ( i<0 ) the internal storage, where  v  has to match the internal value type of the corresponding  RecordAction . source see  recording values  for details on the decorated solver. Further specific  RecordAction s can be found when specific types of  AbstractManoptSolverState  define them on their corresponding site."},{"id":2319,"pagetitle":"Recording values","title":"Technical details","ref":"/manopt/stable/plans/record/#Technical-details","content":" Technical details"},{"id":2320,"pagetitle":"Recording values","title":"Manopt.initialize_solver!","ref":"/manopt/stable/plans/record/#Manopt.initialize_solver!-Tuple{AbstractManoptProblem, RecordSolverState}","content":" Manopt.initialize_solver!  ‚Äî  Method initialize_solver!(ams::AbstractManoptProblem, rss::RecordSolverState) Extend the initialization of the solver by a hook to run records that were added to the  :Start  entry. source"},{"id":2321,"pagetitle":"Recording values","title":"Manopt.step_solver!","ref":"/manopt/stable/plans/record/#Manopt.step_solver!-Tuple{AbstractManoptProblem, RecordSolverState, Any}","content":" Manopt.step_solver!  ‚Äî  Method step_solver!(amp::AbstractManoptProblem, rss::RecordSolverState, i) Extend the  i th step of the solver by a hook to run records, that were added to the  :Iteration  entry. source"},{"id":2322,"pagetitle":"Recording values","title":"Manopt.stop_solver!","ref":"/manopt/stable/plans/record/#Manopt.stop_solver!-Tuple{AbstractManoptProblem, RecordSolverState, Any}","content":" Manopt.stop_solver!  ‚Äî  Method stop_solver!(amp::AbstractManoptProblem, rss::RecordSolverState, i) Extend the call to the stopping criterion by a hook to run records, that were added to the  :Stop  entry. source"},{"id":2325,"pagetitle":"Solver State","title":"Solver state","ref":"/manopt/stable/plans/state/#sec-solver-state","content":" Solver state Given an  AbstractManoptProblem , that is a certain optimisation task, the state specifies the solver to use. It contains the parameters of a solver and all fields necessary during the algorithm, for example the current iterate, a  StoppingCriterion  or a  Stepsize ."},{"id":2326,"pagetitle":"Solver State","title":"Manopt.AbstractManoptSolverState","ref":"/manopt/stable/plans/state/#Manopt.AbstractManoptSolverState","content":" Manopt.AbstractManoptSolverState  ‚Äî  Type AbstractManoptSolverState A general super type for all solver states. Fields The following fields are assumed to be default. If you use different ones, provide the access functions accordingly p  a point on a manifold with the current iterate stop  a  StoppingCriterion . source"},{"id":2327,"pagetitle":"Solver State","title":"Manopt.get_state","ref":"/manopt/stable/plans/state/#Manopt.get_state","content":" Manopt.get_state  ‚Äî  Function get_state(s::AbstractManoptSolverState, recursive::Bool=true) return the (one step) undecorated  AbstractManoptSolverState  of the (possibly) decorated  s . As long as your decorated state stores the state within  s.state  and the  dispatch_objective_decorator  is set to  Val{true} , the internal state are extracted automatically. By default the state that is stored within a decorated state is assumed to be at  s.state . Overwrite  _get_state(s, ::Val{true}, recursive) to change this behaviour for your state s` for both the recursive and the direct case. If  recursive  is set to  false , only the most outer decorator is taken away instead of all. source"},{"id":2328,"pagetitle":"Solver State","title":"Manopt.get_count","ref":"/manopt/stable/plans/state/#Manopt.get_count","content":" Manopt.get_count  ‚Äî  Function get_count(ams::AbstractManoptSolverState, ::Symbol) Obtain the count for a certain countable size, for example the  :Iterations . This function returns 0 if there was nothing to count Available symbols from within the solver state :Iterations  is passed on to the  stop  field to obtain the iteration at which the solver stopped. source get_count(co::ManifoldCountObjective, s::Symbol, mode::Symbol=:None) Get the number of counts for a certain symbol  s . Depending on the  mode  different results appear if the symbol does not exist in the dictionary :None :  (default) silent mode, returns  -1  for non-existing entries :warn :  issues a warning if a field does not exist :error : issues an error if a field does not exist source Since every subtype of an  AbstractManoptSolverState  directly relate to a solver, the concrete states are documented together with the corresponding  solvers . This page documents the general features available for every state. A first example is to obtain or set, the current iterate. This might be useful to continue investigation at the current iterate, or to set up a solver for a next experiment, respectively."},{"id":2329,"pagetitle":"Solver State","title":"Manopt.get_iterate","ref":"/manopt/stable/plans/state/#Manopt.get_iterate","content":" Manopt.get_iterate  ‚Äî  Function get_iterate(O::AbstractManoptSolverState) return the (last stored) iterate within  AbstractManoptSolverState s`. This should usually refer to a single point on the manifold the solver is working on By default this also removes all decorators of the state beforehand. source get_iterate(agst::AbstractGradientSolverState) return the iterate stored within gradient options. THe default returns  agst.p . source"},{"id":2330,"pagetitle":"Solver State","title":"Manopt.set_iterate!","ref":"/manopt/stable/plans/state/#Manopt.set_iterate!","content":" Manopt.set_iterate!  ‚Äî  Function set_iterate!(s::AbstractManoptSolverState, M::AbstractManifold, p) set the iterate within an  AbstractManoptSolverState  to some (start) value  p . source set_iterate!(agst::AbstractGradientSolverState, M, p) set the (current) iterate stored within an  AbstractGradientSolverState  to  p . The default function modifies  s.p . source"},{"id":2331,"pagetitle":"Solver State","title":"Manopt.get_gradient","ref":"/manopt/stable/plans/state/#Manopt.get_gradient-Tuple{AbstractManoptSolverState}","content":" Manopt.get_gradient  ‚Äî  Method get_gradient(s::AbstractManoptSolverState) return the (last stored) gradient within  AbstractManoptSolverState s`. By default also undecorates the state beforehand source"},{"id":2332,"pagetitle":"Solver State","title":"Manopt.set_gradient!","ref":"/manopt/stable/plans/state/#Manopt.set_gradient!","content":" Manopt.set_gradient!  ‚Äî  Function set_gradient!(s::AbstractManoptSolverState, M::AbstractManifold, p, X) set the gradient within an (possibly decorated)  AbstractManoptSolverState  to some (start) value  X  in the tangent space at  p . source set_gradient!(agst::AbstractGradientSolverState, M, p, X) set the (current) gradient stored within an  AbstractGradientSolverState  to  X . The default function modifies  s.X . source An internal function working on the state and elements within a state is used to pass messages from (sub) activities of a state to the corresponding  DebugMessages"},{"id":2333,"pagetitle":"Solver State","title":"Manopt.get_message","ref":"/manopt/stable/plans/state/#Manopt.get_message","content":" Manopt.get_message  ‚Äî  Function get_message(du::AbstractManoptSolverState) get a message (String) from internal functors, in a summary. This should return any message a sub-step might have issued as well. source Furthermore, to access the stopping criterion use"},{"id":2334,"pagetitle":"Solver State","title":"Manopt.get_stopping_criterion","ref":"/manopt/stable/plans/state/#Manopt.get_stopping_criterion","content":" Manopt.get_stopping_criterion  ‚Äî  Function get_stopping_criterion(ams::AbstractManoptSolverState) Return the  StoppingCriterion  stored within the  AbstractManoptSolverState ams . For an undecorated state, this is assumed to be in  ams.stop . Overwrite  _get_stopping_criterion(yms::YMS)  to change this for your manopt solver ( yms ) assuming it has type YMS`. source"},{"id":2335,"pagetitle":"Solver State","title":"Decorators for  AbstractManoptSolverState s","ref":"/manopt/stable/plans/state/#Decorators-for-AbstractManoptSolverStates","content":" Decorators for  AbstractManoptSolverState s A solver state can be decorated using the following trait and function to initialize"},{"id":2336,"pagetitle":"Solver State","title":"Manopt.dispatch_state_decorator","ref":"/manopt/stable/plans/state/#Manopt.dispatch_state_decorator","content":" Manopt.dispatch_state_decorator  ‚Äî  Function dispatch_state_decorator(s::AbstractManoptSolverState) Indicate internally, whether an  AbstractManoptSolverState s  is of decorating type, and stores (encapsulates) a state in itself, by default in the field  s.state . Decorators indicate this by returning  Val{true}  for further dispatch. The default is  Val{false} , so by default a state is not decorated. source"},{"id":2337,"pagetitle":"Solver State","title":"Manopt.is_state_decorator","ref":"/manopt/stable/plans/state/#Manopt.is_state_decorator","content":" Manopt.is_state_decorator  ‚Äî  Function is_state_decorator(s::AbstractManoptSolverState) Indicate, whether  AbstractManoptSolverState s  are of decorator type. source"},{"id":2338,"pagetitle":"Solver State","title":"Manopt.decorate_state!","ref":"/manopt/stable/plans/state/#Manopt.decorate_state!","content":" Manopt.decorate_state!  ‚Äî  Function decorate_state!(s::AbstractManoptSolverState) decorate the  AbstractManoptSolverState s  with specific decorators. Optional arguments optional arguments provide necessary details on the decorators. debug :         ( Array{Union{Symbol,DebugAction,String,Int},1}() ) a set of symbols representing  DebugAction s,  Strings  used as dividers and a sub-sampling integer. These are passed as a  DebugGroup  within  :Iteration  to the  DebugSolverState  decorator dictionary. Only exception is  :Stop  that is passed to  :Stop . record :        ( Array{Union{Symbol,RecordAction,Int},1}() ) specify recordings by using  Symbol s or  RecordAction s directly. An integer can again be used for only recording every  $i$ th iteration. return_state :  ( false ) indicate whether to wrap the options in a  ReturnSolverState , indicating that the solver should return options and not (only) the minimizer. other keywords are ignored. See also DebugSolverState ,  RecordSolverState ,  ReturnSolverState source A simple example is the"},{"id":2339,"pagetitle":"Solver State","title":"Manopt.ReturnSolverState","ref":"/manopt/stable/plans/state/#Manopt.ReturnSolverState","content":" Manopt.ReturnSolverState  ‚Äî  Type ReturnSolverState{O<:AbstractManoptSolverState} <: AbstractManoptSolverState This internal type is used to indicate that the contained  AbstractManoptSolverState state  should be returned at the end of a solver instead of the usual minimizer. See also get_solver_result source as well as  DebugSolverState  and  RecordSolverState ."},{"id":2340,"pagetitle":"Solver State","title":"State actions","ref":"/manopt/stable/plans/state/#State-actions","content":" State actions A state action is a struct for callback functions that can be attached within for example the just mentioned debug decorator or the record decorator."},{"id":2341,"pagetitle":"Solver State","title":"Manopt.AbstractStateAction","ref":"/manopt/stable/plans/state/#Manopt.AbstractStateAction","content":" Manopt.AbstractStateAction  ‚Äî  Type AbstractStateAction a common  Type  for  AbstractStateActions  that might be triggered in decorators, for example within the  DebugSolverState  or within the  RecordSolverState . source Several state decorators or actions might store intermediate values like the (last) iterate to compute some change or the last gradient. In order to minimise the storage of these, there is a generic  StoreStateAction  that acts as generic common storage that can be shared among different actions."},{"id":2342,"pagetitle":"Solver State","title":"Manopt.StoreStateAction","ref":"/manopt/stable/plans/state/#Manopt.StoreStateAction","content":" Manopt.StoreStateAction  ‚Äî  Type StoreStateAction <: AbstractStateAction internal storage for  AbstractStateAction s to store a tuple of fields from an  AbstractManoptSolverState s This functor possesses the usual interface of functions called during an iteration and acts on  (p, s, i) , where  p  is a  AbstractManoptProblem ,  s  is an  AbstractManoptSolverState  and  i  is the current iteration. Fields values :        a dictionary to store interim values based on certain  Symbols keys :          a  Vector  of  Symbols  to refer to fields of  AbstractManoptSolverState point_values :  a  NamedTuple  of mutable values of points on a manifold to be stored in  StoreStateAction . Manifold is later determined by  AbstractManoptProblem  passed to  update_storage! . point_init :    a  NamedTuple  of boolean values indicating whether a point in  point_values  with matching key has been already initialized to a value. When it is false, it corresponds to a general value not being stored for the key present in the vector  keys . vector_values : a  NamedTuple  of mutable values of tangent vectors on a manifold to be stored in  StoreStateAction . Manifold is later determined by  AbstractManoptProblem  passed to  update_storage! . It is not specified at which point the vectors are tangent but for storage it should not matter. vector_init :   a  NamedTuple  of boolean values indicating whether a tangent vector in  vector_values : with matching key has been already initialized to a value. When it is false, it corresponds to a general value not being stored for the key present in the vector  keys . once :          whether to update the internal values only once per iteration lastStored :    last iterate, where this  AbstractStateAction  was called (to determine  once ) To handle the general storage, use  get_storage  and  has_storage  with keys as  Symbol s. For the point storage use  PointStorageKey . For tangent vector storage use  VectorStorageKey . Point and tangent storage have been optimized to be more efficient. Constructors StoreStateAction(s::Vector{Symbol}) This is equivalent as providing  s  to the keyword  store_fields , just that here, no manifold is necessity for the construction. StoreStateAction(M) Keyword arguments store_fields  ( Symbol[] ) store_points  ( Symbol[] ) store_vectors  ( Symbol[] ) as vectors of symbols each referring to fields of the state (lower case symbols) or semantic ones (upper case). p_init  ( rand(M) ) X_init  ( zero_vector(M, p_init) ) are used to initialize the point and vector storage, change these if you use other types (than the default) for your points/vectors on  M . once  ( true ) whether to update internal storage only once per iteration or on every update call source"},{"id":2343,"pagetitle":"Solver State","title":"Manopt.get_storage","ref":"/manopt/stable/plans/state/#Manopt.get_storage","content":" Manopt.get_storage  ‚Äî  Function get_storage(a::AbstractStateAction, key::Symbol) Return the internal value of the  AbstractStateAction a  at the  Symbol key . source get_storage(a::AbstractStateAction, ::PointStorageKey{key}) where {key} Return the internal value of the  AbstractStateAction a  at the  Symbol key  that represents a point. source get_storage(a::AbstractStateAction, ::VectorStorageKey{key}) where {key} Return the internal value of the  AbstractStateAction a  at the  Symbol key  that represents a vector. source"},{"id":2344,"pagetitle":"Solver State","title":"Manopt.has_storage","ref":"/manopt/stable/plans/state/#Manopt.has_storage","content":" Manopt.has_storage  ‚Äî  Function has_storage(a::AbstractStateAction, key::Symbol) Return whether the  AbstractStateAction a  has a value stored at the  Symbol key . source has_storage(a::AbstractStateAction, ::PointStorageKey{key}) where {key} Return whether the  AbstractStateAction a  has a point value stored at the  Symbol key . source has_storage(a::AbstractStateAction, ::VectorStorageKey{key}) where {key} Return whether the  AbstractStateAction a  has a point value stored at the  Symbol key . source"},{"id":2345,"pagetitle":"Solver State","title":"Manopt.update_storage!","ref":"/manopt/stable/plans/state/#Manopt.update_storage!","content":" Manopt.update_storage!  ‚Äî  Function update_storage!(a::AbstractStateAction, amp::AbstractManoptProblem, s::AbstractManoptSolverState) Update the  AbstractStateAction a  internal values to the ones given on the  AbstractManoptSolverState s . Optimized using the information from  amp source update_storage!(a::AbstractStateAction, d::Dict{Symbol,<:Any}) Update the  AbstractStateAction a  internal values to the ones given in the dictionary  d . The values are merged, where the values from  d  are preferred. source"},{"id":2346,"pagetitle":"Solver State","title":"Manopt.PointStorageKey","ref":"/manopt/stable/plans/state/#Manopt.PointStorageKey","content":" Manopt.PointStorageKey  ‚Äî  Type struct PointStorageKey{key} end Refer to point storage of  StoreStateAction  in  get_storage  and  has_storage  functions source"},{"id":2347,"pagetitle":"Solver State","title":"Manopt.VectorStorageKey","ref":"/manopt/stable/plans/state/#Manopt.VectorStorageKey","content":" Manopt.VectorStorageKey  ‚Äî  Type struct VectorStorageKey{key} end Refer to tangent storage of  StoreStateAction  in  get_storage  and  has_storage  functions source as well as two internal functions"},{"id":2348,"pagetitle":"Solver State","title":"Manopt._storage_copy_vector","ref":"/manopt/stable/plans/state/#Manopt._storage_copy_vector","content":" Manopt._storage_copy_vector  ‚Äî  Function _storage_copy_vector(M::AbstractManifold, X) Make a copy of tangent vector  X  from manifold  M  for storage in  StoreStateAction . source"},{"id":2349,"pagetitle":"Solver State","title":"Manopt._storage_copy_point","ref":"/manopt/stable/plans/state/#Manopt._storage_copy_point","content":" Manopt._storage_copy_point  ‚Äî  Function _storage_copy_point(M::AbstractManifold, p) Make a copy of point  p  from manifold  M  for storage in  StoreStateAction . source"},{"id":2350,"pagetitle":"Solver State","title":"Abstract states","ref":"/manopt/stable/plans/state/#Abstract-states","content":" Abstract states In a few cases it is useful to have a hierarchy of types. These are"},{"id":2351,"pagetitle":"Solver State","title":"Manopt.AbstractSubProblemSolverState","ref":"/manopt/stable/plans/state/#Manopt.AbstractSubProblemSolverState","content":" Manopt.AbstractSubProblemSolverState  ‚Äî  Type AbstractSubProblemSolverState <: AbstractManoptSolverState An abstract type for solvers that involve a subsolver. source"},{"id":2352,"pagetitle":"Solver State","title":"Manopt.AbstractGradientSolverState","ref":"/manopt/stable/plans/state/#Manopt.AbstractGradientSolverState","content":" Manopt.AbstractGradientSolverState  ‚Äî  Type AbstractGradientSolverState <: AbstractManoptSolverState A generic  AbstractManoptSolverState  type for gradient based options data. It assumes that the iterate is stored in the field  p the gradient at  p  is stored in  X . See also GradientDescentState ,  StochasticGradientDescentState ,  SubGradientMethodState ,  QuasiNewtonState . source"},{"id":2353,"pagetitle":"Solver State","title":"Manopt.AbstractHessianSolverState","ref":"/manopt/stable/plans/state/#Manopt.AbstractHessianSolverState","content":" Manopt.AbstractHessianSolverState  ‚Äî  Type AbstractHessianSolverState <: AbstractGradientSolverState An  AbstractManoptSolverState  type to represent algorithms that employ the Hessian. These options are assumed to have a field ( gradient ) to store the current gradient  $\\operatorname{grad}f(x)$ source"},{"id":2354,"pagetitle":"Solver State","title":"Manopt.AbstractPrimalDualSolverState","ref":"/manopt/stable/plans/state/#Manopt.AbstractPrimalDualSolverState","content":" Manopt.AbstractPrimalDualSolverState  ‚Äî  Type AbstractPrimalDualSolverState A general type for all primal dual based options to be used within primal dual based algorithms source For the sub problem state, there are two access functions"},{"id":2355,"pagetitle":"Solver State","title":"Manopt.get_sub_problem","ref":"/manopt/stable/plans/state/#Manopt.get_sub_problem","content":" Manopt.get_sub_problem  ‚Äî  Function get_sub_problem(ams::AbstractSubProblemSolverState) Access the sub problem of a solver state that involves a sub optimisation task. By default this returns  ams.sub_problem . source"},{"id":2356,"pagetitle":"Solver State","title":"Manopt.get_sub_state","ref":"/manopt/stable/plans/state/#Manopt.get_sub_state","content":" Manopt.get_sub_state  ‚Äî  Function get_sub_state(ams::AbstractSubProblemSolverState) Access the sub state of a solver state that involves a sub optimisation task. By default this returns  ams.sub_state . source"},{"id":2359,"pagetitle":"Stepsize","title":"Stepsize and line search","ref":"/manopt/stable/plans/stepsize/#Stepsize","content":" Stepsize and line search Most iterative algorithms determine a direction along which the algorithm shall proceed and determine a step size to find the next iterate. How advanced the step size computation can be implemented depends (among others) on the properties the corresponding problem provides. Within  Manopt.jl , the step size determination is implemented as a  functor  which is a subtype of  Stepsize  based on"},{"id":2360,"pagetitle":"Stepsize","title":"Manopt.Stepsize","ref":"/manopt/stable/plans/stepsize/#Manopt.Stepsize","content":" Manopt.Stepsize  ‚Äî  Type Stepsize An abstract type for the functors representing step sizes. These are callable structures. The naming scheme is  TypeOfStepSize , for example  ConstantStepsize . Every Stepsize has to provide a constructor and its function has to have the interface  (p,o,i)  where a  AbstractManoptProblem  as well as  AbstractManoptSolverState  and the current number of iterations are the arguments and returns a number, namely the stepsize to use. See also Linesearch source Usually, a constructor should take the manifold  M  as its first argument, for consistency, to allow general step size functors to be set up based on default values that might depend on the manifold currently under consideration. Currently, the following step sizes are available"},{"id":2361,"pagetitle":"Stepsize","title":"Manopt.AdaptiveWNGradient","ref":"/manopt/stable/plans/stepsize/#Manopt.AdaptiveWNGradient","content":" Manopt.AdaptiveWNGradient  ‚Äî  Type AdaptiveWNGradient <: DirectionUpdateRule Represent an adaptive gradient method introduced by [ GS23 ]. Given a positive threshold  $\\hat c \\mathbb N$ , an minimal bound  $b_{\\mathrm{min}} > 0$ , an initial  $b_0 ‚â• b_{\\mathrm{min}}$ , and a gradient reduction factor threshold  $\\alpha ‚àà [0,1)$ . Set  $c_0=0$  and use  $\\omega_0 = \\lVert \\operatorname{grad} f(p_0) \\rvert_{p_0}$ . For the first iterate use the initial step size  $s_0 = \\frac{1}{b_0}$ . Then, given the last gradient  $X_{k-1} = \\operatorname{grad} f(x_{k-1})$ , and a previous  $\\omega_{k-1}$ , the values  $(b_k, \\omega_k, c_k)$  are computed using  $X_k = \\operatorname{grad} f(p_k)$  and the following cases If  $\\lVert X_k \\rVert_{p_k} \\leq \\alpha\\omega_{k-1}$ , then let  $\\hat b_{k-1} ‚àà [b_\\mathrm{min},b_{k-1}]$  and set \\[(b_k, \\omega_k, c_k) = \\begin{cases}\n\\bigl(\\hat b_{k-1}, \\lVert X_k\\rVert_{p_k}, 0 \\bigr) & \\text{ if } c_{k-1}+1 = \\hat c\\\\\n\\Bigl(b_{k-1} + \\frac{\\lVert X_k\\rVert_{p_k}^2}{b_{k-1}}, \\omega_{k-1}, c_{k-1}+1 \\Bigr) & \\text{ if } c_{k-1}+1<\\hat c\n\\end{cases}\\] If  $\\lVert X_k \\rVert_{p_k} > \\alpha\\omega_{k-1}$ , the set \\[(b_k, \\omega_k, c_k) =\n\\Bigl( b_{k-1} + \\frac{\\lVert X_k\\rVert_{p_k}^2}{b_{k-1}}, \\omega_{k-1}, 0)\\] and return the step size  $s_k = \\frac{1}{b_k}$ . Note that for  $Œ±=0$  this is the Riemannian variant of  WNGRad . Fields count_threshold::Int : ( 4 ) an  Integer  for  $\\hat c$ minimal_bound::Float64 : ( 1e-4 ) for  $b_{\\mathrm{min}}$ alternate_bound::Function : ( (bk, hat_c) -> min(gradient_bound, max(gradient_bound, bk/(3*hat_c) ) how to determine  $\\hat b_k$  as a function of  (bmin, bk, hat_c) -> hat_bk gradient_reduction::Float64 : ( 0.9 ) gradient_bound norm(M, p0, grad_f(M,p0))  the bound  $b_k$ . as well as the internal fields weight  for  $œâ_k$  initialised to  $œâ_0 =$ norm(M, p0, grad_f(M,p0))  if this is not zero,  1.0  otherwise. count  for the  $c_k$ , initialised to  $c_0 = 0$ . Constructor AdaptiveWNGrad(M=DefaultManifold, grad_f=(M, p) -> zero_vector(M, rand(M)), p=rand(M); kwargs...) Where all fields with defaults are keyword arguments and additional keyword arguments are adaptive :   ( true ) switches the  gradient_reduction Œ± to 0`. evaluation : ( AllocatingEvaluation() ) specifies whether the gradient (that is used for initialisation only) is mutating or allocating source"},{"id":2362,"pagetitle":"Stepsize","title":"Manopt.ArmijoLinesearch","ref":"/manopt/stable/plans/stepsize/#Manopt.ArmijoLinesearch","content":" Manopt.ArmijoLinesearch  ‚Äî  Type ArmijoLinesearch <: Linesearch A functor representing Armijo line search including the last runs state string the last stepsize. Fields initial_stepsize :          ( 1.0 ) and initial step size retraction_method :         ( default_retraction_method(M) ) the retraction to use contraction_factor :        ( 0.95 ) exponent for line search reduction sufficient_decrease :       ( 0.1 ) gain within Armijo's rule last_stepsize :             ( initialstepsize ) the last step size to start the search with initial_guess :             ( (p,s,i,l) -> l )  based on a  AbstractManoptProblem p ,  AbstractManoptSolverState s  and a current iterate  i  and a last step size  l , this returns an initial guess. The default uses the last obtained stepsize as well as for internal use candidate_point :           ( allocate_result(M, rand) ) to store an interim result Furthermore the following fields act as safeguards stop_when_stepsize_less :    ( 0.0 ) smallest stepsize when to stop (the last one before is taken) stop_when_stepsize_exceeds : ( max_stepsize (M, p) ) largest stepsize when to stop. stop_increasing_at_step :    ( 100 ) last step to increase the stepsize (phase 1), stop_decreasing_at_step :    ( 1000 ) last step size to decrease the stepsize (phase 2), Pass  :Messages  to a  debug=  to see  @info s when these happen. Constructor ArmijoLinesearch(M=DefaultManifold()) with the fields keyword arguments and the retraction is set to the default retraction on  M . The constructors return the functor to perform Armijo line search, where (a::ArmijoLinesearch)(amp::AbstractManoptProblem, ams::AbstractManoptSolverState, i) of a  AbstractManoptProblem amp ,  AbstractManoptSolverState ams  and a current iterate  i  with keywords. Keyword arguments candidate_point : ( allocate_result(M, rand) ) to pass memory for the candidate point Œ∑ :               ( -get_gradient(mp, get_iterate(s)); ) the search direction to use, by default the steepest descent direction. source"},{"id":2363,"pagetitle":"Stepsize","title":"Manopt.ConstantStepsize","ref":"/manopt/stable/plans/stepsize/#Manopt.ConstantStepsize","content":" Manopt.ConstantStepsize  ‚Äî  Type ConstantStepsize <: Stepsize A functor that always returns a fixed step size. Fields length : constant value for the step size type :   a symbol that indicates whether the stepsize is relatively (:relative),   with respect to the gradient norm, or absolutely (:absolute) constant. Constructors ConstantStepsize(s::Real, t::Symbol=:relative) initialize the stepsize to a constant  s  of type  t . ConstantStepsize(M::AbstractManifold=DefaultManifold(2);\n    stepsize=injectivity_radius(M)/2, type::Symbol=:relative\n) initialize the stepsize to a constant  stepsize , which by default is half the injectivity radius, unless the radius is infinity, then the default step size is  1 . source"},{"id":2364,"pagetitle":"Stepsize","title":"Manopt.DecreasingStepsize","ref":"/manopt/stable/plans/stepsize/#Manopt.DecreasingStepsize","content":" Manopt.DecreasingStepsize  ‚Äî  Type DecreasingStepsize() A functor that represents several decreasing step sizes Fields exponent :   ( 1 ) a value  $e$  the current iteration numbers  $e$ th exponential is taken of factor :     ( 1 ) a value  $f$  to multiply the initial step size with every iteration length :     ( 1 ) the initial step size  $l$ . subtrahend : ( 0 ) a value  $a$  that is subtracted every iteration shift :      ( 0 ) shift the denominator iterator  $i$  by  $s$ `. type :       a symbol that indicates whether the stepsize is relatively (:relative),   with respect to the gradient norm, or absolutely (:absolute) constant. In total the complete formulae reads for the  $i$ th iterate as \\[s_i = \\frac{(l - i a)f^i}{(i+s)^e}\\] and hence the default simplifies to just  $s_i = \\frac{l}{i}$ Constructor DecreasingStepsize(l=1,f=1,a=0,e=1,s=0,type=:relative) Alternatively one can also use the following keyword. DecreasingStepsize(\n    M::AbstractManifold=DefaultManifold(3);\n    length=injectivity_radius(M)/2, multiplier=1.0, subtrahend=0.0,\n    exponent=1.0, shift=0, type=:relative\n) initializes all fields, where none of them is mandatory and the length is set to half and to  $1$  if the injectivity radius is infinite. source"},{"id":2365,"pagetitle":"Stepsize","title":"Manopt.Linesearch","ref":"/manopt/stable/plans/stepsize/#Manopt.Linesearch","content":" Manopt.Linesearch  ‚Äî  Type Linesearch <: Stepsize An abstract functor to represent line search type step size determinations, see  Stepsize  for details. One example is the  ArmijoLinesearch  functor. Compared to simple step sizes, the line search functors provide an interface of the form  (p,o,i,Œ∑) -> s  with an additional (but optional) fourth parameter to provide a search direction; this should default to something reasonable, most prominently the negative gradient. source"},{"id":2366,"pagetitle":"Stepsize","title":"Manopt.NonmonotoneLinesearch","ref":"/manopt/stable/plans/stepsize/#Manopt.NonmonotoneLinesearch","content":" Manopt.NonmonotoneLinesearch  ‚Äî  Type NonmonotoneLinesearch <: Linesearch A functor representing a nonmonotone line search using the Barzilai-Borwein step size [ IP17 ]. Together with a gradient descent algorithm this line search represents the Riemannian Barzilai-Borwein with nonmonotone line-search (RBBNMLS) algorithm. The order is shifted in comparison of the algorithm steps from the paper by Iannazzo and Porcelli so that in each iteration this line search first finds \\[y_{k} = \\operatorname{grad}F(x_{k}) - \\operatorname{T}_{x_{k-1} ‚Üí x_k}(\\operatorname{grad}F(x_{k-1}))\\] and \\[s_{k} = - Œ±_{k-1} * \\operatorname{T}_{x_{k-1} ‚Üí x_k}(\\operatorname{grad}F(x_{k-1})),\\] where  $Œ±_{k-1}$  is the step size computed in the last iteration and  $\\operatorname{T}$  is a vector transport. Then the Barzilai‚ÄîBorwein step size is \\[Œ±_k^{\\text{BB}} = \\begin{cases}\n\\min(Œ±_{\\text{max}}, \\max(Œ±_{\\text{min}}, œÑ_{k})),  & \\text{if } ‚ü®s_{k}, y_{k}‚ü©_{x_k} > 0,\\\\\nŒ±_{\\text{max}}, & \\text{else,}\n\\end{cases}\\] where \\[œÑ_{k} = \\frac{‚ü®s_{k}, s_{k}‚ü©_{x_k}}{‚ü®s_{k}, y_{k}‚ü©_{x_k}},\\] if the direct strategy is chosen, \\[œÑ_{k} = \\frac{‚ü®s_{k}, y_{k}‚ü©_{x_k}}{‚ü®y_{k}, y_{k}‚ü©_{x_k}},\\] in case of the inverse strategy and an alternation between the two in case of the alternating strategy. Then find the smallest  $h = 0, 1, 2, ‚Ä¶$  such that \\[F(\\operatorname{retr}_{x_k}(- œÉ^h Œ±_k^{\\text{BB}} \\operatorname{grad}F(x_k)))\n\\leq\n\\max_{1 ‚â§ j ‚â§ \\min(k+1,m)} F(x_{k+1-j}) - Œ≥ œÉ^h Œ±_k^{\\text{BB}} ‚ü®\\operatorname{grad}F(x_k), \\operatorname{grad}F(x_k)‚ü©_{x_k},\\] where  $œÉ$  is a step length reduction factor  $‚àà (0,1)$ ,  $m$  is the number of iterations after which the function value has to be lower than the current one and  $Œ≥$  is the sufficient decrease parameter  $‚àà(0,1)$ . Then find the new stepsize by \\[Œ±_k = œÉ^h Œ±_k^{\\text{BB}}.\\] Fields initial_stepsize :        ( 1.0 ) the step size to start the search with memory_size :             ( 10 ) number of iterations after which the cost value needs to be lower than the current one bb_min_stepsize :         ( 1e-3 ) lower bound for the Barzilai-Borwein step size greater than zero bb_max_stepsize :         ( 1e3 ) upper bound for the Barzilai-Borwein step size greater than min_stepsize retraction_method :       ( ExponentialRetraction() ) the retraction to use strategy :                ( direct ) defines if the new step size is computed using the direct, indirect or alternating strategy storage :                 (for  :Iterate  and  :Gradient ) a  StoreStateAction stepsize_reduction :      ( 0.5 ) step size reduction factor contained in the interval (0,1) sufficient_decrease :     ( 1e-4 ) sufficient decrease parameter contained in the interval (0,1) vector_transport_method : ( ParallelTransport() ) the vector transport method to use as well as for internal use candidate_point :           ( allocate_result(M, rand) ) to store an interim result Furthermore the following fields act as safeguards stop_when_stepsize_less:     ( 0.0`) smallest stepsize when to stop (the last one before is taken) stop_when_stepsize_exceeds : ( max_stepsize (M, p) ) largest stepsize when to stop. stop_increasing_at_step :    (^100`) last step to increase the stepsize (phase 1), stop_decreasing_at_step :    ( 1000 ) last step size to decrease the stepsize (phase 2), Pass  :Messages  to a  debug=  to see  @info s when these happen. Constructor NonmonotoneLinesearch() with the fields their order as optional arguments (deprecated). THis is deprecated, since both defaults and the memory allocation for the candidate do not take into account which manifold the line search operates on. NonmonotoneLinesearch(M) with the fields as keyword arguments and where the retraction and vector transport are set to the default ones on  M , respectively. The constructors return the functor to perform nonmonotone line search. source"},{"id":2367,"pagetitle":"Stepsize","title":"Manopt.WolfePowellBinaryLinesearch","ref":"/manopt/stable/plans/stepsize/#Manopt.WolfePowellBinaryLinesearch","content":" Manopt.WolfePowellBinaryLinesearch  ‚Äî  Type WolfePowellBinaryLinesearch <: Linesearch A  Linesearch  method that determines a step size  t  fulfilling the Wolfe conditions based on a binary chop. Let  $Œ∑$  be a search direction and  $c1,c_2>0$  be two constants. Then with \\[A(t) = f(x_+) ‚â§ c1 t ‚ü®\\operatorname{grad}f(x), Œ∑‚ü©_{x}\n\\quad\\text{and}\\quad\nW(t) = ‚ü®\\operatorname{grad}f(x_+), \\text{V}_{x_+\\gets x}Œ∑‚ü©_{x_+} ‚â• c_2 ‚ü®Œ∑, \\operatorname{grad}f(x)‚ü©_x,\\] where  $x_+ = \\operatorname{retr}_x(tŒ∑)$  is the current trial point, and  $\\text{V}$  is a vector transport. Then the following Algorithm is performed similar to Algorithm 7 from [ Hua14 ] set  $Œ±=0$ ,  $Œ≤=‚àû$  and  $t=1$ . While either  $A(t)$  does not hold or  $W(t)$  does not hold do steps 3-5. If  $A(t)$  fails, set  $Œ≤=t$ . If  $A(t)$  holds but  $W(t)$  fails, set  $Œ±=t$ . If  $Œ≤<‚àû$  set  $t=\\frac{Œ±+Œ≤}{2}$ , otherwise set  $t=2Œ±$ . Constructors There exist two constructors, where, when provided the manifold  M  as a first (optional) parameter, its default retraction and vector transport are the default. In this case the retraction and the vector transport are also keyword arguments for ease of use. The other constructor is kept for backward compatibility. WolfePowellLinesearch(\n    M=DefaultManifold(),\n    c1::Float64=10^(-4),\n    c2::Float64=0.999;\n    retraction_method = default_retraction_method(M),\n    vector_transport_method = default_vector_transport(M),\n    linesearch_stopsize = 0.0\n) source"},{"id":2368,"pagetitle":"Stepsize","title":"Manopt.WolfePowellLinesearch","ref":"/manopt/stable/plans/stepsize/#Manopt.WolfePowellLinesearch","content":" Manopt.WolfePowellLinesearch  ‚Äî  Type WolfePowellLinesearch <: Linesearch Do a backtracking line search to find a step size  $Œ±$  that fulfils the Wolfe conditions along a search direction  $Œ∑$  starting from  $x$  by \\[f\\bigl( \\operatorname{retr}_x(Œ±Œ∑) \\bigr) ‚â§ f(x_k) + c_1 Œ±_k ‚ü®\\operatorname{grad}f(x), Œ∑‚ü©_x\n\\quad\\text{and}\\quad\n\\frac{\\mathrm{d}}{\\mathrm{d}t} f\\bigr(\\operatorname{retr}_x(tŒ∑)\\bigr)\n\\Big\\vert_{t=Œ±}\n‚â• c_2 \\frac{\\mathrm{d}}{\\mathrm{d}t} f\\bigl(\\operatorname{retr}_x(tŒ∑)\\bigr)\\Big\\vert_{t=0}.\\] Constructors There exist two constructors, where, when provided the manifold  M  as a first (optional) parameter, its default retraction and vector transport are the default. In this case the retraction and the vector transport are also keyword arguments for ease of use. The other constructor is kept for backward compatibility. Note that the  stop_when_stepsize_less  to stop for too small stepsizes is only available in the new signature including  M . WolfePowellLinesearch(M, c1::Float64=10^(-4), c2::Float64=0.999; kwargs... Generate a Wolfe-Powell line search Keyword arguments candidate_point :         ( allocate_result(M, rand) ) memory for a candidate candidate_tangent :       ( allocate_result(M, zero_vector, candidate_point) ) memory for a gradient candidate_direcntion :    ( allocate_result(M, zero_vector, candidate_point) ) memory for a direction max_stepsize :            ( max_stepsize (M, p) ) largest stepsize allowed here. retraction_method :       ( ExponentialRetraction() ) the retraction to use stop_when_stepsize_less : ( 0.0 ) smallest stepsize when to stop (the last one before is taken) vector_transport_method : ( ParallelTransport() ) the vector transport method to use source"},{"id":2369,"pagetitle":"Stepsize","title":"Manopt.default_stepsize","ref":"/manopt/stable/plans/stepsize/#Manopt.default_stepsize-Tuple{AbstractManifold, Type{<:AbstractManoptSolverState}}","content":" Manopt.default_stepsize  ‚Äî  Method default_stepsize(M::AbstractManifold, ams::AbstractManoptSolverState) Returns the default  Stepsize  functor used when running the solver specified by the  AbstractManoptSolverState ams  running with an objective on the  AbstractManifold M . source"},{"id":2370,"pagetitle":"Stepsize","title":"Manopt.get_stepsize","ref":"/manopt/stable/plans/stepsize/#Manopt.get_stepsize-Tuple{AbstractManoptProblem, AbstractManoptSolverState, Vararg{Any}}","content":" Manopt.get_stepsize  ‚Äî  Method get_stepsize(amp::AbstractManoptProblem, ams::AbstractManoptSolverState, vars...) return the stepsize stored within  AbstractManoptSolverState ams  when solving the  AbstractManoptProblem amp . This method also works for decorated options and the  Stepsize  function within the options, by default stored in  o.stepsize . source"},{"id":2371,"pagetitle":"Stepsize","title":"Manopt.linesearch_backtrack!","ref":"/manopt/stable/plans/stepsize/#Manopt.linesearch_backtrack!-Union{Tuple{T}, Tuple{TF}, Tuple{AbstractManifold, Any, TF, Any, T, Any, Any, Any}, Tuple{AbstractManifold, Any, TF, Any, T, Any, Any, Any, T}, Tuple{AbstractManifold, Any, TF, Any, T, Any, Any, Any, T, Any}} where {TF, T}","content":" Manopt.linesearch_backtrack!  ‚Äî  Method (s, msg) = linesearch_backtrack!(M, q, F, p, X, s, decrease, contract Œ∑ = -X, f0 = f(p)) Perform a line search backtrack in-place of  q . For all details and options, see  linesearch_backtrack source"},{"id":2372,"pagetitle":"Stepsize","title":"Manopt.linesearch_backtrack","ref":"/manopt/stable/plans/stepsize/#Manopt.linesearch_backtrack-Union{Tuple{T}, Tuple{AbstractManifold, Any, Any, T, Any, Any, Any}, Tuple{AbstractManifold, Any, Any, T, Any, Any, Any, T}, Tuple{AbstractManifold, Any, Any, T, Any, Any, Any, T, Any}} where T","content":" Manopt.linesearch_backtrack  ‚Äî  Method (s, msg) = linesearch_backtrack(M, F, p, X, s, decrease, contract Œ∑ = -X, f0 = f(p))\n(s, msg) = linesearch_backtrack!(M, q, F, p, X, s, decrease, contract Œ∑ = -X, f0 = f(p)) perform a line search on manifold  M for the cost function  f , at the current point  p with current gradient provided in  X an initial stepsize  s a sufficient  decrease a  contract ion factor  $œÉ$ a  retr action, which defaults to the  default_retraction_method(M) a search direction  $Œ∑ = -X$ an offset,  $f_0 = F(x)$ the method can also be performed in-place of  q , that is the resulting best point one reaches with the step size  s  as second argument. Keywords retraction_method :          ( default_retraction_method(M) ) the retraction to use. stop_when_stepsize_less :    ( 0.0 ) to avoid numerical underflow stop_when_stepsize_exceeds : ( max_stepsize (M, p) / norm(M, p, Œ∑) ) to avoid leaving the injectivity radius on a manifold stop_increasing_at_step :    ( 100 ) stop the initial increase of step size after these many steps stop_decreasing_at_step :    ( 1000 ) stop the decreasing search after these many steps These keywords are used as safeguards, where only the max stepsize is a very manifold specific one. Return value A stepsize  s  and a message  msg  (in case any of the 4 criteria hit) source"},{"id":2373,"pagetitle":"Stepsize","title":"Manopt.max_stepsize","ref":"/manopt/stable/plans/stepsize/#Manopt.max_stepsize-Tuple{AbstractManifold, Any}","content":" Manopt.max_stepsize  ‚Äî  Method max_stepsize(M::AbstractManifold, p)\nmax_stepsize(M::AbstractManifold) Get the maximum stepsize (at point  p ) on manifold  M . It should be used to limit the distance an algorithm is trying to move in a single step. source"},{"id":2374,"pagetitle":"Stepsize","title":"Literature","ref":"/manopt/stable/plans/stepsize/#Literature","content":" Literature [GS23] G.¬†N.¬†Grapiglia and G.¬†F.¬†Stella.  An Adaptive Riemannian Gradient Method Without Function Evaluations .  Journal¬†of¬†Optimization¬†Theory¬†and¬†Applications  197 , 1140‚Äì1160  (2023). [Hua14] W.¬†Huang.  Optimization algorithms on Riemannian manifolds with applications . Ph.D. Thesis, Flordia State University (2014). [IP17] B.¬†Iannazzo and M.¬†Porcelli.  The Riemannian Barzilai‚ÄìBorwein method with nonmonotone line search and the matrix geometric mean computation .  IMA¬†Journal¬†of¬†Numerical¬†Analysis  38 , 495‚Äì517  (2017)."},{"id":2377,"pagetitle":"Stopping Criteria","title":"Stopping criteria","ref":"/manopt/stable/plans/stopping_criteria/#sec-stopping-criteria","content":" Stopping criteria Stopping criteria are implemented as a  functor  and inherit from the base type"},{"id":2378,"pagetitle":"Stopping Criteria","title":"Manopt.StoppingCriterion","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.StoppingCriterion","content":" Manopt.StoppingCriterion  ‚Äî  Type StoppingCriterion An abstract type for the functors representing stopping criteria, so they are callable structures. The naming Scheme follows functions, see for example  StopAfterIteration . Every StoppingCriterion has to provide a constructor and its function has to have the interface  (p,o,i)  where a  AbstractManoptProblem  as well as  AbstractManoptSolverState  and the current number of iterations are the arguments and returns a boolean whether to stop or not. By default each  StoppingCriterion  should provide a fields  reason  to provide details when a criterion is met (and that is empty otherwise). source They can also be grouped, which is summarized in the type of a set of criteria"},{"id":2379,"pagetitle":"Stopping Criteria","title":"Manopt.StoppingCriterionSet","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.StoppingCriterionSet","content":" Manopt.StoppingCriterionSet  ‚Äî  Type StoppingCriterionGroup <: StoppingCriterion An abstract type for a Stopping Criterion that itself consists of a set of Stopping criteria. In total it acts as a stopping criterion itself. Examples are  StopWhenAny  and  StopWhenAll  that can be used to combine stopping criteria. source The stopping criteria  s  might have certain internal values/fields it uses to verify against. This is done when calling them as a function  s(amp::AbstractManoptProblem, ams::AbstractManoptSolverState) , where the  AbstractManoptProblem  and the  AbstractManoptSolverState  together represent the current state of the solver. The functor returns either  false  when the stopping criterion is not fulfilled or  true  otherwise. One field all criteria should have is the  s.reason , a string giving the reason to stop, see  get_reason ."},{"id":2380,"pagetitle":"Stopping Criteria","title":"Generic stopping criteria","ref":"/manopt/stable/plans/stopping_criteria/#Generic-stopping-criteria","content":" Generic stopping criteria The following generic stopping criteria are available. Some require that, for example, the corresponding  AbstractManoptSolverState  have a field  gradient  when the criterion should access that. Further stopping criteria might be available for individual solvers."},{"id":2381,"pagetitle":"Stopping Criteria","title":"Manopt.StopAfter","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.StopAfter","content":" Manopt.StopAfter  ‚Äî  Type StopAfter <: StoppingCriterion store a threshold when to stop looking at the complete runtime. It uses  time_ns()  to measure the time and you provide a  Period  as a time limit, for example  Minute(15) . Constructor StopAfter(t) initialize the stopping criterion to a  Period t  to stop after. source"},{"id":2382,"pagetitle":"Stopping Criteria","title":"Manopt.StopAfterIteration","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.StopAfterIteration","content":" Manopt.StopAfterIteration  ‚Äî  Type StopAfterIteration <: StoppingCriterion A functor for a stopping criterion to stop after a maximal number of iterations. Fields maxIter   stores the maximal iteration number where to stop at reason    stores a reason of stopping if the stopping criterion has one be reached, see  get_reason . Constructor StopAfterIteration(maxIter) initialize the functor to indicate to stop after  maxIter  iterations. source"},{"id":2383,"pagetitle":"Stopping Criteria","title":"Manopt.StopWhenAll","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.StopWhenAll","content":" Manopt.StopWhenAll  ‚Äî  Type StopWhenAll <: StoppingCriterion store an array of  StoppingCriterion  elements and indicates to stop, when  all  indicate to stop. The  reason  is given by the concatenation of all reasons. Constructor StopWhenAll(c::NTuple{N,StoppingCriterion} where N)\nStopWhenAll(c::StoppingCriterion,...) source"},{"id":2384,"pagetitle":"Stopping Criteria","title":"Manopt.StopWhenAny","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.StopWhenAny","content":" Manopt.StopWhenAny  ‚Äî  Type StopWhenAny <: StoppingCriterion store an array of  StoppingCriterion  elements and indicates to stop, when  any  single one indicates to stop. The  reason  is given by the concatenation of all reasons (assuming that all non-indicating return  \"\" ). Constructor StopWhenAny(c::NTuple{N,StoppingCriterion} where N)\nStopWhenAny(c::StoppingCriterion...) source"},{"id":2385,"pagetitle":"Stopping Criteria","title":"Manopt.StopWhenChangeLess","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.StopWhenChangeLess","content":" Manopt.StopWhenChangeLess  ‚Äî  Type StopWhenChangeLess <: StoppingCriterion stores a threshold when to stop looking at the norm of the change of the optimization variable from within a  AbstractManoptSolverState , i.e  get_iterate(o) . For the storage a  StoreStateAction  is used Constructor StopWhenChangeLess(\n    M::AbstractManifold,\n    Œµ::Float64;\n    storage::StoreStateAction=StoreStateAction([:Iterate]),\n    inverse_retraction_method::IRT=default_inverse_retraction_method(manifold)\n) initialize the stopping criterion to a threshold  Œµ  using the  StoreStateAction a , which is initialized to just store  :Iterate  by default. You can also provide an inverse retraction method for the  distance  or a manifold to use its default inverse retraction. source"},{"id":2386,"pagetitle":"Stopping Criteria","title":"Manopt.StopWhenCostLess","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.StopWhenCostLess","content":" Manopt.StopWhenCostLess  ‚Äî  Type StopWhenCostLess <: StoppingCriterion store a threshold when to stop looking at the cost function of the optimization problem from within a  AbstractManoptProblem , i.e  get_cost(p,get_iterate(o)) . Constructor StopWhenCostLess(Œµ) initialize the stopping criterion to a threshold  Œµ . source"},{"id":2387,"pagetitle":"Stopping Criteria","title":"Manopt.StopWhenCostNaN","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.StopWhenCostNaN","content":" Manopt.StopWhenCostNaN  ‚Äî  Type StopWhenCostNaN <: StoppingCriterion stop looking at the cost function of the optimization problem from within a  AbstractManoptProblem , i.e  get_cost(p,get_iterate(o)) . Constructor StopWhenCostNaN() initialize the stopping criterion to NaN. source"},{"id":2388,"pagetitle":"Stopping Criteria","title":"Manopt.StopWhenEntryChangeLess","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.StopWhenEntryChangeLess","content":" Manopt.StopWhenEntryChangeLess  ‚Äî  Type StopWhenEntryChangeLess Evaluate whether a certain fields change is less than a certain threshold Fields field :     a symbol addressing the corresponding field in a certain subtype of  AbstractManoptSolverState  to track distance :  a function  (problem, state, v1, v2) -> R  that computes the distance between two possible values of the  field storage :   a  StoreStateAction  to store the previous value of the  field threshold : the threshold to indicate to stop when the distance is below this value Internal fields reason :       store a string reason when the stop was indicated at_iteration : store the iteration at which the stop indication happened stores a threshold when to stop looking at the norm of the change of the optimization variable from within a  AbstractManoptSolverState , i.e  get_iterate(o) . For the storage a  StoreStateAction  is used Constructor StopWhenEntryChangeLess(\n    field::Symbol\n    distance,\n    threshold;\n    storage::StoreStateAction=StoreStateAction([field]),\n) source"},{"id":2389,"pagetitle":"Stopping Criteria","title":"Manopt.StopWhenGradientChangeLess","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.StopWhenGradientChangeLess","content":" Manopt.StopWhenGradientChangeLess  ‚Äî  Type StopWhenGradientChangeLess <: StoppingCriterion A stopping criterion based on the change of the gradient \\lVert \\mathcal T_{p^{(k)}\\gets p^{(k-1)} \\operatorname{grad} f(p^{(k-1)}) -  \\operatorname{grad} f(p^{(k-1)}) \\rVert < Œµ Constructor StopWhenGradientChangeLess(\n    M::AbstractManifold,\n    Œµ::Float64;\n    storage::StoreStateAction=StoreStateAction([:Iterate]),\n    vector_transport_method::IRT=default_vector_transport_method(M),\n) Create a stopping criterion with threshold  Œµ  for the change gradient, that is, this criterion indicates to stop when  get_gradient  is in (norm of) its change less than  Œµ , where  vector_transport_method  denotes the vector transport  $\\mathcal T$  used. source"},{"id":2390,"pagetitle":"Stopping Criteria","title":"Manopt.StopWhenGradientNormLess","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.StopWhenGradientNormLess","content":" Manopt.StopWhenGradientNormLess  ‚Äî  Type StopWhenGradientNormLess <: StoppingCriterion A stopping criterion based on the current gradient norm. Fields norm :      a function  (M::AbstractManifold, p, X) -> ‚Ñù  that computes a norm of the gradient  X  in the tangent space at  p  on  M ` threshold : the threshold to indicate to stop when the distance is below this value Internal fields reason :       store a string reason when the stop was indicated at_iteration : store the iteration at which the stop indication happened Constructor StopWhenGradientNormLess(Œµ; norm=(M,p,X) -> norm(M,p,X)) Create a stopping criterion with threshold  Œµ  for the gradient, that is, this criterion indicates to stop when  get_gradient  returns a gradient vector of norm less than  Œµ , where the norm to use can be specified in the  norm=  keyword. source"},{"id":2391,"pagetitle":"Stopping Criteria","title":"Manopt.StopWhenIterateNaN","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.StopWhenIterateNaN","content":" Manopt.StopWhenIterateNaN  ‚Äî  Type StopWhenIterateNaN <: StoppingCriterion stop looking at the cost function of the optimization problem from within a  AbstractManoptProblem , i.e  get_cost(p,get_iterate(o)) . Constructor StopWhenIterateNaN() initialize the stopping criterion to NaN. source"},{"id":2392,"pagetitle":"Stopping Criteria","title":"Manopt.StopWhenSmallerOrEqual","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.StopWhenSmallerOrEqual","content":" Manopt.StopWhenSmallerOrEqual  ‚Äî  Type StopWhenSmallerOrEqual <: StoppingCriterion A functor for an stopping criterion, where the algorithm if stopped when a variable is smaller than or equal to its minimum value. Fields value     stores the variable which has to fall under a threshold for the algorithm to stop minValue  stores the threshold where, if the value is smaller or equal to this threshold, the algorithm stops reason    stores a reason of stopping if the stopping criterion has one be reached, see  get_reason . Constructor StopWhenSmallerOrEqual(value, minValue) initialize the functor to indicate to stop after  value  is smaller than or equal to  minValue . source"},{"id":2393,"pagetitle":"Stopping Criteria","title":"Manopt.StopWhenStepsizeLess","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.StopWhenStepsizeLess","content":" Manopt.StopWhenStepsizeLess  ‚Äî  Type StopWhenStepsizeLess <: StoppingCriterion stores a threshold when to stop looking at the last step size determined or found during the last iteration from within a  AbstractManoptSolverState . Constructor StopWhenStepsizeLess(Œµ) initialize the stopping criterion to a threshold  Œµ . source"},{"id":2394,"pagetitle":"Stopping Criteria","title":"Manopt.StopWhenSubgradientNormLess","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.StopWhenSubgradientNormLess","content":" Manopt.StopWhenSubgradientNormLess  ‚Äî  Type StopWhenSubgradientNormLess <: StoppingCriterion A stopping criterion based on the current subgradient norm. Constructor StopWhenSubgradientNormLess(Œµ::Float64) Create a stopping criterion with threshold  Œµ  for the subgradient, that is, this criterion indicates to stop when  get_subgradient  returns a subgradient vector of norm less than  Œµ . source"},{"id":2395,"pagetitle":"Stopping Criteria","title":"Functions for stopping criteria","ref":"/manopt/stable/plans/stopping_criteria/#Functions-for-stopping-criteria","content":" Functions for stopping criteria There are a few functions to update, combine, and modify stopping criteria, especially to update internal values even for stopping criteria already being used within an  AbstractManoptSolverState  structure."},{"id":2396,"pagetitle":"Stopping Criteria","title":"Base.:&","ref":"/manopt/stable/plans/stopping_criteria/#Base.:&-Union{Tuple{T}, Tuple{S}, Tuple{S, T}} where {S<:StoppingCriterion, T<:StoppingCriterion}","content":" Base.:&  ‚Äî  Method &(s1,s2)\ns1 & s2 Combine two  StoppingCriterion  within an  StopWhenAll . If either  s1  (or  s2 ) is already an  StopWhenAll , then  s2  (or  s1 ) is appended to the list of  StoppingCriterion  within  s1  (or  s2 ). Example a = StopAfterIteration(200) & StopWhenChangeLess(1e-6)\nb = a & StopWhenGradientNormLess(1e-6) Is the same as a = StopWhenAll(StopAfterIteration(200), StopWhenChangeLess(1e-6))\nb = StopWhenAll(StopAfterIteration(200), StopWhenChangeLess(1e-6), StopWhenGradientNormLess(1e-6)) source"},{"id":2397,"pagetitle":"Stopping Criteria","title":"Base.:|","ref":"/manopt/stable/plans/stopping_criteria/#Base.:|-Union{Tuple{T}, Tuple{S}, Tuple{S, T}} where {S<:StoppingCriterion, T<:StoppingCriterion}","content":" Base.:|  ‚Äî  Method |(s1,s2)\ns1 | s2 Combine two  StoppingCriterion  within an  StopWhenAny . If either  s1  (or  s2 ) is already an  StopWhenAny , then  s2  (or  s1 ) is appended to the list of  StoppingCriterion  within  s1  (or  s2 ) Example a = StopAfterIteration(200) | StopWhenChangeLess(1e-6)\nb = a | StopWhenGradientNormLess(1e-6) Is the same as a = StopWhenAny(StopAfterIteration(200), StopWhenChangeLess(1e-6))\nb = StopWhenAny(StopAfterIteration(200), StopWhenChangeLess(1e-6), StopWhenGradientNormLess(1e-6)) source"},{"id":2398,"pagetitle":"Stopping Criteria","title":"Manopt.get_active_stopping_criteria","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.get_active_stopping_criteria-Tuple{sCS} where sCS<:StoppingCriterionSet","content":" Manopt.get_active_stopping_criteria  ‚Äî  Method get_active_stopping_criteria(c) returns all active stopping criteria, if any, that are within a  StoppingCriterion c , and indicated a stop, that is their reason is nonempty. To be precise for a simple stopping criterion, this returns either an empty array if no stop is indicated or the stopping criterion as the only element of an array. For a  StoppingCriterionSet  all internal (even nested) criteria that indicate to stop are returned. source"},{"id":2399,"pagetitle":"Stopping Criteria","title":"Manopt.get_reason","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.get_reason-Tuple{AbstractManoptSolverState}","content":" Manopt.get_reason  ‚Äî  Method get_reason(o) return the current reason stored within the  StoppingCriterion  from within the  AbstractManoptSolverState  This reason is empty if the criterion has never been met. source"},{"id":2400,"pagetitle":"Stopping Criteria","title":"Manopt.get_reason","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.get_reason-Tuple{sC} where sC<:StoppingCriterion","content":" Manopt.get_reason  ‚Äî  Method get_reason(c) return the current reason stored within a  StoppingCriterion c . This reason is empty if the criterion has never been met. source"},{"id":2401,"pagetitle":"Stopping Criteria","title":"Manopt.get_stopping_criteria","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.get_stopping_criteria-Tuple{S} where S<:StoppingCriterionSet","content":" Manopt.get_stopping_criteria  ‚Äî  Method get_stopping_criteria(c) return the array of internally stored  StoppingCriterion s for a  StoppingCriterionSet c . source"},{"id":2402,"pagetitle":"Stopping Criteria","title":"Manopt.indicates_convergence","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.indicates_convergence-Tuple{StoppingCriterion}","content":" Manopt.indicates_convergence  ‚Äî  Method indicates_convergence(c::StoppingCriterion) Return whether (true) or not (false) a  StoppingCriterion  does  always  mean that, when it indicates to stop, the solver has converged to a minimizer or critical point. Note that this is independent of the actual state of the stopping criterion, whether some of them indicate to stop, but a purely type-based, static decision. Examples With  s1=StopAfterIteration(20)  and  s2=StopWhenGradientNormLess(1e-7)  the indicator yields indicates_convergence(s1)  is  false indicates_convergence(s2)  is  true indicates_convergence(s1 | s2)  is  false , since this might also stop after 20 iterations indicates_convergence(s1 & s2)  is  true , since  s2  is fulfilled if this stops. source"},{"id":2403,"pagetitle":"Stopping Criteria","title":"Manopt.update_stopping_criterion!","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.update_stopping_criterion!-Tuple{Any, Any, Any}","content":" Manopt.update_stopping_criterion!  ‚Äî  Method update_stopping_criterion!(c::Stoppingcriterion, s::Symbol, v::value)\nupdate_stopping_criterion!(s::AbstractManoptSolverState, symbol::Symbol, v::value)\nupdate_stopping_criterion!(c::Stoppingcriterion, ::Val{Symbol}, v::value) Update a value within a stopping criterion, specified by the symbol  s , to  v . If a criterion does not have a value assigned that corresponds to  s , the update is ignored. For the second signature, the stopping criterion within the  AbstractManoptSolverState o  is updated. To see which symbol updates which value, see the specific stopping criteria. They should use dispatch per symbol value (the third signature). source"},{"id":2404,"pagetitle":"Stopping Criteria","title":"Manopt.update_stopping_criterion!","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.update_stopping_criterion!-Tuple{StopAfter, Val{:MaxTime}, Dates.Period}","content":" Manopt.update_stopping_criterion!  ‚Äî  Method update_stopping_criterion!(c::StopAfter, :MaxTime, v::Period) Update the time period after which an algorithm shall stop. source"},{"id":2405,"pagetitle":"Stopping Criteria","title":"Manopt.update_stopping_criterion!","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.update_stopping_criterion!-Tuple{StopAfterIteration, Val{:MaxIteration}, Int64}","content":" Manopt.update_stopping_criterion!  ‚Äî  Method update_stopping_criterion!(c::StopAfterIteration, :;MaxIteration, v::Int) Update the number of iterations after which the algorithm should stop. source"},{"id":2406,"pagetitle":"Stopping Criteria","title":"Manopt.update_stopping_criterion!","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.update_stopping_criterion!-Tuple{StopWhenChangeLess, Val{:MinIterateChange}, Any}","content":" Manopt.update_stopping_criterion!  ‚Äî  Method update_stopping_criterion!(c::StopWhenChangeLess, :MinIterateChange, v::Int) Update the minimal change below which an algorithm shall stop. source"},{"id":2407,"pagetitle":"Stopping Criteria","title":"Manopt.update_stopping_criterion!","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.update_stopping_criterion!-Tuple{StopWhenCostLess, Val{:MinCost}, Any}","content":" Manopt.update_stopping_criterion!  ‚Äî  Method update_stopping_criterion!(c::StopWhenCostLess, :MinCost, v) Update the minimal cost below which the algorithm shall stop source"},{"id":2408,"pagetitle":"Stopping Criteria","title":"Manopt.update_stopping_criterion!","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.update_stopping_criterion!-Tuple{StopWhenEntryChangeLess, Val{:Threshold}, Any}","content":" Manopt.update_stopping_criterion!  ‚Äî  Method update_stopping_criterion!(c::StopWhenEntryChangeLess, :Threshold, v) Update the minimal cost below which the algorithm shall stop source"},{"id":2409,"pagetitle":"Stopping Criteria","title":"Manopt.update_stopping_criterion!","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.update_stopping_criterion!-Tuple{StopWhenGradientChangeLess, Val{:MinGradientChange}, Any}","content":" Manopt.update_stopping_criterion!  ‚Äî  Method update_stopping_criterion!(c::StopWhenGradientChangeLess, :MinGradientChange, v) Update the minimal change below which an algorithm shall stop. source"},{"id":2410,"pagetitle":"Stopping Criteria","title":"Manopt.update_stopping_criterion!","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.update_stopping_criterion!-Tuple{StopWhenGradientNormLess, Val{:MinGradNorm}, Float64}","content":" Manopt.update_stopping_criterion!  ‚Äî  Method update_stopping_criterion!(c::StopWhenGradientNormLess, :MinGradNorm, v::Float64) Update the minimal gradient norm when an algorithm shall stop source"},{"id":2411,"pagetitle":"Stopping Criteria","title":"Manopt.update_stopping_criterion!","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.update_stopping_criterion!-Tuple{StopWhenStepsizeLess, Val{:MinStepsize}, Any}","content":" Manopt.update_stopping_criterion!  ‚Äî  Method update_stopping_criterion!(c::StopWhenStepsizeLess, :MinStepsize, v) Update the minimal step size below which the algorithm shall stop source"},{"id":2412,"pagetitle":"Stopping Criteria","title":"Manopt.update_stopping_criterion!","ref":"/manopt/stable/plans/stopping_criteria/#Manopt.update_stopping_criterion!-Tuple{StopWhenSubgradientNormLess, Val{:MinSubgradNorm}, Float64}","content":" Manopt.update_stopping_criterion!  ‚Äî  Method update_stopping_criterion!(c::StopWhenSubgradientNormLess, :MinSubgradNorm, v::Float64) Update the minimal subgradient norm when an algorithm shall stop source"},{"id":2415,"pagetitle":"References","title":"Literature","ref":"/manopt/stable/references/#Literature","content":" Literature This is all literature mentioned / referenced in the  Manopt.jl  documentation. Usually you find a small reference section at the end of every documentation page that contains the corresponding references as well. [ABG06] P.-A.¬†Absil, C.¬†Baker and K.¬†Gallivan.  Trust-Region Methods on Riemannian Manifolds .  Foundations¬†of¬†Computational¬†Mathematics  7 , 303‚Äì330  (2006). [AMS08] P.-A.¬†Absil, R.¬†Mahony and R.¬†Sepulchre.  Optimization Algorithms on Matrix Manifolds  (Princeton University Press, 2008), available online at  press.princeton.edu/chapters/absil/ . [AOT22] S.¬†Adachi, T.¬†Okuno and A.¬†Takeda.  Riemannian Levenberg-Marquardt Method with Global and Local Convergence Properties . ArXiv¬†Preprint (2022). [ABBC20] N.¬†Agarwal, N.¬†Boumal, B.¬†Bullins and C.¬†Cartis.  Adaptive regularization with cubics on manifolds .  Mathematical¬†Programming  (2020). [ACOO20] Y.¬†T.¬†Almeida, J.¬†X.¬†Cruz Neto, P.¬†R.¬†Oliveira and J.¬†C.¬†Oliveira Souza.  A modified proximal point method for DC functions on Hadamard manifolds .  Computational¬†Optimization¬†and¬†Applications  76 , 649‚Äì673  (2020). [Bac14] M.¬†Baƒç√°k.  Computing medians and means in Hadamard spaces .  SIAM¬†Journal¬†on¬†Optimization  24 , 1542‚Äì1566  (2014),  arXiv:1210.2145 . [Bea72] E.¬†M.¬†Beale.  A derivation of conjugate gradients . In:  Numerical methods for nonlinear optimization , edited by F.¬†A.¬†Lootsma (Academic Press, London, London, 1972); pp.¬†39‚Äì43. [BFSS23] R.¬†Bergmann, O.¬†P.¬†Ferreira, E.¬†M.¬†Santos and J.¬†C.¬†Souza.  The difference of convex algorithm on Hadamard manifolds , arXiv¬†preprint (2023). [BG18] R.¬†Bergmann and P.-Y.¬†Gousenbourger.  A variational model for data fitting on manifolds by minimizing the acceleration of a B√©zier curve .  Frontiers¬†in¬†Applied¬†Mathematics¬†and¬†Statistics  4  (2018),  arXiv:1807.10090 . [BH19] R.¬†Bergmann and R.¬†Herzog.  Intrinsic formulation of KKT conditions and constraint qualifications on smooth manifolds .  SIAM¬†Journal¬†on¬†Optimization  29 , 2423‚Äì2444  (2019),  arXiv:1804.06214 . [BHJ24] R.¬†Bergmann, R.¬†Herzog and H.¬†Jasa.  The Riemannian Convex Bundle Method , preprint (2024),  arXiv:2402.13670 . [BHS+21] R.¬†Bergmann, R.¬†Herzog, M.¬†Silva Louzeiro, D.¬†Tenbrinck and J.¬†Vidal-N√∫√±ez.  Fenchel duality theory and a primal-dual algorithm on Riemannian manifolds .  Foundations¬†of¬†Computational¬†Mathematics  21 , 1465‚Äì1504  (2021),  arXiv:1908.02022 . [BPS16] R.¬†Bergmann, J.¬†Persch and G.¬†Steidl.  A parallel Douglas Rachford algorithm for minimizing ROF-like functionals on images with values in symmetric Hadamard manifolds .  SIAM¬†Journal¬†on¬†Imaging¬†Sciences  9 , 901‚Äì937  (2016),  arXiv:1512.02814 . [BIA10] P.¬†B.¬†Borckmans, M.¬†Ishteva and P.-A.¬†Absil.  A Modified Particle Swarm Optimization Algorithm for the Best Low Multilinear Rank Approximation of Higher-Order Tensors . In:  7th International Conference on Swarm INtelligence  (Springer Berlin Heidelberg, 2010); pp.¬†13‚Äì23. [Bou23] N.¬†Boumal.  An Introduction to Optimization on Smooth Manifolds . First¬†Edition ( Cambridge University Press, 2023 ). [Car92] M.¬†P.¬†do¬†Carmo.  Riemannian Geometry .  Mathematics: Theory & Applications  (Birkh√§user Boston, Inc., Boston, MA, 1992); p.¬†xiv+300. [CP11] A.¬†Chambolle and T.¬†Pock.  A first-order primal-dual algorithm for convex problems with applications to imaging .  Journal¬†of¬†Mathematical¬†Imaging¬†and¬†Vision  40 , 120‚Äì145  (2011). [CGT00] A.¬†R.¬†Conn, N.¬†I.¬†Gould and P.¬†L.¬†Toint.  Trust Region Methods  (Society for Industrial and Applied Mathematics, 2000). [DY99] Y.¬†H.¬†Dai and Y.¬†Yuan.  A Nonlinear Conjugate Gradient Method with a Strong Global Convergence Property .  SIAM¬†Journal¬†on¬†Optimization  10 , 177‚Äì182  (1999). [DL21] W.¬†Diepeveen and J.¬†Lellmann.  An Inexact Semismooth Newton Method on Riemannian Manifolds with Application to Duality-Based Total Variation Denoising .  SIAM¬†Journal¬†on¬†Imaging¬†Sciences  14 , 1565‚Äì1600  (2021),  arXiv:2102.10309 . [FO98] O.¬†Ferreira and P.¬†R.¬†Oliveira.  Subgradient algorithm on Riemannian manifolds .  Journal¬†of¬†Optimization¬†Theory¬†and¬†Applications  97 , 93‚Äì104  (1998). [Fle13] P.¬†T.¬†Fletcher.  Geodesic regression and the theory of least squares on Riemannian manifolds .  International¬†Journal¬†of¬†Computer¬†Vision  105 , 171‚Äì185  (2013). [Fle87] R.¬†Fletcher.  Practical Methods of Optimization . 2¬†Edition,  A Wiley-Interscience Publication  (John Wiley & Sons Ltd., 1987). [FR64] R.¬†Fletcher and C.¬†M.¬†Reeves.  Function minimization by conjugate gradients .  The¬†Computer¬†Journal  7 , 149‚Äì154  (1964). [GS23] G.¬†N.¬†Grapiglia and G.¬†F.¬†Stella.  An Adaptive Riemannian Gradient Method Without Function Evaluations .  Journal¬†of¬†Optimization¬†Theory¬†and¬†Applications  197 , 1140‚Äì1160  (2023). [HZ06] W.¬†W.¬†Hager and H.¬†Zhang.  A survey of nonlinear conjugate gradient methods . Pacific¬†Journal¬†of¬†Optimization  2 , 35‚Äì58 (2006). [HZ05] W.¬†W.¬†Hager and H.¬†Zhang.  A New Conjugate Gradient Method with Guaranteed Descent and an Efficient Line Search .  SIAM¬†Journal¬†on¬†Optimization  16 , 170‚Äì192  (2005). [HS52] M.¬†Hestenes and E.¬†Stiefel.  Methods of conjugate gradients for solving linear systems .  Journal¬†of¬†Research¬†of¬†the¬†National¬†Bureau¬†of¬†Standards  49 , 409  (1952). [HNP23] N.¬†Hoseini Monjezi, S.¬†Nobakhtian and M.¬†R.¬†Pouryayevali.  A proximal bundle algorithm for nonsmooth optimization on Riemannian manifolds .  IMA¬†Journal¬†of¬†Numerical¬†Analysis  43 , 293‚Äì325  (2023). [Hua14] W.¬†Huang.  Optimization algorithms on Riemannian manifolds with applications . Ph.D. Thesis, Flordia State University (2014). [HAG18] W.¬†Huang, P.-A.¬†Absil and K.¬†A.¬†Gallivan.  A Riemannian BFGS method without differentiated retraction for nonconvex optimization problems .  SIAM¬†Journal¬†on¬†Optimization  28 , 470‚Äì495  (2018). [HGA15] W.¬†Huang, K.¬†A.¬†Gallivan and P.-A.¬†Absil.  A Broyden class of quasi-Newton methods for Riemannian optimization .  SIAM¬†Journal¬†on¬†Optimization  25 , 1660‚Äì1685  (2015). [IP17] B.¬†Iannazzo and M.¬†Porcelli.  The Riemannian Barzilai‚ÄìBorwein method with nonmonotone line search and the matrix geometric mean computation .  IMA¬†Journal¬†of¬†Numerical¬†Analysis  38 , 495‚Äì517  (2017). [Kar77] H.¬†Karcher.  Riemannian center of mass and mollifier smoothing .  Communications¬†on¬†Pure¬†and¬†Applied¬†Mathematics  30 , 509‚Äì541  (1977). [LB19] C.¬†Liu and N.¬†Boumal.  Simple algorithms for optimization on Riemannian manifolds with constraints .  Applied¬†Mathematics¬†&¬†Optimization  (2019),  arXiv:1091.10000 . [LS91] Y.¬†Liu and C.¬†Storey.  Efficient generalized conjugate gradient algorithms,  part 1: Theory .  Journal¬†of¬†Optimization¬†Theory¬†and¬†Applications  69 , 129‚Äì137  (1991). [Ngu23] D.¬†Nguyen.  Operator-Valued Formulas for Riemannian Gradient and Hessian and Families of Tractable Metrics in Riemannian Optimization .  Journal¬†of¬†Optimization¬†Theory¬†and¬†Applications  198 , 135‚Äì164  (2023),  arXiv:2009.10159 . [NW06] J.¬†Nocedal and S.¬†J.¬†Wright.  Numerical Optimization . 2¬†Edition (Springer, New York, 2006). [Pee93] R.¬†Peeters.  On a Riemannian version of the Levenberg-Marquardt algorithm . Serie Research Memoranda¬†0011 (VU University Amsterdam, Faculty of Economics, Business Administration and Econometrics, 1993). [PR69] E.¬†Polak and G.¬†Ribi√®re.  Note sur la convergence de m√©thodes de directions conjugu√©es .  Revue¬†fran√ßaise¬†d‚Äôinformatique¬†et¬†de¬†recherche¬†op√©rationnelle  3 , 35‚Äì43  (1969). [Pol69] B.¬†T.¬†Polyak.  The conjugate gradient method in extremal problems .  USSR¬†Computational¬†Mathematics¬†and¬†Mathematical¬†Physics  9 , 94‚Äì112  (1969). [Pow77] M.¬†J.¬†Powell.  Restart procedures for the conjugate gradient method .  Mathematical¬†Programming  12 , 241‚Äì254  (1977). [SO15] J.¬†C.¬†Souza and P.¬†R.¬†Oliveira.  A proximal point algorithm for DC fuctions on Hadamard manifolds .  Journal¬†of¬†Global¬†Optimization  63 , 797‚Äì810  (2015). [WS22] M.¬†Weber and S.¬†Sra.  Riemannian Optimization via Frank-Wolfe Methods .  Mathematical¬†Programming  199 , 525‚Äì556  (2022). [ZS18] H.¬†Zhang and S.¬†Sra.  Towards Riemannian accelerated gradient methods , arXiv¬†Preprint,¬†1806.02812 (2018)."},{"id":2418,"pagetitle":"Introduction","title":"List of available solvers","ref":"/manopt/stable/solvers/#List-of-available-solvers","content":" List of available solvers Solvers can be applied to  AbstractManoptProblem s with solver specific  AbstractManoptSolverState ."},{"id":2419,"pagetitle":"Introduction","title":"List of algorithms","ref":"/manopt/stable/solvers/#List-of-algorithms","content":" List of algorithms The following algorithms are currently available Solver Function & State Objective Alternating Gradient Descent alternating_gradient_descent AlternatingGradientDescentState $f=(f_1,\\ldots,f_n)$ ,  $\\operatorname{grad} f_i$ Augmented Lagrangian Method augmented_Lagrangian_method ,  AugmentedLagrangianMethodState $f$ ,  $\\operatorname{grad} f$ ,  $g$ ,  $\\operatorname{grad} g_i$ ,  $h$ ,  $\\operatorname{grad} h_j$ Chambolle-Pock ChambollePock ,  ChambollePockState  (using  TwoManifoldProblem ) $f=F+G(Œõ\\cdot)$ ,  $\\operatorname{prox}_{œÉ F}$ ,  $\\operatorname{prox}_{œÑ G^*}$ ,  $Œõ$ Conjugate Gradient Descent conjugate_gradient_descent ,  ConjugateGradientDescentState $f$ ,  $\\operatorname{grad} f$ Convex Bundle Method convex_bundle_method ,  ConvexBundleMethodState $f$ ,  $\\partial f$ Cyclic Proximal Point cyclic_proximal_point ,  CyclicProximalPointState $f=\\sum f_i$ ,  $\\operatorname{prox}_{\\lambda f_i}$ Difference of Convex Algorithm difference_of_convex_algorithm ,  DifferenceOfConvexState $f=g-h$ ,  $‚àÇh$ , and for example  $g$ ,  $\\operatorname{grad} g$ Difference of Convex Proximal Point difference_of_convex_proximal_point ,  DifferenceOfConvexProximalState $f=g-h$ ,  $‚àÇh$ , and for example  $g$ ,  $\\operatorname{grad} g$ Douglas‚ÄîRachford DouglasRachford ,  DouglasRachfordState $f=\\sum f_i$ ,  $\\operatorname{prox}_{\\lambda f_i}$ Exact Penalty Method exact_penalty_method ,  ExactPenaltyMethodState $f$ ,  $\\operatorname{grad} f$ ,  $g$ ,  $\\operatorname{grad} g_i$ ,  $h$ ,  $\\operatorname{grad} h_j$ Frank-Wolfe algorithm Frank_Wolfe_method ,  FrankWolfeState sub-problem solver Gradient Descent gradient_descent ,  GradientDescentState $f$ ,  $\\operatorname{grad} f$ Levenberg-Marquardt LevenbergMarquardt ,  LevenbergMarquardtState $f = \\sum_i f_i$ $\\operatorname{grad} f_i$  (Jacobian) Nelder-Mead NelderMead ,  NelderMeadState $f$ Particle Swarm particle_swarm ,  ParticleSwarmState $f$ Primal-dual Riemannian semismooth Newton Algorithm primal_dual_semismooth_Newton ,   PrimalDualSemismoothNewtonState  (using  TwoManifoldProblem ) $f=F+G(Œõ\\cdot)$ ,  $\\operatorname{prox}_{œÉ F}$  & diff.,  $\\operatorname{prox}_{œÑ G^*}$  & diff.,  $Œõ$ Proximal Bundle Method proximal_bundle_method ,  ProximalBundleMethodState $f$ ,  $\\partial f$ Quasi-Newton Method quasi_Newton ,  QuasiNewtonState $f$ ,  $\\operatorname{grad} f$ Steihaug-Toint Truncated Conjugate-Gradient Method truncated_conjugate_gradient_descent ,  TruncatedConjugateGradientState $f$ ,  $\\operatorname{grad} f$ ,  $\\operatorname{Hess} f$ Subgradient Method subgradient_method ,  SubGradientMethodState $f$ ,  $‚àÇ f$ Stochastic Gradient Descent stochastic_gradient_descent ,  StochasticGradientDescentState $f = \\sum_i f_i$ ,  $\\operatorname{grad} f_i$ The Riemannian Trust-Regions Solver trust_regions ,  TrustRegionsState $f$ ,  $\\operatorname{grad} f$ ,  $\\operatorname{Hess} f$ Note that the solvers (their  AbstractManoptSolverState , to be precise) can also be decorated to enhance your algorithm by general additional properties, see  debug output  and  recording values . This is done using the  debug=  and  record=  keywords in the function calls. Similarly, since Manopt.jl 0.4 a (simple)  caching of the objective function  using the  cache=  keyword is available in any of the function calls.."},{"id":2420,"pagetitle":"Introduction","title":"Technical details","ref":"/manopt/stable/solvers/#Technical-details","content":" Technical details The main function a solver calls is"},{"id":2421,"pagetitle":"Introduction","title":"Manopt.solve!","ref":"/manopt/stable/solvers/#Manopt.solve!-Tuple{AbstractManoptProblem, AbstractManoptSolverState}","content":" Manopt.solve!  ‚Äî  Method solve!(p::AbstractManoptProblem, s::AbstractManoptSolverState) run the solver implemented for the  AbstractManoptProblem p  and the  AbstractManoptSolverState s  employing  initialize_solver! ,  step_solver! , as well as the  stop_solver!  of the solver. source which is a framework that you in general should not change or redefine. It uses the following methods, which also need to be implemented on your own algorithm, if you want to provide one."},{"id":2422,"pagetitle":"Introduction","title":"Manopt.initialize_solver!","ref":"/manopt/stable/solvers/#Manopt.initialize_solver!","content":" Manopt.initialize_solver!  ‚Äî  Function initialize_solver!(ams::AbstractManoptProblem, amp::AbstractManoptSolverState) Initialize the solver to the optimization  AbstractManoptProblem amp  by initializing the necessary values in the  AbstractManoptSolverState amp . source initialize_solver!(amp::AbstractManoptProblem, dss::DebugSolverState) Extend the initialization of the solver by a hook to run the  DebugAction  that was added to the  :Start  entry of the debug lists. All others are triggered (with iteration number  0 ) to trigger possible resets source initialize_solver!(ams::AbstractManoptProblem, rss::RecordSolverState) Extend the initialization of the solver by a hook to run records that were added to the  :Start  entry. source"},{"id":2423,"pagetitle":"Introduction","title":"Manopt.step_solver!","ref":"/manopt/stable/solvers/#Manopt.step_solver!","content":" Manopt.step_solver!  ‚Äî  Function step_solver!(amp::AbstractManoptProblem, ams::AbstractManoptSolverState, i) Do one iteration step (the  i th) for an  AbstractManoptProblem p  by modifying the values in the  AbstractManoptSolverState ams . source step_solver!(amp::AbstractManoptProblem, dss::DebugSolverState, i) Extend the  i th step of the solver by a hook to run debug prints, that were added to the  :BeforeIteration  and  :Iteration  entries of the debug lists. source step_solver!(amp::AbstractManoptProblem, rss::RecordSolverState, i) Extend the  i th step of the solver by a hook to run records, that were added to the  :Iteration  entry. source"},{"id":2424,"pagetitle":"Introduction","title":"Manopt.get_solver_result","ref":"/manopt/stable/solvers/#Manopt.get_solver_result","content":" Manopt.get_solver_result  ‚Äî  Function get_solver_result(ams::AbstractManoptSolverState)\nget_solver_result(tos::Tuple{AbstractManifoldObjective,AbstractManoptSolverState})\nget_solver_result(o::AbstractManifoldObjective, s::AbstractManoptSolverState) Return the final result after all iterations that is stored within the  AbstractManoptSolverState ams , which was modified during the iterations. For the case the objective is passed as well, but default, the objective is ignored, and the solver result for the state is called. source"},{"id":2425,"pagetitle":"Introduction","title":"Manopt.get_solver_return","ref":"/manopt/stable/solvers/#Manopt.get_solver_return","content":" Manopt.get_solver_return  ‚Äî  Function get_solver_return(s::AbstractManoptSolverState)\nget_solver_return(o::AbstractManifoldObjective, s::AbstractManoptSolverState) determine the result value of a call to a solver. By default this returns the same as  get_solver_result . get_solver_return(s::ReturnSolverState)\nget_solver_return(o::AbstractManifoldObjective, s::ReturnSolverState) return the internally stored state of the  ReturnSolverState  instead of the minimizer. This means that when the state are decorated like this, the user still has to call  get_solver_result  on the internal state separately. get_solver_return(o::ReturnManifoldObjective, s::AbstractManoptSolverState) return both the objective and the state as a tuple. source"},{"id":2426,"pagetitle":"Introduction","title":"Manopt.stop_solver!","ref":"/manopt/stable/solvers/#Manopt.stop_solver!-Tuple{AbstractManoptProblem, AbstractManoptSolverState, Any}","content":" Manopt.stop_solver!  ‚Äî  Method stop_solver!(amp::AbstractManoptProblem, ams::AbstractManoptSolverState, i) depending on the current  AbstractManoptProblem amp , the current state of the solver stored in  AbstractManoptSolverState ams  and the current iterate  i  this function determines whether to stop the solver, which by default means to call the internal  StoppingCriterion .  ams.stop source"},{"id":2427,"pagetitle":"Introduction","title":"API for solvers","ref":"/manopt/stable/solvers/#API-for-solvers","content":" API for solvers this is a short overview of the different types of high-level functions are usually available for a solver. Assume the solver is called  new_solver  and requires a cost  f  and some first order information  df  as well as a starting point  p  on  M .  f  and  df  form the objective together called  obj . Then there are basically two different variants to call"},{"id":2428,"pagetitle":"Introduction","title":"The easy to access call","ref":"/manopt/stable/solvers/#The-easy-to-access-call","content":" The easy to access call new_solver(M, f, df, p=rand(M); kwargs...)\nnew_solver!(M, f, df, p; kwargs...) Where the start point should be optional. Keyword arguments include the type of evaluation, decorators like  debug=  or  record=  as well as algorithm specific ones. If you provide an immutable point  p  or the  rand(M)  point is immutable, like on the  Circle()  this method should turn the point into a mutable one as well. The third variant works in place of  p , so it is mandatory. This first interface would set up the objective and pass all keywords on the objective based call."},{"id":2429,"pagetitle":"Introduction","title":"Objective based calls to solvers","ref":"/manopt/stable/solvers/#Objective-based-calls-to-solvers","content":" Objective based calls to solvers new_solver(M, obj, p=rand(M); kwargs...)\nnew_solver!(M, obj, p; kwargs...) Here the objective would be created beforehand for example to compare different solvers on the same objective, and for the first variant the start point is optional. Keyword arguments include decorators like  debug=  or  record=  as well as algorithm specific ones. This variant would generate the  problem  and the  state  and verify validity of all provided keyword arguments that affect the state. Then it would call the iterate process."},{"id":2430,"pagetitle":"Introduction","title":"Manual calls","ref":"/manopt/stable/solvers/#Manual-calls","content":" Manual calls If you generate the corresponding  problem  and  state  as the previous step does, you can also use the third (lowest level) and just call solve!(problem, state)"},{"id":2433,"pagetitle":"Chambolle-Pock","title":"The Riemannian Chambolle-Pock algorithm","ref":"/manopt/stable/solvers/ChambollePock/#The-Riemannian-Chambolle-Pock-algorithm","content":" The Riemannian Chambolle-Pock algorithm The Riemannian Chambolle‚ÄîPock is a generalization of the Chambolle‚ÄîPock algorithm  Chambolle and Pock [CP11]  It is also known as primal-dual hybrid gradient (PDHG) or primal-dual proximal splitting (PDPS) algorithm. In order to minimize over  $p‚àà\\mathcal M$  the cost function consisting of In order to minimize a cost function consisting of \\[F(p) + G(Œõ(p)),\\] over  $p‚àà\\mathcal M$ where  $F:\\mathcal M ‚Üí \\overline{‚Ñù}$ ,  $G:\\mathcal N ‚Üí \\overline{‚Ñù}$ , and  $Œõ:\\mathcal M ‚Üí\\mathcal N$ . If the manifolds  $\\mathcal M$  or  $\\mathcal N$  are not Hadamard, it has to be considered locally only, that is on geodesically convex sets  $\\mathcal C \\subset \\mathcal M$  and  $\\mathcal D \\subset\\mathcal N$  such that  $Œõ(\\mathcal C) \\subset \\mathcal D$ . The algorithm is available in four variants: exact versus linearized (see  variant ) as well as with primal versus dual relaxation (see  relax ). For more details, see  Bergmann, Herzog, Silva Louzeiro, Tenbrinck and Vidal-N√∫√±ez [BHS+21] . In the following description is the case of the exact, primal relaxed Riemannian Chambolle‚ÄîPock algorithm. Given base points  $m‚àà\\mathcal C$ ,  $n=Œõ(m)‚àà\\mathcal D$ , initial primal and dual values  $p^{(0)} ‚àà\\mathcal C$ ,  $Œæ_n^{(0)} ‚ààT_n^*\\mathcal N$ , and primal and dual step sizes  $\\sigma_0$ ,  $\\tau_0$ , relaxation  $\\theta_0$ , as well as acceleration  $\\gamma$ . As an initialization, perform  $\\bar p^{(0)} \\gets p^{(0)}$ . The algorithms performs the steps  $k=1,‚Ä¶,$  (until a  StoppingCriterion  is fulfilled with) \\[Œæ^{(k+1)}_n = \\operatorname{prox}_{\\tau_k G_n^*}\\Bigl(Œæ_n^{(k)} + \\tau_k \\bigl(\\log_n Œõ (\\bar p^{(k)})\\bigr)^\\flat\\Bigr)\\] \\[p^{(k+1)} = \\operatorname{prox}_{\\sigma_k F}\\biggl(\\exp_{p^{(k)}}\\Bigl( \\operatorname{PT}_{p^{(k)}\\gets m}\\bigl(-\\sigma_k DŒõ(m)^*[Œæ_n^{(k+1)}]\\bigr)^\\sharp\\Bigr)\\biggr)\\] Update $\\theta_k = (1+2\\gamma\\sigma_k)^{-\\frac{1}{2}}$ $\\sigma_{k+1} = \\sigma_k\\theta_k$ $\\tau_{k+1} =  \\frac{\\tau_k}{\\theta_k}$ \\[\\bar p^{(k+1)}  = \\exp_{p^{(k+1)}}\\bigl(-\\theta_k \\log_{p^{(k+1)}} p^{(k)}\\bigr)\\] Furthermore you can exchange the exponential map, the logarithmic map, and the parallel transport by a retraction, an inverse retraction, and a vector transport. Finally you can also update the base points  $m$  and  $n$  during the iterations. This introduces a few additional vector transports. The same holds for the case  $Œõ(m^{(k)})\\neq n^{(k)}$  at some point. All these cases are covered in the algorithm."},{"id":2434,"pagetitle":"Chambolle-Pock","title":"Manopt.ChambollePock","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.ChambollePock","content":" Manopt.ChambollePock  ‚Äî  Function ChambollePock(\n    M, N, cost, x0, Œæ0, m, n, prox_F, prox_G_dual, adjoint_linear_operator;\n    forward_operator=missing,\n    linearized_forward_operator=missing,\n    evaluation=AllocatingEvaluation()\n) Perform the Riemannian Chambolle‚ÄîPock algorithm. Given a  cost  function  $\\mathcal E:\\mathcal M ‚Üí ‚Ñù$  of the form \\[\\mathcal E(p) = F(p) + G( Œõ(p) ),\\] where  $F:\\mathcal M ‚Üí ‚Ñù$ ,  $G:\\mathcal N ‚Üí ‚Ñù$ , and  $Œõ:\\mathcal M ‚Üí \\mathcal N$ . The remaining input parameters are p, X :                         primal and dual start points  $x‚àà\\mathcal M$  and  $Œæ‚ààT_n\\mathcal N$ m,n :                          base points on  $\\mathcal M$  and  $\\mathcal N$ , respectively. adjoint_linearized_operator :  the adjoint  $DŒõ^*$  of the linearized operator  $DŒõ(m): T_{m}\\mathcal M ‚Üí T_{Œõ(m)}\\mathcal N$ prox_F, prox_G_Dual :          the proximal maps of  $F$  and  $G^\\ast_n$ note that depending on the  AbstractEvaluationType evaluation  the last three parameters as well as the forward operator  Œõ  and the  linearized_forward_operator  can be given as allocating functions  (Manifolds, parameters) -> result   or as mutating functions  (Manifold, result, parameters)  -> result` to spare allocations. By default, this performs the exact Riemannian Chambolle Pock algorithm, see the optional parameter  DŒõ  for their linearized variant. For more details on the algorithm, see [ BHS+21 ]. Optional parameters acceleration :                ( 0.05 ) dual_stepsize :               ( 1/sqrt(8) ) proximal parameter of the primal prox evaluation :                  ( AllocatingEvaluation ()) specify whether the proximal maps and operators are allocating functions (Manifolds, parameters) -> result or  given as mutating functions (Manifold, result, parameters) -> result Œõ :                           ( missing ) the (forward) operator  $Œõ(‚ãÖ)$  (required for the  :exact  variant) linearized_forward_operator : ( missing ) its linearization  $DŒõ(‚ãÖ)[‚ãÖ]$  (required for the  :linearized  variant) primal_stepsize :             ( 1/sqrt(8) ) proximal parameter of the dual prox relaxation :                  ( 1. ) the relaxation parameter  $Œ≥$ relax :                       ( :primal ) whether to relax the primal or dual variant :                     ( :exact  if  Œõ  is missing, otherwise  :linearized ) variant to use. Note that this changes the arguments the  forward_operator  is called with. stopping_criterion :          ( [StopAfterIteration ](@ref) (100) ) a  StoppingCriterion update_primal_base :          ( missing ) function to update  m  (identity by default/missing) update_dual_base :            ( missing ) function to update  n  (identity by default/missing) retraction_method :           ( default_retraction_method(M, typeof(p)) ) the retraction to use inverse_retraction_method     ( default_inverse_retraction_method(M, typeof(p)) ) an inverse retraction to use. vector_transport_method       ( default_vector_transport_method(M, typeof(p)) ) a vector transport to use Output the obtained (approximate) minimizer  $p^*$ , see  get_solver_return  for details. source"},{"id":2435,"pagetitle":"Chambolle-Pock","title":"Manopt.ChambollePock!","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.ChambollePock!","content":" Manopt.ChambollePock!  ‚Äî  Function ChambollePock(M, N, cost, x0, Œæ0, m, n, prox_F, prox_G_dual, adjoint_linear_operator) Perform the Riemannian Chambolle‚ÄîPock algorithm in place of  x ,  Œæ , and potentially  m ,  n  if they are not fixed. See  ChambollePock  for details and optional parameters. source"},{"id":2436,"pagetitle":"Chambolle-Pock","title":"State","ref":"/manopt/stable/solvers/ChambollePock/#State","content":" State"},{"id":2437,"pagetitle":"Chambolle-Pock","title":"Manopt.ChambollePockState","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.ChambollePockState","content":" Manopt.ChambollePockState  ‚Äî  Type ChambollePockState <: AbstractPrimalDualSolverState stores all options and variables within a linearized or exact Chambolle Pock. The following list provides the order for the constructor, where the previous iterates are initialized automatically and values with a default may be left out. m :                              base point on  $\\mathcal M$ n :                              base point on  $\\mathcal N$ p :                              an initial point on  $x^{(0)} ‚àà\\mathcal M$  (and its previous iterate) X :                              an initial tangent vector  $X^{(0)}‚ààT^*\\mathcal N$  (and its previous iterate) pbar :                           the relaxed iterate used in the next dual update step (when using  :primal  relaxation) Xbar :                           the relaxed iterate used in the next primal update step (when using  :dual  relaxation) primal_stepsize :                ( 1/sqrt(8) ) proximal parameter of the primal prox dual_stepsize :                  ( 1/sqrt(8) ) proximal parameter of the dual prox acceleration :                   ( 0. ) acceleration factor due to Chambolle & Pock relaxation :                     ( 1. ) relaxation in the primal relaxation step (to compute  pbar ) relax :                          ( :primal ) which variable to relax ( :primal  or  :dual ) stop :                           a  StoppingCriterion variant :                        ( exact ) whether to perform an  :exact  or  :linearized  Chambolle-Pock update_primal_base :             ( (p,o,i) -> o.m ) function to update the primal base update_dual_base :               ( (p,o,i) -> o.n ) function to update the dual base retraction_method :              ( default_retraction_method(M, typeof(p)) ) the retraction to use inverse_retraction_method :      ( default_inverse_retraction_method(M, typeof(p)) ) an inverse retraction to use on the manifold  $\\mathcal M$ . inverse_retraction_method_dual : ( default_inverse_retraction_method(N, typeof(n)) ) an inverse retraction to use on manifold  $\\mathcal N$ . vector_transport_method :        ( default_vector_transport_method(M, typeof(p)) ) a vector transport to use on the manifold  $\\mathcal M$ . vector_transport_method_dual :   ( default_vector_transport_method(N, typeof(n)) ) a vector transport to use on manifold  $\\mathcal N$ . where for the last two the functions a  AbstractManoptProblem p ,  AbstractManoptSolverState o  and the current iterate  i  are the arguments. If you activate these to be different from the default identity, you have to provide  p.Œõ  for the algorithm to work (which might be  missing  in the linearized case). Constructor ChambollePockState(M::AbstractManifold, N::AbstractManifold,\n    m::P, n::Q, p::P, X::T, primal_stepsize::Float64, dual_stepsize::Float64;\n    kwargs...\n) where all other fields are keyword arguments with their default values given in brackets. if  Manifolds.jl  is loaded,  N  is also a keyword argument and set to  TangentBundle(M)  by default. source"},{"id":2438,"pagetitle":"Chambolle-Pock","title":"Useful terms","ref":"/manopt/stable/solvers/ChambollePock/#Useful-terms","content":" Useful terms"},{"id":2439,"pagetitle":"Chambolle-Pock","title":"Manopt.primal_residual","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.primal_residual","content":" Manopt.primal_residual  ‚Äî  Function primal_residual(p, o, x_old, X_old, n_old) Compute the primal residual at current iterate  $k$  given the necessary values  $x_{k-1}, X_{k-1}$ , and  $n_{k-1}$  from the previous iterate. \\[\\Bigl\\lVert\n\\frac{1}{œÉ}\\operatorname{retr}^{-1}_{x_{k}}x_{k-1} -\nV_{x_k\\gets m_k}\\bigl(DŒõ^*(m_k)\\bigl[V_{n_k\\gets n_{k-1}}X_{k-1} - X_k \\bigr]\n\\Bigr\\rVert\\] where  $V_{‚ãÖ\\gets‚ãÖ}$  is the vector transport used in the  ChambollePockState source"},{"id":2440,"pagetitle":"Chambolle-Pock","title":"Manopt.dual_residual","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.dual_residual","content":" Manopt.dual_residual  ‚Äî  Function dual_residual(p, o, x_old, X_old, n_old) Compute the dual residual at current iterate  $k$  given the necessary values  $x_{k-1}, X_{k-1}$ , and  $n_{k-1}$  from the previous iterate. The formula is slightly different depending on the  o.variant  used: For the  :linearized  it reads \\[\\Bigl\\lVert\n\\frac{1}{œÑ}\\bigl(\nV_{n_{k}\\gets n_{k-1}}(X_{k-1})\n- X_k\n\\bigr)\n-\nDŒõ(m_k)\\bigl[\nV_{m_k\\gets x_k}\\operatorname{retr}^{-1}_{x_{k}}x_{k-1}\n\\bigr]\n\\Bigr\\rVert\\] and for the  :exact  variant \\[\\Bigl\\lVert\n\\frac{1}{œÑ} V_{n_{k}\\gets n_{k-1}}(X_{k-1})\n-\n\\operatorname{retr}^{-1}_{n_{k}}\\bigl(\nŒõ(\\operatorname{retr}_{m_{k}}(V_{m_k\\gets x_k}\\operatorname{retr}^{-1}_{x_{k}}x_{k-1}))\n\\bigr)\n\\Bigr\\rVert\\] where in both cases  $V_{‚ãÖ\\gets‚ãÖ}$  is the vector transport used in the  ChambollePockState . source"},{"id":2441,"pagetitle":"Chambolle-Pock","title":"Debug","ref":"/manopt/stable/solvers/ChambollePock/#Debug","content":" Debug"},{"id":2442,"pagetitle":"Chambolle-Pock","title":"Manopt.DebugDualBaseIterate","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.DebugDualBaseIterate","content":" Manopt.DebugDualBaseIterate  ‚Äî  Function DebugDualBaseIterate(io::IO=stdout) Print the dual base variable by using  DebugEntry , see their constructors for detail. This method is further set display  o.n . source"},{"id":2443,"pagetitle":"Chambolle-Pock","title":"Manopt.DebugDualBaseChange","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.DebugDualBaseChange","content":" Manopt.DebugDualBaseChange  ‚Äî  Function DebugDualChange(; storage=StoreStateAction([:n]), io::IO=stdout) Print the change of the dual base variable by using  DebugEntryChange , see their constructors for detail, on  o.n . source"},{"id":2444,"pagetitle":"Chambolle-Pock","title":"Manopt.DebugPrimalBaseIterate","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.DebugPrimalBaseIterate","content":" Manopt.DebugPrimalBaseIterate  ‚Äî  Function DebugPrimalBaseIterate() Print the primal base variable by using  DebugEntry , see their constructors for detail. This method is further set display  o.m . source"},{"id":2445,"pagetitle":"Chambolle-Pock","title":"Manopt.DebugPrimalBaseChange","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.DebugPrimalBaseChange","content":" Manopt.DebugPrimalBaseChange  ‚Äî  Function DebugPrimalBaseChange(a::StoreStateAction=StoreStateAction([:m]),io::IO=stdout) Print the change of the primal base variable by using  DebugEntryChange , see their constructors for detail, on  o.n . source"},{"id":2446,"pagetitle":"Chambolle-Pock","title":"Manopt.DebugDualChange","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.DebugDualChange","content":" Manopt.DebugDualChange  ‚Äî  Type DebugDualChange(opts...) Print the change of the dual variable, similar to  DebugChange , see their constructors for detail, but with a different calculation of the change, since the dual variable lives in (possibly different) tangent spaces. source"},{"id":2447,"pagetitle":"Chambolle-Pock","title":"Manopt.DebugDualIterate","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.DebugDualIterate","content":" Manopt.DebugDualIterate  ‚Äî  Function DebugDualIterate(e) Print the dual variable by using  DebugEntry , see their constructors for detail. This method is further set display  o.X . source"},{"id":2448,"pagetitle":"Chambolle-Pock","title":"Manopt.DebugDualResidual","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.DebugDualResidual","content":" Manopt.DebugDualResidual  ‚Äî  Type DebugDualResidual <: DebugAction A Debug action to print the dual residual. The constructor accepts a printing function and some (shared) storage, which should at least record  :Iterate ,  :X  and  :n . Constructor DebugDualResidual() with the keywords io  ( stdout ) - stream to perform the debug to format ( \"$prefix%s\" ) format to print the dual residual, using the prefix  ( \"Dual Residual: \" ) short form to just set the prefix storage  (a new  StoreStateAction ) to store values for the debug. source"},{"id":2449,"pagetitle":"Chambolle-Pock","title":"Manopt.DebugPrimalChange","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.DebugPrimalChange","content":" Manopt.DebugPrimalChange  ‚Äî  Function DebugPrimalChange(opts...) Print the change of the primal variable by using  DebugChange , see their constructors for detail. source"},{"id":2450,"pagetitle":"Chambolle-Pock","title":"Manopt.DebugPrimalIterate","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.DebugPrimalIterate","content":" Manopt.DebugPrimalIterate  ‚Äî  Function DebugPrimalIterate(opts...;kwargs...) Print the change of the primal variable by using  DebugIterate , see their constructors for detail. source"},{"id":2451,"pagetitle":"Chambolle-Pock","title":"Manopt.DebugPrimalResidual","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.DebugPrimalResidual","content":" Manopt.DebugPrimalResidual  ‚Äî  Type DebugPrimalResidual <: DebugAction A Debug action to print the primal residual. The constructor accepts a printing function and some (shared) storage, which should at least record  :Iterate ,  :X  and  :n . Constructor DebugPrimalResidual() with the keywords io  ( stdout ) - stream to perform the debug to format ( \"$prefix%s\" ) format to print the dual residual, using the prefix  ( \"Primal Residual: \" ) short form to just set the prefix storage  (a new  StoreStateAction ) to store values for the debug. source"},{"id":2452,"pagetitle":"Chambolle-Pock","title":"Manopt.DebugPrimalDualResidual","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.DebugPrimalDualResidual","content":" Manopt.DebugPrimalDualResidual  ‚Äî  Type DebugPrimalDualResidual <: DebugAction A Debug action to print the primal dual residual. The constructor accepts a printing function and some (shared) storage, which should at least record  :Iterate ,  :X  and  :n . Constructor DebugPrimalDualResidual() with the keywords io  ( stdout ) - stream to perform the debug to format ( \"$prefix%s\" ) format to print the dual residual, using the prefix  ( \"Primal Residual: \" ) short form to just set the prefix storage  (a new  StoreStateAction ) to store values for the debug. source"},{"id":2453,"pagetitle":"Chambolle-Pock","title":"Record","ref":"/manopt/stable/solvers/ChambollePock/#Record","content":" Record"},{"id":2454,"pagetitle":"Chambolle-Pock","title":"Manopt.RecordDualBaseIterate","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.RecordDualBaseIterate","content":" Manopt.RecordDualBaseIterate  ‚Äî  Function RecordDualBaseIterate(n) Create an  RecordAction  that records the dual base point, an  RecordEntry  of  o.n . source"},{"id":2455,"pagetitle":"Chambolle-Pock","title":"Manopt.RecordDualBaseChange","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.RecordDualBaseChange","content":" Manopt.RecordDualBaseChange  ‚Äî  Function RecordDualBaseChange(e) Create an  RecordAction  that records the dual base point change, an  RecordEntryChange  of  o.n  with distance to the last value to store a value. source"},{"id":2456,"pagetitle":"Chambolle-Pock","title":"Manopt.RecordDualChange","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.RecordDualChange","content":" Manopt.RecordDualChange  ‚Äî  Function RecordDualChange() Create the action either with a given (shared) Storage, which can be set to the  values  Tuple, if that is provided). source"},{"id":2457,"pagetitle":"Chambolle-Pock","title":"Manopt.RecordDualIterate","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.RecordDualIterate","content":" Manopt.RecordDualIterate  ‚Äî  Function RecordDualIterate(X) Create an  RecordAction  that records the dual base point, an  RecordEntry  of  o.X . source"},{"id":2458,"pagetitle":"Chambolle-Pock","title":"Manopt.RecordPrimalBaseIterate","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.RecordPrimalBaseIterate","content":" Manopt.RecordPrimalBaseIterate  ‚Äî  Function RecordPrimalBaseIterate(x) Create an  RecordAction  that records the primal base point, an  RecordEntry  of  o.m . source"},{"id":2459,"pagetitle":"Chambolle-Pock","title":"Manopt.RecordPrimalBaseChange","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.RecordPrimalBaseChange","content":" Manopt.RecordPrimalBaseChange  ‚Äî  Function RecordPrimalBaseChange() Create an  RecordAction  that records the primal base point change, an  RecordEntryChange  of  o.m  with distance to the last value to store a value. source"},{"id":2460,"pagetitle":"Chambolle-Pock","title":"Manopt.RecordPrimalChange","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.RecordPrimalChange","content":" Manopt.RecordPrimalChange  ‚Äî  Function RecordPrimalChange(a) Create an  RecordAction  that records the primal value change,  RecordChange , to record the change of  o.x . source"},{"id":2461,"pagetitle":"Chambolle-Pock","title":"Manopt.RecordPrimalIterate","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.RecordPrimalIterate","content":" Manopt.RecordPrimalIterate  ‚Äî  Function RecordDualBaseIterate(x) Create an  RecordAction  that records the dual base point, an  RecordIterate  of  o.x . source"},{"id":2462,"pagetitle":"Chambolle-Pock","title":"Internals","ref":"/manopt/stable/solvers/ChambollePock/#Internals","content":" Internals"},{"id":2463,"pagetitle":"Chambolle-Pock","title":"Manopt.update_prox_parameters!","ref":"/manopt/stable/solvers/ChambollePock/#Manopt.update_prox_parameters!","content":" Manopt.update_prox_parameters!  ‚Äî  Function update_prox_parameters!(o) update the prox parameters as described in Algorithm 2 of [ CP11 ], $Œ∏_{n} = \\frac{1}{\\sqrt{1+2Œ≥œÑ_n}}$ $œÑ_{n+1} = Œ∏_nœÑ_n$ $œÉ_{n+1} = \\frac{œÉ_n}{Œ∏_n}$ source"},{"id":2464,"pagetitle":"Chambolle-Pock","title":"Technical details","ref":"/manopt/stable/solvers/ChambollePock/#sec-cp-technical-details","content":" Technical details The  ChambollePock  solver requires the following functions of a manifold to be available for both the manifold  $\\mathcal M$ and  $\\mathcal N$ A  retract! (M, q, p, X) ; it is recommended to set the  default_retraction_method  to a favourite retraction. If this default is set, a  retraction_method=  or  retraction_method_dual=  (for  $\\mathcal N$ ) does not have to be specified. An  inverse_retract! (M, X, p, q) ; it is recommended to set the  default_inverse_retraction_method  to a favourite retraction. If this default is set, a  inverse_retraction_method=  or  inverse_retraction_method_dual=  (for  $\\mathcal N$ ) does not have to be specified. A  vector_transport_to! M, Y, p, X, q) ; it is recommended to set the  default_vector_transport_method  to a favourite retraction. If this default is set, a  vector_transport_method=  or  vector_transport_method_dual=  (for  $\\mathcal N$ ) does not have to be specified. A  `copyto! (M, q, p)  and  copy (M,p)  for points."},{"id":2465,"pagetitle":"Chambolle-Pock","title":"Literature","ref":"/manopt/stable/solvers/ChambollePock/#Literature","content":" Literature [BHS+21] R.¬†Bergmann, R.¬†Herzog, M.¬†Silva Louzeiro, D.¬†Tenbrinck and J.¬†Vidal-N√∫√±ez.  Fenchel duality theory and a primal-dual algorithm on Riemannian manifolds .  Foundations¬†of¬†Computational¬†Mathematics  21 , 1465‚Äì1504  (2021),  arXiv:1908.02022 . [CP11] A.¬†Chambolle and T.¬†Pock.  A first-order primal-dual algorithm for convex problems with applications to imaging .  Journal¬†of¬†Mathematical¬†Imaging¬†and¬†Vision  40 , 120‚Äì145  (2011)."},{"id":2468,"pagetitle":"Douglas‚ÄîRachford","title":"Douglas‚ÄîRachford algorithm","ref":"/manopt/stable/solvers/DouglasRachford/#Douglas‚ÄîRachford-algorithm","content":" Douglas‚ÄîRachford algorithm The (Parallel) Douglas‚ÄîRachford ((P)DR) algorithm was generalized to Hadamard manifolds in [ BPS16 ]. The aim is to minimize the sum \\[F(p) = f(p) + g(p)\\] on a manifold, where the two summands have proximal maps  $\\operatorname{prox}_{Œª f}, \\operatorname{prox}_{Œª g}$  that are easy to evaluate (maybe in closed form, or not too costly to approximate). Further, define the reflection operator at the proximal map as \\[\\operatorname{refl}_{Œª f}(p) = \\operatorname{retr}_{\\operatorname{prox}_{Œª f}(p)} \\bigl( -\\operatorname{retr}^{-1}_{\\operatorname{prox}_{Œª f}(p)} p \\bigr).\\] Let  $\\alpha_k ‚àà  [0,1]$  with  $\\sum_{k ‚àà ‚Ñï} \\alpha_k(1-\\alpha_k) =  \\infty$  and  $Œª > 0$  (which might depend on iteration  $k$  as well) be given. Then the (P)DRA algorithm for initial data  $x_0 ‚àà \\mathcal H$  as"},{"id":2469,"pagetitle":"Douglas‚ÄîRachford","title":"Initialization","ref":"/manopt/stable/solvers/DouglasRachford/#Initialization","content":" Initialization Initialize  $t_0 = x_0$  and  $k=0$"},{"id":2470,"pagetitle":"Douglas‚ÄîRachford","title":"Iteration","ref":"/manopt/stable/solvers/DouglasRachford/#Iteration","content":" Iteration Repeat until a convergence criterion is reached Compute  $s_k = \\operatorname{refl}_{Œª f}\\operatorname{refl}_{Œª g}(t_k)$ Within that operation, store  $p_{k+1} = \\operatorname{prox}_{Œª g}(t_k)$  which is the prox the inner reflection reflects at. Compute  $t_{k+1} = g(\\alpha_k; t_k, s_k)$ , where  $g$  is a curve approximating the shortest geodesic, provided by a retraction and its inverse Set  $k = k+1$"},{"id":2471,"pagetitle":"Douglas‚ÄîRachford","title":"Result","ref":"/manopt/stable/solvers/DouglasRachford/#Result","content":" Result The result is given by the last computed  $p_K$ . For the parallel version, the first proximal map is a vectorial version where in each component one prox is applied to the corresponding copy of  $t_k$  and the second proximal map corresponds to the indicator function of the set, where all copies are equal (in  $\\mathcal H^n$ , where  $n$  is the number of copies), leading to the second prox being the Riemannian mean."},{"id":2472,"pagetitle":"Douglas‚ÄîRachford","title":"Interface","ref":"/manopt/stable/solvers/DouglasRachford/#Interface","content":" Interface"},{"id":2473,"pagetitle":"Douglas‚ÄîRachford","title":"Manopt.DouglasRachford","ref":"/manopt/stable/solvers/DouglasRachford/#Manopt.DouglasRachford","content":" Manopt.DouglasRachford  ‚Äî  Function DouglasRachford(M, f, proxes_f, p)\nDouglasRachford(M, mpo, p) Compute the Douglas-Rachford algorithm on the manifold  $\\mathcal M$ , initial data  $p$  and the (two) proximal maps  proxMaps , see [ BPS16 ]. For  $k>2$  proximal maps, the problem is reformulated using the parallel Douglas Rachford: a vectorial proximal map on the power manifold  $\\mathcal M^k$  is introduced as the first proximal map and the second proximal map of the is set to the  mean  (Riemannian Center of mass). This hence also boils down to two proximal maps, though each evaluates proximal maps in parallel, that is, component wise in a vector. If you provide a  ManifoldProximalMapObjective mpo  instead, the proximal maps are kept unchanged. Input M :        a Riemannian Manifold  $\\mathcal M$ F :        a cost function consisting of a sum of cost functions proxes_f : functions of the form  (M, Œª, p)-> q  performing a proximal maps, where  ‚Å†Œª  denotes the proximal parameter, for each of the summands of  F . These can also be given in the  InplaceEvaluation  variants  (M, q, Œª p) -> q  computing in place of  q . p :        initial data  $p ‚àà \\mathcal M$ Optional values evaluation :            ( AllocatingEvaluation ) specify whether the proximal maps work by allocation (default) form  prox(M, Œª, x)  or  InplaceEvaluation  in-place Œª :                     ( (iter) -> 1.0 ) function to provide the value for the proximal parameter during the calls Œ± :                     ( (iter) -> 0.9 ) relaxation of the step from old to new iterate, to be precise  $t_{k+1} = g(Œ±_k; t_k, s_k)$ , where  $s_k$  is the result of the double reflection involved in the DR algorithm inverse_retraction_method  - ( default_inverse_retraction_method(M, typeof(p)) ) the inverse retraction to use within the reflection (ignored, if you set  R  directly) the relaxation step R :                     method employed in the iteration to perform the reflection of  x  at the prox  p . This uses by default  reflect  or  reflect!  depending on  reflection_evaluation  and the retraction and inverse retraction specified by  retraction_method  and  inverse_retraction_method , respectively. reflection_evaluation : ( AllocatingEvaluation  whether  R  works in-place or allocating retraction_method :     ( default_retraction_metiod(M, typeof(p)) ) the retraction to use in the reflection (ignored, if you set  R  directly) the relaxation step stopping_criterion :    ( StopAfterIteration (200) | StopWhenChangeLess (1e-5) ) a  StoppingCriterion . parallel :              ( false ) indicate whether to use a parallel Douglas-Rachford or not. and the ones that are passed to  decorate_state!  for decorators. Output the obtained (approximate) minimizer  $p^*$ , see  get_solver_return  for details source DouglasRachford(M, f, proxes_f, p; kwargs...) a doc string with some math  $t_{k+1} = g(Œ±_k; t_k, s_k)$ source"},{"id":2474,"pagetitle":"Douglas‚ÄîRachford","title":"Manopt.DouglasRachford!","ref":"/manopt/stable/solvers/DouglasRachford/#Manopt.DouglasRachford!","content":" Manopt.DouglasRachford!  ‚Äî  Function  DouglasRachford!(M, f, proxes_f, p)\n DouglasRachford!(M, mpo, p) Compute the Douglas-Rachford algorithm on the manifold  $\\mathcal M$ , initial data  $p ‚àà \\mathcal M$  and the (two) proximal maps  proxes_f  in place of  p . For  $k>2$  proximal maps, the problem is reformulated using the parallel Douglas Rachford: a vectorial proximal map on the power manifold  $\\mathcal M^k$  is introduced as the first proximal map and the second proximal map of the is set to the  mean  (Riemannian Center of mass). This hence also boils down to two proximal maps, though each evaluates proximal maps in parallel, that is component wise in a vector. Note While creating the new staring point  p'  on the power manifold, a copy of  p  Is created, so that the (by k>2 implicitly generated) parallel Douglas Rachford does not work in-place for now. If you provide a  ManifoldProximalMapObjective mpo  instead, the proximal maps are kept unchanged. Input M :        a Riemannian Manifold  $\\mathcal M$ f :        a cost function consisting of a sum of cost functions proxes_f : functions of the form  (M, Œª, p)->q  or  (M, q, Œª, p)->q  performing a proximal map, where  ‚Å†Œª  denotes the proximal parameter, for each of the summands of  f . p :        initial point  $p ‚àà \\mathcal M$ For more options, see  DouglasRachford . source"},{"id":2475,"pagetitle":"Douglas‚ÄîRachford","title":"State","ref":"/manopt/stable/solvers/DouglasRachford/#State","content":" State"},{"id":2476,"pagetitle":"Douglas‚ÄîRachford","title":"Manopt.DouglasRachfordState","ref":"/manopt/stable/solvers/DouglasRachford/#Manopt.DouglasRachfordState","content":" Manopt.DouglasRachfordState  ‚Äî  Type DouglasRachfordState <: AbstractManoptSolverState Store all options required for the DouglasRachford algorithm, Fields p :                         the current iterate (result) For the parallel Douglas-Rachford, this is not a value from the  PowerManifold  manifold but the mean. s :                         the last result of the double reflection at the proximal maps relaxed by  Œ± . Œª :                         function to provide the value for the proximal parameter during the calls Œ± :                         relaxation of the step from old to new iterate, to be precise  $x^{(k+1)} = g(Œ±(k); x^{(k)}, t^{(k)})$ , where  $t^{(k)}$  is the result of the double reflection involved in the DR algorithm inverse_retraction_method : an inverse retraction method R :                          method employed in the iteration to perform the reflection of  x  at the prox  p . reflection_evaluation :     whether  R  works in-place or allocating retraction_method :         a retraction method stop :                      a  StoppingCriterion parallel :                  indicate whether to use a parallel Douglas-Rachford or not. Constructor DouglasRachfordState(M, p; kwargs...) Generate the options for a Manifold  M  and an initial point  p , where the following keyword arguments can be used Œª :                    ( (iter)->1.0 ) function to provide the value for the proximal parameter during the calls Œ± :                    ( (iter)->0.9 ) relaxation of the step from old to new iterate, to be precise  $x^{(k+1)} = g(Œ±(k); x^{(k)}, t^{(k)})$ , where  $t^{(k)}$  is the result of the double reflection involved in the DR algorithm R :                    ( reflect  or  reflect! ) method employed in the iteration to perform the reflection of  x  at the prox  p , which function is used depends on  reflection_evaluation . reflection_evaluation : ( AllocatingEvaluation () ) specify whether the reflection works in-place or allocating (default) stopping_criterion :   ( StopAfterIteration (300) ) a  StoppingCriterion parallel :             ( false ) indicate whether to use a parallel Douglas-Rachford or not. source For specific  DebugAction s and  RecordAction s see also  Cyclic Proximal Point . Furthermore, this solver has a short hand notation for the involved  reflect ion."},{"id":2477,"pagetitle":"Douglas‚ÄîRachford","title":"Manopt.reflect","ref":"/manopt/stable/solvers/DouglasRachford/#Manopt.reflect","content":" Manopt.reflect  ‚Äî  Function reflect(M, f, x; kwargs...)\nreflect!(M, q, f, x; kwargs...) reflect the point  x  from the manifold  M  at the point  f(x)  of the function  $f: \\mathcal M ‚Üí \\mathcal M$ , given by \\[    \\operatorname{refl}_f(x) = \\operatorname{refl}_{f(x)}(x),\\] Compute the result in  q . see also  reflect (M,p,x) , to which the keywords are also passed to. source reflect(M, p, x, kwargs...)\nreflect!(M, q, p, x, kwargs...) Reflect the point  x  from the manifold  M  at point  p , given by \\[    \\operatorname{refl}_p(x) = \\operatorname{retr}_p(-\\operatorname{retr}^{-1}_p x).\\] where  $\\operatorname{retr}$  and  $\\operatorname{retr}^{-1}$  denote a retraction and an inverse retraction, respectively. This can also be done in place of  q . Keyword arguments retraction_method :         ( default_retraction_metiod(M, typeof(p)) ) the retraction to use in the reflection inverse_retraction_method : ( default_inverse_retraction_method(M, typeof(p)) ) the inverse retraction to use within the reflection and for the  reflect!  additionally X :                         ( zero_vector(M,p) ) a temporary memory to compute the inverse retraction in place. otherwise this is the memory that would be allocated anyways. source"},{"id":2478,"pagetitle":"Douglas‚ÄîRachford","title":"Technical details","ref":"/manopt/stable/solvers/DouglasRachford/#sec-dr-technical-details","content":" Technical details The  DouglasRachford  solver requires the following functions of a manifold to be available A  retract! (M, q, p, X) ; it is recommended to set the  default_retraction_method  to a favourite retraction. If this default is set, a  retraction_method=  does not have to be specified. An  inverse_retract! (M, X, p, q) ; it is recommended to set the  default_inverse_retraction_method  to a favourite retraction. If this default is set, a  inverse_retraction_method=  does not have to be specified. A  `copyto! (M, q, p)  and  copy (M,p)  for points. By default, one of the stopping criteria is  StopWhenChangeLess , which requires An  inverse_retract! (M, X, p, q) ; it is recommended to set the  default_inverse_retraction_method  to a favourite retraction. If this default is set, a  inverse_retraction_method=  or  inverse_retraction_method_dual=  (for  $\\mathcal N$ ) does not have to be specified or the  distance (M, p, q)  for said default inverse retraction."},{"id":2479,"pagetitle":"Douglas‚ÄîRachford","title":"Literature","ref":"/manopt/stable/solvers/DouglasRachford/#Literature","content":" Literature"},{"id":2482,"pagetitle":"Frank-Wolfe","title":"Frank‚ÄîWolfe method","ref":"/manopt/stable/solvers/FrankWolfe/#Frank‚ÄîWolfe-method","content":" Frank‚ÄîWolfe method"},{"id":2483,"pagetitle":"Frank-Wolfe","title":"Manopt.Frank_Wolfe_method","ref":"/manopt/stable/solvers/FrankWolfe/#Manopt.Frank_Wolfe_method","content":" Manopt.Frank_Wolfe_method  ‚Äî  Function Frank_Wolfe_method(M, f, grad_f, p)\nFrank_Wolfe_method(M, gradient_objective, p; kwargs...) Perform the Frank-Wolfe algorithm to compute for  $\\mathcal C \\subset \\mathcal M$ \\[    \\operatorname*{arg\\,min}_{p‚àà\\mathcal C} f(p),\\] where the main step is a constrained optimisation is within the algorithm, that is the sub problem (Oracle) \\[    q_k = \\operatorname{arg\\,min}_{q ‚àà C} ‚ü®\\operatorname{grad} F(p_k), \\log_{p_k}q‚ü©.\\] for every iterate  $p_k$  together with a stepsize  $s_k‚â§1$ , by default  $s_k = \\frac{2}{k+2}$ . This algorithm is inspired by but slightly more general than [ WS22 ]. The next iterate is then given by  $p_{k+1} = Œ≥_{p_k,q_k}(s_k)$ , where by default  $Œ≥$  is the shortest geodesic between the two points but can also be changed to use a retraction and its inverse. Input M :      a manifold  $\\mathcal M$ f :      a cost function  $f: \\mathcal M‚Üí‚Ñù$  to find a minimizer  $p^*$  for grad_f : the gradient  $\\operatorname{grad}f: \\mathcal M ‚Üí T\\mathcal M$  of f p :      an initial value  $p ‚àà \\mathcal C$ , note that it really has to be a feasible point Alternatively to  f  and  grad_f  you can provide the  AbstractManifoldGradientObjective gradient_objective  directly. Keyword arguments evaluation :         ( AllocatingEvaluation ) whether  grad_f  is an in-place or allocating (default) function initial_vector :     ( zero_vectoir(M,p) ) how to initialize the inner gradient tangent vector stopping_criterion : ( StopAfterIteration (500) | StopWhenGradientNormLess (1.0e-6) ) a stopping criterion retraction_method :  ( default_retraction_method(M, typeof(p)) ) a type of retraction stepsize :           ( DecreasingStepsize (; length=2.0, shift=2)  a  Stepsize  to use; it has to be always less than 1. The default is the one proposed by Frank & Wolfe:  $s_k = \\frac{2}{k+2}$ . sub_cost :           ( FrankWolfeCost (p, initiel_vector) ) the cost of the Frank-Wolfe sub problem which by default uses the current iterate and (sub)gradient of the current iteration to define a default cost, this is used to define the default  sub_objective . It is ignored, if you set that or the  sub_problem  directly sub_grad :           ( FrankWolfeGradient (p, initial_vector) ) the gradient of the Frank-Wolfe sub problem which by default uses the current iterate and (sub)gradient of the current iteration to define a default gradient this is used to define the default  sub_objective . It is ignored, if you set that or the  sub_problem  directly sub_objective :      ( ManifoldGradientObjective (sub_cost, sub_gradient) ) the objective for the Frank-Wolfe sub problem this is used to define the default  sub_problem . It is ignored, if you set the  sub_problem  manually sub_problem :        ( DefaultManoptProblem (M, sub_objective) ) the Frank-Wolfe sub problem to solve. This can be given in three forms as an  AbstractManoptProblem , then the  sub_state  specifies the solver to use as a closed form solution, as a function evaluating with new allocations  (M, p, X) -> q  that solves the sub problem on  M  given the current iterate  p  and (sub)gradient  X . as a closed form solution, as a function  (M, q, p, X) -> q  working in place of  q . For points 2 and 3 the  sub_state  has to be set to the corresponding  AbstractEvaluationType ,  AllocatingEvaluation  and  InplaceEvaluation , respectively sub_state :          ( evaluation  if  sub_problem  is a function, a decorated  GradientDescentState  otherwise) for a function, the evaluation is inherited from the Frank-Wolfe  evaluation  keyword. sub_kwargs :         ( (;) ) keyword arguments to decorate the  sub_state  default state in case the  sub_problem  is not a function All other keyword arguments are passed to  decorate_state!  for decorators or  decorate_objective! , respectively. If you provide the  ManifoldGradientObjective  directly, these decorations can still be specified Output the obtained (approximate) minimizer  $p^*$ , see  get_solver_return  for details source"},{"id":2484,"pagetitle":"Frank-Wolfe","title":"Manopt.Frank_Wolfe_method!","ref":"/manopt/stable/solvers/FrankWolfe/#Manopt.Frank_Wolfe_method!","content":" Manopt.Frank_Wolfe_method!  ‚Äî  Function Frank_Wolfe_method!(M, f, grad_f, p; kwargs...)\nFrank_Wolfe_method!(M, gradient_objective, p; kwargs...) Perform the Frank Wolfe method in place of  p . For all options and keyword arguments, see  Frank_Wolfe_method . source"},{"id":2485,"pagetitle":"Frank-Wolfe","title":"State","ref":"/manopt/stable/solvers/FrankWolfe/#State","content":" State"},{"id":2486,"pagetitle":"Frank-Wolfe","title":"Manopt.FrankWolfeState","ref":"/manopt/stable/solvers/FrankWolfe/#Manopt.FrankWolfeState","content":" Manopt.FrankWolfeState  ‚Äî  Type FrankWolfeState <: AbstractManoptSolverState A struct to store the current state of the  Frank_Wolfe_method It comes in two forms, depending on the realisation of the  subproblem . Fields p :                         the current iterate, a point on the manifold X :                         the current gradient  $\\operatorname{grad} F(p)$ , a tangent vector to  p . inverse_retraction_method : ( default_inverse_retraction_method(M, typeof(p)) ) an inverse retraction method to use within Frank Wolfe. sub_problem :               an  AbstractManoptProblem  problem or a function  (M, p, X) -> q  or  (M, q, p, X)  for the a closed form solution of the sub problem sub_state :                 an  AbstractManoptSolverState  for the subsolver or an  AbstractEvaluationType  in case the sub problem is provided as a function stop :                      ( StopAfterIteration (200) | StopWhenGradientNormLess (1.0e-6) ) a  StoppingCriterion stepsize :                  ( DecreasingStepsize (; length=2.0, shift=2) )  $s_k$  which by default is set to  $s_k = \\frac{2}{k+2}$ . retraction_method :         ( default_retraction_method(M, typeof(p)) ) a retraction to use within Frank-Wolfe The sub task requires a method to solve \\[    \\operatorname*{argmin}_{q‚àà\\mathcal M} ‚ü®X, \\log_p q‚ü©,\\qquad \\text{ where }X=\\operatorname{grad} f(p)\\] Constructor FrankWolfeState(M, p, X, sub_problem, sub_state) where the remaining fields from before are keyword arguments. source"},{"id":2487,"pagetitle":"Frank-Wolfe","title":"Helpers","ref":"/manopt/stable/solvers/FrankWolfe/#Helpers","content":" Helpers For the inner sub-problem you can easily create the corresponding cost and gradient using"},{"id":2488,"pagetitle":"Frank-Wolfe","title":"Manopt.FrankWolfeCost","ref":"/manopt/stable/solvers/FrankWolfe/#Manopt.FrankWolfeCost","content":" Manopt.FrankWolfeCost  ‚Äî  Type FrankWolfeCost{P,T} A structure to represent the oracle sub problem in the  Frank_Wolfe_method . The cost function reads \\[F(q) = ‚ü®X, \\log_p q‚ü©\\] The values  p  and  X  are stored within this functor and should be references to the iterate and gradient from within  FrankWolfeState . source"},{"id":2489,"pagetitle":"Frank-Wolfe","title":"Manopt.FrankWolfeGradient","ref":"/manopt/stable/solvers/FrankWolfe/#Manopt.FrankWolfeGradient","content":" Manopt.FrankWolfeGradient  ‚Äî  Type FrankWolfeGradient{P,T} A structure to represent the gradient of the oracle sub problem in the  Frank_Wolfe_method , that is for a given point  p  and a tangent vector  X  the function reads \\[F(q) = ‚ü®X, \\log_p q‚ü©\\] Its gradient can be computed easily using  adjoint_differential_log_argument . The values  p  and  X  are stored within this functor and should be references to the iterate and gradient from within  FrankWolfeState . source [WS22] M.¬†Weber and S.¬†Sra.  Riemannian Optimization via Frank-Wolfe Methods .  Mathematical¬†Programming  199 , 525‚Äì556  (2022)."},{"id":2492,"pagetitle":"Levenberg‚ÄìMarquardt","title":"Levenberg-Marquardt","ref":"/manopt/stable/solvers/LevenbergMarquardt/#Levenberg-Marquardt","content":" Levenberg-Marquardt"},{"id":2493,"pagetitle":"Levenberg‚ÄìMarquardt","title":"Manopt.LevenbergMarquardt","ref":"/manopt/stable/solvers/LevenbergMarquardt/#Manopt.LevenbergMarquardt","content":" Manopt.LevenbergMarquardt  ‚Äî  Function LevenbergMarquardt(M, f, jacobian_f, p, num_components=-1) Solve an optimization problem of the form \\[\\operatorname{arg\\,min}_{p ‚àà \\mathcal M} \\frac{1}{2} \\lVert f(p) \\rVert^2,\\] where  $f: \\mathcal M ‚Üí ‚Ñù^d$  is a continuously differentiable function, using the Riemannian Levenberg-Marquardt algorithm [ Pee93 ]. The implementation follows Algorithm 1 [ AOT22 ] Input M :              a manifold  $\\mathcal M$ f :              a cost function  $f: \\mathcal M‚Üí‚Ñù^d$ jacobian_f :     the Jacobian of  $f$ . The Jacobian is supposed to accept a keyword argument  basis_domain  which specifies basis of the tangent space at a given point in which the Jacobian is to be calculated. By default it should be the  DefaultOrthonormalBasis . p :              an initial value  $p ‚àà \\mathcal M$ num_components : length of the vector returned by the cost function ( d ). By default its value is -1 which means that it is determined automatically by calling  f  one additional time. This is only possible when  evaluation  is  AllocatingEvaluation , for mutating evaluation this value must be explicitly specified. These can also be passed as a  NonlinearLeastSquaresObjective , then the keyword  jacobian_tangent_basis  below is ignored Optional evaluation :              ( AllocatingEvaluation ) specify whether the gradient works by allocation (default) form  gradF(M, x)  or  InplaceEvaluation  in place of the form  gradF!(M, X, x) . retraction_method :       ( default_retraction_method(M, typeof(p)) ) a  retraction(M,x,Œæ)  to use. stopping_criterion :      ( StopAfterIteration (200) | StopWhenGradientNormLess (1e-12) ) a functor inheriting from  StoppingCriterion  indicating when to stop. expect_zero_residual :    ( false ) whether or not the algorithm might expect that the value of residual (objective) at minimum is equal to 0. Œ∑ :                       scaling factor for the sufficient cost decrease threshold required to accept new proposal points. Allowed range:  0 < Œ∑ < 1 . damping_term_min :        initial (and also minimal) value of the damping term Œ≤ :                       parameter by which the damping term is multiplied when the current new point is rejected initial_residual_values : the initial residual vector of the cost function  f . initial_jacobian_f :      the initial Jacobian of the cost function  f . jacobian_tangent_basis :  an  AbstractBasis  specify the basis of the tangent space for  jacobian_f . All other keyword arguments are passed to  decorate_state!  for decorators or  decorate_objective! , respectively. If you provide the  ManifoldGradientObjective  directly, these decorations can still be specified Output the obtained (approximate) minimizer  $p^*$ , see  get_solver_return  for details References source"},{"id":2494,"pagetitle":"Levenberg‚ÄìMarquardt","title":"Manopt.LevenbergMarquardt!","ref":"/manopt/stable/solvers/LevenbergMarquardt/#Manopt.LevenbergMarquardt!","content":" Manopt.LevenbergMarquardt!  ‚Äî  Function LevenbergMarquardt!(M, f, jacobian_f, p, num_components=-1; kwargs...) For more options see  LevenbergMarquardt . source"},{"id":2495,"pagetitle":"Levenberg‚ÄìMarquardt","title":"Options","ref":"/manopt/stable/solvers/LevenbergMarquardt/#Options","content":" Options"},{"id":2496,"pagetitle":"Levenberg‚ÄìMarquardt","title":"Manopt.LevenbergMarquardtState","ref":"/manopt/stable/solvers/LevenbergMarquardt/#Manopt.LevenbergMarquardtState","content":" Manopt.LevenbergMarquardtState  ‚Äî  Type LevenbergMarquardtState{P,T} <: AbstractGradientSolverState Describes a Gradient based descent algorithm, with Fields A default value is given in brackets if a parameter can be left out in initialization. x :                     a point (of type  P ) on a manifold as starting point stop :                  ( StopAfterIteration(200) | StopWhenGradientNormLess(1e-12) | StopWhenStepsizeLess(1e-12) ) a  StoppingCriterion retraction_method :     ( default_retraction_method(M, typeof(p)) ) the retraction to use, defaults to the default set for your manifold. residual_values        value of  $F$  calculated in the solver setup or the previous iteration residual_values_temp   value of  $F$  for the current proposal point jacF                   the current Jacobian of  $F$ gradient               the current gradient of  $F$ step_vector            the tangent vector at  x  that is used to move to the next point last_stepsize          length of  step_vector Œ∑                      Scaling factor for the sufficient cost decrease threshold required to accept new proposal points. Allowed range:  0 < Œ∑ < 1 . damping_term           current value of the damping term damping_term_min       initial (and also minimal) value of the damping term Œ≤                      parameter by which the damping term is multiplied when the current new point is rejected expect_zero_residual :  ( false ) if true, the algorithm expects that the value of the residual (objective) at minimum is equal to 0. Constructor LevenbergMarquardtState(M, initialX, initial_residual_values, initial_jacF; initial_vector), kwargs...) Generate Levenberg-Marquardt options. See also gradient_descent ,  LevenbergMarquardt source"},{"id":2497,"pagetitle":"Levenberg‚ÄìMarquardt","title":"Technical details","ref":"/manopt/stable/solvers/LevenbergMarquardt/#sec-lm-technical-details","content":" Technical details The  LevenbergMarquardt  solver requires the following functions of a manifold to be available A  retract! (M, q, p, X) ; it is recommended to set the  default_retraction_method  to a favourite retraction. If this default is set, a  retraction_method=  does not have to be specified. the  norm  as well, to stop when the norm of the gradient is small, but if you implemented  inner , the norm is provided already. A  `copyto! (M, q, p)  and  copy (M,p)  for points."},{"id":2498,"pagetitle":"Levenberg‚ÄìMarquardt","title":"Literature","ref":"/manopt/stable/solvers/LevenbergMarquardt/#Literature","content":" Literature [AOT22] S.¬†Adachi, T.¬†Okuno and A.¬†Takeda.  Riemannian Levenberg-Marquardt Method with Global and Local Convergence Properties . ArXiv¬†Preprint (2022). [Pee93] R.¬†Peeters.  On a Riemannian version of the Levenberg-Marquardt algorithm . Serie Research Memoranda¬†0011 (VU University Amsterdam, Faculty of Economics, Business Administration and Econometrics, 1993)."},{"id":2501,"pagetitle":"Nelder‚ÄìMead","title":"Nelder Mead method","ref":"/manopt/stable/solvers/NelderMead/#sec-nelder-meadSolver","content":" Nelder Mead method"},{"id":2502,"pagetitle":"Nelder‚ÄìMead","title":"Manopt.NelderMead","ref":"/manopt/stable/solvers/NelderMead/#Manopt.NelderMead","content":" Manopt.NelderMead  ‚Äî  Function NelderMead(M::AbstractManifold, f)\nNelderMead(M::AbstractManifold, f, population::NelderMeadSimplex)\nNelderMead(M::AbstractManifold, mco::AbstractManifoldCostObjective)\nNelderMead(M::AbstractManifold, mco::AbstractManifoldCostObjective, population::NelderMeadSimplex) Solve a Nelder-Mead minimization problem for the cost function  $f:  \\mathcal M$  on the manifold  M . If the initial population  p  is not given, a random set of points is chosen. This algorithm is adapted from the Euclidean Nelder-Mead method, see  https://en.wikipedia.org/wiki/Nelder-Mead_method  and  http://www.optimization-online.org/DB_FILE/2007/08/1742.pdf . Input M :            a manifold  $\\mathcal M$ f :            a cost function to minimize population :   ( $n+1$ rand(M) s) an initial population of  $n+1$  points, where  $n$  is the dimension of the manifold  M . Optional stopping_criterion :        ( StopAfterIteration (2000) | StopWhenPopulationConcentrated () ) a  StoppingCriterion Œ± :                         ( 1. ) reflection parameter ( $Œ± > 0$ ) Œ≥ :                         ( 2. ) expansion parameter ( $Œ≥$ ) œÅ :                         ( 1/2 ) contraction parameter,  $0 < œÅ ‚â§ \\frac{1}{2}$ , œÉ :                         ( 1/2 ) shrink coefficient,  $0 < œÉ ‚â§ 1$ retraction_method :         ( default_retraction_method(M, typeof(p)) ) the retraction to use inverse_retraction_method : ( default_inverse_retraction_method(M, typeof(p)) ) an inverse retraction to use. and the ones that are passed to  decorate_state!  for decorators. Note The manifold  M  used here has to either provide a  mean(M, pts)  or you have to load  Manifolds.jl  to use its statistics part. Output the obtained (approximate) minimizer  $p^*$ , see  get_solver_return  for details source"},{"id":2503,"pagetitle":"Nelder‚ÄìMead","title":"Manopt.NelderMead!","ref":"/manopt/stable/solvers/NelderMead/#Manopt.NelderMead!","content":" Manopt.NelderMead!  ‚Äî  Function NelderMead(M::AbstractManifold, f [, population::NelderMeadSimplex]) Solve a Nelder Mead minimization problem for the cost function  f  on the manifold  M . If the initial population  population  is not given, a random set of points is chosen. If it is given, the computation is done in place of  population . For more options see  NelderMead . source"},{"id":2504,"pagetitle":"Nelder‚ÄìMead","title":"State","ref":"/manopt/stable/solvers/NelderMead/#State","content":" State"},{"id":2505,"pagetitle":"Nelder‚ÄìMead","title":"Manopt.NelderMeadState","ref":"/manopt/stable/solvers/NelderMead/#Manopt.NelderMeadState","content":" Manopt.NelderMeadState  ‚Äî  Type NelderMeadState <: AbstractManoptSolverState Describes all parameters and the state of a Nelder-Mead heuristic based optimization algorithm. Fields The naming of these parameters follows the  Wikipedia article  of the Euclidean case. The default is given in brackets, the required value range after the description population                 an  Array{ point ,1}  of  $n+1$  points  $x_i$ ,  $i=1,‚Ä¶,n+1$ , where  $n$  is the dimension of the manifold. stopping_criterion :        ( StopAfterIteration (2000) | StopWhenPopulationConcentrated () ) a  StoppingCriterion Œ± :                         ( 1. ) reflection parameter ( $Œ± > 0$ ) Œ≥ :                         ( 2. ) expansion parameter ( $Œ≥ > 0$ ) œÅ :                         ( 1/2 ) contraction parameter,  $0 < œÅ ‚â§ \\frac{1}{2}$ , œÉ :                         ( 1/2 ) shrink coefficient,  $0 < œÉ ‚â§ 1$ p :                         ( copy(population.pts[1]) ) - a field to collect the current best value (initialized to  some  point here) retraction_method :         ( default_retraction_method(M, typeof(p)) ) the retraction to use. inverse_retraction_method : ( default_inverse_retraction_method(M, typeof(p)) ) an inverse retraction to use. Constructors NelderMeadState(M[, population::NelderMeadSimplex]; kwargs...) Construct a Nelder-Mead Option with a default population (if not provided) of set of  dimension(M)+1  random points stored in  NelderMeadSimplex . In the constructor all fields (besides the population) are keyword arguments. source"},{"id":2506,"pagetitle":"Nelder‚ÄìMead","title":"Simplex","ref":"/manopt/stable/solvers/NelderMead/#Simplex","content":" Simplex"},{"id":2507,"pagetitle":"Nelder‚ÄìMead","title":"Manopt.NelderMeadSimplex","ref":"/manopt/stable/solvers/NelderMead/#Manopt.NelderMeadSimplex","content":" Manopt.NelderMeadSimplex  ‚Äî  Type NelderMeadSimplex A simplex for the Nelder-Mead algorithm. Constructors NelderMeadSimplex(M::AbstractManifold) Construct a  simplex using  $n+1$  random points from manifold  M , where  $n$  is the manifold dimension of  M . NelderMeadSimplex(\n    M::AbstractManifold,\n    p,\n    B::AbstractBasis=DefaultOrthonormalBasis();\n    a::Real=0.025,\n    retraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)),\n) Construct a simplex from a basis  B  with one point being  p  and other points constructed by moving by  a  in each principal direction defined by basis  B  of the tangent space at point  p  using retraction  retraction_method . This works similarly to how the initial simplex is constructed in the Euclidean Nelder-Mead algorithm, just in the tangent space at point  p . source"},{"id":2508,"pagetitle":"Nelder‚ÄìMead","title":"Additional stopping criteria","ref":"/manopt/stable/solvers/NelderMead/#Additional-stopping-criteria","content":" Additional stopping criteria"},{"id":2509,"pagetitle":"Nelder‚ÄìMead","title":"Manopt.StopWhenPopulationConcentrated","ref":"/manopt/stable/solvers/NelderMead/#Manopt.StopWhenPopulationConcentrated","content":" Manopt.StopWhenPopulationConcentrated  ‚Äî  Type StopWhenPopulationConcentrated <: StoppingCriterion A stopping criterion for  NelderMead  to indicate to stop when both the maximal distance of the first to the remaining the cost values and the maximal distance of the first to the remaining the population points drops below a certain tolerance  tol_f  and  tol_p , respectively. Constructor StopWhenPopulationConcentrated(tol_f::Real=1e-8, tol_x::Real=1e-8) source"},{"id":2510,"pagetitle":"Nelder‚ÄìMead","title":"Technical details","ref":"/manopt/stable/solvers/NelderMead/#Technical-details","content":" Technical details The  NelderMead  solver requires the following functions of a manifold to be available A  retract! (M, q, p, X) ; it is recommended to set the  default_retraction_method  to a favourite retraction. If this default is set, a  retraction_method=  does not have to be specified. An  inverse_retract! (M, X, p, q) ; it is recommended to set the  default_inverse_retraction_method  to a favourite retraction. If this default is set, a  inverse_retraction_method=  does not have to be specified. The  distance (M, p, q)  when using the default stopping criterion, which includes  StopWhenPopulationConcentrated . Within the default initialization  rand (M)  is used to generate the initial population A  mean (M, population)  has to be available, for example by loading  Manifolds.jl  and its  statistics  tools"},{"id":2513,"pagetitle":"Adaptive Regularization with Cubics","title":"Adaptive regularization with cubics","ref":"/manopt/stable/solvers/adaptive-regularization-with-cubics/#Adaptive-regularization-with-cubics","content":" Adaptive regularization with cubics"},{"id":2514,"pagetitle":"Adaptive Regularization with Cubics","title":"Manopt.adaptive_regularization_with_cubics","ref":"/manopt/stable/solvers/adaptive-regularization-with-cubics/#Manopt.adaptive_regularization_with_cubics","content":" Manopt.adaptive_regularization_with_cubics  ‚Äî  Function adaptive_regularization_with_cubics(M, f, grad_f, Hess_f, p=rand(M); kwargs...)\nadaptive_regularization_with_cubics(M, f, grad_f, p=rand(M); kwargs...)\nadaptive_regularization_with_cubics(M, mho, p=rand(M); kwargs...) Solve an optimization problem on the manifold  M  by iteratively minimizing \\[  m_k(X) = f(p_k) + ‚ü®X, \\operatorname{grad} f(p_k)‚ü© + \\frac{1}{2}‚ü®X, \\operatorname{Hess} f(p_k)[X]‚ü© + \\frac{œÉ_k}{3}\\lVert X \\rVert^3\\] on the tangent space at the current iterate  $p_k$ , where  $X ‚àà T_{p_k}\\mathcal M$  and  $œÉ_k > 0$  is a regularization parameter. Let  $X_k$  denote the minimizer of the model  $m_k$  and use the model improvement \\[  œÅ_k = \\frac{f(p_k) - f(\\operatorname{retr}_{p_k}(X_k))}{m_k(0) - m_k(X_k) + \\frac{œÉ_k}{3}\\lVert X_k\\rVert^3}.\\] With two thresholds  $Œ∑_2 ‚â• Œ∑_1 > 0$  set  $p_{k+1} = \\operatorname{retr}_{p_k}(X_k)$  if  $œÅ ‚â• Œ∑_1$  and reject the candidate otherwise, that is, set  $p_{k+1} = p_k$ . Further update the regularization parameter using factors  $0 < Œ≥_1 < 1 < Œ≥_2$ \\[œÉ_{k+1} =\n\\begin{cases}\n    \\max\\{œÉ_{\\min}, Œ≥_1œÉ_k\\} & \\text{ if } œÅ \\geq Œ∑_2 &\\text{   (the model was very successful)},\\\\\n    œÉ_k & \\text{ if } œÅ ‚àà [Œ∑_1, Œ∑_2)&\\text{   (the model was successful)},\\\\\n    Œ≥_2œÉ_k & \\text{ if } œÅ < Œ∑_1&\\text{   (the model was unsuccessful)}.\n\\end{cases}\\] For more details see [ ABBC20 ]. Input M :      a manifold  $\\mathcal M$ f :      a cost function  $F: \\mathcal M ‚Üí ‚Ñù$  to minimize grad_f : the gradient  $\\operatorname{grad}F: \\mathcal M ‚Üí T \\mathcal M$  of  $F$ Hess_f : (optional) the Hessian  $H( \\mathcal M, x, Œæ)$  of  $F$ p :      an initial value  $p ‚àà \\mathcal M$ For the case that no Hessian is provided, the Hessian is computed using finite difference, see  ApproxHessianFiniteDifference . the cost  f  and its gradient and Hessian might also be provided as a  ManifoldHessianObjective Keyword arguments the default values are given in brackets œÉ :                      ( 100.0 / sqrt(manifold_dimension(M) ) initial regularization parameter œÉmin :                   ( 1e-10 ) minimal regularization value  $œÉ_{\\min}$ Œ∑1 :                     ( 0.1 ) lower model success threshold Œ∑2 :                     ( 0.9 ) upper model success threshold Œ≥1 :                     ( 0.1 ) regularization reduction factor (for the success case) Œ≥2 :                     ( 2.0 ) regularization increment factor (for the non-success case) evaluation :             ( AllocatingEvaluation ) specify whether the gradient works by allocation (default) form  grad_f(M, p)  or  InplaceEvaluation  in place, that is of the form  grad_f!(M, X, p)  and analogously for the Hessian. retraction_method :      ( default_retraction_method(M, typeof(p)) ) a retraction to use initial_tangent_vector : ( zero_vector(M, p) ) initialize any tangent vector data, maxIterLanczos :         ( 200 ) a shortcut to set the stopping criterion in the sub solver, œÅ_regularization :       ( 1e3 ) a regularization to avoid dividing by zero for small values of cost and model stopping_criterion :     ( StopAfterIteration (40) | StopWhenGradientNormLess (1e-9) | StopWhenAllLanczosVectorsUsed (maxIterLanczos) ) sub_state :               LanczosState (M, copy(M, p); maxIterLanczos=maxIterLanczos, œÉ=œÉ) a state for the subproblem or an [ AbstractEvaluationType`](@ref) if the problem is a function. sub_objective :          a shortcut to modify the objective of the subproblem used within in the sub_problem :             DefaultManoptProblem (M, sub_objective)  the problem (or a function) for the sub problem All other keyword arguments are passed to  decorate_state!  for state decorators or  decorate_objective!  for objective, respectively. If you provide the  ManifoldGradientObjective  directly, these decorations can still be specified By default the  debug=  keyword is set to  DebugIfEntry (:œÅ_denominator, >(0); message=\"Denominator nonpositive\", type=:error)  to avoid that by rounding errors the denominator in the computation of  œÅ  gets nonpositive. source"},{"id":2515,"pagetitle":"Adaptive Regularization with Cubics","title":"Manopt.adaptive_regularization_with_cubics!","ref":"/manopt/stable/solvers/adaptive-regularization-with-cubics/#Manopt.adaptive_regularization_with_cubics!","content":" Manopt.adaptive_regularization_with_cubics!  ‚Äî  Function adaptive_regularization_with_cubics!(M, f, grad_f, Hess_f, p; kwargs...)\nadaptive_regularization_with_cubics!(M, f, grad_f, p; kwargs...)\nadaptive_regularization_with_cubics!(M, mho, p; kwargs...) evaluate the Riemannian adaptive regularization with cubics solver in place of  p . Input M :      a manifold  $\\mathcal M$ f :      a cost function  $F: \\mathcal M ‚Üí ‚Ñù$  to minimize grad_f : the gradient  $\\operatorname{grad}F: \\mathcal M ‚Üí T \\mathcal M$  of  $F$ Hess_f : (optional) the Hessian  $H( \\mathcal M, x, Œæ)$  of  $F$ p :      an initial value  $p  ‚àà  \\mathcal M$ For the case that no Hessian is provided, the Hessian is computed using finite difference, see  ApproxHessianFiniteDifference . the cost  f  and its gradient and Hessian might also be provided as a  ManifoldHessianObjective for more details and all options, see  adaptive_regularization_with_cubics . source"},{"id":2516,"pagetitle":"Adaptive Regularization with Cubics","title":"State","ref":"/manopt/stable/solvers/adaptive-regularization-with-cubics/#State","content":" State"},{"id":2517,"pagetitle":"Adaptive Regularization with Cubics","title":"Manopt.AdaptiveRegularizationState","ref":"/manopt/stable/solvers/adaptive-regularization-with-cubics/#Manopt.AdaptiveRegularizationState","content":" Manopt.AdaptiveRegularizationState  ‚Äî  Type AdaptiveRegularizationState{P,T} <: AbstractHessianSolverState A state for the  adaptive_regularization_with_cubics  solver. Fields a default value is given in brackets if a parameter can be left out in initialization. Œ∑1 ,  Œ∑2 :           ( 0.1 ,  0.9 ) bounds for evaluating the regularization parameter Œ≥1 ,  Œ≥2 :           ( 0.1 ,  2.0 ) shrinking and expansion factors for regularization parameter  œÉ p :                  ( rand(M)  the current iterate X :                  ( zero_vector(M,p) ) the current gradient  $\\operatorname{grad}f(p)$ s :                  ( zero_vector(M,p) ) the tangent vector step resulting from minimizing the model problem in the tangent space  $\\mathcal T_{p} \\mathcal M$ œÉ :                  the current cubic regularization parameter œÉmin :               ( 1e-7 ) lower bound for the cubic regularization parameter œÅ_regularization :   ( 1e3 ) regularization parameter for computing œÅ. When approaching convergence œÅ may be difficult to compute with numerator and denominator approaching zero.  Regularizing the ratio lets œÅ go to 1 near convergence. evaluation :         ( AllocatingEvaluation() ) if you provide a retraction_method :  ( default_retraction_method(M) ) the retraction to use stopping_criterion : ( StopAfterIteration (100) ) a  StoppingCriterion sub_problem :        sub problem solved in each iteration sub_state :          sub state for solving the sub problem, either a solver state if the problem is an  AbstractManoptProblem  or an  AbstractEvaluationType  if it is a function, where it defaults to  AllocatingEvaluation . Furthermore the following integral fields are defined q :                  ( copy(M,p) ) a point for the candidates to evaluate model and œÅ H :                  ( copy(M, p, X) ) the current Hessian,  $\\operatorname{Hess}F(p)[‚ãÖ]$ S :                  ( copy(M, p, X) ) the current solution from the subsolver œÅ :                  the current regularized ratio of actual improvement and model improvement. œÅ_denominator :      ( one(œÅ) ) a value to store the denominator from the computation of œÅ to allow for a warning or error when this value is non-positive. Constructor AdaptiveRegularizationState(M, p=rand(M); X=zero_vector(M, p); kwargs...) Construct the solver state with all fields stated as keyword arguments. source"},{"id":2518,"pagetitle":"Adaptive Regularization with Cubics","title":"Sub solvers","ref":"/manopt/stable/solvers/adaptive-regularization-with-cubics/#Sub-solvers","content":" Sub solvers There are several ways to approach the subsolver. The default is the first one."},{"id":2519,"pagetitle":"Adaptive Regularization with Cubics","title":"Lanczos iteration","ref":"/manopt/stable/solvers/adaptive-regularization-with-cubics/#Lanczos-iteration","content":" Lanczos iteration"},{"id":2520,"pagetitle":"Adaptive Regularization with Cubics","title":"Manopt.LanczosState","ref":"/manopt/stable/solvers/adaptive-regularization-with-cubics/#Manopt.LanczosState","content":" Manopt.LanczosState  ‚Äî  Type LanczosState{P,T,SC,B,I,R,TM,V,Y} <: AbstractManoptSolverState Solve the adaptive regularized subproblem with a Lanczos iteration Fields stop :            the stopping criterion œÉ :               the current regularization parameter X :               the Iterate Lanczos_vectors : the obtained Lanczos vectors tridig_matrix :   the tridiagonal coefficient matrix T coefficients :    the coefficients  $y_1,...y_k$  that determine the solution Hp :              a temporary vector containing the evaluation of the Hessian Hp_residual :     a temporary vector containing the residual to the Hessian S :               the current obtained / approximated solution source"},{"id":2521,"pagetitle":"Adaptive Regularization with Cubics","title":"(Conjugate) gradient descent","ref":"/manopt/stable/solvers/adaptive-regularization-with-cubics/#(Conjugate)-gradient-descent","content":" (Conjugate) gradient descent There is a generic objective, that implements the sub problem"},{"id":2522,"pagetitle":"Adaptive Regularization with Cubics","title":"Manopt.AdaptiveRagularizationWithCubicsModelObjective","ref":"/manopt/stable/solvers/adaptive-regularization-with-cubics/#Manopt.AdaptiveRagularizationWithCubicsModelObjective","content":" Manopt.AdaptiveRagularizationWithCubicsModelObjective  ‚Äî  Type AdaptiveRagularizationWithCubicsModelObjective A model for the adaptive regularization with Cubics \\[m(X) = f(p) + ‚ü®\\operatorname{grad} f(p), X ‚ü©_p + \\frac{1}{2} ‚ü®\\operatorname{Hess} f(p)[X], X‚ü©_p\n       +  \\frac{œÉ}{3} \\lVert X \\rVert^3,\\] cf. Eq. (33) in [ ABBC20 ] Fields objective : an  AbstractManifoldHessianObjective  proving  $f$ , its gradient and Hessian œÉ :         the current (cubic) regularization parameter Constructors AdaptiveRagularizationWithCubicsModelObjective(mho, œÉ=1.0) with either an  AbstractManifoldHessianObjective objective  or an decorator containing such an objective. source Since the sub problem is given on the tangent space, you have to provide arc_obj = AdaptiveRagularizationWithCubicsModelObjective(mho, œÉ)\nsub_problem = DefaultProblem(TangentSpaceAt(M,p), arc_obj) where  mho  is the Hessian objective of  f  to solve. Then use this for the  sub_problem  keyword and use your favourite gradient based solver for the  sub_state  keyword, for example a  ConjugateGradientDescentState"},{"id":2523,"pagetitle":"Adaptive Regularization with Cubics","title":"Additional stopping criteria","ref":"/manopt/stable/solvers/adaptive-regularization-with-cubics/#Additional-stopping-criteria","content":" Additional stopping criteria"},{"id":2524,"pagetitle":"Adaptive Regularization with Cubics","title":"Manopt.StopWhenAllLanczosVectorsUsed","ref":"/manopt/stable/solvers/adaptive-regularization-with-cubics/#Manopt.StopWhenAllLanczosVectorsUsed","content":" Manopt.StopWhenAllLanczosVectorsUsed  ‚Äî  Type StopWhenAllLanczosVectorsUsed <: StoppingCriterion When an inner iteration has used up all Lanczos vectors, then this stopping criterion is a fallback / security stopping criterion to not access a non-existing field in the array allocated for vectors. Note that this stopping criterion (for now) is only implemented for the case that an  AdaptiveRegularizationState  when using a  LanczosState  subsolver Fields maxLanczosVectors : maximal number of Lanczos vectors reason :            a String indicating the reason if the criterion indicated to stop Constructor StopWhenAllLanczosVectorsUsed(maxLancosVectors::Int) source"},{"id":2525,"pagetitle":"Adaptive Regularization with Cubics","title":"Manopt.StopWhenFirstOrderProgress","ref":"/manopt/stable/solvers/adaptive-regularization-with-cubics/#Manopt.StopWhenFirstOrderProgress","content":" Manopt.StopWhenFirstOrderProgress  ‚Äî  Type StopWhenFirstOrderProgress <: StoppingCriterion A stopping criterion related to the Riemannian adaptive regularization with cubics (ARC) solver indicating that the model function at the current (outer) iterate, \\[    m(X) = f(p) + <X, \\operatorname{grad}f(p)>\n      + \\frac{1}{2} <X, \\operatorname{Hess} f(p)[X]> +  \\frac{œÉ}{3} \\lVert X \\rVert^3,\\] defined on the tangent space  $T_{p}\\mathcal M$  fulfills at the current iterate  $X_k$  that \\[m(X_k) \\leq m(0)\n\\quad\\text{ and }\\quad\n\\lVert \\operatorname{grad} m(X_k) \\rVert ‚â§ Œ∏ \\lVert X_k \\rVert^2\\] Fields Œ∏ :      the factor  $Œ∏$  in the second condition reason : a String indicating the reason if the criterion indicated to stop source"},{"id":2526,"pagetitle":"Adaptive Regularization with Cubics","title":"Technical details","ref":"/manopt/stable/solvers/adaptive-regularization-with-cubics/#sec-arc-technical-details","content":" Technical details The  adaptive_regularization_with_cubics  requires the following functions of a manifolds to be available A  retract! (M, q, p, X) ; it is recommended to set the  default_retraction_method  to a favourite retraction. If this default is set, a  retraction_method=  does not have to be specified. if you do not provide an initial regularization parameter  œÉ , a  manifold_dimension  is required. By default the tangent vector storing the gradient is initialized calling  zero_vector (M,p) . inner (M, p, X, Y)  is used within the algorithm step Furthermore, within the Lanczos subsolver, generating a random vector (at  p ) using  rand! (M, X; vector_at=p) in place of X` is required"},{"id":2527,"pagetitle":"Adaptive Regularization with Cubics","title":"Literature","ref":"/manopt/stable/solvers/adaptive-regularization-with-cubics/#Literature","content":" Literature [ABBC20] N.¬†Agarwal, N.¬†Boumal, B.¬†Bullins and C.¬†Cartis.  Adaptive regularization with cubics on manifolds .  Mathematical¬†Programming  (2020)."},{"id":2530,"pagetitle":"Alternating Gradient Descent","title":"Alternating gradient descent","ref":"/manopt/stable/solvers/alternating_gradient_descent/#solver-alternating-gradient-descent","content":" Alternating gradient descent"},{"id":2531,"pagetitle":"Alternating Gradient Descent","title":"Manopt.alternating_gradient_descent","ref":"/manopt/stable/solvers/alternating_gradient_descent/#Manopt.alternating_gradient_descent","content":" Manopt.alternating_gradient_descent  ‚Äî  Function alternating_gradient_descent(M::ProductManifold, f, grad_f, p=rand(M))\nalternating_gradient_descent(M::ProductManifold, ago::ManifoldAlternatingGradientObjective, p) perform an alternating gradient descent Input M :      the product manifold  $\\mathcal M = \\mathcal M_1 √ó \\mathcal M_2 √ó ‚ãØ √ó\\mathcal M_n$ f :      the objective function (cost) defined on  M . grad_f : a gradient, that can be of two cases is a single function returning an  ArrayPartition  or is a vector functions each returning a component part of the whole gradient p :      an initial value  $p_0 ‚àà \\mathcal M$ Optional evaluation :         ( AllocatingEvaluation ) specify whether the gradients work by allocation (default) form  gradF(M, x)  or  InplaceEvaluation  in place of the form  gradF!(M, X, x)  (elementwise). evaluation_order :   ( :Linear ) whether to use a randomly permuted sequence ( :FixedRandom ), a per cycle permuted sequence ( :Random ) or the default  :Linear  one. inner_iterations :   ( 5 ) how many gradient steps to take in a component before alternating to the next stopping_criterion : ( StopAfterIteration (1000) ) a  StoppingCriterion stepsize :           ( ArmijoLinesearch () ) a  Stepsize order :              ( [1:n] ) the initial permutation, where  n  is the number of gradients in  gradF . retraction_method :  ( default_retraction_method(M, typeof(p)) ) a  retraction(M, p, X)  to use. Output usually the obtained (approximate) minimizer, see  get_solver_return  for details Note The input of each of the (component) gradients is still the whole vector  X , just that all other then the  i th input component are assumed to be fixed and just the  i th components gradient is computed / returned. source"},{"id":2532,"pagetitle":"Alternating Gradient Descent","title":"Manopt.alternating_gradient_descent!","ref":"/manopt/stable/solvers/alternating_gradient_descent/#Manopt.alternating_gradient_descent!","content":" Manopt.alternating_gradient_descent!  ‚Äî  Function alternating_gradient_descent!(M::ProductManifold, f, grad_f, p)\nalternating_gradient_descent!(M::ProductManifold, ago::ManifoldAlternatingGradientObjective, p) perform a alternating gradient descent in place of  p . Input M :      a product manifold  $\\mathcal M$ f :      the objective functioN (cost) grad_f : a gradient function, that either returns a vector of the subgradients or is a vector of gradients p :      an initial value  $p_0 ‚àà \\mathcal M$ you can also pass a  ManifoldAlternatingGradientObjective ago  containing  f  and  grad_f  instead. for all optional parameters, see  alternating_gradient_descent . source"},{"id":2533,"pagetitle":"Alternating Gradient Descent","title":"State","ref":"/manopt/stable/solvers/alternating_gradient_descent/#State","content":" State"},{"id":2534,"pagetitle":"Alternating Gradient Descent","title":"Manopt.AlternatingGradientDescentState","ref":"/manopt/stable/solvers/alternating_gradient_descent/#Manopt.AlternatingGradientDescentState","content":" Manopt.AlternatingGradientDescentState  ‚Äî  Type AlternatingGradientDescentState <: AbstractGradientDescentSolverState Store the fields for an alternating gradient descent algorithm, see also  alternating_gradient_descent . Fields direction :          ( AlternatingGradient(zero_vector(M, x))  a  DirectionUpdateRule evaluation_order :   ( :Linear ) whether to use a randomly permuted sequence ( :FixedRandom ), a per cycle newly permuted sequence ( :Random ) or the default  :Linear  evaluation order. inner_iterations :   ( 5 ) how many gradient steps to take in a component before alternating to the next order  the current permutation retraction_method :  ( default_retraction_method(M, typeof(p)) ) a  retraction(M,x,Œæ)  to use. stepsize :           ( ConstantStepsize (M) ) a  Stepsize stopping_criterion : ( StopAfterIteration (1000) ) a  StoppingCriterion p :                  the current iterate X :                  ( zero_vector(M,p) ) the current gradient tangent vector k , √¨`:              internal counters for the outer and inner iterations, respectively. Constructors AlternatingGradientDescentState(M, p; kwargs...) Generate the options for point  p  and where  inner_iterations ,  order_type ,  order ,  retraction_method ,  stopping_criterion , and  stepsize ` are keyword arguments source Additionally, the options share a  DirectionUpdateRule , which chooses the current component, so they can be decorated further; The most inner one should always be the following one though."},{"id":2535,"pagetitle":"Alternating Gradient Descent","title":"Manopt.AlternatingGradient","ref":"/manopt/stable/solvers/alternating_gradient_descent/#Manopt.AlternatingGradient","content":" Manopt.AlternatingGradient  ‚Äî  Type AlternatingGradient <: DirectionUpdateRule The default gradient processor, which just evaluates the (alternating) gradient on one of the components source"},{"id":2536,"pagetitle":"Alternating Gradient Descent","title":"Technical details","ref":"/manopt/stable/solvers/alternating_gradient_descent/#sec-agd-technical-details","content":" Technical details The  alternating_gradient_descent  solver requires the following functions of a manifold to be available The problem has to be phrased on a  ProductManifold , to be able to alternate between parts of the input. A  retract! (M, q, p, X) ; it is recommended to set the  default_retraction_method  to a favourite retraction. If this default is set, a  retraction_method=  does not have to be specified. By default alternating gradient descent uses  ArmijoLinesearch  which requires  max_stepsize (M)  to be set and an implementation of  inner (M, p, X) . By default the tangent vector storing the gradient is initialized calling  zero_vector (M,p) ."},{"id":2539,"pagetitle":"Augmented Lagrangian Method","title":"Augmented Lagrangian method","ref":"/manopt/stable/solvers/augmented_Lagrangian_method/#Augmented-Lagrangian-method","content":" Augmented Lagrangian method"},{"id":2540,"pagetitle":"Augmented Lagrangian Method","title":"Manopt.augmented_Lagrangian_method","ref":"/manopt/stable/solvers/augmented_Lagrangian_method/#Manopt.augmented_Lagrangian_method","content":" Manopt.augmented_Lagrangian_method  ‚Äî  Function augmented_Lagrangian_method(M, f, grad_f, p=rand(M); kwargs...)\naugmented_Lagrangian_method(M, cmo::ConstrainedManifoldObjective, p=rand(M); kwargs...) perform the augmented Lagrangian method (ALM) [ LB19 ]. The aim of the ALM is to find the solution of the constrained optimisation task \\[\\begin{aligned}\n\\min_{p ‚àà\\mathcal{M}} &f(p)\\\\\n\\text{subject to } &g_i(p)\\leq 0 \\quad \\text{ for } i= 1, ‚Ä¶, m,\\\\\n\\quad &h_j(p)=0 \\quad \\text{ for } j=1,‚Ä¶,n,\n\\end{aligned}\\] where  M  is a Riemannian manifold, and  $f$ ,  $\\{g_i\\}_{i=1}^m$  and  $\\{h_j\\}_{j=1}^p$  are twice continuously differentiable functions from  M  to ‚Ñù. In every step  $k$  of the algorithm, the  AugmentedLagrangianCost $\\mathcal{L}_{œÅ^{(k-1)}}(p, Œº^{(k-1)}, Œª^{(k-1)})$  is minimized on  $\\mathcal{M}$ , where  $Œº^{(k-1)} ‚àà \\mathbb R^n$  and  $Œª^{(k-1)} ‚àà ‚Ñù^m$  are the current iterates of the Lagrange multipliers and  $œÅ^{(k-1)}$  is the current penalty parameter. The Lagrange multipliers are then updated by \\[Œª_j^{(k)} =\\operatorname{clip}_{[Œª_{\\min},Œª_{\\max}]} (Œª_j^{(k-1)} + œÅ^{(k-1)} h_j(p^{(k)})) \\text{for all} j=1,‚Ä¶,p,\\] and \\[Œº_i^{(k)} =\\operatorname{clip}_{[0,Œº_{\\max}]} (Œº_i^{(k-1)} + œÅ^{(k-1)} g_i(p^{(k)})) \\text{ for all } i=1,‚Ä¶,m,\\] where  $Œª_{\\min} \\leq Œª_{\\max}$  and  $Œº_{\\max}$  are the multiplier boundaries. Next, the accuracy tolerance  $œµ$  is updated as \\[œµ^{(k)}=\\max\\{œµ_{\\min}, Œ∏_œµ œµ^{(k-1)}\\},\\] where  $œµ_{\\min}$  is the lowest value  $œµ$  is allowed to become and  $Œ∏_œµ ‚àà (0,1)$  is constant scaling factor. Last, the penalty parameter  $œÅ$  is updated as follows: with \\[œÉ^{(k)}=\\max_{j=1,‚Ä¶,p, i=1,‚Ä¶,m} \\{\\|h_j(p^{(k)})\\|, \\|\\max_{i=1,‚Ä¶,m}\\{g_i(p^{(k)}), -\\frac{Œº_i^{(k-1)}}{œÅ^{(k-1)}} \\}\\| \\}.\\] œÅ  is updated as \\[œÅ^{(k)} = \\begin{cases}\nœÅ^{(k-1)}/Œ∏_œÅ,  & \\text{if } œÉ^{(k)}\\leq Œ∏_œÅ œÉ^{(k-1)} ,\\\\\nœÅ^{(k-1)}, & \\text{else,}\n\\end{cases}\\] where  $Œ∏_œÅ ‚àà (0,1)$  is a constant scaling factor. Input M       a manifold  $\\mathcal M$ f       a cost function  $F:\\mathcal M‚Üí‚Ñù$  to minimize grad_f  the gradient of the cost function Optional (if not called with the  ConstrainedManifoldObjective cmo ) g :      ( nothing ) the inequality constraints h :      ( nothing ) the equality constraints grad_g : ( nothing ) the gradient of the inequality constraints grad_h : ( nothing ) the gradient of the equality constraints Note that one of the pairs ( g ,  grad_g ) or ( h ,  grad_h ) has to be provided. Otherwise the problem is not constrained and a better solver would be for example  quasi_Newton . Optional œµ :                      ( 1e-3 ) the accuracy tolerance œµ_min :                  ( 1e-6 ) the lower bound for the accuracy tolerance œµ_exponent :             ( 1/100 ) exponent of the œµ update factor;  also 1/number of iterations until maximal accuracy is needed to end algorithm naturally Œ∏_œµ :                    ( (œµ_min / œµ)^(œµ_exponent) ) the scaling factor of the exactness Œº :                      ( ones(size(h(M,x),1)) ) the Lagrange multiplier with respect to the inequality constraints Œº_max :                  ( 20.0 ) an upper bound for the Lagrange multiplier belonging to the inequality constraints Œª :                      ( ones(size(h(M,x),1)) ) the Lagrange multiplier with respect to the equality constraints Œª_max :                  ( 20.0 ) an upper bound for the Lagrange multiplier belonging to the equality constraints Œª_min :                  ( - Œª_max ) a lower bound for the Lagrange multiplier belonging to the equality constraints œÑ :                      ( 0.8 ) factor for the improvement of the evaluation of the penalty parameter œÅ :                      ( 1.0 ) the penalty parameter Œ∏_œÅ :                    ( 0.3 ) the scaling factor of the penalty parameter sub_cost :               ( AugmentedLagrangianCost (problem, œÅ, Œº, Œª) ) use augmented Lagrangian, especially with the same numbers  œÅ,Œº  as in the options for the sub problem sub_grad :               ( AugmentedLagrangianGrad (problem, œÅ, Œº, Œª) ) use augmented Lagrangian gradient, especially with the same numbers  œÅ,Œº  as in the options for the sub problem sub_kwargs :             keyword arguments to decorate the sub options, for example the  debug=  keyword. sub_stopping_criterion : ( StopAfterIteration (200) | StopWhenGradientNormLess (œµ) | StopWhenStepsizeLess (1e-8) ) specify a stopping criterion for the subsolver. sub_problem :            ( DefaultManoptProblem (M, ConstrainedManifoldObjective (subcost, subgrad; evaluation=evaluation)) ) problem for the subsolver sub_state :              ( QuasiNewtonState ) using  QuasiNewtonLimitedMemoryDirectionUpdate  with  InverseBFGS  and  sub_stopping_criterion  as a stopping criterion. See also  sub_kwargs . stopping_criterion :     ( StopAfterIteration (300)  | ( StopWhenSmallerOrEqual (œµ, œµ_min)  &  StopWhenChangeLess (1e-10)) ) a functor inheriting from  StoppingCriterion  indicating when to stop. Output the obtained (approximate) minimizer  $p^*$ , see  get_solver_return  for details source"},{"id":2541,"pagetitle":"Augmented Lagrangian Method","title":"Manopt.augmented_Lagrangian_method!","ref":"/manopt/stable/solvers/augmented_Lagrangian_method/#Manopt.augmented_Lagrangian_method!","content":" Manopt.augmented_Lagrangian_method!  ‚Äî  Function augmented_Lagrangian_method!(M, f, grad_f, p=rand(M); kwargs...) perform the augmented Lagrangian method (ALM) in-place of  p . For all options, see  augmented_Lagrangian_method . source"},{"id":2542,"pagetitle":"Augmented Lagrangian Method","title":"State","ref":"/manopt/stable/solvers/augmented_Lagrangian_method/#State","content":" State"},{"id":2543,"pagetitle":"Augmented Lagrangian Method","title":"Manopt.AugmentedLagrangianMethodState","ref":"/manopt/stable/solvers/augmented_Lagrangian_method/#Manopt.AugmentedLagrangianMethodState","content":" Manopt.AugmentedLagrangianMethodState  ‚Äî  Type AugmentedLagrangianMethodState{P,T} <: AbstractManoptSolverState Describes the augmented Lagrangian method, with Fields a default value is given in brackets if a parameter can be left out in initialization. p :                  a point on a manifold as starting point and current iterate sub_problem :        an  AbstractManoptProblem  problem for the subsolver sub_state :          an  AbstractManoptSolverState  for the subsolver œµ :                  ( 1e‚Äì3 ) the accuracy tolerance œµ_min :              ( 1e-6 ) the lower bound for the accuracy tolerance Œª :                  ( ones(len( get_equality_constraints (p,x)) ) the Lagrange multiplier with respect to the equality constraints Œª_max :              ( 20.0 ) an upper bound for the Lagrange multiplier belonging to the equality constraints Œª_min :              ( - Œª_max ) a lower bound for the Lagrange multiplier belonging to the equality constraints Œº :                  ( ones(len( get_inequality_constraints (p,x)) ) the Lagrange multiplier with respect to the inequality constraints Œº_max :              ( 20.0 ) an upper bound for the Lagrange multiplier belonging to the inequality constraints œÅ :                  ( 1.0 ) the penalty parameter œÑ :                  ( 0.8 ) factor for the improvement of the evaluation of the penalty parameter Œ∏_œÅ :                ( 0.3 ) the scaling factor of the penalty parameter Œ∏_œµ :                (( (œµ_min/œµ)^(œµ_exponent) ) the scaling factor of the accuracy tolerance penalty :            evaluation of the current penalty term, initialized to  Inf . stopping_criterion : ( ( StopAfterIteration (300) | ( StopWhenSmallerOrEqual (œµ, œµ_min) & StopWhenChangeLess (1e-10)) ) a functor inheriting from  StoppingCriterion  indicating when to stop. Constructor AugmentedLagrangianMethodState(M::AbstractManifold, co::ConstrainedManifoldObjective, p; kwargs...) construct an augmented Lagrangian method options with the fields and defaults as stated before, where the manifold  M  and the  ConstrainedManifoldObjective co  can be helpful for manifold- or objective specific defaults. See also augmented_Lagrangian_method source"},{"id":2544,"pagetitle":"Augmented Lagrangian Method","title":"Helping functions","ref":"/manopt/stable/solvers/augmented_Lagrangian_method/#Helping-functions","content":" Helping functions"},{"id":2545,"pagetitle":"Augmented Lagrangian Method","title":"Manopt.AugmentedLagrangianCost","ref":"/manopt/stable/solvers/augmented_Lagrangian_method/#Manopt.AugmentedLagrangianCost","content":" Manopt.AugmentedLagrangianCost  ‚Äî  Type AugmentedLagrangianCost{CO,R,T} Stores the parameters  $œÅ ‚àà ‚Ñù$ ,  $Œº ‚àà ‚Ñù^m$ ,  $Œª ‚àà ‚Ñù^n$  of the augmented Lagrangian associated to the  ConstrainedManifoldObjective co . This struct is also a functor  (M,p) -> v  that can be used as a cost function within a solver, based on the internal  ConstrainedManifoldObjective  it computes \\[\\mathcal L_\\rho(p, Œº, Œª)\n= f(x) + \\frac{œÅ}{2} \\biggl(\n    \\sum_{j=1}^n \\Bigl( h_j(p) + \\frac{Œª_j}{œÅ} \\Bigr)^2\n    +\n    \\sum_{i=1}^m \\max\\Bigl\\{ 0, \\frac{Œº_i}{œÅ} + g_i(p) \\Bigr\\}^2\n\\Bigr)\\] Fields co::CO ,  œÅ::R ,  Œº::T ,  Œª::T  as mentioned in the formula, where  $R$  should be the number type used and  $T$  the vector type. Constructor AugmentedLagrangianCost(co, œÅ, Œº, Œª) source"},{"id":2546,"pagetitle":"Augmented Lagrangian Method","title":"Manopt.AugmentedLagrangianGrad","ref":"/manopt/stable/solvers/augmented_Lagrangian_method/#Manopt.AugmentedLagrangianGrad","content":" Manopt.AugmentedLagrangianGrad  ‚Äî  Type AugmentedLagrangianGrad{CO,R,T} Stores the parameters  $œÅ ‚àà ‚Ñù$ ,  $Œº ‚àà ‚Ñù^m$ ,  $Œª ‚àà ‚Ñù^n$  of the augmented Lagrangian associated to the  ConstrainedManifoldObjective co . This struct is also a functor in both formats (M, p) -> X  to compute the gradient in allocating fashion. (M, X, p)  to compute the gradient in in-place fashion. based on the internal  ConstrainedManifoldObjective  and computes the gradient  $\\operatorname{grad} \\mathcal L_{œÅ}(p, Œº, Œª)$ , see also  AugmentedLagrangianCost . Fields co::CO ,  œÅ::R ,  Œº::T ,  Œª::T  as mentioned in the formula, where  $R$  should be the number type used and  $T$  the vector type. Constructor AugmentedLagrangianGrad(co, œÅ, Œº, Œª) source"},{"id":2547,"pagetitle":"Augmented Lagrangian Method","title":"Technical details","ref":"/manopt/stable/solvers/augmented_Lagrangian_method/#sec-agd-technical-details","content":" Technical details The  augmented_Lagrangian_method  solver requires the following functions of a manifold to be available A  `copyto! (M, q, p)  and  copy (M,p)  for points. Everything the subsolver requires, which by default is the  quasi_Newton  method A  zero_vector (M,p) ."},{"id":2548,"pagetitle":"Augmented Lagrangian Method","title":"Literature","ref":"/manopt/stable/solvers/augmented_Lagrangian_method/#Literature","content":" Literature [LB19] C.¬†Liu and N.¬†Boumal.  Simple algorithms for optimization on Riemannian manifolds with constraints .  Applied¬†Mathematics¬†&¬†Optimization  (2019),  arXiv:1091.10000 ."},{"id":2551,"pagetitle":"Conjugate gradient descent","title":"Conjugate gradient descent","ref":"/manopt/stable/solvers/conjugate_gradient_descent/#Conjugate-gradient-descent","content":" Conjugate gradient descent"},{"id":2552,"pagetitle":"Conjugate gradient descent","title":"Manopt.conjugate_gradient_descent","ref":"/manopt/stable/solvers/conjugate_gradient_descent/#Manopt.conjugate_gradient_descent","content":" Manopt.conjugate_gradient_descent  ‚Äî  Function conjugate_gradient_descent(M, F, gradF, p=rand(M))\nconjugate_gradient_descent(M, gradient_objective, p) perform a conjugate gradient based descent \\[p_{k+1} = \\operatorname{retr}_{p_k} \\bigl( s_kŒ¥_k \\bigr),\\] where  $\\operatorname{retr}$  denotes a retraction on the  Manifold M  and one can employ different rules to update the descent direction  $Œ¥_k$  based on the last direction  $Œ¥_{k-1}$  and both gradients  $\\operatorname{grad}f(x_k)$ , $\\operatorname{grad}f(x_{k-1})$ . The  Stepsize $s_k$  may be determined by a  Linesearch . Alternatively to  f  and  grad_f  you can provide the  AbstractManifoldGradientObjective gradient_objective  directly. Available update rules are  SteepestDirectionUpdateRule , which yields a  gradient_descent ,  ConjugateDescentCoefficient  (the default),  DaiYuanCoefficient ,  FletcherReevesCoefficient ,  HagerZhangCoefficient ,  HestenesStiefelCoefficient ,  LiuStoreyCoefficient , and  PolakRibiereCoefficient . These can all be combined with a  ConjugateGradientBealeRestart  rule. They all compute  $Œ≤_k$  such that this algorithm updates the search direction as \\[\\delta_k=\\operatorname{grad}f(p_k) + Œ≤_k \\delta_{k-1}\\] Input M       a manifold  $\\mathcal M$ f       a cost function  $F:\\mathcal M‚Üí‚Ñù$  to minimize implemented as a function  (M,p) -> v grad_f  the gradient  $\\operatorname{grad}F:\\mathcal M ‚Üí T\\mathcal M$  of  $F$  implemented also as  (M,x) -> X p       an initial value  $x‚àà\\mathcal M$ Optional coefficient :             ( ConjugateDescentCoefficient <: DirectionUpdateRule ) rule to compute the descent direction update coefficient  $Œ≤_k$ , as a functor, where the resulting function maps are  (amp, cgs, i) -> Œ≤  with  amp  an  AbstractManoptProblem ,  cgs  is the  ConjugateGradientDescentState , and  i  is the current iterate. evaluation :              ( AllocatingEvaluation ) specify whether the gradient works by allocation (default) form  gradF(M, x)  or  InplaceEvaluation  in place of the form  gradF!(M, X, x) . retraction_method : ( default_retraction_method(M, typeof(p)) ) a retraction method to use. stepsize :                ( ArmijoLinesearch  via  default_stepsize ) A  Stepsize  function applied to the search direction. The default is a constant step size 1. stopping_criterion :      ( stopWhenAny( stopAtIteration(200), stopGradientNormLess(10.0^-8)) ) a function indicating when to stop. vector_transport_method : ( default_vector_transport_method(M, typeof(p)) ) vector transport method to transport the old descent direction when computing the new descent direction. If you provide the  ManifoldGradientObjective  directly,  evaluation  is ignored. Output the obtained (approximate) minimizer  $p^*$ , see  get_solver_return  for details source"},{"id":2553,"pagetitle":"Conjugate gradient descent","title":"Manopt.conjugate_gradient_descent!","ref":"/manopt/stable/solvers/conjugate_gradient_descent/#Manopt.conjugate_gradient_descent!","content":" Manopt.conjugate_gradient_descent!  ‚Äî  Function conjugate_gradient_descent!(M, F, gradF, x)\nconjugate_gradient_descent!(M, gradient_objective, p; kwargs...) perform a conjugate gradient based descent in place of  x  as \\[p_{k+1} = \\operatorname{retr}_{p_k} \\bigl( s_k\\delta_k \\bigr),\\] where  $\\operatorname{retr}$  denotes a retraction on the  Manifold M Input M :      a manifold  $\\mathcal M$ f :      a cost function  $F:\\mathcal M‚Üí‚Ñù$  to minimize grad_f : the gradient  $\\operatorname{grad}F:\\mathcal M‚Üí T\\mathcal M$  of F p :      an initial value  $p‚àà\\mathcal M$ Alternatively to  f  and  grad_f  you can provide the  AbstractManifoldGradientObjective gradient_objective  directly. for more details and options, especially the  DirectionUpdateRule s, see  conjugate_gradient_descent . source"},{"id":2554,"pagetitle":"Conjugate gradient descent","title":"State","ref":"/manopt/stable/solvers/conjugate_gradient_descent/#State","content":" State"},{"id":2555,"pagetitle":"Conjugate gradient descent","title":"Manopt.ConjugateGradientDescentState","ref":"/manopt/stable/solvers/conjugate_gradient_descent/#Manopt.ConjugateGradientDescentState","content":" Manopt.ConjugateGradientDescentState  ‚Äî  Type ConjugateGradientState <: AbstractGradientSolverState specify options for a conjugate gradient descent algorithm, that solves a [ DefaultManoptProblem ]. Fields p :                       the current iterate, a point on a manifold X :                       the current gradient, also denoted as  $Œæ$  or  $X_k$  for the gradient in the  $k$ th step. Œ¥ :                       the current descent direction, also a tangent vector Œ≤ :                       the current update coefficient rule, see . coefficient :             ( ConjugateDescentCoefficient () ) a  DirectionUpdateRule  function to determine the new  Œ≤ stepsize :                ( default_stepsize (M, ConjugateGradientDescentState; retraction_method=retraction_method) ) a  Stepsize  function stop :                    ( StopAfterIteration (500) | StopWhenGradientNormLess (1e-8) ) a  StoppingCriterion retraction_method :       ( default_retraction_method(M, typeof(p)) ) a type of retraction vector_transport_method : ( default_retraction_method(M, typeof(p)) ) a type of retraction Constructor ConjugateGradientState(M, p) where the last five fields can be set by their names as keyword and the  X  can be set to a tangent vector type using the keyword  initial_gradient  which defaults to  zero_vector(M,p) , and  Œ¥  is initialized to a copy of this vector. See also conjugate_gradient_descent ,  DefaultManoptProblem ,  ArmijoLinesearch source"},{"id":2556,"pagetitle":"Conjugate gradient descent","title":"Available coefficients","ref":"/manopt/stable/solvers/conjugate_gradient_descent/#cg-coeffs","content":" Available coefficients The update rules act as  DirectionUpdateRule , which internally always first evaluate the gradient itself."},{"id":2557,"pagetitle":"Conjugate gradient descent","title":"Manopt.ConjugateGradientBealeRestart","ref":"/manopt/stable/solvers/conjugate_gradient_descent/#Manopt.ConjugateGradientBealeRestart","content":" Manopt.ConjugateGradientBealeRestart  ‚Äî  Type ConjugateGradientBealeRestart <: DirectionUpdateRule An update rule might require a restart, that is using pure gradient as descent direction, if the last two gradients are nearly orthogonal, see [ HZ06 , page 12] (in the preprint, page 46 in Journal page numbers). This method is named after E. Beale from his proceedings paper in 1972 [ Bea72 ]. This method acts as a  decorator  to any existing  DirectionUpdateRule direction_update . When obtain from the  ConjugateGradientDescentState cgs  the last  $p_k,X_k$  and the current  $p_{k+1},X_{k+1}$  iterate and the gradient, respectively. Then a restart is performed, hence  $Œ≤_k = 0$  returned if \\[    \\frac{ ‚ü®X_{k+1}, P_{p_{k+1}\\gets p_k}X_k‚ü©}{\\lVert X_k \\rVert_{p_k}} > Œæ,\\] where  $P_{a\\gets b}(‚ãÖ)$  denotes a vector transport from the tangent space at  $a$  to  $b$ , and  $Œæ$  is the  threshold . The default threshold is chosen as  0.2  as recommended in [ Pow77 ] Constructor ConjugateGradientBealeRestart(\n    direction_update::D,\n    threshold=0.2;\n    manifold::AbstractManifold = DefaultManifold(),\n    vector_transport_method::V=default_vector_transport_method(manifold),\n) source"},{"id":2558,"pagetitle":"Conjugate gradient descent","title":"Manopt.ConjugateDescentCoefficient","ref":"/manopt/stable/solvers/conjugate_gradient_descent/#Manopt.ConjugateDescentCoefficient","content":" Manopt.ConjugateDescentCoefficient  ‚Äî  Type ConjugateDescentCoefficient <: DirectionUpdateRule Computes an update coefficient for the conjugate gradient method, where the  ConjugateGradientDescentState cgds  include the last iterates  $p_k,X_k$ , the current iterates  $p_{k+1},X_{k+1}$  of the iterate and the gradient, respectively, and the last update direction  $\\delta=\\delta_k$ ,  based on [ Fle87 ] adapted to manifolds: \\[Œ≤_k =\n\\frac{ \\lVert X_{k+1} \\rVert_{p_{k+1}}^2 }\n{\\langle -\\delta_k,X_k \\rangle_{p_k}}.\\] See also  conjugate_gradient_descent Constructor ConjugateDescentCoefficient(a::StoreStateAction=()) Construct the conjugate descent coefficient update rule, a new storage is created by default. source"},{"id":2559,"pagetitle":"Conjugate gradient descent","title":"Manopt.DaiYuanCoefficient","ref":"/manopt/stable/solvers/conjugate_gradient_descent/#Manopt.DaiYuanCoefficient","content":" Manopt.DaiYuanCoefficient  ‚Äî  Type DaiYuanCoefficient <: DirectionUpdateRule Computes an update coefficient for the conjugate gradient method, where the  ConjugateGradientDescentState cgds  include the last iterates  $p_k,X_k$ , the current iterates  $p_{k+1},X_{k+1}$  of the iterate and the gradient, respectively, and the last update direction  $\\delta=\\delta_k$ , based on [ DY99 ] adapted to manifolds: Let  $\\nu_k = X_{k+1} - P_{p_{k+1}\\gets p_k}X_k$ , where  $P_{a\\gets b}(‚ãÖ)$  denotes a vector transport from the tangent space at  $a$  to  $b$ . Then the coefficient reads \\[Œ≤_k =\n\\frac{ \\lVert X_{k+1} \\rVert_{p_{k+1}}^2 }\n{\\langle P_{p_{k+1}\\gets p_k}\\delta_k, \\nu_k \\rangle_{p_{k+1}}}.\\] See also  conjugate_gradient_descent Constructor function DaiYuanCoefficient(\n    M::AbstractManifold=DefaultManifold(2);\n    t::AbstractVectorTransportMethod=default_vector_transport_method(M)\n) Construct the Dai‚ÄîYuan coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default. source"},{"id":2560,"pagetitle":"Conjugate gradient descent","title":"Manopt.FletcherReevesCoefficient","ref":"/manopt/stable/solvers/conjugate_gradient_descent/#Manopt.FletcherReevesCoefficient","content":" Manopt.FletcherReevesCoefficient  ‚Äî  Type FletcherReevesCoefficient <: DirectionUpdateRule Computes an update coefficient for the conjugate gradient method, where the  ConjugateGradientDescentState cgds  include the last iterates  $p_k,X_k$ , the current iterates  $p_{k+1},X_{k+1}$  of the iterate and the gradient, respectively, and the last update direction  $\\delta=\\delta_k$ ,  based on [ FR64 ] adapted to manifolds: \\[Œ≤_k =\n\\frac{\\lVert X_{k+1}\\rVert_{p_{k+1}}^2}{\\lVert X_k\\rVert_{x_{k}}^2}.\\] See also  conjugate_gradient_descent Constructor FletcherReevesCoefficient(a::StoreStateAction=()) Construct the Fletcher‚ÄîReeves coefficient update rule, a new storage is created by default. source"},{"id":2561,"pagetitle":"Conjugate gradient descent","title":"Manopt.HagerZhangCoefficient","ref":"/manopt/stable/solvers/conjugate_gradient_descent/#Manopt.HagerZhangCoefficient","content":" Manopt.HagerZhangCoefficient  ‚Äî  Type HagerZhangCoefficient <: DirectionUpdateRule Computes an update coefficient for the conjugate gradient method, where the  ConjugateGradientDescentState cgds  include the last iterates  $p_k,X_k$ , the current iterates  $p_{k+1},X_{k+1}$  of the iterate and the gradient, respectively, and the last update direction  $\\delta=\\delta_k$ , based on [ HZ05 ]. adapted to manifolds: let  $\\nu_k = X_{k+1} - P_{p_{k+1}\\gets p_k}X_k$ , where  $P_{a\\gets b}(‚ãÖ)$  denotes a vector transport from the tangent space at  $a$  to  $b$ . \\[Œ≤_k = \\Bigl\\langle\\nu_k -\n\\frac{ 2\\lVert \\nu_k\\rVert_{p_{k+1}}^2 }{ \\langle P_{p_{k+1}\\gets p_k}\\delta_k, \\nu_k \\rangle_{p_{k+1}} }\nP_{p_{k+1}\\gets p_k}\\delta_k,\n\\frac{X_{k+1}}{ \\langle P_{p_{k+1}\\gets p_k}\\delta_k, \\nu_k \\rangle_{p_{k+1}} }\n\\Bigr\\rangle_{p_{k+1}}.\\] This method includes a numerical stability proposed by those authors. See also  conjugate_gradient_descent Constructor function HagerZhangCoefficient(t::AbstractVectorTransportMethod)\nfunction HagerZhangCoefficient(M::AbstractManifold = DefaultManifold(2)) Construct the Hager Zhang coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default. source"},{"id":2562,"pagetitle":"Conjugate gradient descent","title":"Manopt.HestenesStiefelCoefficient","ref":"/manopt/stable/solvers/conjugate_gradient_descent/#Manopt.HestenesStiefelCoefficient","content":" Manopt.HestenesStiefelCoefficient  ‚Äî  Type HestenesStiefelCoefficient <: DirectionUpdateRule Computes an update coefficient for the conjugate gradient method, where the  ConjugateGradientDescentState cgds  include the last iterates  $p_k,X_k$ , the current iterates  $p_{k+1},X_{k+1}$  of the iterate and the gradient, respectively, and the last update direction  $\\delta=\\delta_k$ ,  based on [ HS52 ] adapted to manifolds as follows: Let  $\\nu_k = X_{k+1} - P_{p_{k+1}\\gets p_k}X_k$ . Then the update reads \\[Œ≤_k = \\frac{\\langle X_{k+1}, \\nu_k \\rangle_{p_{k+1}} }\n    { \\langle P_{p_{k+1}\\gets p_k} \\delta_k, \\nu_k\\rangle_{p_{k+1}} },\\] where  $P_{a\\gets b}(‚ãÖ)$  denotes a vector transport from the tangent space at  $a$  to  $b$ . Constructor function HestenesStiefelCoefficient(transport_method::AbstractVectorTransportMethod)\nfunction HestenesStiefelCoefficient(M::AbstractManifold = DefaultManifold(2)) Construct the Heestens Stiefel coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default. See also  conjugate_gradient_descent source"},{"id":2563,"pagetitle":"Conjugate gradient descent","title":"Manopt.LiuStoreyCoefficient","ref":"/manopt/stable/solvers/conjugate_gradient_descent/#Manopt.LiuStoreyCoefficient","content":" Manopt.LiuStoreyCoefficient  ‚Äî  Type LiuStoreyCoefficient <: DirectionUpdateRule Computes an update coefficient for the conjugate gradient method, where the  ConjugateGradientDescentState cgds  include the last iterates  $p_k,X_k$ , the current iterates  $p_{k+1},X_{k+1}$  of the iterate and the gradient, respectively, and the last update direction  $\\delta=\\delta_k$ ,  based on [ LS91 ] adapted to manifolds: Let  $\\nu_k = X_{k+1} - P_{p_{k+1}\\gets p_k}X_k$ , where  $P_{a\\gets b}(‚ãÖ)$  denotes a vector transport from the tangent space at  $a$  to  $b$ . Then the coefficient reads \\[Œ≤_k = -\n\\frac{ \\langle X_{k+1},\\nu_k \\rangle_{p_{k+1}} }\n{\\langle \\delta_k,X_k \\rangle_{p_k}}.\\] See also  conjugate_gradient_descent Constructor function LiuStoreyCoefficient(t::AbstractVectorTransportMethod)\nfunction LiuStoreyCoefficient(M::AbstractManifold = DefaultManifold(2)) Construct the Lui Storey coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default. source"},{"id":2564,"pagetitle":"Conjugate gradient descent","title":"Manopt.PolakRibiereCoefficient","ref":"/manopt/stable/solvers/conjugate_gradient_descent/#Manopt.PolakRibiereCoefficient","content":" Manopt.PolakRibiereCoefficient  ‚Äî  Type PolakRibiereCoefficient <: DirectionUpdateRule Computes an update coefficient for the conjugate gradient method, where the  ConjugateGradientDescentState cgds  include the last iterates  $p_k,X_k$ , the current iterates  $p_{k+1},X_{k+1}$  of the iterate and the gradient, respectively, and the last update direction  $\\delta=\\delta_k$ ,  based on [ PR69 ] and [ Pol69 ] adapted to manifolds: Let  $\\nu_k = X_{k+1} - P_{p_{k+1}\\gets p_k}X_k$ , where  $P_{a\\gets b}(‚ãÖ)$  denotes a vector transport from the tangent space at  $a$  to  $b$ . Then the update reads \\[Œ≤_k =\n\\frac{ \\langle X_{k+1}, \\nu_k \\rangle_{p_{k+1}} }\n{\\lVert X_k \\rVert_{p_k}^2 }.\\] Constructor function PolakRibiereCoefficient(\n    M::AbstractManifold=DefaultManifold(2);\n    t::AbstractVectorTransportMethod=default_vector_transport_method(M)\n) Construct the PolakRibiere coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default. See also  conjugate_gradient_descent source"},{"id":2565,"pagetitle":"Conjugate gradient descent","title":"Manopt.SteepestDirectionUpdateRule","ref":"/manopt/stable/solvers/conjugate_gradient_descent/#Manopt.SteepestDirectionUpdateRule","content":" Manopt.SteepestDirectionUpdateRule  ‚Äî  Type SteepestDirectionUpdateRule <: DirectionUpdateRule The simplest rule to update is to have no influence of the last direction and hence return an update  $Œ≤ = 0$  for all  ConjugateGradientDescentState cgds See also  conjugate_gradient_descent source"},{"id":2566,"pagetitle":"Conjugate gradient descent","title":"Technical details","ref":"/manopt/stable/solvers/conjugate_gradient_descent/#sec-cgd-technical-details","content":" Technical details The  conjugate_gradient_descent  solver requires the following functions of a manifold to be available A  retract! (M, q, p, X) ; it is recommended to set the  default_retraction_method  to a favourite retraction. If this default is set, a  retraction_method=  does not have to be specified. A  vector_transport_to! M, Y, p, X, q) ; it is recommended to set the  default_vector_transport_method  to a favourite retraction. If this default is set, a  vector_transport_method=  or  vector_transport_method_dual=  (for  $\\mathcal N$ ) does not have to be specified. By default gradient descent uses  ArmijoLinesearch  which requires  max_stepsize (M)  to be set and an implementation of  inner (M, p, X) . By default the stopping criterion uses the  norm  as well, to stop when the norm of the gradient is small, but if you implemented  inner , the norm is provided already. By default the tangent vector storing the gradient is initialized calling  zero_vector (M,p) ."},{"id":2567,"pagetitle":"Conjugate gradient descent","title":"Literature","ref":"/manopt/stable/solvers/conjugate_gradient_descent/#Literature","content":" Literature [Bea72] E.¬†M.¬†Beale.  A derivation of conjugate gradients . In:  Numerical methods for nonlinear optimization , edited by F.¬†A.¬†Lootsma (Academic Press, London, London, 1972); pp.¬†39‚Äì43. [DY99] Y.¬†H.¬†Dai and Y.¬†Yuan.  A Nonlinear Conjugate Gradient Method with a Strong Global Convergence Property .  SIAM¬†Journal¬†on¬†Optimization  10 , 177‚Äì182  (1999). [Fle87] R.¬†Fletcher.  Practical Methods of Optimization . 2¬†Edition,  A Wiley-Interscience Publication  (John Wiley & Sons Ltd., 1987). [FR64] R.¬†Fletcher and C.¬†M.¬†Reeves.  Function minimization by conjugate gradients .  The¬†Computer¬†Journal  7 , 149‚Äì154  (1964). [HZ06] W.¬†W.¬†Hager and H.¬†Zhang.  A survey of nonlinear conjugate gradient methods . Pacific¬†Journal¬†of¬†Optimization  2 , 35‚Äì58 (2006). [HZ05] W.¬†W.¬†Hager and H.¬†Zhang.  A New Conjugate Gradient Method with Guaranteed Descent and an Efficient Line Search .  SIAM¬†Journal¬†on¬†Optimization  16 , 170‚Äì192  (2005). [HS52] M.¬†Hestenes and E.¬†Stiefel.  Methods of conjugate gradients for solving linear systems .  Journal¬†of¬†Research¬†of¬†the¬†National¬†Bureau¬†of¬†Standards  49 , 409  (1952). [LS91] Y.¬†Liu and C.¬†Storey.  Efficient generalized conjugate gradient algorithms,  part 1: Theory .  Journal¬†of¬†Optimization¬†Theory¬†and¬†Applications  69 , 129‚Äì137  (1991). [PR69] E.¬†Polak and G.¬†Ribi√®re.  Note sur la convergence de m√©thodes de directions conjugu√©es .  Revue¬†fran√ßaise¬†d‚Äôinformatique¬†et¬†de¬†recherche¬†op√©rationnelle  3 , 35‚Äì43  (1969). [Pol69] B.¬†T.¬†Polyak.  The conjugate gradient method in extremal problems .  USSR¬†Computational¬†Mathematics¬†and¬†Mathematical¬†Physics  9 , 94‚Äì112  (1969). [Pow77] M.¬†J.¬†Powell.  Restart procedures for the conjugate gradient method .  Mathematical¬†Programming  12 , 241‚Äì254  (1977)."},{"id":2570,"pagetitle":"Convex bundle method","title":"Convex Bundle Method","ref":"/manopt/stable/solvers/convex_bundle_method/#ConvexBundleMethodSolver","content":" Convex Bundle Method"},{"id":2571,"pagetitle":"Convex bundle method","title":"Manopt.convex_bundle_method","ref":"/manopt/stable/solvers/convex_bundle_method/#Manopt.convex_bundle_method","content":" Manopt.convex_bundle_method  ‚Äî  Function convex_bundle_method(M, f, ‚àÇf, p) perform a convex bundle method  $p_{j+1} = \\mathrm{retr}(p_k, -g_k)$ , where  $\\mathrm{retr}$  is a retraction and \\[g_k = \\sum_{j\\in J_k} Œª_j^k \\mathrm{P}_{p_k‚Üêq_j}X_{q_j},\\] $p_k$  is the last serious iterate,  $X_{q_j} ‚àà ‚àÇf(q_j)$ , and the  $Œª_j^k$  are solutions to the quadratic subproblem provided by the  convex_bundle_method_subsolver . Though the subdifferential might be set valued, the argument  ‚àÇf  should always return one element from the subdifferential, but not necessarily deterministic. For more details, see [ BHJ24 ]. Input M :  a manifold  $\\mathcal M$ f :   a cost function  $f:\\mathcal M‚Üí‚Ñù$  to minimize ‚àÇf : the subgradient  $‚àÇf: \\mathcal M ‚Üí T\\mathcal M$  of f restricted to always only returning one value/element from the subdifferential. This function can be passed as an allocation function  (M, p) -> X  or a mutating function  (M, X, p) -> X , see  evaluation . p :  ( rand(M) ) an initial value  $p_0 ‚àà \\mathcal M$ Optional atol_Œª :                    ( eps() ) tolerance parameter for the convex coefficients in Œª. atol_errors :               ( eps() ) tolerance parameter for the linearization errors. m :                         ( 1e-3 ) the parameter to test the decrease of the cost:  $f(q_{k+1}) \\le f(p_k) + m \\xi$ . diameter :                  ( 50.0 ) estimate for the diameter of the level set of the objective function at the starting point. domain :                    ( (M, p) -> isfinite(f(M, p)) ) a function to that evaluates to true when the current candidate is in the domain of the objective  f , and false otherwise, e.g. : domain = (M, p) -> p ‚àà dom f(M, p) ? true : false. k_max :                     upper bound on the sectional curvature of the manifold. k_size :                    ( 100 ) sample size for the estimation of the bounds on the sectional curvature of the manifold if k_max` is not provided. p_estimate :                ( p ) the point around which to estimate the sectional curvature of the manifold. Œ± :                         ( (i) -> one(number_eltype(X)) / i ) a function for evaluating suitable stepsizes when obtaining candidate points at iteration  i . œ± :                         curvature-dependent bound. evaluation :                ( AllocatingEvaluation ) specify whether the subgradient works by  allocation (default) form  ‚àÇf(M, q)  or  InplaceEvaluation  in place, i.e. is  of the form  ‚àÇf!(M, X, p) . inverse_retraction_method : ( default_inverse_retraction_method(M, typeof(p)) ) an inverse retraction method to use retraction_method :         ( default_retraction_method(M, typeof(p)) ) a  retraction(M, p, X)  to use. stopping_criterion :        ( StopWhenLagrangeMultiplierLess (1e-8) ) a functor, see StoppingCriterion , indicating when to stop vector_transport_method :   ( default_vector_transport_method(M, typeof(p)) ) a vector transport method to use sub_problem :               a function evaluating with new allocations that solves the sub problem on  M  given the last serious iterate  p_last_serious , the linearization errors  linearization_errors , and the transported subgradients  transported_subgradients Output the obtained (approximate) minimizer  $p^*$ , see  get_solver_return  for details source"},{"id":2572,"pagetitle":"Convex bundle method","title":"Manopt.convex_bundle_method!","ref":"/manopt/stable/solvers/convex_bundle_method/#Manopt.convex_bundle_method!","content":" Manopt.convex_bundle_method!  ‚Äî  Function convex_bundle_method!(M, f, ‚àÇf, p) perform a bundle method  $p_{j+1} = \\mathrm{retr}(p_k, -g_k)$  in place of  p . Input M :  a manifold  $\\mathcal M$ f :  a cost function  $f:\\mathcal M‚Üí‚Ñù$  to minimize ‚àÇf : the (sub)gradient  $‚àÇf:\\mathcal M‚Üí T\\mathcal M$  of F restricted to always only returning one value/element from the subdifferential. This function can be passed as an allocation function  (M, p) -> X  or a mutating function  (M, X, p) -> X , see  evaluation . p :  an initial value  $p_0=p ‚àà \\mathcal M$ for more details and all optional parameters, see  convex_bundle_method . source"},{"id":2573,"pagetitle":"Convex bundle method","title":"State","ref":"/manopt/stable/solvers/convex_bundle_method/#State","content":" State"},{"id":2574,"pagetitle":"Convex bundle method","title":"Manopt.ConvexBundleMethodState","ref":"/manopt/stable/solvers/convex_bundle_method/#Manopt.ConvexBundleMethodState","content":" Manopt.ConvexBundleMethodState  ‚Äî  Type ConvexBundleMethodState <: AbstractManoptSolverState Stores option values for a  convex_bundle_method  solver. Fields atol_Œª :                    ( eps() ) tolerance parameter for the convex coefficients in Œª atol_errors :               ( eps() ) tolerance parameter for the linearization errors bundle :                    bundle that collects each iterate with the computed subgradient at the iterate bundle_cap :                ( 25 ) the maximal number of elements the bundle is allowed to remember diameter :                  ( 50.0 ) estimate for the diameter of the level set of the objective function at the starting point domain :                    ( (M, p) -> isfinite(f(M, p)) ) a function to that evaluates to true when the current candidate is in the domain of the objective  f , and false otherwise, e.g. : domain = (M, p) -> p ‚àà dom f(M, p) ? true : false g :                         descent direction inverse_retraction_method : the inverse retraction to use within linearization_errors :      linearization errors at the last serious step m :                         ( 1e-3 ) the parameter to test the decrease of the cost:  $f(q_{k+1}) \\le f(p_k) + m \\xi$ . p :                         current candidate point p_last_serious :            last serious iterate retraction_method :         the retraction to use within stop :                      a  StoppingCriterion transported_subgradients :  subgradients of the bundle that are transported to p last serious vector_transport_method :   the vector transport method to use within X :                         ( zero_vector(M, p) ) the current element from the possible subgradients at  p  that was last evaluated. stepsize :                  ( ConstantStepsize (M) ) a  Stepsize Œµ :                         convex combination of the linearization errors Œª :                         convex coefficients that solve the subproblem Œæ :                         the stopping parameter given by  $Œæ = -\\lvert g\\rvert^2 ‚Äì Œµ$ œ± :                         curvature-dependent bound sub_problem :               ([ convex_bundle_method_subsolver ]) a function that solves the sub problem on  M  given the last serious iterate  p_last_serious , the linearization errors  linearization_errors , and the transported subgradients  transported_subgradients , sub_state :                 an  AbstractEvaluationType  indicating whether  sub_problem  works inplace of  Œª  or allocates a solution Constructor ConvexBundleMethodState(M::AbstractManifold, p; kwargs...) with keywords for all fields with defaults besides  p_last_serious  which obtains the same type as  p .     You can use e.g.  X=  to specify the type of tangent vector to use Keyword arguments k_max :      upper bound on the sectional curvature of the manifold k_size :     ( 100 ) sample size for the estimation of the bounds on the sectional curvature of the manifold p_estimate : ( p ) the point around which to estimate the sectional curvature of the manifold source"},{"id":2575,"pagetitle":"Convex bundle method","title":"Stopping Criteria","ref":"/manopt/stable/solvers/convex_bundle_method/#Stopping-Criteria","content":" Stopping Criteria"},{"id":2576,"pagetitle":"Convex bundle method","title":"Manopt.StopWhenLagrangeMultiplierLess","ref":"/manopt/stable/solvers/convex_bundle_method/#Manopt.StopWhenLagrangeMultiplierLess","content":" Manopt.StopWhenLagrangeMultiplierLess  ‚Äî  Type StopWhenLagrangeMultiplierLess <: StoppingCriterion Stopping Criteria for Lagrange multipliers. Currenlty these are meant for the  convex_bundle_method  and  proximal_bundle_method , where based on the Lagrange multipliers an approximate (sub)gradient  $g$  and an error estimate  $Œµ$  is computed. In  mode=:both  we require that both  $Œµ$  and  $\\lvert g \\rvert$  are smaller than their  tolerance s for the  convex_bundle_method , and that  $c$  and  $\\lvert d \\rvert$  are smaller than their  tolerance s for the  proximal_bundle_method . In the  mode=:estimate  we require that, for the  convex_bundle_method $-Œæ = \\lvert g \\rvert^2 + Œµ$  is less than a given  tolerance . For the  proximal_bundle_method , the equation reads  $-ŒΩ = Œº \\lvert d \\rvert^2 + c$ . Constructors StopWhenLagrangeMultiplierLess(tolerance=1e-6; mode::Symbol=:estimate) Create the stopping criterion for one of the  mode s mentioned. Note that tolerance can be a single number for the  :estimate  case, but a vector of two values is required for the  :both  mode. Here the first entry specifies the tolerance for  $Œµ$  ( $c$ ), the second the tolerance for  $\\lvert g \\rvert$  ( $\\lvert d \\rvert$ ), respectively. source"},{"id":2577,"pagetitle":"Convex bundle method","title":"Debug Functions","ref":"/manopt/stable/solvers/convex_bundle_method/#Debug-Functions","content":" Debug Functions"},{"id":2578,"pagetitle":"Convex bundle method","title":"Manopt.DebugWarnIfLagrangeMultiplierIncreases","ref":"/manopt/stable/solvers/convex_bundle_method/#Manopt.DebugWarnIfLagrangeMultiplierIncreases","content":" Manopt.DebugWarnIfLagrangeMultiplierIncreases  ‚Äî  Type DebugWarnIfLagrangeMultiplierIncreases <: DebugAction print a warning if the Lagrange parameter based value  $-Œæ$  of the bundle method increases. Constructor DebugWarnIfLagrangeMultiplierIncreases(warn=:Once; tol=1e2) Initialize the warning to warning level ( :Once ) and introduce a tolerance for the test of  1e2 . The  warn  level can be set to  :Once  to only warn the first time the cost increases, to  :Always  to report an increase every time it happens, and it can be set to  :No  to deactivate the warning, then this  DebugAction  is inactive. All other symbols are handled as if they were  :Always: source"},{"id":2579,"pagetitle":"Convex bundle method","title":"Helpers and internal functions","ref":"/manopt/stable/solvers/convex_bundle_method/#Helpers-and-internal-functions","content":" Helpers and internal functions"},{"id":2580,"pagetitle":"Convex bundle method","title":"Manopt.convex_bundle_method_subsolver","ref":"/manopt/stable/solvers/convex_bundle_method/#Manopt.convex_bundle_method_subsolver","content":" Manopt.convex_bundle_method_subsolver  ‚Äî  Function Œª = convex_bundle_method_subsolver(M, p_last_serious, linearization_errors, transported_subgradients)\nconvex_bundle_method_subsolver!(M, Œª, p_last_serious, linearization_errors, transported_subgradients) solver for the subproblem of the convex bundle method at the last serious iterate  $p_k$  given the current linearization errors  $c_j^k$ , and transported subgradients  $\\mathrm{P}_{p_k‚Üêq_j} X_{q_j}$ . The computation can also be done in-place of  Œª . The subproblem for the convex bundle method is \\[\\begin{align*}\n    \\operatorname*{arg\\,min}_{Œª ‚àà ‚Ñù^{\\lvert J_k\\rvert}}&\n    \\frac{1}{2} \\Bigl\\lVert \\sum_{j ‚àà J_k} Œª_j \\mathrm{P}_{p_k‚Üêq_j} X_{q_j} \\Bigr\\rVert^2\n    + \\sum_{j ‚àà J_k} Œª_j \\, c_j^k\n    \\\\\n    \\text{s. t.}\\quad &\n    \\sum_{j ‚àà J_k} Œª_j = 1,\n    \\quad Œª_j ‚â• 0\n    \\quad \\text{for all }\n    j ‚àà J_k,\n\\end{align*}\\] where  $J_k = \\{j ‚àà J_{k-1} \\ | \\ Œª_j > 0\\} \\cup \\{k\\}$ . See [ BHJ24 ] for mre details Tip A default subsolver based on  RipQP .jl  and  QuadraticModels  is available if these two packages are loaded. source"},{"id":2581,"pagetitle":"Convex bundle method","title":"Manopt.estimate_sectional_curvature","ref":"/manopt/stable/solvers/convex_bundle_method/#Manopt.estimate_sectional_curvature","content":" Manopt.estimate_sectional_curvature  ‚Äî  Function estimate_sectional_curvature(M::AbstractManifold, p) Estimate the sectional curvature of a manifold  $\\mathcal M$  at a point  $p \\in \\mathcal M$  on two random tangent vectors at  $p$  that are orthogonal to each other. See also sectional_curvature source"},{"id":2582,"pagetitle":"Convex bundle method","title":"Manopt.Œ∂_1","ref":"/manopt/stable/solvers/convex_bundle_method/#Manopt.Œ∂_1","content":" Manopt.Œ∂_1  ‚Äî  Function Œ∂_1(œâ, Œ¥) compute a curvature-dependent bound. The formula reads \\[\\zeta_{1, œâ}(Œ¥)\n\\coloneqq\n\\begin{cases}\n    1 & \\text{if } œâ ‚â• 0, \\\\\n    \\sqrt{-œâ} \\, Œ¥ \\cot(\\sqrt{-œâ} \\, Œ¥) & \\text{if } œâ < 0,\n\\end{cases}\\] where  $œâ ‚â§ Œ∫_p$  for all  $p ‚àà \\mathcal U$  is a lower bound to the sectional curvature in a (strongly geodesically convex) bounded subset  $\\mathcal U ‚äÜ \\mathcal M$  with diameter  $Œ¥$ . source"},{"id":2583,"pagetitle":"Convex bundle method","title":"Manopt.Œ∂_2","ref":"/manopt/stable/solvers/convex_bundle_method/#Manopt.Œ∂_2","content":" Manopt.Œ∂_2  ‚Äî  Function Œ∂_2(Œ©, Œ¥) compute a curvature-dependent bound. The formula reads \\[\\zeta_{2, Œ©}(Œ¥) \\coloneqq\n\\begin{cases}\n    1 & \\text{if } Œ© ‚â§ 0,\\\\\n    \\sqrt{Œ©} \\, Œ¥ \\cot(\\sqrt{Œ©} \\, Œ¥) & \\text{if } Œ© > 0,\n\\end{cases}\\] where  $Œ© ‚â• Œ∫_p$  for all  $p ‚àà \\mathcal U$  is an upper bound to the sectional curvature in a (strongly geodesically convex) bounded subset  $\\mathcal U ‚äÜ \\mathcal M$  with diameter  $Œ¥$ . source"},{"id":2584,"pagetitle":"Convex bundle method","title":"Manopt.close_point","ref":"/manopt/stable/solvers/convex_bundle_method/#Manopt.close_point","content":" Manopt.close_point  ‚Äî  Function close_point(M, p, tol; retraction_method=default_retraction_method(M, typeof(p))) sample a random point close to  $p ‚àà \\mathcal M$  within a tolerance  tol  and a  retraction . source"},{"id":2585,"pagetitle":"Convex bundle method","title":"Literature","ref":"/manopt/stable/solvers/convex_bundle_method/#Literature","content":" Literature [BHJ24] R.¬†Bergmann, R.¬†Herzog and H.¬†Jasa.  The Riemannian Convex Bundle Method , preprint (2024),  arXiv:2402.13670 ."},{"id":2588,"pagetitle":"Cyclic Proximal Point","title":"Cyclic proximal point","ref":"/manopt/stable/solvers/cyclic_proximal_point/#Cyclic-proximal-point","content":" Cyclic proximal point The Cyclic Proximal Point (CPP) algorithm aims to minimize \\[F(x) = \\sum_{i=1}^c f_i(x)\\] assuming that the proximal maps  $\\operatorname{prox}_{Œª f_i}(x)$  are given in closed form or can be computed efficiently (at least approximately). The algorithm then cycles through these proximal maps, where the type of cycle might differ and the proximal parameter  $Œª_k$  changes after each cycle  $k$ . For a convergence result on  Hadamard manifolds  see  Baƒç√°k [Bac14] ."},{"id":2589,"pagetitle":"Cyclic Proximal Point","title":"Manopt.cyclic_proximal_point","ref":"/manopt/stable/solvers/cyclic_proximal_point/#Manopt.cyclic_proximal_point","content":" Manopt.cyclic_proximal_point  ‚Äî  Function cyclic_proximal_point(M, f, proxes_f, p)\ncyclic_proximal_point(M, mpo, p) perform a cyclic proximal point algorithm. Input M :        a manifold  $\\mathcal M$ f :        a cost function  $f:\\mathcal M‚Üí‚Ñù$  to minimize proxes_f : an Array of proximal maps ( Function s)  (M,Œª,p) -> q  or  (M, q, Œª, p) -> q  for the summands of  $f$  (see  evaluation ) p :        an initial value  $p ‚àà \\mathcal M$ where  f  and the proximal maps  proxes_f  can also be given directly as a  ManifoldProximalMapObjective mpo Optional evaluation :         ( AllocatingEvaluation ) specify whether the proximal maps work by allocation (default) form  prox(M, Œª, x)  or  InplaceEvaluation  in place of form  prox!(M, y, Œª, x) . evaluation_order :   ( :Linear ) whether to use a randomly permuted sequence ( :FixedRandom ), a per cycle permuted sequence ( :Random ) or the default linear one. Œª :                  ( iter -> 1/iter  ) a function returning the (square summable but not summable) sequence of  $Œª_i$ stopping_criterion : ( StopAfterIteration (5000) | StopWhenChangeLess (1e-12) ) a  StoppingCriterion . All other keyword arguments are passed to  decorate_state!  for decorators or  decorate_objective! , respectively. If you provide the  ManifoldProximalMapObjective  directly, these decorations can still be specified. Output the obtained (approximate) minimizer  $p^*$ , see  get_solver_return  for details source"},{"id":2590,"pagetitle":"Cyclic Proximal Point","title":"Manopt.cyclic_proximal_point!","ref":"/manopt/stable/solvers/cyclic_proximal_point/#Manopt.cyclic_proximal_point!","content":" Manopt.cyclic_proximal_point!  ‚Äî  Function cyclic_proximal_point!(M, F, proxes, p)\ncyclic_proximal_point!(M, mpo, p) perform a cyclic proximal point algorithm in place of  p . Input M :      a manifold  $\\mathcal M$ F :      a cost function  $F:\\mathcal M‚Üí‚Ñù$  to minimize proxes : an Array of proximal maps ( Function s)  (M, Œª, p) -> q  or  (M, q, Œª, p)  for the summands of  $F$ p :      an initial value  $p ‚àà \\mathcal M$ where  f  and the proximal maps  proxes_f  can also be given directly as a  ManifoldProximalMapObjective mpo for all options, see  cyclic_proximal_point . source"},{"id":2591,"pagetitle":"Cyclic Proximal Point","title":"Technical details","ref":"/manopt/stable/solvers/cyclic_proximal_point/#sec-cppa-technical-details","content":" Technical details The  cyclic_proximal_point  solver requires no additional functions to be available for your manifold, besides the ones you use in the proximal maps. By default, one of the stopping criteria is  StopWhenChangeLess , which either requires An  inverse_retract! (M, X, p, q) ; it is recommended to set the  default_inverse_retraction_method  to a favourite retraction. If this default is set, a  inverse_retraction_method=  or  inverse_retraction_method_dual=  (for  $\\mathcal N$ ) does not have to be specified or the  distance (M, p, q)  for said default inverse retraction."},{"id":2592,"pagetitle":"Cyclic Proximal Point","title":"State","ref":"/manopt/stable/solvers/cyclic_proximal_point/#State","content":" State"},{"id":2593,"pagetitle":"Cyclic Proximal Point","title":"Manopt.CyclicProximalPointState","ref":"/manopt/stable/solvers/cyclic_proximal_point/#Manopt.CyclicProximalPointState","content":" Manopt.CyclicProximalPointState  ‚Äî  Type CyclicProximalPointState <: AbstractManoptSolverState stores options for the  cyclic_proximal_point  algorithm. These are the Fields p :                  the current iterate stopping_criterion :  a  StoppingCriterion Œª :                  (@(i) -> 1/i) a function for the values of  $Œª_k$  per iteration(cycle  $√¨$ oder_type :          ( :LinearOrder ) whether to use a randomly permuted sequence ( :FixedRandomOrder ), a per cycle permuted sequence ( :RandomOrder ) or the default linear one. Constructor CyclicProximalPointState(M, p) Generate the options with the following keyword arguments stopping_criterion : ( StopAfterIteration(2000) ) a  StoppingCriterion . Œª :                  (  i -> 1.0 / i ) a function to compute the  $Œª_k, k ‚àà \\mathbb N$ , evaluation_order :   ( :LinearOrder ) a Symbol indicating the order the proximal maps are applied. See also cyclic_proximal_point source"},{"id":2594,"pagetitle":"Cyclic Proximal Point","title":"Debug functions","ref":"/manopt/stable/solvers/cyclic_proximal_point/#Debug-functions","content":" Debug functions"},{"id":2595,"pagetitle":"Cyclic Proximal Point","title":"Manopt.DebugProximalParameter","ref":"/manopt/stable/solvers/cyclic_proximal_point/#Manopt.DebugProximalParameter","content":" Manopt.DebugProximalParameter  ‚Äî  Type DebugProximalParameter <: DebugAction print the current iterates proximal point algorithm parameter given by  AbstractManoptSolverState s  o.Œª . source"},{"id":2596,"pagetitle":"Cyclic Proximal Point","title":"Record functions","ref":"/manopt/stable/solvers/cyclic_proximal_point/#Record-functions","content":" Record functions"},{"id":2597,"pagetitle":"Cyclic Proximal Point","title":"Manopt.RecordProximalParameter","ref":"/manopt/stable/solvers/cyclic_proximal_point/#Manopt.RecordProximalParameter","content":" Manopt.RecordProximalParameter  ‚Äî  Type RecordProximalParameter <: RecordAction record the current iterates proximal point algorithm parameter given by in  AbstractManoptSolverState s  o.Œª . source"},{"id":2598,"pagetitle":"Cyclic Proximal Point","title":"Literature","ref":"/manopt/stable/solvers/cyclic_proximal_point/#Literature","content":" Literature [Bac14] M.¬†Baƒç√°k.  Computing medians and means in Hadamard spaces .  SIAM¬†Journal¬†on¬†Optimization  24 , 1542‚Äì1566  (2014),  arXiv:1210.2145 ."},{"id":2601,"pagetitle":"Difference of Convex","title":"Difference of convex","ref":"/manopt/stable/solvers/difference_of_convex/#Difference-of-convex","content":" Difference of convex"},{"id":2602,"pagetitle":"Difference of Convex","title":"Difference of convex algorithm","ref":"/manopt/stable/solvers/difference_of_convex/#solver-difference-of-convex","content":" Difference of convex algorithm"},{"id":2603,"pagetitle":"Difference of Convex","title":"Manopt.difference_of_convex_algorithm","ref":"/manopt/stable/solvers/difference_of_convex/#Manopt.difference_of_convex_algorithm","content":" Manopt.difference_of_convex_algorithm  ‚Äî  Function difference_of_convex_algorithm(M, f, g, ‚àÇh, p=rand(M); kwargs...)\ndifference_of_convex_algorithm(M, mdco, p; kwargs...) Compute the difference of convex algorithm [ BFSS23 ] to minimize \\[    \\operatorname*{arg\\,min}_{p‚àà\\mathcal M}\\  g(p) - h(p)\\] where you need to provide  $f(p) = g(p) - h(p)$ ,  $g$  and the subdifferential  $‚àÇh$  of  $h$ . This algorithm performs the following steps given a start point  p =  $p^{(0)}$ . Then repeat for  $k=0,1,\\ldots$ Take  $X^{(k)}  ‚àà ‚àÇh(p^{(k)})$ Set the next iterate to the solution of the subproblem \\[  p^{(k+1)} ‚àà \\operatorname*{argmin}_{q ‚àà \\mathcal M} g(q) - ‚ü®X^{(k)}, \\log_{p^{(k)}}q‚ü©\\] until the  stopping_criterion  is fulfilled. Optional parameters evaluation           ( AllocatingEvaluation ) specify whether the gradient works by allocation (default) form  grad_f(M, p)  or  InplaceEvaluation  form  grad_f!(M, X, x) gradient             ( nothing ) specify  $\\operatorname{grad} f$ , for debug / analysis or enhancing  stopping_criterion= grad_g               ( nothing ) specify the gradient of  g . If specified, a subsolver is automatically set up. initial_vector       ( zero_vector(M, p) ) initialise the inner tangent vector to store the subgradient result. stopping_criterion   ( StopAfterIteration (200) | StopWhenChangeLess (1e-8) ) a  StoppingCriterion  for the algorithm. This includes a  StopWhenGradientNormLess (1e-8) , when a  gradient  is provided. if you specify the  ManifoldDifferenceOfConvexObjective mdco , additionally g                    - ( nothing ) specify the function  g  If specified, a subsolver is automatically set up. While there are several parameters for a sub solver, the easiest is to provide the function  grad_g= , such that together with the mandatory function  g  a default cost and gradient can be generated and passed to a default subsolver. Hence the easiest example call looks like difference_of_convex_algorithm(M, f, g, grad_h, p; grad_g=grad_g) Optional parameters for the sub problem sub_cost               ( LinearizedDCCost (g, p, initial_vector) ) a cost to be used within the default  sub_problem  Use this if you have a more efficient version than the default that is built using  g  from before. sub_grad               ( LinearizedDCGrad (grad_g, p, initial_vector; evaluation=evaluation)  gradient to be used within the default  sub_problem . This is generated by default when  grad_g  is provided. You can specify your own by overwriting this keyword. sub_hess               (a finite difference approximation by default) specify a Hessian  of the subproblem, which the default solver, see  sub_state  needs sub_kwargs             ( (;) ) pass keyword arguments to the  sub_state , in form of a  Dict(:kwname=>value) , unless you set the  sub_state  directly. sub_objective          (a gradient or Hessian objective based on the last 3 keywords) provide the objective used within  sub_problem  (if that is not specified by the user) sub_problem            ( DefaultManoptProblem (M, sub_objective)  specify a manopt problem for the sub-solver runs. You can also provide a function for a closed form solution. Then  evaluation=  is taken into account for the form of this function. sub_state              ( TrustRegionsState  by default, requires  sub_hessian  to be provided; decorated with  sub_kwargs ). Choose the solver by specifying a solver state to solve the  sub_problem  if the  sub_problem  if a function (a closed form solution), this is set to  evaluation  and can be changed to the evaluation type of the closed form solution accordingly. sub_stopping_criterion  ( StopAfterIteration (300) | StopWhenStepsizeLess (1e-9) | StopWhenGradientNormLess (1e-9) ) a stopping criterion used withing the default  sub_state= sub_stepsize            ( ArmijoLinesearch (M) ) specify a step size used within the  sub_state , all others are passed on to decorate the inner  DifferenceOfConvexState . Output the obtained (approximate) minimizer  $p^*$ , see  get_solver_return  for details source"},{"id":2604,"pagetitle":"Difference of Convex","title":"Manopt.difference_of_convex_algorithm!","ref":"/manopt/stable/solvers/difference_of_convex/#Manopt.difference_of_convex_algorithm!","content":" Manopt.difference_of_convex_algorithm!  ‚Äî  Function difference_of_convex_algorithm!(M, f, g, ‚àÇh, p; kwargs...)\ndifference_of_convex_algorithm!(M, mdco, p; kwargs...) Run the difference of convex algorithm and perform the steps in place of  p . See  difference_of_convex_algorithm  for more details. if you specify the  ManifoldDifferenceOfConvexObjective mdco , the  g  is a keyword argument. source"},{"id":2605,"pagetitle":"Difference of Convex","title":"Difference of convex proximal point","ref":"/manopt/stable/solvers/difference_of_convex/#solver-difference-of-convex-proximal-point","content":" Difference of convex proximal point"},{"id":2606,"pagetitle":"Difference of Convex","title":"Manopt.difference_of_convex_proximal_point","ref":"/manopt/stable/solvers/difference_of_convex/#Manopt.difference_of_convex_proximal_point","content":" Manopt.difference_of_convex_proximal_point  ‚Äî  Function difference_of_convex_proximal_point(M, grad_h, p=rand(M); kwargs...)\ndifference_of_convex_proximal_point(M, mdcpo, p=rand(M); kwargs...) Compute the difference of convex proximal point algorithm [ SO15 ] to minimize \\[    \\operatorname*{arg\\,min}_{p‚àà\\mathcal M} g(p) - h(p)\\] where you have to provide the (sub) gradient  $‚àÇh$  of  $h$  and either the proximal map  $\\operatorname{prox}_{\\lambda g}$  of  g  as a function  prox_g(M, Œª, p)  or   prox_g(M, q, Œª, p) the functions  g  and  grad_g  to compute the proximal map using a sub solver your own sub-solver, see optional keywords below This algorithm performs the following steps given a start point  p =  $p^{(0)}$ . Then repeat for  $k=0,1,\\ldots$ $X^{(k)}  ‚àà \\operatorname{grad} h(p^{(k)})$ $q^{(k)} = \\operatorname{retr}_{p^{(k)}}(Œª_kX^{(k)})$ $r^{(k)} = \\operatorname{prox}_{Œª_kg}(q^{(k)})$ $X^{(k)} = \\operatorname{retr}^{-1}_{p^{(k)}}(r^{(k)})$ Compute a stepsize  $s_k$  and set  $p^{(k+1)} = \\operatorname{retr}_{p^{(k)}}(s_kX^{(k)})$ . until the  stopping_criterion  is fulfilled. See [ ACOO20 ] for more details on the modified variant, where steps 4-6 are slightly changed, since here the classical proximal point method for DC functions is obtained for  $s_k = 1$  and one can hence employ usual line search method. Optional parameters Œª :                          (  i -> 1/2  ) a function returning the sequence of prox parameters Œªi evaluation :                 ( AllocatingEvaluation ) specify whether the gradient works by allocation (default) form  gradF(M, x)  or  InplaceEvaluation  in place of the form  gradF!(M, X, x) . cost :                       ( nothing ) provide the cost  f , for debug reasons / analysis the default  sub_problem . Use this if you have a more efficient version than using  g  from before. gradient :                   ( nothing ) specify  $\\operatorname{grad} f$ , for debug / analysis  or enhancing the  stopping_criterion prox_g :                     ( nothing ) specify a proximal map for the sub problem  or  both of the following g :                          ( nothing ) specify the function  g . grad_g :                     ( nothing ) specify the gradient of  g . If both  g and  grad_g  are specified, a subsolver is automatically set up. inverse_retraction_method :  ( default_inverse_retraction_method(M) ) an inverse retraction method to use (see step 4). retraction_method :          ( default_retraction_method(M) ) a retraction to use (see step 2) stepsize :                   ( ConstantStepsize (M) ) specify a  Stepsize  to run the modified algorithm (experimental.) functor. stopping_criterion :         ( StopAfterIteration (200) | StopWhenChangeLess (1e-8) ) a  StoppingCriterion  for the algorithm, also includes a  StopWhenGradientNormLess (1e-8) , when a  gradient  is provided. While there are several parameters for a sub solver, the easiest is to provide the function  g  and  grad_g , such that together with the mandatory function  g  a default cost and gradient can be generated and passed to a default subsolver. Hence the easiest example call looks like difference_of_convex_proximal_point(M, grad_h, p0; g=g, grad_g=grad_g) Optional parameters for the sub problem sub_cost :               ( ProximalDCCost (g, copy(M, p), Œª(1)) ) cost to be used within the default  sub_problem  that is initialized as soon as  g  is provided. sub_grad :               ( ProximalDCGrad (grad_g, copy(M, p), Œª(1); evaluation=evaluation)  gradient to be used within the default  sub_problem , that is initialized as soon as  grad_g  is provided. This is generated by default when  grad_g  is provided. You can specify your own by overwriting this keyword. sub_hess :               (a finite difference approximation by default) specify a Hessian of the subproblem, which the default solver, see  sub_state  needs sub_kwargs :             ( (;) ) pass keyword arguments to the  sub_state , in form of a  Dict(:kwname=>value) , unless you set the  sub_state  directly. sub_objective :          (a gradient or Hessian objective based on the last 3 keywords) provide the objective used within  sub_problem  (if that is not specified by the user) sub_problem :            ( DefaultManoptProblem (M, sub_objective)  specify a manopt problem for the sub-solver runs. You can also provide a function for a closed form solution. Then  evaluation=  is taken into account for the form of this function. sub_state :              ( TrustRegionsState ). requires the  sub_Hessian to be provided,  decorated with sub kwargs ) choose the solver by specifying a solver state to solve the sub problem` sub_stopping_criterion : ( StopAfterIteration (300) | StopWhenStepsizeLess (1e-9) | StopWhenGradientNormLess (1e-9) ) a stopping criterion used withing the default  sub_state= all others are passed on to decorate the inner  DifferenceOfConvexProximalState . Output the obtained (approximate) minimizer  $p^*$ , see  get_solver_return  for details source"},{"id":2607,"pagetitle":"Difference of Convex","title":"Manopt.difference_of_convex_proximal_point!","ref":"/manopt/stable/solvers/difference_of_convex/#Manopt.difference_of_convex_proximal_point!","content":" Manopt.difference_of_convex_proximal_point!  ‚Äî  Function difference_of_convex_proximal_point!(M, grad_h, p; cost=nothing, kwargs...)\ndifference_of_convex_proximal_point!(M, mdcpo, p; cost=nothing, kwargs...)\ndifference_of_convex_proximal_point!(M, mdcpo, prox_g, p; cost=nothing, kwargs...) Compute the difference of convex algorithm to minimize \\[    \\operatorname*{arg\\,min}_{p‚àà\\mathcal M} g(p) - h(p)\\] where you have to provide the proximal map of  g  and the gradient of  h . The computation is done in-place of  p . For all further details, especially the keyword arguments, see  difference_of_convex_proximal_point . source"},{"id":2608,"pagetitle":"Difference of Convex","title":"Solver states","ref":"/manopt/stable/solvers/difference_of_convex/#Solver-states","content":" Solver states"},{"id":2609,"pagetitle":"Difference of Convex","title":"Manopt.DifferenceOfConvexState","ref":"/manopt/stable/solvers/difference_of_convex/#Manopt.DifferenceOfConvexState","content":" Manopt.DifferenceOfConvexState  ‚Äî  Type DifferenceOfConvexState{Pr,St,P,T,SC<:StoppingCriterion} <:\n           AbstractManoptSolverState A struct to store the current state of the [ difference_of_convex_algorithm ])(@ref). It comes in two forms, depending on the realisation of the  subproblem . Fields p            the current iterate, a point on the manifold X            the current subgradient, a tangent vector to  p . sub_problem  problem for the subsolver sub_state    state of the subproblem stop         a functor inheriting from  StoppingCriterion  indicating when to stop. For the sub task, a method to solve \\[    \\operatorname*{argmin}_{q‚àà\\mathcal M}\\ g(p) - ‚ü®X, \\log_p q‚ü©\\] is needed. Besides a problem and options, one can also provide a function and an  AbstractEvaluationType , respectively, to indicate a closed form solution for the sub task. Constructors DifferenceOfConvexState(M, p, sub_problem, sub_state; kwargs...)\nDifferenceOfConvexState(M, p, sub_solver; evaluation=InplaceEvaluation(), kwargs...) Generate the state either using a solver from Manopt, given by an  AbstractManoptProblem sub_problem  and an  AbstractManoptSolverState sub_state , or a closed form solution  sub_solver  for the sub-problem the function expected to be of the form  (M, p, X) -> q  or  (M, q, p, X) -> q , where by default its  AbstractEvaluationType evaluation  is in-place of  q . Here the elements passed are the current iterate  p  and the subgradient  X  of  h  can be passed to that function. further keyword arguments initial_vector=zero_vector  ( zero_vectoir(M,p) ) how to initialize the inner gradient tangent vector stopping_criterion          a  StopAfterIteration (200)  a stopping criterion source"},{"id":2610,"pagetitle":"Difference of Convex","title":"Manopt.DifferenceOfConvexProximalState","ref":"/manopt/stable/solvers/difference_of_convex/#Manopt.DifferenceOfConvexProximalState","content":" Manopt.DifferenceOfConvexProximalState  ‚Äî  Type DifferenceOfConvexProximalState{Type} <: Options A struct to store the current state of the algorithm as well as the form. It comes in two forms, depending on the realisation of the  subproblem . Fields inverse_retraction_method : ( default_inverse_retraction_method(M) ) an inverse retraction method to use within Frank Wolfe. retraction_method :         ( default_retraction_method(M) ) a type of retraction p ,  q ,  r :               the current iterate, the gradient step and the prox, respectively their type is set by initializing  p stepsize :                  ( ConstantStepsize (1.0) ) a  Stepsize  function to run the modified algorithm (experimental) stop :                      ( StopWhenChangeLess (1e-8) ) a  StoppingCriterion X ,  Y :                    ( zero_vector(M,p) ) the current gradient and descent direction, respectively their common type is set by the keyword  X Constructor DifferenceOfConvexProximalState(M, p; kwargs...) Keyword arguments X ,  retraction_method ,  inverse_retraction_method ,  stepsize  for the corresponding fields stoppping_criterion  for the  StoppingCriterion source"},{"id":2611,"pagetitle":"Difference of Convex","title":"The difference of convex objective","ref":"/manopt/stable/solvers/difference_of_convex/#The-difference-of-convex-objective","content":" The difference of convex objective"},{"id":2612,"pagetitle":"Difference of Convex","title":"Manopt.ManifoldDifferenceOfConvexObjective","ref":"/manopt/stable/solvers/difference_of_convex/#Manopt.ManifoldDifferenceOfConvexObjective","content":" Manopt.ManifoldDifferenceOfConvexObjective  ‚Äî  Type ManifoldDifferenceOfConvexObjective{E} <: AbstractManifoldCostObjective{E} Specify an objective for a  difference_of_convex_algorithm . The objective  $f: \\mathcal M ‚Üí ‚Ñù$  is given as \\[    f(p) = g(p) - h(p)\\] where both  $g$  and  $h$  are convex, lower semicontinuous and proper. Furthermore the subdifferential  $‚àÇh$  of  $h$  is required. Fields cost : an implementation of  $f(p) = g(p)-h(p)$  as a function  f(M,p) . ‚àÇh!! : a deterministic version of  $‚àÇh: \\mathcal M ‚Üí T\\mathcal M$ , in the sense that calling  ‚àÇh(M, p)  returns a subgradient of  $h$  at  p  and if there is more than one, it returns a deterministic choice. Note that the subdifferential might be given in two possible signatures ‚àÇh(M,p)  which does an  AllocatingEvaluation ‚àÇh!(M, X, p)  which does an  InplaceEvaluation  in place of  X . source as well as for the corresponding sub problem"},{"id":2613,"pagetitle":"Difference of Convex","title":"Manopt.LinearizedDCCost","ref":"/manopt/stable/solvers/difference_of_convex/#Manopt.LinearizedDCCost","content":" Manopt.LinearizedDCCost  ‚Äî  Type LinearizedDCCost A functor  (M,q) ‚Üí ‚Ñù  to represent the inner problem of a  ManifoldDifferenceOfConvexObjective . This is a cost function of the form \\[    F_{p_k,X_k}(p) = g(p) - ‚ü®X_k, \\log_{p_k}p‚ü©\\] for a point  p_k  and a tangent vector  X_k  at  p_k  (for example outer iterates) that are stored within this functor as well. Fields g  a function pk  a point on a manifold Xk  a tangent vector at  pk Both interim values can be set using  set_manopt_parameter!(::LinearizedDCCost, ::Val{:p}, p)  and  set_manopt_parameter!(::LinearizedDCCost, ::Val{:X}, X) , respectively. Constructor LinearizedDCCost(g, p, X) source"},{"id":2614,"pagetitle":"Difference of Convex","title":"Manopt.LinearizedDCGrad","ref":"/manopt/stable/solvers/difference_of_convex/#Manopt.LinearizedDCGrad","content":" Manopt.LinearizedDCGrad  ‚Äî  Type LinearizedDCGrad A functor  (M,X,p) ‚Üí ‚Ñù  to represent the gradient of the inner problem of a  ManifoldDifferenceOfConvexObjective . This is a gradient function of the form \\[    F_{p_k,X_k}(p) = g(p) - ‚ü®X_k, \\log_{p_k}p‚ü©\\] its gradient is given by using  $F=F_1(F_2(p))$ , where  $F_1(X) = ‚ü®X_k,X‚ü©$  and  $F_2(p) = \\log_{p_k}p$  and the chain rule as well as the adjoint differential of the logarithmic map with respect to its argument for  $D^*F_2(p)$ \\[    \\operatorname{grad} F(q) = \\operatorname{grad} f(q) - DF_2^*(q)[X]\\] for a point  pk  and a tangent vector  Xk  at  pk  (the outer iterates) that are stored within this functor as well Fields grad_g!!  the gradient of  $g$  (see also  LinearizedDCCost ) pk  a point on a manifold Xk  a tangent vector at  pk Both interim values can be set using  set_manopt_parameter!(::LinearizedDCGrad, ::Val{:p}, p)  and  set_manopt_parameter!(::LinearizedDCGrad, ::Val{:X}, X) , respectively. Constructor LinearizedDCGrad(grad_g, p, X; evaluation=AllocatingEvaluation()) Where you specify whether  grad_g  is  AllocatingEvaluation  or  InplaceEvaluation , while this function still provides  both  signatures. source"},{"id":2615,"pagetitle":"Difference of Convex","title":"Manopt.ManifoldDifferenceOfConvexProximalObjective","ref":"/manopt/stable/solvers/difference_of_convex/#Manopt.ManifoldDifferenceOfConvexProximalObjective","content":" Manopt.ManifoldDifferenceOfConvexProximalObjective  ‚Äî  Type ManifoldDifferenceOfConvexProximalObjective{E} <: Problem Specify an objective  difference_of_convex_proximal_point  algorithm. The problem is of the form \\[    \\operatorname*{argmin}_{p‚àà\\mathcal M} g(p) - h(p)\\] where both  $g$  and  $h$  are convex, lower semicontinuous and proper. Fields cost :     ( nothing ) implementation of  $f(p) = g(p)-h(p)$  (optional) gradient : the gradient of the cost grad_h!! : a function  $\\operatorname{grad}h: \\mathcal M ‚Üí T\\mathcal M$ , Note that both the gradients might be given in two possible signatures as allocating or in-place. Constructor ManifoldDifferenceOfConvexProximalObjective(gradh; cost=nothing, gradient=nothing) an note that neither cost nor gradient are required for the algorithm, just for eventual debug or stopping criteria. source as well as for the corresponding sub problems"},{"id":2616,"pagetitle":"Difference of Convex","title":"Manopt.ProximalDCCost","ref":"/manopt/stable/solvers/difference_of_convex/#Manopt.ProximalDCCost","content":" Manopt.ProximalDCCost  ‚Äî  Type ProximalDCCost A functor  (M, p) ‚Üí ‚Ñù  to represent the inner cost function of a  ManifoldDifferenceOfConvexProximalObjective . This is the cost function of the proximal map of  g . \\[    F_{p_k}(p) = \\frac{1}{2Œª}d_{\\mathcal M}(p_k,p)^2 + g(p)\\] for a point  pk  and a proximal parameter  $Œª$ . Fields g   - a function pk  - a point on a manifold Œª   - the prox parameter Both interim values can be set using  set_manopt_parameter!(::ProximalDCCost, ::Val{:p}, p)  and  set_manopt_parameter!(::ProximalDCCost, ::Val{:Œª}, Œª) , respectively. Constructor ProximalDCCost(g, p, Œª) source"},{"id":2617,"pagetitle":"Difference of Convex","title":"Manopt.ProximalDCGrad","ref":"/manopt/stable/solvers/difference_of_convex/#Manopt.ProximalDCGrad","content":" Manopt.ProximalDCGrad  ‚Äî  Type ProximalDCGrad A functor  (M,X,p) ‚Üí ‚Ñù  to represent the gradient of the inner cost function of a  ManifoldDifferenceOfConvexProximalObjective . This is the gradient function of the proximal map cost function of  g . Based on \\[    F_{p_k}(p) = \\frac{1}{2Œª}d_{\\mathcal M}(p_k,p)^2 + g(p)\\] it reads \\[    \\operatorname{grad} F_{p_k}(p) = \\operatorname{grad} g(p) - \\frac{1}{Œª}\\log_p p_k\\] for a point  pk  and a proximal parameter  Œª . Fields grad_g   - a gradient function pk  - a point on a manifold Œª   - the prox parameter Both interim values can be set using  set_manopt_parameter!(::ProximalDCGrad, ::Val{:p}, p)  and  set_manopt_parameter!(::ProximalDCGrad, ::Val{:Œª}, Œª) , respectively. Constructor ProximalDCGrad(grad_g, pk, Œª; evaluation=AllocatingEvaluation()) Where you specify whether  grad_g  is  AllocatingEvaluation  or  InplaceEvaluation , while this function still always provides  both  signatures. source"},{"id":2618,"pagetitle":"Difference of Convex","title":"Helper functions","ref":"/manopt/stable/solvers/difference_of_convex/#Helper-functions","content":" Helper functions"},{"id":2619,"pagetitle":"Difference of Convex","title":"Manopt.get_subtrahend_gradient","ref":"/manopt/stable/solvers/difference_of_convex/#Manopt.get_subtrahend_gradient","content":" Manopt.get_subtrahend_gradient  ‚Äî  Function X = get_subtrahend_gradient(amp, q)\nget_subtrahend_gradient!(amp, X, q) Evaluate the (sub)gradient of the subtrahend  h  from within a  ManifoldDifferenceOfConvexObjective amp  at the point  q  (in place of  X ). The evaluation is done in place of  X  for the  ! -variant. The  T= AllocatingEvaluation  problem might still allocate memory within. When the non-mutating variant is called with a  T= InplaceEvaluation  memory for the result is allocated. source X = get_subtrahend_gradient(M::AbstractManifold, dcpo::ManifoldDifferenceOfConvexProximalObjective, p)\nget_subtrahend_gradient!(M::AbstractManifold, X, dcpo::ManifoldDifferenceOfConvexProximalObjective, p) Evaluate the gradient of the subtrahend  $h$  from within a  ManifoldDifferenceOfConvexProximalObjective P at the point p` (in place of X). source"},{"id":2620,"pagetitle":"Difference of Convex","title":"Technical details","ref":"/manopt/stable/solvers/difference_of_convex/#sec-cp-technical-details","content":" Technical details The  difference_of_convex_algorithm  and  difference_of_convex_proximal_point  solver requires the following functions of a manifold to be available A  retract! (M, q, p, X) ; it is recommended to set the  default_retraction_method  to a favourite retraction. If this default is set, a  retraction_method=  or  retraction_method_dual=  (for  $\\mathcal N$ ) does not have to be specified. An  inverse_retract! (M, X, p, q) ; it is recommended to set the  default_inverse_retraction_method  to a favourite retraction. If this default is set, a  inverse_retraction_method=  or  inverse_retraction_method_dual=  (for  $\\mathcal N$ ) does not have to be specified. By default, one of the stopping criteria is  StopWhenChangeLess , which either requires A  retract! (M, q, p, X) ; it is recommended to set the  default_retraction_method  to a favourite retraction. If this default is set, a  retraction_method=  or  retraction_method_dual=  (for  $\\mathcal N$ ) does not have to be specified. An  inverse_retract! (M, X, p, q) ; it is recommended to set the  default_inverse_retraction_method  to a favourite retraction. If this default is set, a  inverse_retraction_method=  or  inverse_retraction_method_dual=  (for  $\\mathcal N$ ) does not have to be specified or the  distance (M, p, q)  for said default inverse retraction. A  `copyto! (M, q, p)  and  copy (M,p)  for points. By default the tangent vector storing the gradient is initialized calling  zero_vector (M,p) . everything the subsolver requires, which by default is the  trust_regions  or if you do not provide a Hessian  gradient_descent ."},{"id":2621,"pagetitle":"Difference of Convex","title":"Literature","ref":"/manopt/stable/solvers/difference_of_convex/#Literature","content":" Literature [ACOO20] Y.¬†T.¬†Almeida, J.¬†X.¬†Cruz Neto, P.¬†R.¬†Oliveira and J.¬†C.¬†Oliveira Souza.  A modified proximal point method for DC functions on Hadamard manifolds .  Computational¬†Optimization¬†and¬†Applications  76 , 649‚Äì673  (2020). [BFSS23] R.¬†Bergmann, O.¬†P.¬†Ferreira, E.¬†M.¬†Santos and J.¬†C.¬†Souza.  The difference of convex algorithm on Hadamard manifolds , arXiv¬†preprint (2023). [SO15] J.¬†C.¬†Souza and P.¬†R.¬†Oliveira.  A proximal point algorithm for DC fuctions on Hadamard manifolds .  Journal¬†of¬†Global¬†Optimization  63 , 797‚Äì810  (2015)."},{"id":2624,"pagetitle":"Exact Penalty Method","title":"Exact penalty method","ref":"/manopt/stable/solvers/exact_penalty_method/#Exact-penalty-method","content":" Exact penalty method"},{"id":2625,"pagetitle":"Exact Penalty Method","title":"Manopt.exact_penalty_method","ref":"/manopt/stable/solvers/exact_penalty_method/#Manopt.exact_penalty_method","content":" Manopt.exact_penalty_method  ‚Äî  Function exact_penalty_method(M, F, gradF, p=rand(M); kwargs...)\nexact_penalty_method(M, cmo::ConstrainedManifoldObjective, p=rand(M); kwargs...) perform the exact penalty method (EPM) [ LB19 ] The aim of the EPM is to find a solution of the constrained optimisation task \\[\\begin{aligned}\n\\min_{p ‚àà\\mathcal{M}} &f(p)\\\\\n\\text{subject to } &g_i(p)\\leq 0 \\quad \\text{ for } i= 1, ‚Ä¶, m,\\\\\n\\quad &h_j(p)=0 \\quad  \\text{ for } j=1,‚Ä¶,n,\n\\end{aligned}\\] where  M  is a Riemannian manifold, and  $f$ ,  $\\{g_i\\}_{i=1}^m$  and  $\\{h_j\\}_{j=1}^n$  are twice continuously differentiable functions from  M  to ‚Ñù. For that a weighted  $L_1$ -penalty term for the violation of the constraints is added to the objective \\[f(x) + œÅ\\biggl( \\sum_{i=1}^m \\max\\bigl\\{0, g_i(x)\\bigr\\} + \\sum_{j=1}^n \\vert h_j(x)\\vert\\biggr),\\] where  $œÅ>0$  is the penalty parameter. Since this is non-smooth, a  SmoothingTechnique  with parameter  u  is applied, see the  ExactPenaltyCost . In every step  $k$  of the exact penalty method, the smoothed objective is then minimized over all  $x ‚àà\\mathcal{M}$ . Then, the accuracy tolerance  $œµ$  and the smoothing parameter  $u$  are updated by setting \\[œµ^{(k)}=\\max\\{œµ_{\\min}, Œ∏_œµ œµ^{(k-1)}\\},\\] where  $œµ_{\\min}$  is the lowest value  $œµ$  is allowed to become and  $Œ∏_œµ ‚àà (0,1)$  is constant scaling factor, and \\[u^{(k)} = \\max \\{u_{\\min}, \\theta_u u^{(k-1)} \\},\\] where  $u_{\\min}$  is the lowest value  $u$  is allowed to become and  $Œ∏_u ‚àà (0,1)$  is constant scaling factor. Finally, the penalty parameter  $œÅ$  is updated as \\[œÅ^{(k)} = \\begin{cases}\nœÅ^{(k-1)}/Œ∏_œÅ,  & \\text{if } \\displaystyle \\max_{j ‚àà \\mathcal{E},i ‚àà \\mathcal{I}} \\Bigl\\{ \\vert h_j(x^{(k)}) \\vert, g_i(x^{(k)})\\Bigr\\} \\geq u^{(k-1)} \\Bigr) ,\\\\\nœÅ^{(k-1)}, & \\text{else,}\n\\end{cases}\\] where  $Œ∏_œÅ ‚àà (0,1)$  is a constant scaling factor. Input M       a manifold  $\\mathcal M$ f       a cost function  $f:\\mathcal M‚Üí‚Ñù$  to minimize grad_f  the gradient of the cost function Optional (if not called with the  ConstrainedManifoldObjective cmo ) g :      ( nothing ) the inequality constraints h :      ( nothing ) the equality constraints grad_g : ( nothing ) the gradient of the inequality constraints grad_h : ( nothing ) the gradient of the equality constraints Note that one of the pairs ( g ,  grad_g ) or ( h ,  grad_h ) has to be provided. Otherwise the problem is not constrained and you should consider using unconstrained solvers like  quasi_Newton . Optional smoothing :              ( LogarithmicSumOfExponentials )  SmoothingTechnique  to use œµ :                      ( 1e‚Äì3 ) the accuracy tolerance œµ_exponent :             ( 1/100 ) exponent of the œµ update factor; œµ_min :                  ( 1e-6 ) the lower bound for the accuracy tolerance u :                      ( 1e‚Äì1 ) the smoothing parameter and threshold for violation of the constraints u_exponent :             ( 1/100 ) exponent of the u update factor; u_min :                  ( 1e-6 ) the lower bound for the smoothing parameter and threshold for violation of the constraints œÅ :                      ( 1.0 ) the penalty parameter min_stepsize :           ( 1e-10 ) the minimal step size sub_cost :               ( ExactPenaltyCost (problem, œÅ, u; smoothing=smoothing) ) use this exact penalty cost, especially with the same numbers  œÅ,u  as in the options for the sub problem sub_grad :               ( ExactPenaltyGrad (problem, œÅ, u; smoothing=smoothing) ) use this exact penalty gradient, especially with the same numbers  œÅ,u  as in the options for the sub problem sub_kwargs :             keyword arguments to decorate the sub options, for example debug, that automatically respects the main solvers debug options (like sub-sampling) as well sub_stopping_criterion : ( StopAfterIteration (200) | StopWhenGradientNormLess (œµ) | StopWhenStepsizeLess (1e-10) ) specify a stopping criterion for the subsolver. sub_problem :            ( DefaultManoptProblem (M, ManifoldGradientObjective (sub_cost, sub_grad; evaluation=evaluation) , provide a problem for the subsolver sub_state :              ( QuasiNewtonState ) using  QuasiNewtonLimitedMemoryDirectionUpdate  with  InverseBFGS  and  sub_stopping_criterion  as a stopping criterion. See also  sub_kwargs . stopping_criterion :     ( StopAfterIteration (300)  | ( StopWhenSmallerOrEqual (œµ, œµ_min)  &  StopWhenChangeLess (1e-10) ) a functor inheriting from  StoppingCriterion  indicating when to stop. Output the obtained (approximate) minimizer  $p^*$ , see  get_solver_return  for details source"},{"id":2626,"pagetitle":"Exact Penalty Method","title":"Manopt.exact_penalty_method!","ref":"/manopt/stable/solvers/exact_penalty_method/#Manopt.exact_penalty_method!","content":" Manopt.exact_penalty_method!  ‚Äî  Function exact_penalty_method!(M, f, grad_f, p; kwargs...)\nexact_penalty_method!(M, cmo::ConstrainedManifoldObjective, p; kwargs...) perform the exact penalty method (EPM) performed in place of  p . For all options, see  exact_penalty_method . source"},{"id":2627,"pagetitle":"Exact Penalty Method","title":"State","ref":"/manopt/stable/solvers/exact_penalty_method/#State","content":" State"},{"id":2628,"pagetitle":"Exact Penalty Method","title":"Manopt.ExactPenaltyMethodState","ref":"/manopt/stable/solvers/exact_penalty_method/#Manopt.ExactPenaltyMethodState","content":" Manopt.ExactPenaltyMethodState  ‚Äî  Type ExactPenaltyMethodState{P,T} <: AbstractManoptSolverState Describes the exact penalty method, with Fields a default value is given in brackets if a parameter can be left out in initialization. p :                   a set point on a manifold as starting point sub_problem :         an  AbstractManoptProblem  problem for the subsolver sub_state :           an  AbstractManoptSolverState  for the subsolver œµ :                   ( 1e‚Äì3 ) the accuracy tolerance œµ_min :               ( 1e-6 ) the lower bound for the accuracy tolerance u :                   ( 1e‚Äì1 ) the smoothing parameter and threshold for violation of the constraints u_min :               ( 1e-6 ) the lower bound for the smoothing parameter and threshold for violation of the constraints œÅ :                   ( 1.0 ) the penalty parameter Œ∏_œÅ :                 ( 0.3 ) the scaling factor of the penalty parameter stopping_criterion :  ( StopAfterIteration (300) | ( StopWhenSmallerOrEqual (œµ, œµ_min) & StopWhenChangeLess (min_stepsize)) ) a functor inheriting from  StoppingCriterion  indicating when to stop. Constructor ExactPenaltyMethodState(M::AbstractManifold, p, sub_problem, sub_state; kwargs...) construct an exact penalty options with the remaining previously mentioned fields as keywords using their provided defaults. See also exact_penalty_method source"},{"id":2629,"pagetitle":"Exact Penalty Method","title":"Helping functions","ref":"/manopt/stable/solvers/exact_penalty_method/#Helping-functions","content":" Helping functions"},{"id":2630,"pagetitle":"Exact Penalty Method","title":"Manopt.ExactPenaltyCost","ref":"/manopt/stable/solvers/exact_penalty_method/#Manopt.ExactPenaltyCost","content":" Manopt.ExactPenaltyCost  ‚Äî  Type ExactPenaltyCost{S, Pr, R} Represent the cost of the exact penalty method based on a  ConstrainedManifoldObjective P  and a parameter  $œÅ$  given by \\[f(p) + œÅ\\Bigl(\n    \\sum_{i=0}^m \\max\\{0,g_i(p)\\} + \\sum_{j=0}^n \\lvert h_j(p)\\rvert\n\\Bigr),\\] where an additional parameter  $u$  is used as well as a smoothing technique, for example  LogarithmicSumOfExponentials  or  LinearQuadraticHuber  to obtain a smooth cost function. This struct is also a functor  (M,p) -> v  of the cost  $v$ . Fields œÅ ,  u : as described in the mathematical formula, . co :     the original cost Constructor ExactPenaltyCost(co::ConstrainedManifoldObjective, œÅ, u; smoothing=LinearQuadraticHuber()) source"},{"id":2631,"pagetitle":"Exact Penalty Method","title":"Manopt.ExactPenaltyGrad","ref":"/manopt/stable/solvers/exact_penalty_method/#Manopt.ExactPenaltyGrad","content":" Manopt.ExactPenaltyGrad  ‚Äî  Type ExactPenaltyGrad{S, CO, R} Represent the gradient of the  ExactPenaltyCost  based on a  ConstrainedManifoldObjective co  and a parameter  $œÅ$  and a smoothing technique, which uses an additional parameter  $u$ . This struct is also a functor in both formats (M, p) -> X  to compute the gradient in allocating fashion. (M, X, p)  to compute the gradient in in-place fashion. Fields œÅ ,  u  as stated before co  the nonsmooth objective Constructor ExactPenaltyGradient(co::ConstrainedManifoldObjective, œÅ, u; smoothing=LinearQuadraticHuber()) source"},{"id":2632,"pagetitle":"Exact Penalty Method","title":"Manopt.SmoothingTechnique","ref":"/manopt/stable/solvers/exact_penalty_method/#Manopt.SmoothingTechnique","content":" Manopt.SmoothingTechnique  ‚Äî  Type abstract type SmoothingTechnique Specify a smoothing technique, see for example  ExactPenaltyCost  and  ExactPenaltyGrad . source"},{"id":2633,"pagetitle":"Exact Penalty Method","title":"Manopt.LinearQuadraticHuber","ref":"/manopt/stable/solvers/exact_penalty_method/#Manopt.LinearQuadraticHuber","content":" Manopt.LinearQuadraticHuber  ‚Äî  Type LinearQuadraticHuber <: SmoothingTechnique Specify a smoothing based on  $\\max\\{0,x\\} ‚âà \\mathcal P(x,u)$  for some  $u$ , where \\[\\mathcal P(x, u) = \\begin{cases}\n  0 & \\text{ if } x \\leq 0,\\\\\n  \\frac{x^2}{2u} & \\text{ if } 0 \\leq x \\leq u,\\\\\n  x-\\frac{u}{2} & \\text{ if } x \\geq u.\n\\end{cases}\\] source"},{"id":2634,"pagetitle":"Exact Penalty Method","title":"Manopt.LogarithmicSumOfExponentials","ref":"/manopt/stable/solvers/exact_penalty_method/#Manopt.LogarithmicSumOfExponentials","content":" Manopt.LogarithmicSumOfExponentials  ‚Äî  Type LogarithmicSumOfExponentials <: SmoothingTechnique Specify a smoothing based on  $\\max\\{a,b\\} ‚âà u \\log(\\mathrm{e}^{\\frac{a}{u}}+\\mathrm{e}^{\\frac{b}{u}})$  for some  $u$ . source"},{"id":2635,"pagetitle":"Exact Penalty Method","title":"Technical details","ref":"/manopt/stable/solvers/exact_penalty_method/#sec-dr-technical-details","content":" Technical details The  exact_penalty_method  solver requires the following functions of a manifold to be available A  `copyto! (M, q, p)  and  copy (M,p)  for points. Everything the subsolver requires, which by default is the  quasi_Newton  method A  zero_vector (M,p) . The stopping criteria involves  StopWhenChangeLess  and  StopWhenGradientNormLess  which require An  inverse_retract! (M, X, p, q) ; it is recommended to set the  default_inverse_retraction_method  to a favourite retraction. If this default is set, a  inverse_retraction_method=  or  inverse_retraction_method_dual=  (for  $\\mathcal N$ ) does not have to be specified or the  distance (M, p, q)  for said default inverse retraction. the  norm  as well, to stop when the norm of the gradient is small, but if you implemented  inner , the norm is provided already."},{"id":2636,"pagetitle":"Exact Penalty Method","title":"Literature","ref":"/manopt/stable/solvers/exact_penalty_method/#Literature","content":" Literature [LB19] C.¬†Liu and N.¬†Boumal.  Simple algorithms for optimization on Riemannian manifolds with constraints .  Applied¬†Mathematics¬†&¬†Optimization  (2019),  arXiv:1091.10000 ."},{"id":2639,"pagetitle":"Gradient Descent","title":"Gradient descent","ref":"/manopt/stable/solvers/gradient_descent/#Gradient-descent","content":" Gradient descent"},{"id":2640,"pagetitle":"Gradient Descent","title":"Manopt.gradient_descent","ref":"/manopt/stable/solvers/gradient_descent/#Manopt.gradient_descent","content":" Manopt.gradient_descent  ‚Äî  Function gradient_descent(M, f, grad_f, p=rand(M); kwargs...)\ngradient_descent(M, gradient_objective, p=rand(M); kwargs...) perform a gradient descent \\[p_{k+1} = \\operatorname{retr}_{p_k}\\bigl( s_k\\operatorname{grad}f(p_k) \\bigr),\n\\qquad k=0,1,‚Ä¶\\] with different choices of the stepsize  $s_k$  available (see  stepsize  option below). Input M        a manifold  $\\mathcal M$ f        a cost function  $f: \\mathcal M‚Üí‚Ñù$  to find a minimizer  $p^*$  for grad_f   the gradient  $\\operatorname{grad}f: \\mathcal M ‚Üí T\\mathcal M$  of f as a function  (M, p) -> X  or a function  (M, X, p) -> X p        an initial value  p $= p_0 ‚àà \\mathcal M$ Alternatively to  f  and  grad_f  you can provide the  AbstractManifoldGradientObjective gradient_objective  directly. Optional direction :          ( IdentityUpdateRule ) perform a processing of the direction, e.g. evaluation :         ( AllocatingEvaluation ) specify whether the gradient works by allocation (default) form  grad_f(M, p)  or  InplaceEvaluation  in place of the form  grad_f!(M, X, p) . retraction_method :  ( default_retraction_method (M, typeof(p)) ) a retraction to use stepsize :           ( default_stepsize (M, GradientDescentState) ) a  Stepsize stopping_criterion : ( StopAfterIteration (200) | StopWhenGradientNormLess (1e-8) ) a functor inheriting from  StoppingCriterion  indicating when to stop. X :                  ([ zero_vector(M,p) ]) provide memory and/or type of the gradient to use` If you provide the  ManifoldGradientObjective  directly,  evaluation  is ignored. All other keyword arguments are passed to  decorate_state!  for state decorators or  decorate_objective!  for objective, respectively. If you provide the  ManifoldGradientObjective  directly, these decorations can still be specified Output the obtained (approximate) minimizer  $p^*$ . To obtain the whole final state of the solver, see  get_solver_return  for details source"},{"id":2641,"pagetitle":"Gradient Descent","title":"Manopt.gradient_descent!","ref":"/manopt/stable/solvers/gradient_descent/#Manopt.gradient_descent!","content":" Manopt.gradient_descent!  ‚Äî  Function gradient_descent!(M, f, grad_f, p; kwargs...)\ngradient_descent!(M, gradient_objective, p; kwargs...) perform a Gradient descent in-place of  p \\[p_{k+1} = \\operatorname{retr}_{p_k}\\bigl( s_k\\operatorname{grad}f(p_k) \\bigr)\\] in place of  p  with different choices of  $s_k$  available. Input M       a manifold  $\\mathcal M$ f       a cost function  $F:\\mathcal M‚Üí‚Ñù$  to minimize grad_f  the gradient  $\\operatorname{grad}F:\\mathcal M‚Üí T\\mathcal M$  of F p       an initial value  $p ‚àà \\mathcal M$ Alternatively to  f  and  grad_f  you can provide the  AbstractManifoldGradientObjective gradient_objective  directly. For more options, especially  Stepsize s for  $s_k$ , see  gradient_descent source"},{"id":2642,"pagetitle":"Gradient Descent","title":"State","ref":"/manopt/stable/solvers/gradient_descent/#State","content":" State"},{"id":2643,"pagetitle":"Gradient Descent","title":"Manopt.GradientDescentState","ref":"/manopt/stable/solvers/gradient_descent/#Manopt.GradientDescentState","content":" Manopt.GradientDescentState  ‚Äî  Type GradientDescentState{P,T} <: AbstractGradientSolverState Describes a Gradient based descent algorithm, with Fields a default value is given in brackets if a parameter can be left out in initialization. p :                  ( rand(M)  the current iterate X :                  ( zero_vector(M,p) ) the current gradient  $\\operatorname{grad}f(p)$ , initialised to zero vector. stopping_criterion : ( StopAfterIteration (100) ) a  StoppingCriterion stepsize :           ( default_stepsize (M, GradientDescentState) ) a  Stepsize direction :          ( IdentityUpdateRule ) a processor to compute the gradient retraction_method :  ( default_retraction_method(M, typeof(p)) ) the retraction to use, defaults to the default set for your manifold. Constructor GradientDescentState(M, p=rand(M); X=zero_vector(M, p), kwargs...) Generate gradient descent options, where  X  can be used to set the tangent vector to store the gradient in a certain type. All other fields are keyword arguments. See also gradient_descent source"},{"id":2644,"pagetitle":"Gradient Descent","title":"Direction update rules","ref":"/manopt/stable/solvers/gradient_descent/#Direction-update-rules","content":" Direction update rules A field of the options is the  direction , a  DirectionUpdateRule , which by default  IdentityUpdateRule  just evaluates the gradient but can be enhanced for example to"},{"id":2645,"pagetitle":"Gradient Descent","title":"Manopt.DirectionUpdateRule","ref":"/manopt/stable/solvers/gradient_descent/#Manopt.DirectionUpdateRule","content":" Manopt.DirectionUpdateRule  ‚Äî  Type DirectionUpdateRule A general functor, that handles direction update rules. It's fields are usually only a  StoreStateAction  by default initialized to the fields required for the specific coefficient, but can also be replaced by a (common, global) individual one that provides these values. source"},{"id":2646,"pagetitle":"Gradient Descent","title":"Manopt.IdentityUpdateRule","ref":"/manopt/stable/solvers/gradient_descent/#Manopt.IdentityUpdateRule","content":" Manopt.IdentityUpdateRule  ‚Äî  Type IdentityUpdateRule <: DirectionUpdateRule The default gradient direction update is the identity, usually it just evaluates the gradient. source"},{"id":2647,"pagetitle":"Gradient Descent","title":"Manopt.MomentumGradient","ref":"/manopt/stable/solvers/gradient_descent/#Manopt.MomentumGradient","content":" Manopt.MomentumGradient  ‚Äî  Type MomentumGradient <: DirectionUpdateRule Append a momentum to a gradient processor, where the last direction and last iterate are stored and the new is composed as  $Œ∑_i = m*Œ∑_{i-1}' - s d_i$ , where  $sd_i$  is the current (inner) direction and  $Œ∑_{i-1}'$  is the vector transported last direction multiplied by momentum  $m$ . Fields p_old :                   ( rand(M) ) remember the last iterate for parallel transporting the last direction momentum :                ( 0.2 ) factor for momentum direction :               internal  DirectionUpdateRule  to determine directions to add the momentum to. vector_transport_method : ( default_vector_transport_method(M, typeof(p)) ) vector transport method to use X_old :                   ( zero_vector(M,x0) ) the last gradient/direction update added as momentum Constructors Add momentum to a gradient problem, where by default just a gradient evaluation is used MomentumGradient(\n    M::AbstractManifold;\n    p=rand(M),\n    s::DirectionUpdateRule=IdentityUpdateRule();\n    X=zero_vector(p.M, x0), momentum=0.2\n    vector_transport_method=default_vector_transport_method(M, typeof(p)),\n) Initialize a momentum gradient rule to  s , where  p  and  X  are memory for interim values. source"},{"id":2648,"pagetitle":"Gradient Descent","title":"Manopt.AverageGradient","ref":"/manopt/stable/solvers/gradient_descent/#Manopt.AverageGradient","content":" Manopt.AverageGradient  ‚Äî  Type AverageGradient <: DirectionUpdateRule Add an average of gradients to a gradient processor. A set of previous directions (from the inner processor) and the last iterate are stored, average is taken after vector transporting them to the current iterates tangent space. Fields gradients :               the last  n  gradient/direction updates last_iterate :            last iterate (needed to transport the gradients) direction :               internal  DirectionUpdateRule  to determine directions to apply the averaging to vector_transport_method : vector transport method to use Constructors AverageGradient(\n    M::AbstractManifold,\n    p::P=rand(M);\n    n::Int=10\n    s::DirectionUpdateRule=IdentityUpdateRule();\n    gradients = fill(zero_vector(p.M, o.x),n),\n    last_iterate = deepcopy(x0),\n    vector_transport_method = default_vector_transport_method(M, typeof(p))\n) Add average to a gradient problem, where n :                       determines the size of averaging s :                       is the internal  DirectionUpdateRule  to determine the gradients to store gradients :               can be pre-filled with some history last_iterate :            stores the last iterate vector_transport_method : determines how to transport all gradients to the current iterates tangent space before averaging source"},{"id":2649,"pagetitle":"Gradient Descent","title":"Manopt.Nesterov","ref":"/manopt/stable/solvers/gradient_descent/#Manopt.Nesterov","content":" Manopt.Nesterov  ‚Äî  Type Nesterov <: DirectionUpdateRule Fields Œ≥ Œº  the strong convexity coefficient v  (= $=v_k$ ,  $v_0=x_0$ ) an interim point to compute the next gradient evaluation point  y_k shrinkage  ( = i -> 0.8 ) a function to compute the shrinkage  $Œ≤_k$  per iterate. Assume  $f$  is  $L$ -Lipschitz and  $Œº$ -strongly convex. Given a step size  $h_k<\\frac{1}{L}$  (from the  GradientDescentState a  shrinkage  parameter  $Œ≤_k$ and a current iterate  $x_k$ as well as the interim values  $Œ≥_k$  and  $v_k$  from the previous iterate. This compute a Nesterov type update using the following steps, see [ ZS18 ] Compute the positive root  $Œ±_k‚àà(0,1)$  of  $Œ±^2 = h_k\\bigl((1-Œ±_k)Œ≥_k+Œ±_k Œº\\bigr)$ . Set  $\\bar Œ≥_k+1 = (1-Œ±_k)Œ≥_k + Œ±_kŒº$ $y_k = \\operatorname{retr}_{x_k}\\Bigl(\\frac{Œ±_kŒ≥_k}{Œ≥_k + Œ±_kŒº}\\operatorname{retr}^{-1}_{x_k}v_k \\Bigr)$ $x_{k+1} = \\operatorname{retr}_{y_k}(-h_k \\operatorname{grad}f(y_k))$ $v_{k+1} = `\\operatorname{retr}_{y_k}\\Bigl(\\frac{(1-Œ±_k)Œ≥_k}{\\barŒ≥_k}\\operatorname{retr}_{y_k}^{-1}(v_k) - \\frac{Œ±_k}{\\bar Œ≥_{k+1}}\\operatorname{grad}f(y_k) \\Bigr)$ $Œ≥_{k+1} = \\frac{1}{1+Œ≤_k}\\bar Œ≥_{k+1}$ Then the direction from  $x_k$  to  $x_k+1$  by  $d = \\operatorname{retr}^{-1}_{x_k}x_{k+1}$  is returned. Constructor Nesterov(M::AbstractManifold, p::P; Œ≥=0.001, Œº=0.9, shrinkage = k -> 0.8;\n    inverse_retraction_method=LogarithmicInverseRetraction()) Initialize the Nesterov acceleration, where  x0  initializes  v . source"},{"id":2650,"pagetitle":"Gradient Descent","title":"Debug actions","ref":"/manopt/stable/solvers/gradient_descent/#Debug-actions","content":" Debug actions"},{"id":2651,"pagetitle":"Gradient Descent","title":"Manopt.DebugGradient","ref":"/manopt/stable/solvers/gradient_descent/#Manopt.DebugGradient","content":" Manopt.DebugGradient  ‚Äî  Type DebugGradient <: DebugAction debug for the gradient evaluated at the current iterate Constructors DebugGradient(; long=false, prefix= , format= \"$prefix%s\", io=stdout) display the short ( false ) or long ( true ) default text for the gradient, or set the  prefix  manually. Alternatively the complete format can be set. source"},{"id":2652,"pagetitle":"Gradient Descent","title":"Manopt.DebugGradientNorm","ref":"/manopt/stable/solvers/gradient_descent/#Manopt.DebugGradientNorm","content":" Manopt.DebugGradientNorm  ‚Äî  Type DebugGradientNorm <: DebugAction debug for gradient evaluated at the current iterate. Constructors DebugGradientNorm([long=false,p=print]) display the short ( false ) or long ( true ) default text for the gradient norm. DebugGradientNorm(prefix[, p=print]) display the a  prefix  in front of the gradient norm. source"},{"id":2653,"pagetitle":"Gradient Descent","title":"Manopt.DebugStepsize","ref":"/manopt/stable/solvers/gradient_descent/#Manopt.DebugStepsize","content":" Manopt.DebugStepsize  ‚Äî  Type DebugStepsize <: DebugAction debug for the current step size. Constructors DebugStepsize(;long=false,prefix=\"step size:\", format=\"$prefix%s\", io=stdout) display the a  prefix  in front of the step size. source"},{"id":2654,"pagetitle":"Gradient Descent","title":"Record actions","ref":"/manopt/stable/solvers/gradient_descent/#Record-actions","content":" Record actions"},{"id":2655,"pagetitle":"Gradient Descent","title":"Manopt.RecordGradient","ref":"/manopt/stable/solvers/gradient_descent/#Manopt.RecordGradient","content":" Manopt.RecordGradient  ‚Äî  Type RecordGradient <: RecordAction record the gradient evaluated at the current iterate Constructors RecordGradient(Œæ) initialize the  RecordAction  to the corresponding type of the tangent vector. source"},{"id":2656,"pagetitle":"Gradient Descent","title":"Manopt.RecordGradientNorm","ref":"/manopt/stable/solvers/gradient_descent/#Manopt.RecordGradientNorm","content":" Manopt.RecordGradientNorm  ‚Äî  Type RecordGradientNorm <: RecordAction record the norm of the current gradient source"},{"id":2657,"pagetitle":"Gradient Descent","title":"Manopt.RecordStepsize","ref":"/manopt/stable/solvers/gradient_descent/#Manopt.RecordStepsize","content":" Manopt.RecordStepsize  ‚Äî  Type RecordStepsize <: RecordAction record the step size source"},{"id":2658,"pagetitle":"Gradient Descent","title":"Technical details","ref":"/manopt/stable/solvers/gradient_descent/#sec-gradient-descent-technical-details","content":" Technical details The  gradient_descent  solver requires the following functions of a manifold to be available A  retract! (M, q, p, X) ; it is recommended to set the  default_retraction_method  to a favourite retraction. If this default is set, a  retraction_method=  does not have to be specified. By default gradient descent uses  ArmijoLinesearch  which requires  max_stepsize (M)  to be set and an implementation of  inner (M, p, X) . By default the stopping criterion uses the  norm  as well, to stop when the norm of the gradient is small, but if you implemented  inner , the norm is provided already. By default the tangent vector storing the gradient is initialized calling  zero_vector (M,p) ."},{"id":2659,"pagetitle":"Gradient Descent","title":"Literature","ref":"/manopt/stable/solvers/gradient_descent/#Literature","content":" Literature [Lue72] D.¬†G.¬†Luenberger.  The gradient projection method along geodesics . Management¬†Science  18 , 620‚Äì631 (1972). [ZS18] H.¬†Zhang and S.¬†Sra.  Towards Riemannian accelerated gradient methods , arXiv¬†Preprint,¬†1806.02812 (2018)."},{"id":2662,"pagetitle":"Particle Swarm Optimization","title":"Particle swarm optimization","ref":"/manopt/stable/solvers/particle_swarm/#Particle-swarm-optimization","content":" Particle swarm optimization"},{"id":2663,"pagetitle":"Particle Swarm Optimization","title":"Manopt.particle_swarm","ref":"/manopt/stable/solvers/particle_swarm/#Manopt.particle_swarm","content":" Manopt.particle_swarm  ‚Äî  Function patricle_swarm(M, f; kwargs...)\npatricle_swarm(M, f, swarm; kwargs...)\npatricle_swarm(M, mco::AbstractManifoldCostObjective; kwargs..)\npatricle_swarm(M, mco::AbstractManifoldCostObjective, swarm; kwargs..) perform the particle swarm optimization algorithm (PSO), starting with an initial  swarm  [ BIA10 ]. If no  swarm  is provided,  swarm_size  many random points are used. The aim of PSO is to find the particle position  $p$  on the  Manifold M  that solves approximately \\[\\min_{p ‚àà\\mathcal{M}} F(p).\\] To this end, a swarm  $S = \\{s_1, \\ldots, s_n\\}$  of particles is moved around the manifold  M  in the following manner. For every particle  $s_k^{(i)}$  the new particle velocities  $X_k^{(i)}$  are computed in every step  $i$  of the algorithm by \\[  X_k^{(i)} = œâ \\, \\operatorname{T}_{s_k^{(i)}\\gets s_k^{(i-1)}}X_k^{(i-1)} + c r_1  \\operatorname{retr}_{s_k^{(i)}}^{-1}(p_k^{(i)}) + s r_2 \\operatorname{retr}_{s_k^{(i)}}^{-1}(p),\\] where $s_k^{(i)}$  is the current particle position, $œâ$  denotes the inertia, $c$  and  $s$  are a cognitive and a social weight, respectively, $r_j$ ,  $j=1,2$  are random factors which are computed new for each particle and step $T$  denotes the vector transport and  $\\operatorname{retr}^{-1}$  the inverse retraction used Then the position of the particle is updated as \\[s_k^{(i+1)} = \\operatorname{retr}_{s_k^{(i)}}(X_k^{(i)}),\\] where  $\\operatorname{retr}$  denotes a retraction on the  Manifold M . Then the single particles best entries  $p_k^{(i)}$  are updated as \\[p_k^{(i+1)} = \\begin{cases}\ns_k^{(i+1)},  & \\text{if } F(s_k^{(i+1)})<F(p_{k}^{(i)}),\\\\\np_{k}^{(i)}, & \\text{else,}\n\\end{cases}\\] and the global best position \\[g^{(i+1)} = \\begin{cases}\np_k^{(i+1)},  & \\text{if } F(p_k^{(i+1)})<F(g_{k}^{(i)}),\\\\\ng_{k}^{(i)}, & \\text{else,}\n\\end{cases}\\] Input M :     a manifold  $\\mathcal M$ f :     a cost function  $F:\\mathcal M‚Üí‚Ñù$  to minimize swarm : ( [rand(M) for _ in 1:swarm_size] ) an initial swarm of points. Instead of a cost function  f  you can also provide an  AbstractManifoldCostObjective mco . Optional cognitive_weight :          ( 1.4 ) a cognitive weight factor inertia :                   ( 0.65 ) the inertia of the particles inverse_retraction_method : ( default_inverse_retraction_method(M, eltype(swarm)) ) an inverse retraction to use. swarm_size :                ( 100 ) swarm size, if it should be generated randomly retraction_method :         ( default_retraction_method(M, eltype(swarm)) ) a retraction to use. social_weight :             ( 1.4 ) a social weight factor stopping_criterion :        ( StopAfterIteration (500) | StopWhenChangeLess (1e-4) ) a functor inheriting from  StoppingCriterion  indicating when to stop. vector_transport_mthod :    ( default_vector_transport_method(M, eltype(swarm)) ) a vector transport method to use. velocity :                  a set of tangent vectors (of type  AbstractVector{T} ) representing the velocities of the particles, per default a random tangent vector per initial position All other keyword arguments are passed to  decorate_state!  for decorators or  decorate_objective! , respectively. If you provide the  ManifoldGradientObjective  directly, these decorations can still be specified Output the obtained (approximate) minimizer  $g$ , see  get_solver_return  for details source"},{"id":2664,"pagetitle":"Particle Swarm Optimization","title":"Manopt.particle_swarm!","ref":"/manopt/stable/solvers/particle_swarm/#Manopt.particle_swarm!","content":" Manopt.particle_swarm!  ‚Äî  Function patricle_swarm!(M, f, swarm; kwargs...)\npatricle_swarm!(M, mco::AbstractManifoldCostObjective, swarm; kwargs..) perform the particle swarm optimization algorithm (PSO), starting with the initial  swarm  which is then modified in place. Input M :     a manifold  $\\mathcal M$ f :     a cost function  $f:\\mathcal M‚Üí‚Ñù$  to minimize swarm : ( [rand(M) for _ in 1:swarm_size] ) an initial swarm of points. Instead of a cost function  f  you can also provide an  AbstractManifoldCostObjective mco . For more details and optional arguments, see  particle_swarm . source"},{"id":2665,"pagetitle":"Particle Swarm Optimization","title":"State","ref":"/manopt/stable/solvers/particle_swarm/#State","content":" State"},{"id":2666,"pagetitle":"Particle Swarm Optimization","title":"Manopt.ParticleSwarmState","ref":"/manopt/stable/solvers/particle_swarm/#Manopt.ParticleSwarmState","content":" Manopt.ParticleSwarmState  ‚Äî  Type ParticleSwarmState{P,T} <: AbstractManoptSolverState Describes a particle swarm optimizing algorithm, with Fields cognitive_weight :          ( 1.4 ) a cognitive weight factor inertia :                   ( 0.65 ) the inertia of the particles inverse_retraction_method : ( default_inverse_retraction_method(M, eltype(swarm)) ) an inverse retraction to use. retraction_method :         ( default_retraction_method(M, eltype(swarm)) ) the retraction to use social_weight :             ( 1.4 ) a social weight factor stopping_criterion :        ( [ StopAfterIteration ](@ref) (500) |  [ StopWhenChangeLess ](@ref) (1e-4) ) a functor inheriting from [ StoppingCriterion`](@ref) indicating when to stop. vector_transport_method :  ( default_vector_transport_method(M, eltype(swarm)) ) a vector transport to use velocity :                 a set of tangent vectors (of type  AbstractVector{T} ) representing the velocities of the particles Internal and temporary fields cognitive_vector : temporary storage for a tangent vector related to  cognitive_weight p :                storage for the best point  $p$  visited by all particles. positional_best :  storing the best position  $p_i$  every single swarm participant visited q :                temporary storage for a point to avoid allocations during a step of the algorithm social_vec :       temporary storage for a tangent vector related to  social_weight swarm :            a set of points (of type  AbstractVector{P} ) on a manifold  $\\{s_i\\}_{i=1}^N$ Constructor ParticleSwarmState(M, initial_swarm, velocity; kawrgs...) construct a particle swarm solver state for the manifold  M  starting at initial population  x0  with  velocities , where the manifold is used within the defaults specified previously. All fields with defaults are keyword arguments here. See also particle_swarm source"},{"id":2667,"pagetitle":"Particle Swarm Optimization","title":"Stopping Criteria","ref":"/manopt/stable/solvers/particle_swarm/#Stopping-Criteria","content":" Stopping Criteria"},{"id":2668,"pagetitle":"Particle Swarm Optimization","title":"Manopt.StopWhenSwarmVelocityLess","ref":"/manopt/stable/solvers/particle_swarm/#Manopt.StopWhenSwarmVelocityLess","content":" Manopt.StopWhenSwarmVelocityLess  ‚Äî  Type StopWhenSwarmVelocityLess <: StoppingCriterion Stoping criterion for  particle_swarm , when the velocity of the swarm is less than a threshold. Fields threshold :      the threshold at_iteration :   store the iteration the stopping criterion was (last) fulfilled reason :         store the reaason why the stopping criterion was filfilled, see  get_reason velocity_norms : interims vector to store the norms of the velocities before coputing its norm Constructor StopWhenSwarmVelocityLess(tolerance::Float64) initialize the stopping criterion to a certain  tolerance . source"},{"id":2669,"pagetitle":"Particle Swarm Optimization","title":"Technical details","ref":"/manopt/stable/solvers/particle_swarm/#sec-arc-technical-details","content":" Technical details The  particle_swarm  solver requires the following functions of a manifold to be available A  retract! (M, q, p, X) ; it is recommended to set the  default_retraction_method  to a favourite retraction. If this default is set, a  retraction_method=  does not have to be specified. An  inverse_retract! (M, X, p, q) ; it is recommended to set the  default_inverse_retraction_method  to a favourite retraction. If this default is set, a  inverse_retraction_method=  does not have to be specified. A  vector_transport_to! M, Y, p, X, q) ; it is recommended to set the  default_vector_transport_method  to a favourite retraction. If this default is set, a  vector_transport_method=  does not have to be specified. By default the stopping criterion uses the  norm  as well, to stop when the norm of the gradient is small, but if you implemented  inner , the norm is provided already. Tangent vectors storing the social and cognitive vectors are initialized calling  zero_vector (M,p) . A  `copyto! (M, q, p)  and  copy (M,p)  for points. The  distance (M, p, q)  when using the default stopping criterion, which uses  StopWhenChangeLess ."},{"id":2670,"pagetitle":"Particle Swarm Optimization","title":"Literature","ref":"/manopt/stable/solvers/particle_swarm/#Literature","content":" Literature [BIA10] P.¬†B.¬†Borckmans, M.¬†Ishteva and P.-A.¬†Absil.  A Modified Particle Swarm Optimization Algorithm for the Best Low Multilinear Rank Approximation of Higher-Order Tensors . In:  7th International Conference on Swarm INtelligence  (Springer Berlin Heidelberg, 2010); pp.¬†13‚Äì23."},{"id":2673,"pagetitle":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton algorithm","ref":"/manopt/stable/solvers/primal_dual_semismooth_Newton/#solver-pdrssn","content":" Primal-dual Riemannian semismooth Newton algorithm The Primal-dual Riemannian semismooth Newton Algorithm is a second-order method derived from the  ChambollePock . The aim is to solve an optimization problem on a manifold with a cost function of the form \\[F(p) + G(Œõ(p)),\\] where  $F:\\mathcal M ‚Üí \\overline{‚Ñù}$ ,  $G:\\mathcal N ‚Üí \\overline{‚Ñù}$ , and  $Œõ:\\mathcal M ‚Üí\\mathcal N$ . If the manifolds  $\\mathcal M$  or  $\\mathcal N$  are not Hadamard, it has to be considered locally only, that is on geodesically convex sets  $\\mathcal C \\subset \\mathcal M$  and  $\\mathcal D \\subset\\mathcal N$  such that  $Œõ(\\mathcal C) \\subset \\mathcal D$ . The algorithm comes down to applying the Riemannian semismooth Newton method to the rewritten primal-dual optimality conditions. Define the vector field  $X: \\mathcal{M} \\times \\mathcal{T}_{n}^{*} \\mathcal{N} \\rightarrow \\mathcal{T} \\mathcal{M} \\times \\mathcal{T}_{n}^{*} \\mathcal{N}$  as \\[X\\left(p, \\xi_{n}\\right):=\\left(\\begin{array}{c}\n-\\log _{p} \\operatorname{prox}_{\\sigma F}\\left(\\exp _{p}\\left(\\mathcal{P}_{p \\leftarrow m}\\left(-\\sigma\\left(D_{m} \\Lambda\\right)^{*}\\left[\\mathcal{P}_{\\Lambda(m) \\leftarrow n} \\xi_{n}\\right]\\right)^{\\sharp}\\right)\\right) \\\\\n\\xi_{n}-\\operatorname{prox}_{\\tau G_{n}^{*}}\\left(\\xi_{n}+\\tau\\left(\\mathcal{P}_{n \\leftarrow \\Lambda(m)} D_{m} \\Lambda\\left[\\log _{m} p\\right]\\right)^{\\flat}\\right)\n\\end{array}\\right)\\] and solve for  $X(p,Œæ_{n})=0$ . Given base points  $m‚àà\\mathcal C$ ,  $n=Œõ(m)‚àà\\mathcal D$ , initial primal and dual values  $p^{(0)} ‚àà\\mathcal C$ ,  $Œæ_{n}^{(0)} ‚àà \\mathcal T_{n}^{*}\\mathcal N$ , and primal and dual step sizes  $\\sigma$ ,  $\\tau$ . The algorithms performs the steps  $k=1,‚Ä¶,$  (until a  StoppingCriterion  is reached) Choose any element \\[V^{(k)} ‚àà ‚àÇ_C X(p^{(k)},Œæ_n^{(k)})\\] of the Clarke generalized covariant derivative Solve \\[V^{(k)} [(d_p^{(k)}, d_n^{(k)})] = - X(p^{(k)},Œæ_n^{(k)})\\] in the vector space  $\\mathcal{T}_{p^{(k)}} \\mathcal{M} \\times \\mathcal{T}_{n}^{*} \\mathcal{N}$ Update \\[p^{(k+1)} := \\exp_{p^{(k)}}(d_p^{(k)})\\] and \\[Œæ_n^{(k+1)} := Œæ_n^{(k)} + d_n^{(k)}\\] Furthermore you can exchange the exponential map, the logarithmic map, and the parallel transport by a retraction, an inverse retraction and a vector transport. Finally you can also update the base points  $m$  and  $n$  during the iterations. This introduces a few additional vector transports. The same holds for the case that  $Œõ(m^{(k)})\\neq n^{(k)}$  at some point. All these cases are covered in the algorithm."},{"id":2674,"pagetitle":"Primal-dual Riemannian semismooth Newton","title":"Manopt.primal_dual_semismooth_Newton","ref":"/manopt/stable/solvers/primal_dual_semismooth_Newton/#Manopt.primal_dual_semismooth_Newton","content":" Manopt.primal_dual_semismooth_Newton  ‚Äî  Function primal_dual_semismooth_Newton(M, N, cost, p, X, m, n, prox_F, diff_prox_F, prox_G_dual, diff_prox_dual_G, linearized_operator, adjoint_linearized_operator) Perform the Primal-Dual Riemannian semismooth Newton algorithm. Given a  cost  function  $\\mathcal E: \\mathcal M ‚Üí \\overline{‚Ñù}$  of the form \\[\\mathcal E(p) = F(p) + G( Œõ(p) ),\\] where  $F: \\mathcal M ‚Üí \\overline{‚Ñù}$ ,  $G: \\mathcal N ‚Üí \\overline{‚Ñù}$ , and  $\\Lambda: \\mathcal M ‚Üí \\mathcal N$ . The remaining input parameters are p, X :                          primal and dual start points  $p‚àà\\mathcal M$  and  $X ‚àà T_n\\mathcal N$ m,n :                           base points on  $\\mathcal M$  and  $\\mathcal N$ , respectively. linearized_forward_operator :   the linearization  $DŒõ(‚ãÖ)[‚ãÖ]$  of the operator  $Œõ(‚ãÖ)$ . adjoint_linearized_operator :   the adjoint  $DŒõ^*$  of the linearized operator  $DŒõ(m):  T_{m}\\mathcal M ‚Üí T_{Œõ(m)}\\mathcal N$ prox_F, prox_G_Dual :           the proximal maps of  $F$  and  $G^\\ast_n$ diff_prox_F, diff_prox_dual_G : the (Clarke Generalized) differentials of the proximal maps of  $F$  and  $G^\\ast_n$ For more details on the algorithm, see [ DL21 ]. Optional parameters primal_stepsize :           ( 1/sqrt(8) ) proximal parameter of the primal prox Œõ :                         ( missing ) the exact operator, that is required if  Œõ(m)=n  does not hold;  missing  indicates, that the forward operator is exact. dual_stepsize :             ( 1/sqrt(8) ) proximal parameter of the dual prox reg_param :                 ( 1e-5 ) regularisation parameter for the Newton matrix Note that this changes the arguments the  forward_operator  is called. stopping_criterion :        ( stopAtIteration(50) ) a  StoppingCriterion update_primal_base :        ( missing ) function to update  m  (identity by default/missing) update_dual_base :          ( missing ) function to update  n  (identity by default/missing) retraction_method :         ( default_retraction_method(M, typeof(p)) ) the retraction to use inverse_retraction_method : ( default_inverse_retraction_method(M, typeof(p)) ) an inverse retraction to use. vector_transport_method :   ( default_vector_transport_method(M, typeof(p)) ) a vector transport to use Output the obtained (approximate) minimizer  $p^*$ , see  get_solver_return  for details source"},{"id":2675,"pagetitle":"Primal-dual Riemannian semismooth Newton","title":"Manopt.primal_dual_semismooth_Newton!","ref":"/manopt/stable/solvers/primal_dual_semismooth_Newton/#Manopt.primal_dual_semismooth_Newton!","content":" Manopt.primal_dual_semismooth_Newton!  ‚Äî  Function primal_dual_semismooth_Newton(M, N, cost, x0, Œæ0, m, n, prox_F, diff_prox_F, prox_G_dual, diff_prox_G_dual, linearized_forward_operator, adjoint_linearized_operator) Perform the Riemannian Primal-dual Riemannian semismooth Newton algorithm in place of  x ,  Œæ , and potentially  m ,  n  if they are not fixed. See  primal_dual_semismooth_Newton  for details and optional parameters. source"},{"id":2676,"pagetitle":"Primal-dual Riemannian semismooth Newton","title":"State","ref":"/manopt/stable/solvers/primal_dual_semismooth_Newton/#State","content":" State"},{"id":2677,"pagetitle":"Primal-dual Riemannian semismooth Newton","title":"Manopt.PrimalDualSemismoothNewtonState","ref":"/manopt/stable/solvers/primal_dual_semismooth_Newton/#Manopt.PrimalDualSemismoothNewtonState","content":" Manopt.PrimalDualSemismoothNewtonState  ‚Äî  Type PrimalDualSemismoothNewtonState <: AbstractPrimalDualSolverState m :                         base point on  $\\mathcal M$ n :                         base point on  $\\mathcal N$ x :                         an initial point on  $x^{(0)} ‚àà \\mathcal M$  (and its previous iterate) Œæ :                         an initial tangent vector  $\\xi^{(0)} ‚àà T_{n}^*\\mathcal N$  (and its previous iterate) primal_stepsize :           ( 1/sqrt(8) ) proximal parameter of the primal prox dual_stepsize :             ( 1/sqrt(8) ) proximal parameter of the dual prox reg_param :                 ( 1e-5 ) regularisation parameter for the Newton matrix stop :                      a  StoppingCriterion update_primal_base :        ( ( amp, ams, i) -> o.m ) function to update the primal base update_dual_base :          ( (amp, ams, i) -> o.n ) function to update the dual base retraction_method :         ( default_retraction_method(M, typeof(p)) ) the retraction to use inverse_retraction_method : ( default_inverse_retraction_method(M, typeof(p)) ) an inverse retraction to use. vector_transport_method :   ( default_vector_transport_method(M, typeof(p)) ) a vector transport to use where for the update functions a  AbstractManoptProblem amp ,  AbstractManoptSolverState ams  and the current iterate  i  are the arguments. If you activate these to be different from the default identity, you have to provide  p.Œõ  for the algorithm to work (which might be  missing ). Constructor PrimalDualSemismoothNewtonState(M::AbstractManifold,\n    m::P, n::Q, x::P, Œæ::T, primal_stepsize::Float64, dual_stepsize::Float64, reg_param::Float64;\n    stopping_criterion::StoppingCriterion = StopAfterIteration(50),\n    update_primal_base::Union{Function,Missing} = missing,\n    update_dual_base::Union{Function,Missing} = missing,\n    retraction_method = default_retraction_method(M, typeof(p)),\n    inverse_retraction_method = default_inverse_retraction_method(M, typeof(p)),\n    vector_transport_method = default_vector_transport_method(M, typeof(p)),\n) source"},{"id":2678,"pagetitle":"Primal-dual Riemannian semismooth Newton","title":"Technical details","ref":"/manopt/stable/solvers/primal_dual_semismooth_Newton/#sec-ssn-technical-details","content":" Technical details The  primal_dual_semismooth_Newton  solver requires the following functions of a manifold to be available for both the manifold  $\\mathcal M$ and  $\\mathcal N$ A  retract! (M, q, p, X) ; it is recommended to set the  default_retraction_method  to a favourite retraction. If this default is set, a  retraction_method=  does not have to be specified. An  inverse_retract! (M, X, p, q) ; it is recommended to set the  default_inverse_retraction_method  to a favourite retraction. If this default is set, a  inverse_retraction_method=  does not have to be specified. A  vector_transport_to! M, Y, p, X, q) ; it is recommended to set the  default_vector_transport_method  to a favourite retraction. If this default is set, a  vector_transport_method=  does not have to be specified. A  `copyto! (M, q, p)  and  copy (M,p)  for points. A  get_basis  for the  DefaultOrthonormalBasis  on  $\\mathcal M$ exp  and  log  (on  $\\mathcal M$ ) A  DiagonalizingOrthonormalBasis  to compute the differentials of the exponential and logarithmic map Tangent vectors storing the social and cognitive vectors are initialized calling  zero_vector (M,p) ."},{"id":2679,"pagetitle":"Primal-dual Riemannian semismooth Newton","title":"Literature","ref":"/manopt/stable/solvers/primal_dual_semismooth_Newton/#Literature","content":" Literature [DL21] W.¬†Diepeveen and J.¬†Lellmann.  An Inexact Semismooth Newton Method on Riemannian Manifolds with Application to Duality-Based Total Variation Denoising .  SIAM¬†Journal¬†on¬†Imaging¬†Sciences  14 , 1565‚Äì1600  (2021),  arXiv:2102.10309 ."},{"id":2682,"pagetitle":"Proximal bundle method","title":"Proximal Bundle Method","ref":"/manopt/stable/solvers/proximal_bundle_method/#ProxBundleMethodSolver","content":" Proximal Bundle Method"},{"id":2683,"pagetitle":"Proximal bundle method","title":"Manopt.proximal_bundle_method","ref":"/manopt/stable/solvers/proximal_bundle_method/#Manopt.proximal_bundle_method","content":" Manopt.proximal_bundle_method  ‚Äî  Function proximal_bundle_method(M, f, ‚àÇf, p) perform a proximal bundle method  $p_{j+1} = \\mathrm{retr}(p_k, -d_k)$ , where \\[d_k = \\frac{1}{\\mu_l} \\sum_{j\\in J_k} Œª_j^k \\mathrm{P}_{p_k‚Üêq_j}X_{q_j},\\] where  $X_{q_j}\\in‚àÇf(q_j)$ ,  $\\mathrm{retr}$  is a retraction,  $p_k$  is the last serious iterate,  $\\mu_l$  is a proximal parameter, and the  $Œª_j^k$  are solutionsto the quadratic subproblem provided by the  proximal_bundle_method_subsolver . Though the subdifferential might be set valued, the argument  ‚àÇf  should always return  one  element from the subdifferential, but not necessarily deterministic. For more details see [ HNP23 ]. Input M : a manifold  $\\mathcal M$ f : a cost function  $F:\\mathcal M ‚Üí ‚Ñù$  to minimize ‚àÇf : the (sub)gradient  $‚àÇ f: \\mathcal M ‚Üí T\\mathcal M$  of f restricted to always only returning one value/element from the subdifferential. This function can be passed as an allocation function  (M, p) -> X  or a mutating function  (M, X, p) -> X , see  evaluation . p : an initial value  $p ‚àà \\mathcal M$ Optional m : a real number that controls the decrease of the cost function evaluation  ‚Äì ( AllocatingEvaluation ) specify whether the subgradient works by  allocation (default) form  ‚àÇf(M, q)  or  InplaceEvaluation  in place, i.e. is  of the form  ‚àÇf!(M, X, p) . inverse_retraction_method : ( default_inverse_retraction_method(M, typeof(p)) ) an inverse retraction method to use retraction  ‚Äì ( default_retraction_method(M, typeof(p)) ) a  retraction(M, p, X)  to use. stopping_criterion  ‚Äì ( StopWhenLagrangeMultiplierLess (1e-8) ) a functor, see StoppingCriterion , indicating when to stop. vector_transport_method : ( default_vector_transport_method(M, typeof(p)) ) a vector transport method to use ... and the ones that are passed to  decorate_state!  for decorators. Output the obtained (approximate) minimizer  $p^*$ , see  get_solver_return  for details source"},{"id":2684,"pagetitle":"Proximal bundle method","title":"Manopt.proximal_bundle_method!","ref":"/manopt/stable/solvers/proximal_bundle_method/#Manopt.proximal_bundle_method!","content":" Manopt.proximal_bundle_method!  ‚Äî  Function proximal_bundle_method!(M, f, ‚àÇf, p) perform a proximal bundle method  $p_{j+1} = \\mathrm{retr}(p_k, -d_k)$  in place of  p Input M  ‚Äì a manifold  $\\mathcal M$ f  ‚Äì a cost function  $f:\\mathcal M‚Üí‚Ñù$  to minimize ‚àÇf - the (sub)gradient  $\\partial f:\\mathcal M‚Üí T\\mathcal M$  of F restricted to always only returning one value/element from the subdifferential. This function can be passed as an allocation function  (M, p) -> X  or a mutating function  (M, X, p) -> X , see  evaluation . p  ‚Äì an initial value  $p_0=p ‚àà \\mathcal M$ for more details and all optional parameters, see  proximal_bundle_method . source"},{"id":2685,"pagetitle":"Proximal bundle method","title":"State","ref":"/manopt/stable/solvers/proximal_bundle_method/#State","content":" State"},{"id":2686,"pagetitle":"Proximal bundle method","title":"Manopt.ProximalBundleMethodState","ref":"/manopt/stable/solvers/proximal_bundle_method/#Manopt.ProximalBundleMethodState","content":" Manopt.ProximalBundleMethodState  ‚Äî  Type ProximalBundleMethodState <: AbstractManoptSolverState stores option values for a  proximal_bundle_method  solver. Fields approx_errors :            approximation of the linearization errors at the last serious step bundle :                   bundle that collects each iterate with the computed subgradient at the iterate bundle_size :              ( 50 ) the maximal size of the bundle c :                         convex combination of the approximation errors d :                         descent direction inverse_retraction_method : the inverse retraction to use within m :                         ( 0.0125 ) the parameter to test the decrease of the cost p :                         current candidate point p_last_serious :            last serious iterate retraction_method :         the retraction to use within stop :                      a  StoppingCriterion transported_subgradients :  subgradients of the bundle that are transported to p last serious vector_transport_method :   the vector transport method to use within X :                         ( zero_vector(M, p) ) the current element from the possible subgradients at  p  that was last evaluated. Œ±‚ÇÄ :                        ( 1.2 ) initalization value for  Œ± , used to update  Œ∑ Œ± :                         curvature-dependent parameter used to update  Œ∑ Œµ :                         ( 1e-2 ) stepsize-like parameter related to the injectivity radius of the manifold Œ¥ :                         parameter for updating  Œº : if  $Œ¥ < 0$  then  $Œº = \\log(i + 1)$ , else  $Œº += Œ¥ Œº$ Œ∑ :                         curvature-dependent term for updating the approximation errors Œª :                         convex coefficients that solve the subproblem Œº :                         ( 0.5 ) (initial) proximal parameter for the subproblem ŒΩ :                         the stopping parameter given by  $ŒΩ = - Œº |d|^2 - c$ sub_problem :               a function evaluating with new allocations that solves the sub problem on  M  given the last serious iterate  p_last_serious , the linearization errors  linearization_errors , and the transported subgradients  transported_subgradients , Constructor ProximalBundleMethodState(M::AbstractManifold, p; kwargs...) with keywords for all fields above besides  p_last_serious  which obtains the same type as  p . You can use e.g.  X=  to specify the type of tangent vector to use source"},{"id":2687,"pagetitle":"Proximal bundle method","title":"Helpers and internal functions","ref":"/manopt/stable/solvers/proximal_bundle_method/#Helpers-and-internal-functions","content":" Helpers and internal functions"},{"id":2688,"pagetitle":"Proximal bundle method","title":"Manopt.proximal_bundle_method_subsolver","ref":"/manopt/stable/solvers/proximal_bundle_method/#Manopt.proximal_bundle_method_subsolver","content":" Manopt.proximal_bundle_method_subsolver  ‚Äî  Function Œª = proximal_bundle_method_subsolver(M, p_last_serious, Œº, approximation_errors, transported_subgradients)\nproximal_bundle_method_subsolver!(M, Œª, p_last_serious, Œº, approximation_errors, transported_subgradients) solver for the subproblem of the proximal bundle method. The subproblem for the proximal bundle method is \\[\\begin{align*}\n    \\operatorname*{arg\\,min}_{Œª ‚àà ‚Ñù^{\\lvert L_l\\rvert}} &\n    \\frac{1}{2 \\mu_l} \\Bigl\\lVert \\sum_{j ‚àà L_l} Œª_j \\mathrm{P}_{p_k‚Üêq_j} X_{q_j} \\Bigr\\rVert^2\n    + \\sum_{j ‚àà L_l} Œª_j \\, c_j^k\n    \\\\\n    \\text{s. t.} \\quad &\n    \\sum_{j ‚àà L_l} Œª_j = 1,\n    \\quad Œª_j ‚â• 0\n    \\quad \\text{for all } j ‚àà L_l,\n\\end{align*}\\] where  $L_l = \\{k\\}$  if  $q_k$  is a serious iterate, and  $L_l = L_{l-1} \\cup \\{k\\}$  otherwise. See [ HNP23 ]. Tip A default subsolver based on  RipQP .jl  and  QuadraticModels  is available if these two packages are loaded. source"},{"id":2689,"pagetitle":"Proximal bundle method","title":"Literature","ref":"/manopt/stable/solvers/proximal_bundle_method/#Literature","content":" Literature [HNP23] N.¬†Hoseini Monjezi, S.¬†Nobakhtian and M.¬†R.¬†Pouryayevali.  A proximal bundle algorithm for nonsmooth optimization on Riemannian manifolds .  IMA¬†Journal¬†of¬†Numerical¬†Analysis  43 , 293‚Äì325  (2023)."},{"id":2692,"pagetitle":"Quasi-Newton","title":"Riemannian quasi-Newton methods","ref":"/manopt/stable/solvers/quasi_Newton/#Riemannian-quasi-Newton-methods","content":" Riemannian quasi-Newton methods"},{"id":2693,"pagetitle":"Quasi-Newton","title":"Manopt.quasi_Newton","ref":"/manopt/stable/solvers/quasi_Newton/#Manopt.quasi_Newton","content":" Manopt.quasi_Newton  ‚Äî  Function quasi_Newton(M, f, grad_f, p) Perform a quasi Newton iteration for  f  on the manifold  M  starting in the point  p . The  $k$ th iteration consists of Compute the search direction  $Œ∑_k = -\\mathcal{B}_k [\\operatorname{grad}f (p_k)]$  or solve  $\\mathcal{H}_k [Œ∑_k] = -\\operatorname{grad}f (p_k)]$ . Determine a suitable stepsize  $Œ±_k$  along the curve  $\\gamma(Œ±) = R_{p_k}(Œ± Œ∑_k)$ , usually by using  WolfePowellLinesearch . Compute  p_{k+1} = R_{p_k}(Œ±_k Œ∑_k) `. Define  $s_k = T_{p_k, Œ±_k Œ∑_k}(Œ±_k Œ∑_k)$  and  $y_k = \\operatorname{grad}f(p_{k+1}) - T_{p_k, Œ±_k Œ∑_k}(\\operatorname{grad}f(p_k))$ . Compute the new approximate Hessian  $H_{k+1}$  or its inverse  $B_k$ . Input M       a manifold  $\\mathcal{M}$ . f       a cost function  $F : \\mathcal{M} ‚Üí‚Ñù$  to minimize. grad_f  the gradient  $\\operatorname{grad}F : \\mathcal{M} ‚ÜíT_x\\mathcal M$  of  $F$ . p       an initial value  $p ‚àà \\mathcal{M}$ . Optional basis :                   ( DefaultOrthonormalBasis() ) basis within the tangent spaces to represent the Hessian (inverse). cautious_update :         ( false ) whether or not to use a  QuasiNewtonCautiousDirectionUpdate cautious_function :       ( (x) -> x*10^(-4) ) a monotone increasing function that is zero at 0 and strictly increasing at 0 for the cautious update. direction_update :        ( InverseBFGS () ) the update rule to use. evaluation :              ( AllocatingEvaluation ) specify whether the gradient works by  allocation (default) form  gradF(M, x)  or  InplaceEvaluation  in place of form  gradF!(M, X, x) . initial_operator :        ( Matrix{Float64}(I,n,n) ) initial matrix to use die the approximation, where  n=manifold_dimension(M) , see also  scale_initial_operator . memory_size :             ( 20 ) limited memory, number of  $s_k, y_k$  to store. Set to a negative value to use a full memory representation retraction_method :       ( default_retraction_method(M, typeof(p)) ) a retraction method to use scale_initial_operator :  ( true ) scale initial operator with  $\\frac{‚ü®s_k,y_k‚ü©_{p_k}}{\\lVert y_k\\rVert_{p_k}}$  in the computation stabilize :               ( true ) stabilize the method numerically by projecting computed (Newton-) directions to the tangent space to reduce numerical errors stepsize :                ( WolfePowellLinesearch (retraction_method, vector_transport_method) ) specify a  Stepsize . stopping_criterion :      ( StopAfterIteration (max(1000, memory_size)) | StopWhenGradientNormLess (1e-6) ) specify a  StoppingCriterion vector_transport_method : ( default_vector_transport_method(M, typeof(p)) ) a vector transport to use. nondescent_direction_behavior : ( :step_towards_negative_gradient ) specify how non-descent direction is handled. This can be ` :step_towards_negative_gradient  ‚Äì the direction is replaced with negative gradient, a message is stored. :ignore  ‚Äì the check is not performed, so any computed direction is accepted. No message is stored. any other value performs the check, keeps the direction but stores a message. A stored message can be displayed using  DebugMessages . Output the obtained (approximate) minimizer  $p^*$ , see  get_solver_return  for details. source"},{"id":2694,"pagetitle":"Quasi-Newton","title":"Manopt.quasi_Newton!","ref":"/manopt/stable/solvers/quasi_Newton/#Manopt.quasi_Newton!","content":" Manopt.quasi_Newton!  ‚Äî  Function quasi_Newton!(M, F, gradF, x; options...) Perform a quasi Newton iteration for  F  on the manifold  M  starting in the point  x  using a retraction  $R$  and a vector transport  $T$ . Input M      a manifold  $\\mathcal{M}$ . F      a cost function  $F: \\mathcal{M} ‚Üí‚Ñù$  to minimize. gradF  the gradient  $\\operatorname{grad}F : \\mathcal{M} ‚Üí T_x\\mathcal M$  of  $F$  implemented as  gradF(M,p) . x      an initial value  $x ‚àà \\mathcal{M}$ . For all optional parameters, see  quasi_Newton . source"},{"id":2695,"pagetitle":"Quasi-Newton","title":"Background","ref":"/manopt/stable/solvers/quasi_Newton/#Background","content":" Background The aim is to minimize a real-valued function on a Riemannian manifold, that is \\[\\min f(x), \\quad x ‚àà \\mathcal{M}.\\] Riemannian quasi-Newtonian methods are as generalizations of their Euclidean counterparts Riemannian line search methods. These methods determine a search direction  $Œ∑_k ‚àà T_{x_k} \\mathcal{M}$  at the current iterate  $x_k$  and a suitable stepsize  $Œ±_k$  along  $\\gamma(Œ±) = R_{x_k}(Œ± Œ∑_k)$ , where  $R: T \\mathcal{M} ‚Üí\\mathcal{M}$  is a retraction. The next iterate is obtained by \\[x_{k+1} = R_{x_k}(Œ±_k Œ∑_k).\\] In quasi-Newton methods, the search direction is given by \\[Œ∑_k = -{\\mathcal{H}_k}^{-1}[\\operatorname{grad}f (x_k)] = -\\mathcal{B}_k [\\operatorname{grad} (x_k)],\\] where  $\\mathcal{H}_k : T_{x_k} \\mathcal{M} ‚ÜíT_{x_k} \\mathcal{M}$  is a positive definite self-adjoint operator, which approximates the action of the Hessian  $\\operatorname{Hess} f (x_k)[‚ãÖ]$  and  $\\mathcal{B}_k = {\\mathcal{H}_k}^{-1}$ . The idea of quasi-Newton methods is instead of creating a complete new approximation of the Hessian operator  $\\operatorname{Hess} f(x_{k+1})$  or its inverse at every iteration, the previous operator  $\\mathcal{H}_k$  or  $\\mathcal{B}_k$  is updated by a convenient formula using the obtained information about the curvature of the objective function during the iteration. The resulting operator  $\\mathcal{H}_{k+1}$  or  $\\mathcal{B}_{k+1}$  acts on the tangent space  $T_{x_{k+1}} \\mathcal{M}$  of the freshly computed iterate  $x_{k+1}$ . In order to get a well-defined method, the following requirements are placed on the new operator  $\\mathcal{H}_{k+1}$  or  $\\mathcal{B}_{k+1}$  that is created by an update. Since the Hessian  $\\operatorname{Hess} f(x_{k+1})$  is a self-adjoint operator on the tangent space  $T_{x_{k+1}} \\mathcal{M}$ , and  $\\mathcal{H}_{k+1}$  approximates it, one requirement is, that  $\\mathcal{H}_{k+1}$  or  $\\mathcal{B}_{k+1}$  is also self-adjoint on  $T_{x_{k+1}} \\mathcal{M}$ . In order to achieve a steady descent, the next requirement is that  $Œ∑_k$  is a descent direction in each iteration. Hence a further requirement is that  $\\mathcal{H}_{k+1}$  or  $\\mathcal{B}_{k+1}$  is a positive definite operator on  $T_{x_{k+1}} \\mathcal{M}$ . In order to get information about the curvature of the objective function into the new operator  $\\mathcal{H}_{k+1}$  or  $\\mathcal{B}_{k+1}$ , the last requirement is a form of a Riemannian quasi-Newton equation: \\[\\mathcal{H}_{k+1} [T_{x_k \\rightarrow x_{k+1}}({R_{x_k}}^{-1}(x_{k+1}))] = \\operatorname{grad}(x_{k+1}) - T_{x_k \\rightarrow x_{k+1}}(\\operatorname{grad}f(x_k))\\] or \\[\\mathcal{B}_{k+1} [\\operatorname{grad}f(x_{k+1}) - T_{x_k \\rightarrow x_{k+1}}(\\operatorname{grad}f(x_k))] = T_{x_k \\rightarrow x_{k+1}}({R_{x_k}}^{-1}(x_{k+1}))\\] where  $T_{x_k \\rightarrow x_{k+1}} : T_{x_k} \\mathcal{M} ‚ÜíT_{x_{k+1}} \\mathcal{M}$  and the chosen retraction  $R$  is the associated retraction of  $T$ . Note that, of course, not all updates in all situations meet these conditions in every iteration. For specific quasi-Newton updates, the fulfilment of the Riemannian curvature condition, which requires that \\[g_{x_{k+1}}(s_k, y_k) > 0\\] holds, is a requirement for the inheritance of the self-adjointness and positive definiteness of the  $\\mathcal{H}_k$  or  $\\mathcal{B}_k$  to the operator  $\\mathcal{H}_{k+1}$  or  $\\mathcal{B}_{k+1}$ . Unfortunately, the fulfilment of the Riemannian curvature condition is not given by a step size  $\\alpha_k > 0$  that satisfies the generalized Wolfe conditions. However, to create a positive definite operator  $\\mathcal{H}_{k+1}$  or  $\\mathcal{B}_{k+1}$  in each iteration, the so-called locking condition was introduced in [ HGA15 ], which requires that the isometric vector transport  $T^S$ , which is used in the update formula, and its associate retraction  $R$  fulfil \\[T^{S}{x, Œæ_x}(Œæ_x) = Œ≤ T^{R}{x, Œæ_x}(Œæ_x), \\quad Œ≤ = \\frac{\\lVert Œæ_x \\rVert_x}{\\lVert T^{R}{x, Œæ_x}(Œæ_x) \\rVert_{R_{x}(Œæ_x)}},\\] where  $T^R$  is the vector transport by differentiated retraction. With the requirement that the isometric vector transport  $T^S$  and its associated retraction  $R$  satisfies the locking condition and using the tangent vector \\[y_k = {Œ≤_k}^{-1} \\operatorname{grad}f(x_{k+1}) - T^{S}{x_k, Œ±_k Œ∑_k}(\\operatorname{grad}f(x_k)),\\] where \\[Œ≤_k = \\frac{\\lVert Œ±_k Œ∑_k \\rVert_{x_k}}{\\lVert T^{R}{x_k, Œ±_k Œ∑_k}(Œ±_k Œ∑_k) \\rVert_{x_{k+1}}},\\] in the update, it can be shown that choosing a stepsize  $Œ±_k > 0$  that satisfies the Riemannian Wolfe conditions leads to the fulfilment of the Riemannian curvature condition, which in turn implies that the operator generated by the updates is positive definite. In the following the specific operators are denoted in matrix notation and hence use  $H_k$  and  $B_k$ , respectively."},{"id":2696,"pagetitle":"Quasi-Newton","title":"Direction updates","ref":"/manopt/stable/solvers/quasi_Newton/#Direction-updates","content":" Direction updates In general there are different ways to compute a fixed  AbstractQuasiNewtonUpdateRule . In general these are represented by"},{"id":2697,"pagetitle":"Quasi-Newton","title":"Manopt.AbstractQuasiNewtonDirectionUpdate","ref":"/manopt/stable/solvers/quasi_Newton/#Manopt.AbstractQuasiNewtonDirectionUpdate","content":" Manopt.AbstractQuasiNewtonDirectionUpdate  ‚Äî  Type AbstractQuasiNewtonDirectionUpdate An abstract representation of an Quasi Newton Update rule to determine the next direction given current  QuasiNewtonState . All subtypes should be functors, they should be callable as  H(M,x,d)  to compute a new direction update. source"},{"id":2698,"pagetitle":"Quasi-Newton","title":"Manopt.QuasiNewtonMatrixDirectionUpdate","ref":"/manopt/stable/solvers/quasi_Newton/#Manopt.QuasiNewtonMatrixDirectionUpdate","content":" Manopt.QuasiNewtonMatrixDirectionUpdate  ‚Äî  Type QuasiNewtonMatrixDirectionUpdate <: AbstractQuasiNewtonDirectionUpdate The  QuasiNewtonMatrixDirectionUpdate  represent a quasi-Newton update rule, where the operator is stored as a matrix. A distinction is made between the update of the approximation of the Hessian,  $H_k \\mapsto H_{k+1}$ , and the update of the approximation of the Hessian inverse,  $B_k \\mapsto B_{k+1}$ . For the first case, the coordinates of the search direction  $Œ∑_k$  with respect to a basis  $\\{b_i\\}^{n}_{i=1}$  are determined by solving a linear system of equations \\[\\text{Solve} \\quad \\hat{Œ∑_k} = - H_k \\widehat{\\operatorname{grad}f(x_k)},\\] where  $H_k$  is the matrix representing the operator with respect to the basis  $\\{b_i\\}^{n}_{i=1}$  and  $\\widehat{\\operatorname{grad}f(x_k)}$  represents the coordinates of the gradient of the objective function  $f$  in  $x_k$  with respect to the basis  $\\{b_i\\}^{n}_{i=1}$ . If a method is chosen where Hessian inverse is approximated, the coordinates of the search direction  $Œ∑_k$  with respect to a basis  $\\{b_i\\}^{n}_{i=1}$  are obtained simply by matrix-vector multiplication \\[\\hat{Œ∑_k} = - B_k \\widehat{\\operatorname{grad}f(x_k)},\\] where  $B_k$  is the matrix representing the operator with respect to the basis  $\\{b_i\\}^{n}_{i=1}$  and  $\\widehat{\\operatorname{grad}f(x_k)}$ . In the end, the search direction  $Œ∑_k$  is generated from the coordinates  $\\hat{eta_k}$  and the vectors of the basis  $\\{b_i\\}^{n}_{i=1}$  in both variants. The  AbstractQuasiNewtonUpdateRule  indicates which quasi-Newton update rule is used. In all of them, the Euclidean update formula is used to generate the matrix  $H_{k+1}$  and  $B_{k+1}$ , and the basis  $\\{b_i\\}^{n}_{i=1}$  is transported into the upcoming tangent space  $T_{x_{k+1}} \\mathcal{M}$ , preferably with an isometric vector transport, or generated there. Provided functors (mp::AbstractManoptproblem, st::QuasiNewtonState) -> Œ∑  to compute the update direction (Œ∑, mp::AbstractManoptproblem, st::QuasiNewtonState) -> Œ∑  to compute the update direction in-place of  Œ∑ Fields basis :                  an  AbstractBasis  to use in the tangent spaces matrix :                 ( Matrix{Float64}(I, manifold_dimension(M), manifold_dimension(M)) ) the matrix which represents the approximating operator. scale :                  (`true) indicates whether the initial matrix (= identity matrix) should be scaled before the first update. update :                 a  AbstractQuasiNewtonUpdateRule . vector_transport_method : ( vector_transport_method )an  AbstractVectorTransportMethod Constructor QuasiNewtonMatrixDirectionUpdate(\n    M::AbstractManifold,\n    update,\n    basis::B=DefaultOrthonormalBasis(),\n    m=Matrix{Float64}(I, manifold_dimension(M), manifold_dimension(M));\n    kwargs...\n) Keyword arguments scale ,  vector_transport_method  for the two fields Generate the Update rule with defaults from a manifold and the names corresponding to the fields. See also QuasiNewtonLimitedMemoryDirectionUpdate QuasiNewtonCautiousDirectionUpdate AbstractQuasiNewtonDirectionUpdate source"},{"id":2699,"pagetitle":"Quasi-Newton","title":"Manopt.QuasiNewtonLimitedMemoryDirectionUpdate","ref":"/manopt/stable/solvers/quasi_Newton/#Manopt.QuasiNewtonLimitedMemoryDirectionUpdate","content":" Manopt.QuasiNewtonLimitedMemoryDirectionUpdate  ‚Äî  Type QuasiNewtonLimitedMemoryDirectionUpdate <: AbstractQuasiNewtonDirectionUpdate This  AbstractQuasiNewtonDirectionUpdate  represents the limited-memory Riemannian BFGS update, where the approximating operator is represented by  $m$  stored pairs of tangent vectors  $\\{ \\widetilde{s}_i, \\widetilde{y}_i\\}_{i=k-m}^{k-1}$  in the  $k$ -th iteration. For the calculation of the search direction  $Œ∑_k$ , the generalisation of the two-loop recursion is used (see [ HGA15 ]), since it only requires inner products and linear combinations of tangent vectors in  $T_{x_k} \\mathcal{M}$ . For that the stored pairs of tangent vectors  $\\{ \\widetilde{s}_i, \\widetilde{y}_i\\}_{i=k-m}^{k-1}$ , the gradient  $\\operatorname{grad}f(x_k)$  of the objective function  $f$  in  $x_k$  and the positive definite self-adjoint operator \\[\\mathcal{B}^{(0)}_k[‚ãÖ] = \\frac{g_{x_k}(s_{k-1}, y_{k-1})}{g_{x_k}(y_{k-1}, y_{k-1})} \\; \\mathrm{id}_{T_{x_k} \\mathcal{M}}[‚ãÖ]\\] are used. The two-loop recursion can be understood as that the  InverseBFGS  update is executed  $m$  times in a row on  $\\mathcal{B}^{(0)}_k[‚ãÖ]$  using the tangent vectors  $\\{ \\widetilde{s}_i, \\widetilde{y}_i\\}_{i=k-m}^{k-1}$ , and in the same time the resulting operator  $\\mathcal{B}^{LRBFGS}_k [‚ãÖ]$  is directly applied on  $\\operatorname{grad}f(x_k)$ . When updating there are two cases: if there is still free memory,  $k < m$ , the previously stored vector pairs  $\\{ \\widetilde{s}_i, \\widetilde{y}_i\\}_{i=k-m}^{k-1}$  have to be transported into the upcoming tangent space  $T_{x_{k+1}} \\mathcal{M}$ . If there is no free memory, the oldest pair  $\\{ \\widetilde{s}_{k‚àím}, \\widetilde{y}_{k‚àím}\\}$  has to be discarded and then all the remaining vector pairs  $\\{ \\widetilde{s}_i, \\widetilde{y}_i\\}_{i=k-m+1}^{k-1}$  are transported into the tangent space  $T_{x_{k+1}} \\mathcal{M}$ . After that the new values  $s_k = \\widetilde{s}_k = T^{S}_{x_k, Œ±_k Œ∑_k}(Œ±_k Œ∑_k)$  and  $y_k = \\widetilde{y}_k$  are stored at the beginning. This process ensures that new information about the objective function is always included and the old, probably no longer relevant, information is discarded. Provided functors (mp::AbstractManoptproblem, st::QuasiNewtonState) -> Œ∑  to compute the update direction (Œ∑, mp::AbstractManoptproblem, st::QuasiNewtonState) -> Œ∑  to compute the update direction in-place of  Œ∑ Fields memory_s                 the set of the stored (and transported) search directions times step size  $\\{ \\widetilde{s}_i\\}_{i=k-m}^{k-1}$ . memory_y                 set of the stored gradient differences  $\\{ \\widetilde{y}_i\\}_{i=k-m}^{k-1}$ . Œæ                        a variable used in the two-loop recursion. œÅ                        a variable used in the two-loop recursion. scale                    initial scaling of the Hessian vector_transport_method  a  AbstractVectorTransportMethod message                  a string containing a potential warning that might have appeared Constructor QuasiNewtonLimitedMemoryDirectionUpdate(\n    M::AbstractManifold,\n    x,\n    update::AbstractQuasiNewtonUpdateRule,\n    memory_size;\n    initial_vector=zero_vector(M,x),\n    scale::Real=1.0\n    project::Bool=true\n) See also InverseBFGS QuasiNewtonCautiousDirectionUpdate AbstractQuasiNewtonDirectionUpdate source"},{"id":2700,"pagetitle":"Quasi-Newton","title":"Manopt.QuasiNewtonCautiousDirectionUpdate","ref":"/manopt/stable/solvers/quasi_Newton/#Manopt.QuasiNewtonCautiousDirectionUpdate","content":" Manopt.QuasiNewtonCautiousDirectionUpdate  ‚Äî  Type QuasiNewtonCautiousDirectionUpdate <: AbstractQuasiNewtonDirectionUpdate These  AbstractQuasiNewtonDirectionUpdate s represent any quasi-Newton update rule, which are based on the idea of a so-called cautious update. The search direction is calculated as given in  QuasiNewtonMatrixDirectionUpdate  or  QuasiNewtonLimitedMemoryDirectionUpdate , butut the update  then is only executed if \\[\\frac{g_{x_{k+1}}(y_k,s_k)}{\\lVert s_k \\rVert^{2}_{x_{k+1}}} ‚â• Œ∏(\\lVert \\operatorname{grad}f(x_k) \\rVert_{x_k}),\\] is satisfied, where  $Œ∏$  is a monotone increasing function satisfying  $Œ∏(0) = 0$  and  $Œ∏$  is strictly increasing at  $0$ . If this is not the case, the corresponding update is skipped, which means that for  QuasiNewtonMatrixDirectionUpdate  the matrix  $H_k$  or  $B_k$  is not updated. The basis  $\\{b_i\\}^{n}_{i=1}$  is nevertheless transported into the upcoming tangent space  $T_{x_{k+1}} \\mathcal{M}$ , and for  QuasiNewtonLimitedMemoryDirectionUpdate  neither the oldest vector pair  $\\{ \\widetilde{s}_{k‚àím}, \\widetilde{y}_{k‚àím}\\}$  is discarded nor the newest vector pair  $\\{ \\widetilde{s}_{k}, \\widetilde{y}_{k}\\}$  is added into storage, but all stored vector pairs  $\\{ \\widetilde{s}_i, \\widetilde{y}_i\\}_{i=k-m}^{k-1}$  are transported into the tangent space  $T_{x_{k+1}} \\mathcal{M}$ . If  InverseBFGS  or  InverseBFGS  is chosen as update, then the resulting method follows the method of [ HAG18 ], taking into account that the corresponding step size is chosen. Provided functors (mp::AbstractManoptproblem, st::QuasiNewtonState) -> Œ∑  to compute the update direction (Œ∑, mp::AbstractManoptproblem, st::QuasiNewtonState) -> Œ∑  to compute the update direction in-place of  Œ∑ Fields update : an  AbstractQuasiNewtonDirectionUpdate Œ∏ :      a monotone increasing function satisfying  $Œ∏(0) = 0$  and  $Œ∏$  is strictly increasing at  $0$ . Constructor QuasiNewtonCautiousDirectionUpdate(U::QuasiNewtonMatrixDirectionUpdate; Œ∏ = x -> x)\nQuasiNewtonCautiousDirectionUpdate(U::QuasiNewtonLimitedMemoryDirectionUpdate; Œ∏ = x -> x) Generate a cautious update for either a matrix based or a limited memory based update rule. See also QuasiNewtonMatrixDirectionUpdate QuasiNewtonLimitedMemoryDirectionUpdate source"},{"id":2701,"pagetitle":"Quasi-Newton","title":"Hessian update rules","ref":"/manopt/stable/solvers/quasi_Newton/#Hessian-update-rules","content":" Hessian update rules Using"},{"id":2702,"pagetitle":"Quasi-Newton","title":"Manopt.update_hessian!","ref":"/manopt/stable/solvers/quasi_Newton/#Manopt.update_hessian!","content":" Manopt.update_hessian!  ‚Äî  Function update_hessian!(d, amp, st, p_old, iter) update the Hessian within the  QuasiNewtonState o  given a  AbstractManoptProblem amp  as well as the an  AbstractQuasiNewtonDirectionUpdate d  and the last iterate  p_old . Note that the current ( iter th) iterate is already stored in  o.x . See also  AbstractQuasiNewtonUpdateRule  for the different rules that are available within  d . source the following update formulae for either  $H_{k+1}$  or  $B_{k+1}$  are available."},{"id":2703,"pagetitle":"Quasi-Newton","title":"Manopt.AbstractQuasiNewtonUpdateRule","ref":"/manopt/stable/solvers/quasi_Newton/#Manopt.AbstractQuasiNewtonUpdateRule","content":" Manopt.AbstractQuasiNewtonUpdateRule  ‚Äî  Type AbstractQuasiNewtonUpdateRule Specify a type for the different  AbstractQuasiNewtonDirectionUpdate s, that is for a  QuasiNewtonMatrixDirectionUpdate  there are several different updates to the matrix, while the default for  QuasiNewtonLimitedMemoryDirectionUpdate  the most prominent is  InverseBFGS . source"},{"id":2704,"pagetitle":"Quasi-Newton","title":"Manopt.BFGS","ref":"/manopt/stable/solvers/quasi_Newton/#Manopt.BFGS","content":" Manopt.BFGS  ‚Äî  Type BFGS <: AbstractQuasiNewtonUpdateRule indicates in  AbstractQuasiNewtonDirectionUpdate  that the Riemannian BFGS update is used in the Riemannian quasi-Newton method. Denote by  $\\widetilde{H}_k^\\mathrm{BFGS}$  the operator concatenated with a vector transport and its inverse before and after to act on  $x_{k+1} = R_{x_k}(Œ±_k Œ∑_k)$ . Then the update formula reads \\[H^\\mathrm{BFGS}_{k+1} = \\widetilde{H}^\\mathrm{BFGS}_k  + \\frac{y_k y^{\\mathrm{T}}_k }{s^{\\mathrm{T}}_k y_k} - \\frac{\\widetilde{H}^\\mathrm{BFGS}_k s_k s^{\\mathrm{T}}_k \\widetilde{H}^\\mathrm{BFGS}_k }{s^{\\mathrm{T}}_k \\widetilde{H}^\\mathrm{BFGS}_k s_k}\\] where  $s_k$  and  $y_k$  are the coordinate vectors with respect to the current basis (from  QuasiNewtonState ) of \\[T^{S}_{x_k, Œ±_k Œ∑_k}(Œ±_k Œ∑_k) \\quad\\text{and}\\quad\n\\operatorname{grad}f(x_{k+1}) - T^{S}_{x_k, Œ±_k Œ∑_k}(\\operatorname{grad}f(x_k)) ‚àà T_{x_{k+1}} \\mathcal{M},\\] respectively. source"},{"id":2705,"pagetitle":"Quasi-Newton","title":"Manopt.DFP","ref":"/manopt/stable/solvers/quasi_Newton/#Manopt.DFP","content":" Manopt.DFP  ‚Äî  Type DFP <: AbstractQuasiNewtonUpdateRule indicates in an  AbstractQuasiNewtonDirectionUpdate  that the Riemannian DFP update is used in the Riemannian quasi-Newton method. Denote by  $\\widetilde{H}_k^\\mathrm{DFP}$  the operator concatenated with a vector transport and its inverse before and after to act on  $x_{k+1} = R_{x_k}(Œ±_k Œ∑_k)$ . Then the update formula reads \\[H^\\mathrm{DFP}_{k+1} = \\Bigl(\n  \\mathrm{id}_{T_{x_{k+1}} \\mathcal{M}} - \\frac{y_k s^{\\mathrm{T}}_k}{s^{\\mathrm{T}}_k y_k}\n\\Bigr)\n\\widetilde{H}^\\mathrm{DFP}_k\n\\Bigl(\n  \\mathrm{id}_{T_{x_{k+1}} \\mathcal{M}} - \\frac{s_k y^{\\mathrm{T}}_k}{s^{\\mathrm{T}}_k y_k}\n\\Bigr) + \\frac{y_k y^{\\mathrm{T}}_k}{s^{\\mathrm{T}}_k y_k}\\] where  $s_k$  and  $y_k$  are the coordinate vectors with respect to the current basis (from  QuasiNewtonState ) of \\[T^{S}_{x_k, Œ±_k Œ∑_k}(Œ±_k Œ∑_k) \\quad\\text{and}\\quad\n\\operatorname{grad}f(x_{k+1}) - T^{S}_{x_k, Œ±_k Œ∑_k}(\\operatorname{grad}f(x_k)) ‚àà T_{x_{k+1}} \\mathcal{M},\\] respectively. source"},{"id":2706,"pagetitle":"Quasi-Newton","title":"Manopt.Broyden","ref":"/manopt/stable/solvers/quasi_Newton/#Manopt.Broyden","content":" Manopt.Broyden  ‚Äî  Type Broyden <: AbstractQuasiNewtonUpdateRule indicates in  AbstractQuasiNewtonDirectionUpdate  that the Riemannian Broyden update is used in the Riemannian quasi-Newton method, which is as a convex combination of  BFGS  and  DFP . Denote by  $\\widetilde{H}_k^\\mathrm{Br}$  the operator concatenated with a vector transport and its inverse before and after to act on  $x_{k+1} = R_{x_k}(Œ±_k Œ∑_k)$ . Then the update formula reads \\[H^\\mathrm{Br}_{k+1} = \\widetilde{H}^\\mathrm{Br}_k\n  - \\frac{\\widetilde{H}^\\mathrm{Br}_k s_k s^{\\mathrm{T}}_k \\widetilde{H}^\\mathrm{Br}_k}{s^{\\mathrm{T}}_k \\widetilde{H}^\\mathrm{Br}_k s_k} + \\frac{y_k y^{\\mathrm{T}}_k}{s^{\\mathrm{T}}_k y_k}\n  + œÜ_k s^{\\mathrm{T}}_k \\widetilde{H}^\\mathrm{Br}_k s_k\n  \\Bigl(\n        \\frac{y_k}{s^{\\mathrm{T}}_k y_k} - \\frac{\\widetilde{H}^\\mathrm{Br}_k s_k}{s^{\\mathrm{T}}_k \\widetilde{H}^\\mathrm{Br}_k s_k}\n  \\Bigr)\n  \\Bigl(\n        \\frac{y_k}{s^{\\mathrm{T}}_k y_k} - \\frac{\\widetilde{H}^\\mathrm{Br}_k s_k}{s^{\\mathrm{T}}_k \\widetilde{H}^\\mathrm{Br}_k s_k}\n  \\Bigr)^{\\mathrm{T}}\\] where  $s_k$  and  $y_k$  are the coordinate vectors with respect to the current basis (from  QuasiNewtonState ) of \\[T^{S}_{x_k, Œ±_k Œ∑_k}(Œ±_k Œ∑_k) \\quad\\text{and}\\quad\n\\operatorname{grad}f(x_{k+1}) - T^{S}_{x_k, Œ±_k Œ∑_k}(\\operatorname{grad}f(x_k)) ‚àà T_{x_{k+1}} \\mathcal{M},\\] respectively, and  $œÜ_k$  is the Broyden factor which is  :constant  by default but can also be set to  :Davidon . Constructor Broyden(œÜ, update_rule::Symbol = :constant) source"},{"id":2707,"pagetitle":"Quasi-Newton","title":"Manopt.SR1","ref":"/manopt/stable/solvers/quasi_Newton/#Manopt.SR1","content":" Manopt.SR1  ‚Äî  Type SR1 <: AbstractQuasiNewtonUpdateRule indicates in  AbstractQuasiNewtonDirectionUpdate  that the Riemannian SR1 update is used in the Riemannian quasi-Newton method. Denote by  $\\widetilde{H}_k^\\mathrm{SR1}$  the operator concatenated with a vector transport and its inverse before and after to act on  $x_{k+1} = R_{x_k}(Œ±_k Œ∑_k)$ . Then the update formula reads \\[H^\\mathrm{SR1}_{k+1} = \\widetilde{H}^\\mathrm{SR1}_k\n+ \\frac{\n  (y_k - \\widetilde{H}^\\mathrm{SR1}_k s_k) (y_k - \\widetilde{H}^\\mathrm{SR1}_k s_k)^{\\mathrm{T}}\n}{\n(y_k - \\widetilde{H}^\\mathrm{SR1}_k s_k)^{\\mathrm{T}} s_k\n}\\] where  $s_k$  and  $y_k$  are the coordinate vectors with respect to the current basis (from  QuasiNewtonState ) of \\[T^{S}_{x_k, Œ±_k Œ∑_k}(Œ±_k Œ∑_k) \\quad\\text{and}\\quad\n\\operatorname{grad}f(x_{k+1}) - T^{S}_{x_k, Œ±_k Œ∑_k}(\\operatorname{grad}f(x_k)) ‚àà T_{x_{k+1}} \\mathcal{M},\\] respectively. This method can be stabilized by only performing the update if denominator is larger than  $r\\lVert s_k\\rVert_{x_{k+1}}\\lVert y_k - \\widetilde{H}^\\mathrm{SR1}_k s_k \\rVert_{x_{k+1}}$  for some  $r>0$ . For more details, see Section 6.2 in [ NW06 ]. Constructor SR1(r::Float64=-1.0) Generate the  SR1  update. source"},{"id":2708,"pagetitle":"Quasi-Newton","title":"Manopt.InverseBFGS","ref":"/manopt/stable/solvers/quasi_Newton/#Manopt.InverseBFGS","content":" Manopt.InverseBFGS  ‚Äî  Type InverseBFGS <: AbstractQuasiNewtonUpdateRule indicates in  AbstractQuasiNewtonDirectionUpdate  that the inverse Riemannian BFGS update is used in the Riemannian quasi-Newton method. Denote by  $\\widetilde{B}_k^\\mathrm{BFGS}$  the operator concatenated with a vector transport and its inverse before and after to act on  $x_{k+1} = R_{x_k}(Œ±_k Œ∑_k)$ . Then the update formula reads \\[B^\\mathrm{BFGS}_{k+1}  = \\Bigl(\n  \\mathrm{id}_{T_{x_{k+1}} \\mathcal{M}} - \\frac{s_k y^{\\mathrm{T}}_k }{s^{\\mathrm{T}}_k y_k}\n\\Bigr)\n\\widetilde{B}^\\mathrm{BFGS}_k\n\\Bigl(\n  \\mathrm{id}_{T_{x_{k+1}} \\mathcal{M}} - \\frac{y_k s^{\\mathrm{T}}_k }{s^{\\mathrm{T}}_k y_k}\n\\Bigr) + \\frac{s_k s^{\\mathrm{T}}_k}{s^{\\mathrm{T}}_k y_k}\\] where  $s_k$  and  $y_k$  are the coordinate vectors with respect to the current basis (from  QuasiNewtonState ) of \\[T^{S}_{x_k, Œ±_k Œ∑_k}(Œ±_k Œ∑_k) \\quad\\text{and}\\quad\n\\operatorname{grad}f(x_{k+1}) - T^{S}_{x_k, Œ±_k Œ∑_k}(\\operatorname{grad}f(x_k)) ‚àà T_{x_{k+1}} \\mathcal{M},\\] respectively. source"},{"id":2709,"pagetitle":"Quasi-Newton","title":"Manopt.InverseDFP","ref":"/manopt/stable/solvers/quasi_Newton/#Manopt.InverseDFP","content":" Manopt.InverseDFP  ‚Äî  Type InverseDFP <: AbstractQuasiNewtonUpdateRule indicates in  AbstractQuasiNewtonDirectionUpdate  that the inverse Riemannian DFP update is used in the Riemannian quasi-Newton method. Denote by  $\\widetilde{B}_k^\\mathrm{DFP}$  the operator concatenated with a vector transport and its inverse before and after to act on  $x_{k+1} = R_{x_k}(Œ±_k Œ∑_k)$ . Then the update formula reads \\[B^\\mathrm{DFP}_{k+1} = \\widetilde{B}^\\mathrm{DFP}_k + \\frac{s_k s^{\\mathrm{T}}_k}{s^{\\mathrm{T}}_k y_k}\n  - \\frac{\\widetilde{B}^\\mathrm{DFP}_k y_k y^{\\mathrm{T}}_k \\widetilde{B}^\\mathrm{DFP}_k}{y^{\\mathrm{T}}_k \\widetilde{B}^\\mathrm{DFP}_k y_k}\\] where  $s_k$  and  $y_k$  are the coordinate vectors with respect to the current basis (from  QuasiNewtonState ) of \\[T^{S}_{x_k, Œ±_k Œ∑_k}(Œ±_k Œ∑_k) \\quad\\text{and}\\quad\n\\operatorname{grad}f(x_{k+1}) - T^{S}_{x_k, Œ±_k Œ∑_k}(\\operatorname{grad}f(x_k)) ‚àà T_{x_{k+1}} \\mathcal{M},\\] respectively. source"},{"id":2710,"pagetitle":"Quasi-Newton","title":"Manopt.InverseBroyden","ref":"/manopt/stable/solvers/quasi_Newton/#Manopt.InverseBroyden","content":" Manopt.InverseBroyden  ‚Äî  Type InverseBroyden <: AbstractQuasiNewtonUpdateRule Indicates in  AbstractQuasiNewtonDirectionUpdate  that the Riemannian Broyden update is used in the Riemannian quasi-Newton method, which is as a convex combination of  InverseBFGS  and  InverseDFP . Denote by  $\\widetilde{H}_k^\\mathrm{Br}$  the operator concatenated with a vector transport and its inverse before and after to act on  $x_{k+1} = R_{x_k}(Œ±_k Œ∑_k)$ . Then the update formula reads \\[B^\\mathrm{Br}_{k+1} = \\widetilde{B}^\\mathrm{Br}_k\n - \\frac{\\widetilde{B}^\\mathrm{Br}_k y_k y^{\\mathrm{T}}_k \\widetilde{B}^\\mathrm{Br}_k}{y^{\\mathrm{T}}_k \\widetilde{B}^\\mathrm{Br}_k y_k}\n   + \\frac{s_k s^{\\mathrm{T}}_k}{s^{\\mathrm{T}}_k y_k}\n + œÜ_k y^{\\mathrm{T}}_k \\widetilde{B}^\\mathrm{Br}_k y_k\n \\Bigl(\n     \\frac{s_k}{s^{\\mathrm{T}}_k y_k} - \\frac{\\widetilde{B}^\\mathrm{Br}_k y_k}{y^{\\mathrm{T}}_k \\widetilde{B}^\\mathrm{Br}_k y_k}\n    \\Bigr) \\Bigl(\n        \\frac{s_k}{s^{\\mathrm{T}}_k y_k} - \\frac{\\widetilde{B}^\\mathrm{Br}_k y_k}{y^{\\mathrm{T}}_k \\widetilde{B}^\\mathrm{Br}_k y_k}\n \\Bigr)^{\\mathrm{T}}\\] where  $s_k$  and  $y_k$  are the coordinate vectors with respect to the current basis (from  QuasiNewtonState ) of \\[T^{S}_{x_k, Œ±_k Œ∑_k}(Œ±_k Œ∑_k) \\quad\\text{and}\\quad\n\\operatorname{grad}f(x_{k+1}) - T^{S}_{x_k, Œ±_k Œ∑_k}(\\operatorname{grad}f(x_k)) ‚àà T_{x_{k+1}} \\mathcal{M},\\] respectively, and  $œÜ_k$  is the Broyden factor which is  :constant  by default but can also be set to  :Davidon . Constructor InverseBroyden(œÜ, update_rule::Symbol = :constant) source"},{"id":2711,"pagetitle":"Quasi-Newton","title":"Manopt.InverseSR1","ref":"/manopt/stable/solvers/quasi_Newton/#Manopt.InverseSR1","content":" Manopt.InverseSR1  ‚Äî  Type InverseSR1 <: AbstractQuasiNewtonUpdateRule indicates in  AbstractQuasiNewtonDirectionUpdate  that the inverse Riemannian SR1 update is used in the Riemannian quasi-Newton method. Denote by  $\\widetilde{B}_k^\\mathrm{SR1}$  the operator concatenated with a vector transport and its inverse before and after to act on  $x_{k+1} = R_{x_k}(Œ±_k Œ∑_k)$ . Then the update formula reads \\[B^\\mathrm{SR1}_{k+1} = \\widetilde{B}^\\mathrm{SR1}_k\n+ \\frac{\n  (s_k - \\widetilde{B}^\\mathrm{SR1}_k y_k) (s_k - \\widetilde{B}^\\mathrm{SR1}_k y_k)^{\\mathrm{T}}\n}{\n  (s_k - \\widetilde{B}^\\mathrm{SR1}_k y_k)^{\\mathrm{T}} y_k\n}\\] where  $s_k$  and  $y_k$  are the coordinate vectors with respect to the current basis (from  QuasiNewtonState ) of \\[T^{S}_{x_k, Œ±_k Œ∑_k}(Œ±_k Œ∑_k) \\quad\\text{and}\\quad\n\\operatorname{grad}f(x_{k+1}) - T^{S}_{x_k, Œ±_k Œ∑_k}(\\operatorname{grad}f(x_k)) ‚àà T_{x_{k+1}} \\mathcal{M},\\] respectively. This method can be stabilized by only performing the update if denominator is larger than  $r\\lVert y_k\\rVert_{x_{k+1}}\\lVert s_k - \\widetilde{H}^\\mathrm{SR1}_k y_k \\rVert_{x_{k+1}}$  for some  $r>0$ . For more details, see Section 6.2 in [ NW06 ]. Constructor InverseSR1(r::Float64=-1.0) Generate the  InverseSR1 . source"},{"id":2712,"pagetitle":"Quasi-Newton","title":"State","ref":"/manopt/stable/solvers/quasi_Newton/#State","content":" State The quasi Newton algorithm is based on a  DefaultManoptProblem ."},{"id":2713,"pagetitle":"Quasi-Newton","title":"Manopt.QuasiNewtonState","ref":"/manopt/stable/solvers/quasi_Newton/#Manopt.QuasiNewtonState","content":" Manopt.QuasiNewtonState  ‚Äî  Type QuasiNewtonState <: AbstractManoptSolverState These Quasi Newton  AbstractManoptSolverState  represent any quasi-Newton based method and can be used with any update rule for the direction. Fields p                              the current iterate, a point on a manifold X                              the current gradient sk                             the current step yk                             the current gradient difference direction_update               an  AbstractQuasiNewtonDirectionUpdate  rule. nondescent_direction_behavior  a  Symbol  to specify how to handle direction that are not descent ones. retraction_method              an  AbstractRetractionMethod stepsize                       a  Stepsize stop                           a  StoppingCriterion as well as for internal use p_old                       the last iterate Œ∑                           the current update direction X_old                       the last gradient nondescent_direction_value  the value from the last inner product check for descent directions Constructor QuasiNewtonState(\n    M::AbstractManifold,\n    x;\n    initial_vector=zero_vector(M,x),\n    direction_update::D=QuasiNewtonLimitedMemoryDirectionUpdate(M, x, InverseBFGS(), 20;\n        vector_transport_method=vector_transport_method,\n    )\n    stopping_criterion=StopAfterIteration(1000) | StopWhenGradientNormLess(1e-6),\n    retraction_method::RM=default_retraction_method(M, typeof(p)),\n    vector_transport_method::VTM=default_vector_transport_method(M, typeof(p)),\n    stepsize=default_stepsize(M; QuasiNewtonState)\n) See also quasi_Newton source"},{"id":2714,"pagetitle":"Quasi-Newton","title":"Technical details","ref":"/manopt/stable/solvers/quasi_Newton/#sec-qn-technical-details","content":" Technical details The  quasi_Newton  solver requires the following functions of a manifold to be available A  retract! (M, q, p, X) ; it is recommended to set the  default_retraction_method  to a favourite retraction. If this default is set, a  retraction_method=  does not have to be specified. A  vector_transport_to! M, Y, p, X, q) ; it is recommended to set the  default_vector_transport_method  to a favourite retraction. If this default is set, a  vector_transport_method=  or  vector_transport_method_dual=  (for  $\\mathcal N$ ) does not have to be specified. By default quasi Newton uses  ArmijoLinesearch  which requires  max_stepsize (M)  to be set and an implementation of  inner (M, p, X) . the  norm  as well, to stop when the norm of the gradient is small, but if you implemented  inner , the norm is provided already. A  `copyto! (M, q, p)  and  copy (M,p)  for points and similarly  copy(M, p, X)  for tangent vectors. By default the tangent vector storing the gradient is initialized calling  zero_vector (M,p) . Most Hessian approximations further require  get_coordinates (M, p, X, b)  with respect to the  AbstractBasis b  provided, which is  DefaultOrthonormalBasis  by default from the  basis=  keyword."},{"id":2715,"pagetitle":"Quasi-Newton","title":"Literature","ref":"/manopt/stable/solvers/quasi_Newton/#Literature","content":" Literature [HAG18] W.¬†Huang, P.-A.¬†Absil and K.¬†A.¬†Gallivan.  A Riemannian BFGS method without differentiated retraction for nonconvex optimization problems .  SIAM¬†Journal¬†on¬†Optimization  28 , 470‚Äì495  (2018). [HGA15] W.¬†Huang, K.¬†A.¬†Gallivan and P.-A.¬†Absil.  A Broyden class of quasi-Newton methods for Riemannian optimization .  SIAM¬†Journal¬†on¬†Optimization  25 , 1660‚Äì1685  (2015). [NW06] J.¬†Nocedal and S.¬†J.¬†Wright.  Numerical Optimization . 2¬†Edition (Springer, New York, 2006)."},{"id":2718,"pagetitle":"Stochastic Gradient Descent","title":"Stochastic gradient descent","ref":"/manopt/stable/solvers/stochastic_gradient_descent/#Stochastic-gradient-descent","content":" Stochastic gradient descent"},{"id":2719,"pagetitle":"Stochastic Gradient Descent","title":"Manopt.stochastic_gradient_descent","ref":"/manopt/stable/solvers/stochastic_gradient_descent/#Manopt.stochastic_gradient_descent","content":" Manopt.stochastic_gradient_descent  ‚Äî  Function stochastic_gradient_descent(M, grad_f, p; kwargs...)\nstochastic_gradient_descent(M, msgo, p; kwargs...) perform a stochastic gradient descent Input M :      a manifold  $\\mathcal M$ grad_f : a gradient function, that either returns a vector of the subgradients or is a vector of gradients p :      an initial value  $x ‚àà \\mathcal M$ alternatively to the gradient you can provide an  ManifoldStochasticGradientObjective msgo , then using the  cost=  keyword does not have any effect since if so, the cost is already within the objective. Optional cost :               ( missing ) you can provide a cost function for example to track the function value evaluation :         ( AllocatingEvaluation ) specify whether the gradients works by  allocation (default) form  gradF(M, x)  or  InplaceEvaluation  in place of the form  gradF!(M, X, x)  (elementwise). evaluation_order :   ( :Random ) specify whether to use a randomly permuted sequence ( :FixedRandom ), a per cycle permuted sequence ( :Linear ) or the default  :Random  one. stopping_criterion : ( StopAfterIteration (1000) ) a  StoppingCriterion stepsize :           ( ConstantStepsize (1.0) ) a  Stepsize order_type :         ( :RandomOder ) a type of ordering of gradient evaluations. Possible values are  :RandomOrder , a  :FixedPermutation ,  :LinearOrder order :              ( [1:n] ) the initial permutation, where  n  is the number of gradients in  gradF . retraction_method :  ( default_retraction_method(M, typeof(p)) ) a retraction to use. Output the obtained (approximate) minimizer  $p^*$ , see  get_solver_return  for details source"},{"id":2720,"pagetitle":"Stochastic Gradient Descent","title":"Manopt.stochastic_gradient_descent!","ref":"/manopt/stable/solvers/stochastic_gradient_descent/#Manopt.stochastic_gradient_descent!","content":" Manopt.stochastic_gradient_descent!  ‚Äî  Function stochastic_gradient_descent!(M, grad_f, p)\nstochastic_gradient_descent!(M, msgo, p) perform a stochastic gradient descent in place of  p . Input M :      a manifold  $\\mathcal M$ grad_f : a gradient function, that either returns a vector of the subgradients or is a vector of gradients p :      an initial value  $p ‚àà \\mathcal M$ Alternatively to the gradient you can provide an  ManifoldStochasticGradientObjective msgo , then using the  cost=  keyword does not have any effect since if so, the cost is already within the objective. for all optional parameters, see  stochastic_gradient_descent . source"},{"id":2721,"pagetitle":"Stochastic Gradient Descent","title":"State","ref":"/manopt/stable/solvers/stochastic_gradient_descent/#State","content":" State"},{"id":2722,"pagetitle":"Stochastic Gradient Descent","title":"Manopt.StochasticGradientDescentState","ref":"/manopt/stable/solvers/stochastic_gradient_descent/#Manopt.StochasticGradientDescentState","content":" Manopt.StochasticGradientDescentState  ‚Äî  Type StochasticGradientDescentState <: AbstractGradientDescentSolverState Store the following fields for a default stochastic gradient descent algorithm, see also  ManifoldStochasticGradientObjective  and  stochastic_gradient_descent . Fields p :                  the current iterate direction :          ( StochasticGradient ) a direction update to use stopping_criterion : ( StopAfterIteration (1000) ) a  StoppingCriterion stepsize :           ( ConstantStepsize (1.0) ) a  Stepsize evaluation_order :   ( :Random ) specify whether to use a randomly permuted sequence ( :FixedRandom ), a per cycle permuted sequence ( :Linear ) or the default  :Random  one. order :              the current permutation retraction_method :  ( default_retraction_method(M, typeof(p)) ) a  retraction(M, p, X)  to use. Constructor StochasticGradientDescentState(M, p) Create a  StochasticGradientDescentState  with start point  p . all other fields are optional keyword arguments, and the defaults are taken from  M . source Additionally, the options share a  DirectionUpdateRule , so you can also apply  MomentumGradient  and  AverageGradient  here. The most inner one should always be."},{"id":2723,"pagetitle":"Stochastic Gradient Descent","title":"Manopt.AbstractGradientGroupProcessor","ref":"/manopt/stable/solvers/stochastic_gradient_descent/#Manopt.AbstractGradientGroupProcessor","content":" Manopt.AbstractGradientGroupProcessor  ‚Äî  Type AbstractStochasticGradientDescentSolverState <: AbstractManoptSolverState A generic type for all options related to stochastic gradient descent methods source"},{"id":2724,"pagetitle":"Stochastic Gradient Descent","title":"Manopt.StochasticGradient","ref":"/manopt/stable/solvers/stochastic_gradient_descent/#Manopt.StochasticGradient","content":" Manopt.StochasticGradient  ‚Äî  Type StochasticGradient <: AbstractGradientGroupProcessor The default gradient processor, which just evaluates the (stochastic) gradient or a subset thereof. Constructor StochasticGradient(M::AbstractManifold; p=rand(M), X=zero_vector(M, p)) Initialize the stochastic Gradient processor with tangent vector type of  X , where both  M  and  p  are just help variables. source"},{"id":2725,"pagetitle":"Stochastic Gradient Descent","title":"Technical details","ref":"/manopt/stable/solvers/stochastic_gradient_descent/#sec-sgd-technical-details","content":" Technical details The  stochastic_gradient_descent  solver requires the following functions of a manifold to be available A  retract! (M, q, p, X) ; it is recommended to set the  default_retraction_method  to a favourite retraction. If this default is set, a  retraction_method=  does not have to be specified."},{"id":2728,"pagetitle":"Subgradient method","title":"Subgradient method","ref":"/manopt/stable/solvers/subgradient/#sec-subgradient-method","content":" Subgradient method"},{"id":2729,"pagetitle":"Subgradient method","title":"Manopt.subgradient_method","ref":"/manopt/stable/solvers/subgradient/#Manopt.subgradient_method","content":" Manopt.subgradient_method  ‚Äî  Function subgradient_method(M, f, ‚àÇf, p=rand(M); kwargs...)\nsubgradient_method(M, sgo, p=rand(M); kwargs...) perform a subgradient method  $p_{k+1} = \\mathrm{retr}(p_k, s_k‚àÇf(p_k))$ , where  $\\mathrm{retr}$  is a retraction,  $s_k$  is a step size, usually the  ConstantStepsize  but also be specified. Though the subgradient might be set valued, the argument  ‚àÇf  should always return  one  element from the subgradient, but not necessarily deterministic. For more details see [ FO98 ]. Input M :  a manifold  $\\mathcal M$ f :  a cost function  $f:\\mathcal M‚Üí‚Ñù$  to minimize ‚àÇf : the (sub)gradient  $‚àÇ f: \\mathcal M‚Üí T\\mathcal M$  of f restricted to always only returning one value/element from the subdifferential. This function can be passed as an allocation function  (M, p) -> X  or a mutating function  (M, X, p) -> X , see  evaluation . p :  ( rand(M) ) an initial value  $p_0=p ‚àà \\mathcal M$ alternatively to  f  and  ‚àÇf  a  ManifoldSubgradientObjective sgo  can be provided. Optional evaluation :         ( AllocatingEvaluation ) specify whether the subgradient works by allocation (default) form  ‚àÇf(M, y)  or  InplaceEvaluation  in place of the form  ‚àÇf!(M, X, x) . retraction :         ( default_retraction_method(M, typeof(p)) ) a retraction to use. stepsize :           ( ConstantStepsize (M) ) specify a  Stepsize stopping_criterion : ( StopAfterIteration (5000) ) a functor, see StoppingCriterion , indicating when to stop. and the ones that are passed to  decorate_state!  for decorators. Output the obtained (approximate) minimizer  $p^*$ , see  get_solver_return  for details source"},{"id":2730,"pagetitle":"Subgradient method","title":"Manopt.subgradient_method!","ref":"/manopt/stable/solvers/subgradient/#Manopt.subgradient_method!","content":" Manopt.subgradient_method!  ‚Äî  Function subgradient_method!(M, f, ‚àÇf, p)\nsubgradient_method!(M, sgo, p) perform a subgradient method  $p_{k+1} = \\mathrm{retr}(p_k, s_k‚àÇf(p_k))$ , Input M :  a manifold  $\\mathcal M$ f :  a cost function  $f:\\mathcal M‚Üí‚Ñù$  to minimize ‚àÇf : the (sub)gradient  $‚àÇf: \\mathcal M‚Üí T\\mathcal M$  of F restricted to always only returning one value/element from the subdifferential. This function can be passed as an allocation function  (M, p) -> X  or a mutating function  (M, X, p) -> X , see  evaluation . p :  an initial value  $p_0=p ‚àà \\mathcal M$ alternatively to  f  and  ‚àÇf  a  ManifoldSubgradientObjective sgo  can be provided. for more details and all optional parameters, see  subgradient_method . source"},{"id":2731,"pagetitle":"Subgradient method","title":"State","ref":"/manopt/stable/solvers/subgradient/#State","content":" State"},{"id":2732,"pagetitle":"Subgradient method","title":"Manopt.SubGradientMethodState","ref":"/manopt/stable/solvers/subgradient/#Manopt.SubGradientMethodState","content":" Manopt.SubGradientMethodState  ‚Äî  Type SubGradientMethodState <: AbstractManoptSolverState stores option values for a  subgradient_method  solver Fields retraction_method : the retraction to use within stepsize :          ( ConstantStepsize (M) ) a  Stepsize stop :              ( StopAfterIteration (5000) )a [ StoppingCriterion`](@ref) p :                 (initial or current) value the algorithm is at p_star :            optimal value (initialized to a copy of  p .) X :                 ( zero_vector(M, p) ) the current element from the possible subgradients at  p  that was last evaluated. Constructor SubGradientMethodState(M::AbstractManifold, p; kwargs...) with keywords for all fields besides  p_star  which obtains the same type as  p . You can use  X=  to specify the type of tangent vector to use source For  DebugAction s and  RecordAction s to record (sub)gradient, its norm and the step sizes, see the  gradient descent  actions."},{"id":2733,"pagetitle":"Subgradient method","title":"Technical details","ref":"/manopt/stable/solvers/subgradient/#sec-sgm-technical-details","content":" Technical details The  subgradient_method  solver requires the following functions of a manifold to be available A  retract! (M, q, p, X) ; it is recommended to set the  default_retraction_method  to a favourite retraction. If this default is set, a  retraction_method=  does not have to be specified."},{"id":2734,"pagetitle":"Subgradient method","title":"Literature","ref":"/manopt/stable/solvers/subgradient/#Literature","content":" Literature [FO98] O.¬†Ferreira and P.¬†R.¬†Oliveira.  Subgradient algorithm on Riemannian manifolds .  Journal¬†of¬†Optimization¬†Theory¬†and¬†Applications  97 , 93‚Äì104  (1998)."},{"id":2737,"pagetitle":"Steihaug-Toint TCG Method","title":"Steihaug-Toint truncated conjugate gradient method","ref":"/manopt/stable/solvers/truncated_conjugate_gradient_descent/#tCG","content":" Steihaug-Toint truncated conjugate gradient method Solve the constraint optimization problem on the tangent space \\[\\begin{align*}\n\\operatorname*{arg\\,min}_{Y  ‚àà  T_p\\mathcal{M}}&\\ m_p(Y) = f(p) +\n‚ü®\\operatorname{grad}f(p), Y‚ü©_p + \\frac{1}{2} ‚ü®\\mathcal{H}_p[Y], Y‚ü©_p\\\\\n\\text{such that}& \\ \\lVert Y \\rVert_p ‚â§ Œî\n\\end{align*}\\] on the tangent space  $T_p\\mathcal M$  of a Riemannian manifold  $\\mathcal M$  by using the Steihaug-Toint truncated conjugate-gradient (tCG) method, see [ ABG06 ], Algorithm 2, and [ CGT00 ]. Here  $\\mathcal H_p$  is either the Hessian  $\\operatorname{Hess} f(p)$  or a linear symmetric operator on the tangent space approximating the Hessian."},{"id":2738,"pagetitle":"Steihaug-Toint TCG Method","title":"Interface","ref":"/manopt/stable/solvers/truncated_conjugate_gradient_descent/#Interface","content":" Interface"},{"id":2739,"pagetitle":"Steihaug-Toint TCG Method","title":"Manopt.truncated_conjugate_gradient_descent","ref":"/manopt/stable/solvers/truncated_conjugate_gradient_descent/#Manopt.truncated_conjugate_gradient_descent","content":" Manopt.truncated_conjugate_gradient_descent  ‚Äî  Function truncated_conjugate_gradient_descent(M, f, grad_f, p; kwargs...)\ntruncated_conjugate_gradient_descent(M, f, grad_f, p, X; kwargs...)\ntruncated_conjugate_gradient_descent(M, f, grad_f, Hess_f; kwargs...)\ntruncated_conjugate_gradient_descent(M, f, grad_f, Hess_f, p; kwargs...)\ntruncated_conjugate_gradient_descent(M, f, grad_f, Hess_f, p, X; kwargs...)\ntruncated_conjugate_gradient_descent(M, mho::ManifoldHessianObjective, p, X; kwargs...)\ntruncated_conjugate_gradient_descent(M, trmo::TrustRegionModelObjective, p, X; kwargs...) solve the trust-region subproblem \\[\\begin{align*}\n\\operatorname*{arg\\,min}_{Y  ‚àà  T_p\\mathcal{M}}&\\ m_p(Y) = f(p) +\n‚ü®\\operatorname{grad}f(p), Y‚ü©_p + \\frac{1}{2} ‚ü®\\mathcal{H}_p[Y], Y‚ü©_p\\\\\n\\text{such that}& \\ \\lVert Y \\rVert_p ‚â§ Œî\n\\end{align*}\\] on a manifold M by using the Steihaug-Toint truncated conjugate-gradient (tCG) method. For a description of the algorithm and theorems offering convergence guarantees, see [ ABG06 ,  CGT00 ]. Input M :      a manifold  $\\mathcal M$ f :      a cost function  $f: \\mathcal M ‚Üí ‚Ñù$  to minimize grad_f : the gradient  $\\operatorname{grad}f: \\mathcal M ‚Üí T\\mathcal M$  of  F Hess_f : (optional, cf.  ApproxHessianFiniteDifference ) the Hessian  $\\operatorname{Hess}f: T_p\\mathcal M ‚Üí T_p\\mathcal M$ ,  $X ‚Ü¶ \\operatorname{Hess}F(p)[X] = ‚àá_X\\operatorname{grad}f(p)$ p :      a point on the manifold  $p ‚àà \\mathcal M$ X :      an initial tangential vector  $X ‚àà T_p\\mathcal M$ Instead of the three functions, you either provide a  ManifoldHessianObjective mho  which is then used to build the trust region model, or a  TrustRegionModelObjective trmo  directly. Optional evaluation :          ( AllocatingEvaluation ) specify whether the gradient and Hessian work by  allocation (default) or  InplaceEvaluation  in place preconditioner :      a preconditioner for the Hessian H Œ∏ :                   ( 1.0 ) 1+Œ∏ is the superlinear convergence target rate. Œ∫ :                   ( 0.1 ) the linear convergence target rate. randomize :           set to true if the trust-region solve is initialized to a random tangent vector. This disables preconditioning. trust_region_radius : ( injectivity_radius(M)/4 ) a trust-region radius project! :            ( copyto! ) for numerical stability it is possible to project onto the tangent space after every iteration. By default this only copies instead. stopping_criterion :  ( StopAfterIteration (manifol_dimension(M)) | StopWhenResidualIsReducedByFactorOrPower (;Œ∫=Œ∫, Œ∏=Œ∏) | StopWhenCurvatureIsNegative () | StopWhenTrustRegionIsExceeded () | StopWhenModelIncreased () ) a functor inheriting from  StoppingCriterion  indicating when to stop, and the ones that are passed to  decorate_state!  for decorators. Output the obtained (approximate) minimizer  $Y^*$ , see  get_solver_return  for details See also trust_regions source"},{"id":2740,"pagetitle":"Steihaug-Toint TCG Method","title":"Manopt.truncated_conjugate_gradient_descent!","ref":"/manopt/stable/solvers/truncated_conjugate_gradient_descent/#Manopt.truncated_conjugate_gradient_descent!","content":" Manopt.truncated_conjugate_gradient_descent!  ‚Äî  Function truncated_conjugate_gradient_descent!(M, f, grad_f, Hess_f, p, X; kwargs...)\ntruncated_conjugate_gradient_descent!(M, f, grad_f, p, X; kwargs...) solve the trust-region subproblem in place of  X  (and  p ). Input M :      a manifold  $\\mathcal M$ f :      a cost function  $F: \\mathcal M ‚Üí ‚Ñù$  to minimize grad_f : the gradient  $\\operatorname{grad}f: \\mathcal M ‚Üí T\\mathcal M$  of  f Hess_f : the Hessian  $\\operatorname{Hess}f(x): T_p\\mathcal M ‚Üí T_p\\mathcal M$ ,  $X ‚Ü¶ \\operatorname{Hess}f(p)[X]$ p :      a point on the manifold  $p ‚àà \\mathcal M$ X :      an update tangential vector  $X ‚àà T_x\\mathcal M$ For more details and all optional arguments, see  truncated_conjugate_gradient_descent . source"},{"id":2741,"pagetitle":"Steihaug-Toint TCG Method","title":"State","ref":"/manopt/stable/solvers/truncated_conjugate_gradient_descent/#State","content":" State"},{"id":2742,"pagetitle":"Steihaug-Toint TCG Method","title":"Manopt.TruncatedConjugateGradientState","ref":"/manopt/stable/solvers/truncated_conjugate_gradient_descent/#Manopt.TruncatedConjugateGradientState","content":" Manopt.TruncatedConjugateGradientState  ‚Äî  Type TruncatedConjugateGradientState <: AbstractHessianSolverState describe the Steihaug-Toint truncated conjugate-gradient method, with Fields a default value is given in brackets if a parameter can be left out in initialization. Y :                   ( zero_vector(M,p) ) Current iterate, whose type is also used for the other, internal, tangent vector fields stop :                a  StoppingCriterion . X :                   the gradient  $\\operatorname{grad}f(p)$ ` Œ¥ :                   the conjugate gradient search direction Œ∏ :                   ( 1.0 ) 1+Œ∏ is the superlinear convergence target rate. Œ∫ :                   ( 0.1 ) the linear convergence target rate. trust_region_radius : ( injectivity_radius(M)/4 ) the trust-region radius residual :            the gradient of the model  $m(Y)$ randomize :           ( false ) project! :            ( copyto! ) for numerical stability it is possible to project onto the tangent space after every iteration. By default this only copies instead. Internal fields HŒ¥ ,  HY :                 temporary results of the Hessian applied to  Œ¥  and  Y , respectively. Œ¥HŒ¥ ,  YPŒ¥ ,  Œ¥PŒ¥ ,  YPŒ¥ : temporary inner products with  HŒ¥  and preconditioned inner products. z :                        the preconditioned residual z_r :                      inner product of the residual and  z Constructor TruncatedConjugateGradientState(TpM::TangentSpace, Y=rand(TpM); kwargs...) See also truncated_conjugate_gradient_descent ,  trust_regions source"},{"id":2743,"pagetitle":"Steihaug-Toint TCG Method","title":"Stopping criteria","ref":"/manopt/stable/solvers/truncated_conjugate_gradient_descent/#Stopping-criteria","content":" Stopping criteria"},{"id":2744,"pagetitle":"Steihaug-Toint TCG Method","title":"Manopt.StopWhenResidualIsReducedByFactorOrPower","ref":"/manopt/stable/solvers/truncated_conjugate_gradient_descent/#Manopt.StopWhenResidualIsReducedByFactorOrPower","content":" Manopt.StopWhenResidualIsReducedByFactorOrPower  ‚Äî  Type StopWhenResidualIsReducedByFactorOrPower <: StoppingCriterion A functor for testing if the norm of residual at the current iterate is reduced either by a power of 1+Œ∏ or by a factor Œ∫ compared to the norm of the initial residual. The criterion hence reads  $\\Vert r_k \\Vert_p \\leqq \\Vert r_0 \\Vert_p \\min \\bigl( \\kappa, \\Vert r_0 \\Vert_p^Œ∏ \\bigr)$ . Fields Œ∫ :      the reduction factor Œ∏ :      part of the reduction power reason : stores a reason of stopping if the stopping criterion has one be reached, see  get_reason . Constructor StopWhenResidualIsReducedByFactorOrPower(; Œ∫=0.1, Œ∏=1.0) Initialize the StopWhenResidualIsReducedByFactorOrPower functor to indicate to stop after the norm of the current residual is lesser than either the norm of the initial residual to the power of 1+Œ∏ or the norm of the initial residual times Œ∫. See also truncated_conjugate_gradient_descent ,  trust_regions source"},{"id":2745,"pagetitle":"Steihaug-Toint TCG Method","title":"Manopt.StopWhenTrustRegionIsExceeded","ref":"/manopt/stable/solvers/truncated_conjugate_gradient_descent/#Manopt.StopWhenTrustRegionIsExceeded","content":" Manopt.StopWhenTrustRegionIsExceeded  ‚Äî  Type StopWhenTrustRegionIsExceeded <: StoppingCriterion A functor for testing if the norm of the next iterate in the Steihaug-Toint truncated conjugate gradient method is larger than the trust-region radius  $Œ∏ \\leq \\Vert Y_{k}^{*} \\Vert_p$  and to end the algorithm when the trust region has been left. Fields reason : stores a reason of stopping if the stopping criterion has been reached, see  get_reason . Constructor StopWhenTrustRegionIsExceeded() initialize the StopWhenTrustRegionIsExceeded functor to indicate to stop after the norm of the next iterate is greater than the trust-region radius. See also truncated_conjugate_gradient_descent ,  trust_regions source"},{"id":2746,"pagetitle":"Steihaug-Toint TCG Method","title":"Manopt.StopWhenCurvatureIsNegative","ref":"/manopt/stable/solvers/truncated_conjugate_gradient_descent/#Manopt.StopWhenCurvatureIsNegative","content":" Manopt.StopWhenCurvatureIsNegative  ‚Äî  Type StopWhenCurvatureIsNegative <: StoppingCriterion A functor for testing if the curvature of the model is negative,  $‚ü®Œ¥_k, \\operatorname{Hess}[F](\\delta_k)‚ü©_p ‚â¶ 0$ . In this case, the model is not strictly convex, and the stepsize as computed does not yield a reduction of the model. Fields reason : stores a reason of stopping if the stopping criterion has been reached, see  get_reason . Constructor StopWhenCurvatureIsNegative() See also truncated_conjugate_gradient_descent ,  trust_regions source"},{"id":2747,"pagetitle":"Steihaug-Toint TCG Method","title":"Manopt.StopWhenModelIncreased","ref":"/manopt/stable/solvers/truncated_conjugate_gradient_descent/#Manopt.StopWhenModelIncreased","content":" Manopt.StopWhenModelIncreased  ‚Äî  Type StopWhenModelIncreased <: StoppingCriterion A functor for testing if the curvature of the model value increased. Fields reason : stores a reason of stopping if the stopping criterion has been reached, see  get_reason . Constructor StopWhenModelIncreased() See also truncated_conjugate_gradient_descent ,  trust_regions source"},{"id":2748,"pagetitle":"Steihaug-Toint TCG Method","title":"Manopt.update_stopping_criterion!","ref":"/manopt/stable/solvers/truncated_conjugate_gradient_descent/#Manopt.update_stopping_criterion!-Tuple{StopWhenResidualIsReducedByFactorOrPower, Val{:ResidualPower}, Any}","content":" Manopt.update_stopping_criterion!  ‚Äî  Method update_stopping_criterion!(c::StopWhenResidualIsReducedByFactorOrPower, :ResidualPower, v) Update the residual Power  Œ∏   to  v . source"},{"id":2749,"pagetitle":"Steihaug-Toint TCG Method","title":"Manopt.update_stopping_criterion!","ref":"/manopt/stable/solvers/truncated_conjugate_gradient_descent/#Manopt.update_stopping_criterion!-Tuple{StopWhenResidualIsReducedByFactorOrPower, Val{:ResidualFactor}, Any}","content":" Manopt.update_stopping_criterion!  ‚Äî  Method update_stopping_criterion!(c::StopWhenResidualIsReducedByFactorOrPower, :ResidualFactor, v) Update the residual Factor  Œ∫  to  v . source"},{"id":2750,"pagetitle":"Steihaug-Toint TCG Method","title":"Trust region model","ref":"/manopt/stable/solvers/truncated_conjugate_gradient_descent/#Trust-region-model","content":" Trust region model"},{"id":2751,"pagetitle":"Steihaug-Toint TCG Method","title":"Manopt.TrustRegionModelObjective","ref":"/manopt/stable/solvers/truncated_conjugate_gradient_descent/#Manopt.TrustRegionModelObjective","content":" Manopt.TrustRegionModelObjective  ‚Äî  Type TrustRegionModelObjective{O<:AbstractManifoldHessianObjective} <: AbstractManifoldSubObjective{O} A trust region model of the form \\[    m(X) = f(p) + ‚ü®\\operatorname{grad} f(p), X‚ü©_p + \\frac{1}(2} ‚ü®\\operatorname{Hess} f(p)[X], X‚ü©_p\\] Fields objective : an  AbstractManifoldHessianObjective  proving  $f$ , its gradient and Hessian Constructors TrustRegionModelObjective(objective) with either an  AbstractManifoldHessianObjective objective  or an decorator containing such an objective source"},{"id":2752,"pagetitle":"Steihaug-Toint TCG Method","title":"Technical details","ref":"/manopt/stable/solvers/truncated_conjugate_gradient_descent/#sec-tr-technical-details","content":" Technical details The  trust_regions  solver requires the following functions of a manifold to be available if you do not provide a  trust_region_radius= , then  injectivity_radius  on the manifold  M  is required. the  norm  as well, to stop when the norm of the gradient is small, but if you implemented  inner , the norm is provided already. A  zero_vector! (M,X,p) . A  `copyto! (M, q, p)  and  copy (M,p)  for points."},{"id":2753,"pagetitle":"Steihaug-Toint TCG Method","title":"Literature","ref":"/manopt/stable/solvers/truncated_conjugate_gradient_descent/#Literature","content":" Literature [ABG06] P.-A.¬†Absil, C.¬†Baker and K.¬†Gallivan.  Trust-Region Methods on Riemannian Manifolds .  Foundations¬†of¬†Computational¬†Mathematics  7 , 303‚Äì330  (2006). [CGT00] A.¬†R.¬†Conn, N.¬†I.¬†Gould and P.¬†L.¬†Toint.  Trust Region Methods  (Society for Industrial and Applied Mathematics, 2000)."},{"id":2756,"pagetitle":"Trust-Regions Solver","title":"The Riemannian trust regions solver","ref":"/manopt/stable/solvers/trust_regions/#The-Riemannian-trust-regions-solver","content":" The Riemannian trust regions solver Minimize a function \\[\\operatorname*{\\arg\\,min}_{p ‚àà \\mathcal{M}}\\ f(p)\\] by using the Riemannian trust-regions solver following [ ABG06 ] a model is build by lifting the objective at the  $k$ th iterate  $p_k$  by locally mapping the cost function  $f$  to the tangent space as  $f_k: T_{p_k}\\mathcal M ‚Üí ‚Ñù$  as  $f_k(X) = f(\\operatorname{retr}_{p_k}(X))$ . The trust region subproblem is then defined as \\[\\operatorname*{arg\\,min}_{X ‚àà T_{p_k}\\mathcal M}\\ m_k(X),\\] where \\[\\begin{align*}\nm_k&: T_{p_K}\\mathcal M ‚Üí ‚Ñù,\\\\\nm_k(X) &= f(p_k) + ‚ü®\\operatorname{grad} f(p_k), X‚ü©_{p_k} + \\frac{1}{2}\\langle \\mathcal H_k(X),X‚ü©_{p_k}\\\\\n\\text{such that}&\\ \\lVert X \\rVert_{p_k} ‚â§ Œî_k.\n\\end{align*}\\] Here  $Œî_k$  is a trust region radius, that is adapted every iteration, and  $\\mathcal H_k$  is some symmetric linear operator that approximates the Hessian  $\\operatorname{Hess} f$  of  $f$ ."},{"id":2757,"pagetitle":"Trust-Regions Solver","title":"Interface","ref":"/manopt/stable/solvers/trust_regions/#Interface","content":" Interface"},{"id":2758,"pagetitle":"Trust-Regions Solver","title":"Manopt.trust_regions","ref":"/manopt/stable/solvers/trust_regions/#Manopt.trust_regions","content":" Manopt.trust_regions  ‚Äî  Function trust_regions(M, f, grad_f, hess_f, p=rand(M))\ntrust_regions(M, f, grad_f, p=rand(M)) run the Riemannian trust-regions solver for optimization on manifolds to minimize  f , see on [ ABG06 ,  CGT00 ]. For the case that no Hessian is provided, the Hessian is computed using finite differences, see  ApproxHessianFiniteDifference . For solving the inner trust-region subproblem of finding an update-vector, by default the  truncated_conjugate_gradient_descent  is used. Input M :      a manifold  $\\mathcal M$ f :      a cost function  $f : \\mathcal M ‚Üí ‚Ñù$  to minimize grad_f : the gradient  $\\operatorname{grad}F : \\mathcal M ‚Üí T \\mathcal M$  of  $F$ Hess_f : (optional), the Hessian  $\\operatorname{Hess}F(x): T_x\\mathcal M ‚Üí T_x\\mathcal M$ ,  $X ‚Ü¶ \\operatorname{Hess}F(x)[X] = ‚àá_Œæ\\operatorname{grad}f(x)$ p :      ( rand(M) ) an initial value  $x  ‚àà  \\mathcal M$ Keyword arguments acceptance_rate :        Accept/reject threshold: if œÅ (the performance ratio for the iterate) is at least the acceptance rate œÅ', the candidate is accepted. This value should  be between  $0$  and  $\\frac{1}{4}$ augmentation_threshold : ( 0.75 ) trust-region augmentation threshold: if œÅ is larger than this threshold, a solution is on the trust region boundary and negative curvature, and the radius is extended (augmented) augmentation_factor :    ( 2.0 ) trust-region augmentation factor evaluation :             ( AllocatingEvaluation ) specify whether the gradient and Hessian work by allocation (default) or  InplaceEvaluation  in place Œ∫ :                      ( 0.1 ) the linear convergence target rate of the tCG method    truncated_conjugate_gradient_descent , and is used in a stopping criterion therein max_trust_region_radius : the maximum trust-region radius preconditioner :          a preconditioner (a symmetric, positive definite operator that should approximate the inverse of the Hessian) project! ;               ( copyto! ) specify a projection operation for tangent vectors within the subsolver for numerical stability. The required form is  (M, Y, p, X) -> ...  working in place of  Y . randomize ;              set to true if the trust-region solve is to be initiated with a random tangent vector and no preconditioner is used. œÅ_regularization :       ( 1e3 ) regularize the performance evaluation  $œÅ$  to avoid numerical inaccuracies. reduction_factor :       ( 0.25 ) trust-region reduction factor reduction_threshold :    ( 0.1 ) trust-region reduction threshold: if œÅ is below this threshold, the trust region radius is reduced by  reduction_factor . retraction  ( default_retraction_method(M, typeof(p)) ) a retraction to use stopping_criterion :     ( StopAfterIteration (1000) | StopWhenGradientNormLess (1e-6) ) a functor inheriting from  StoppingCriterion  indicating when to stop. sub_kwargs :             keyword arguments passed to the sub state and used to decorate the sub options sub_stopping_criterion : a stopping criterion for the sub solver, uses the same standard as TCG. sub_problem :            ( DefaultManoptProblem (M, ConstrainedManifoldObjective (subcost, subgrad; evaluation=evaluation)) ) problem for the subsolver sub_state :              ( QuasiNewtonState ) using  QuasiNewtonLimitedMemoryDirectionUpdate  with  InverseBFGS  and  sub_stopping_criterion  as a stopping criterion. See also  sub_kwargs . Œ∏ :                      ( 1.0 ) 1+Œ∏ is the superlinear convergence target rate of the tCG-method  truncated_conjugate_gradient_descent , and is used in a stopping criterion therein trust_region_radius :     the initial trust-region radius For the case that no Hessian is provided, the Hessian is computed using finite difference, see  ApproxHessianFiniteDifference . Output the obtained (approximate) minimizer  $p^*$ , see  get_solver_return  for details See also truncated_conjugate_gradient_descent source"},{"id":2759,"pagetitle":"Trust-Regions Solver","title":"Manopt.trust_regions!","ref":"/manopt/stable/solvers/trust_regions/#Manopt.trust_regions!","content":" Manopt.trust_regions!  ‚Äî  Function trust_regions!(M, f, grad_f, Hess_f, p; kwargs...)\ntrust_regions!(M, f, grad_f, p; kwargs...) evaluate the Riemannian trust-regions solver in place of  p . Input M :      a manifold  $\\mathcal M$ f :      a cost function  $f: \\mathcal M ‚Üí ‚Ñù$  to minimize grad_f : the gradient  $\\operatorname{grad}f: \\mathcal M ‚Üí T \\mathcal M$  of  $F$ Hess_f : (optional) the Hessian  $\\operatorname{Hess} f$ p :      an initial value  $p  ‚àà  \\mathcal M$ For the case that no Hessian is provided, the Hessian is computed using finite difference, see  ApproxHessianFiniteDifference . for more details and all options, see  trust_regions source"},{"id":2760,"pagetitle":"Trust-Regions Solver","title":"State","ref":"/manopt/stable/solvers/trust_regions/#State","content":" State"},{"id":2761,"pagetitle":"Trust-Regions Solver","title":"Manopt.TrustRegionsState","ref":"/manopt/stable/solvers/trust_regions/#Manopt.TrustRegionsState","content":" Manopt.TrustRegionsState  ‚Äî  Type TrustRegionsState <: AbstractHessianSolverState Store the state of the trust-regions solver. Fields All the following fields (besides  p ) can be set by specifying them as keywords. acceptance_rate :         ( 0.1 ) a lower bound of the performance ratio for the iterate that decides if the iteration is accepted or not. max_trust_region_radius : ( sqrt(manifold_dimension(M)) ) the maximum trust-region radius p :                       ( rand(M)  if a manifold is provided) the current iterate project! :                ( copyto! ) specify a projection operation for tangent vectors for numerical stability. A function  (M, Y, p, X) -> ...  working in place of  Y . per default, no projection is performed, set it to  project!  to activate projection. stop :                    ( StopAfterIteration (1000) | StopWhenGradientNormLess (1e-6) ) randomize :               ( false ) indicates if the trust-region solve is to be initiated with a random tangent vector. If set to true, no preconditioner is used. This option is set to true in some scenarios to escape saddle points, but is otherwise seldom activated. œÅ_regularization :        ( 10000.0 ) regularize the model fitness  $œÅ$  to avoid division by zero sub_problem :             an  AbstractManoptProblem  problem or a function  (M, p, X) -> q  or  (M, q, p, X)  for the a closed form solution of the sub problem sub_state :               ( TruncatedConjugateGradientState (M, p, X) ) œÉ :                       ( 0.0  or  1e-6  depending on  randomize ) Gaussian standard deviation when creating the random initial tangent vector trust_region_radius :     ( max_trust_region_radius / 8 ) the (initial) trust-region radius X :                       ( zero_vector(M,p) ) the current gradient  grad_f(p)  Use this default to specify the type of tangent vector to allocate also for the internal (tangent vector) fields. Internal fields HX ,  HY ,  HZ :          interim storage (to avoid allocation) of ` \\operatorname{Hess} f(p)[\\cdot]  of  X ,  Y ,  Z Y :                       the solution (tangent vector) of the subsolver Z :                       the Cauchy point (only used if random is activated) Constructors All the following constructors have the fields as keyword arguments with the defaults given in brackets. If no initial point  p  is provided,  p=rand(M)  is used TrustRegionsState(M, mho; kwargs...)\nTrustRegionsState(M, p, mho; kwargs...) A trust region state, where the sub problem is set to a  DefaultManoptProblem  on the tangent space using the  TrustRegionModelObjective  to be solved with  truncated_conjugate_gradient_descent!  or in other words the sub state is set to  TruncatedConjugateGradientState . TrustRegionsState(M, sub_problem, sub_state; kwargs...)\nTrustRegionsState(M, p, sub_problem, sub_state; kwargs...) A trust region state, where the sub problem is solved using a  AbstractManoptProblem sub_problem  and an  AbstractManoptSolverState sub_state . TrustRegionsState(M, f::Function; evaluation=AllocatingEvaluation, kwargs...)\nTrustRegionsState(M, p, f; evaluation=AllocatingEvaluation, kwargs...) A trust region state, where the sub problem is solved in closed form by a function  f(M, p, Y, Œî) , where  p  is the current iterate,  Y  the initial tangent vector at  p  and  Œî  the current trust region radius. See also trust_regions ,  trust_regions! source"},{"id":2762,"pagetitle":"Trust-Regions Solver","title":"Approximation of the Hessian","ref":"/manopt/stable/solvers/trust_regions/#Approximation-of-the-Hessian","content":" Approximation of the Hessian Several different methods to approximate the Hessian are available."},{"id":2763,"pagetitle":"Trust-Regions Solver","title":"Manopt.ApproxHessianFiniteDifference","ref":"/manopt/stable/solvers/trust_regions/#Manopt.ApproxHessianFiniteDifference","content":" Manopt.ApproxHessianFiniteDifference  ‚Äî  Type ApproxHessianFiniteDifference{E, P, T, G, RTR,, VTR, R <: Real} <: AbstractApproxHessian A functor to approximate the Hessian by a finite difference of gradient evaluation. Given a point  p  and a direction  X  and the gradient  $\\operatorname{grad}F: \\mathcal M ‚Üí T\\mathcal M$  of a function  $F$  the Hessian is approximated as follows: let  $c$  be a stepsize,  $X‚àà T_p\\mathcal M$  a tangent vector and  $q = \\operatorname{retr}_p(\\frac{c}{\\lVert X \\rVert_p}X)$  be a step in direction  $X$  of length  $c$  following a retraction Then the Hessian is approximated by the finite difference of the gradients, where  $\\mathcal T_{\\cdot\\gets\\cdot}$  is a vector transport. \\[\\operatorname{Hess}F(p)[X] ‚âà\n\\frac{\\lVert X \\rVert_p}{c}\\Bigl(\n  \\mathcal T_{p\\gets q}\\bigr(\\operatorname{grad}F(q)\\bigl) - \\operatorname{grad}F(p)\n\\Bigl)\\] Fields gradient!! :              the gradient function (either allocating or mutating, see  evaluation  parameter) step_length :             a step length for the finite difference retraction_method :       a retraction to use vector_transport_method : a vector transport to use Internal temporary fields grad_tmp :     a temporary storage for the gradient at the current  p grad_dir_tmp : a temporary storage for the gradient at the current  p_dir p_dir::P :     a temporary storage to the forward direction (or the  $q$  in the formula) Constructor ApproximateFiniteDifference(M, p, grad_f; kwargs...) Keyword arguments evaluation :              ( AllocatingEvaluation ) whether the gradient is given as an allocation function or an in-place ( InplaceEvaluation ). steplength :              ( $2^{-14}$ ) step length  $c$  to approximate the gradient evaluations retraction_method :       ( default_retraction_method(M, typeof(p)) ) a  retraction(M, p, X)  to use in the approximation. vector_transport_method : ( default_vector_transport_method(M, typeof(p)) ) a vector transport to use source"},{"id":2764,"pagetitle":"Trust-Regions Solver","title":"Manopt.ApproxHessianSymmetricRankOne","ref":"/manopt/stable/solvers/trust_regions/#Manopt.ApproxHessianSymmetricRankOne","content":" Manopt.ApproxHessianSymmetricRankOne  ‚Äî  Type ApproxHessianSymmetricRankOne{E, P, G, T, B<:AbstractBasis{‚Ñù}, VTR, R<:Real} <: AbstractApproxHessian A functor to approximate the Hessian by the symmetric rank one update. Fields gradient!!  the gradient function (either allocating or mutating, see  evaluation  parameter). ŒΩ  a small real number to ensure that the denominator in the update does not become too small and thus the method does not break down. vector_transport_method  a vector transport to use. Internal temporary fields p_tmp  a temporary storage the current point  p . grad_tmp  a temporary storage for the gradient at the current  p . matrix  a temporary storage for the matrix representation of the approximating operator. basis  a temporary storage for an orthonormal basis at the current  p . Constructor ApproxHessianSymmetricRankOne(M, p, gradF; kwargs...) Keyword arguments initial_operator  ( Matrix{Float64}(I, manifold_dimension(M), manifold_dimension(M)) ) the matrix representation of the initial approximating operator. basis  ( DefaultOrthonormalBasis() ) an orthonormal basis in the tangent space of the initial iterate p. nu  ( -1 ) evaluation  ( AllocatingEvaluation ) whether the gradient is given as an allocation function or an in-place ( InplaceEvaluation ). vector_transport_method  ( ParallelTransport() ) vector transport  $\\mathcal T_{\\cdot\\gets\\cdot}$  to use. source"},{"id":2765,"pagetitle":"Trust-Regions Solver","title":"Manopt.ApproxHessianBFGS","ref":"/manopt/stable/solvers/trust_regions/#Manopt.ApproxHessianBFGS","content":" Manopt.ApproxHessianBFGS  ‚Äî  Type ApproxHessianBFGS{E, P, G, T, B<:AbstractBasis{‚Ñù}, VTR, R<:Real} <: AbstractApproxHessian A functor to approximate the Hessian by the BFGS update. Fields gradient!!  the gradient function (either allocating or mutating, see  evaluation  parameter). scale vector_transport_method  a vector transport to use. Internal temporary fields p_tmp  a temporary storage the current point  p . grad_tmp  a temporary storage for the gradient at the current  p . matrix  a temporary storage for the matrix representation of the approximating operator. basis  a temporary storage for an orthonormal basis at the current  p . Constructor ApproxHessianBFGS(M, p, gradF; kwargs...) Keyword arguments initial_operator  ( Matrix{Float64}(I, manifold_dimension(M), manifold_dimension(M)) ) the matrix representation of the initial approximating operator. basis  ( DefaultOrthonormalBasis() ) an orthonormal basis in the tangent space of the initial iterate p. nu  ( -1 ) evaluation  ( AllocatingEvaluation ) whether the gradient is given as an allocation function or an in-place ( InplaceEvaluation ). vector_transport_method  ( ParallelTransport() ) vector transport  $\\mathcal T_{\\cdot\\gets\\cdot}$  to use. source as well as their (non-exported) common supertype"},{"id":2766,"pagetitle":"Trust-Regions Solver","title":"Manopt.AbstractApproxHessian","ref":"/manopt/stable/solvers/trust_regions/#Manopt.AbstractApproxHessian","content":" Manopt.AbstractApproxHessian  ‚Äî  Type AbstractApproxHessian <: Function An abstract supertypes for approximate Hessian functions, declares them also to be functions. source"},{"id":2767,"pagetitle":"Trust-Regions Solver","title":"Technical details","ref":"/manopt/stable/solvers/trust_regions/#sec-tr-technical-details","content":" Technical details The  trust_regions  solver requires the following functions of a manifold to be available A  retract! (M, q, p, X) ; it is recommended to set the  default_retraction_method  to a favourite retraction. If this default is set, a  retraction_method=  does not have to be specified. By default the stopping criterion uses the  norm  as well, to stop when the norm of the gradient is small, but if you implemented  inner , the norm is provided already. if you do not provide an initial  max_trust_region_radius , a  manifold_dimension  is required. A  `copyto! (M, q, p)  and  copy (M,p)  for points. By default the tangent vectors are initialized calling  zero_vector (M,p) ."},{"id":2768,"pagetitle":"Trust-Regions Solver","title":"Literature","ref":"/manopt/stable/solvers/trust_regions/#Literature","content":" Literature [ABG06] P.-A.¬†Absil, C.¬†Baker and K.¬†Gallivan.  Trust-Region Methods on Riemannian Manifolds .  Foundations¬†of¬†Computational¬†Mathematics  7 , 303‚Äì330  (2006). [CGT00] A.¬†R.¬†Conn, N.¬†I.¬†Gould and P.¬†L.¬†Toint.  Trust Region Methods  (Society for Industrial and Applied Mathematics, 2000)."},{"id":2771,"pagetitle":"Use automatic differentiation","title":"Using Automatic Differentiation in Manopt.jl","ref":"/manopt/stable/tutorials/AutomaticDifferentiation/#Using-Automatic-Differentiation-in-Manopt.jl","content":" Using Automatic Differentiation in Manopt.jl Since  Manifolds.jl  0.7, the support of automatic differentiation support has been extended. This tutorial explains how to use Euclidean tools to derive a gradient for a real-valued function  $f: \\mathcal M ‚Üí ‚Ñù$ . Two methods are considered: an intrinsic variant and a variant employing the embedding. These gradients can then be used within any gradient based optimization algorithm in  Manopt.jl . While by default  FiniteDifferences.jl are used, one can also use  FiniteDiff.jl ,  ForwardDiff.jl ,  ReverseDiff.jl , or  Zygote.jl . This tutorial looks at a few possibilities to approximate or derive the gradient of a function  $f:\\mathcal M ‚Üí ‚Ñù$  on a Riemannian manifold, without computing it yourself. There are mainly two different philosophies: Working  intrinsically , that is staying on the manifold and in the tangent spaces, considering to approximate the gradient by forward differences. Working in an embedding where all tools from functions on Euclidean spaces can be used, like finite differences or automatic differentiation, and then compute the corresponding Riemannian gradient from there. First, load all necessary packages using Manopt, Manifolds, Random, LinearAlgebra\nusing FiniteDifferences, ManifoldDiff\nRandom.seed!(42);"},{"id":2772,"pagetitle":"Use automatic differentiation","title":"1. (Intrinsic) Forward Differences","ref":"/manopt/stable/tutorials/AutomaticDifferentiation/#1.-(Intrinsic)-Forward-Differences","content":" 1. (Intrinsic) Forward Differences A first idea is to generalize (multivariate) finite differences to Riemannian manifolds. Let  $X_1,\\ldots,X_d ‚àà T_p\\mathcal M$  denote an orthonormal basis of the tangent space  $T_p\\mathcal M$  at the point  $p‚àà\\mathcal M$  on the Riemannian manifold. The notion of a directional derivative is generalized to a ‚Äúdirection‚Äù  $Y‚ààT_p\\mathcal M$ . Let  $c: [-Œµ,Œµ]$ ,  $Œµ>0$ , be a curve with  $c(0) = p$ ,  $\\dot c(0) = Y$ , for example  $c(t)= \\exp_p(tY)$ . This yields \\[    Df(p)[Y] = \\left. \\frac{d}{dt} \\right|_{t=0} f(c(t)) = \\lim_{t ‚Üí 0} \\frac{1}{t}(f(\\exp_p(tY))-f(p))\\] The differential  $Df(p)[X]$  is approximated by a finite difference scheme for an  $h>0$  as \\[DF(p)[Y] ‚âà G_h(Y) := \\frac{1}{h}(f(\\exp_p(hY))-f(p))\\] Furthermore the gradient  $\\operatorname{grad}f$  is the Riesz representer of the differential: \\[    Df(p)[Y] = g_p(\\operatorname{grad}f(p), Y),\\qquad \\text{ for all } Y ‚àà T_p\\mathcal M\\] and since it is a tangent vector, we can write it in terms of a basis as \\[    \\operatorname{grad}f(p) = \\sum_{i=1}^{d} g_p(\\operatorname{grad}f(p),X_i)X_i\n    = \\sum_{i=1}^{d} Df(p)[X_i]X_i\\] and perform the approximation from above to obtain \\[    \\operatorname{grad}f(p) ‚âà \\sum_{i=1}^{d} G_h(X_i)X_i\\] for some suitable step size  $h$ . This comes at the cost of  $d+1$  function evaluations and  $d$  exponential maps. This is the first variant we can use. An advantage is that it is  intrinsic  in the sense that it does not require any embedding of the manifold."},{"id":2773,"pagetitle":"Use automatic differentiation","title":"An Example: the Rayleigh Quotient","ref":"/manopt/stable/tutorials/AutomaticDifferentiation/#An-Example:-the-Rayleigh-Quotient","content":" An Example: the Rayleigh Quotient The Rayleigh quotient is concerned with finding eigenvalues (and eigenvectors) of a symmetric matrix  $A ‚àà ‚Ñù^{(n+1)√ó(n+1)}$ . The optimization problem reads \\[F:  ‚Ñù^{n+1} ‚Üí ‚Ñù,\\quad F(\\mathbf x) = \\frac{\\mathbf x^\\mathrm{T}A\\mathbf x}{\\mathbf x^\\mathrm{T}\\mathbf x}\\] Minimizing this function yields the smallest eigenvalue  $\\lambda_1$  as a value and the corresponding minimizer  $\\mathbf x^*$  is a corresponding eigenvector. Since the length of an eigenvector is irrelevant, there is an ambiguity in the cost function. It can be better phrased on the sphere  $  ùïä^n $  of unit vectors in  $‚Ñù^{n+1}$ , \\[\\operatorname*{arg\\,min}_{p ‚àà ùïä^n}\\ f(p) = \\operatorname*{arg\\,min}_{\\ p ‚àà ùïä^n} p^\\mathrm{T}Ap\\] We can compute the Riemannian gradient exactly as \\[\\operatorname{grad} f(p) = 2(Ap - pp^\\mathrm{T}Ap)\\] so we can compare it to the approximation by finite differences. n = 200\nA = randn(n + 1, n + 1)\nA = Symmetric(A)\nM = Sphere(n);\n\nf1(p) = p' * A'p\ngradf1(p) = 2 * (A * p - p * p' * A * p) gradf1 (generic function with 1 method) Manifolds provides a finite difference scheme in tangent spaces, that you can introduce to use an existing framework (if the wrapper is implemented) form Euclidean space. Here we use  FiniteDiff.jl . r_backend = ManifoldDiff.TangentDiffBackend(\n    ManifoldDiff.FiniteDifferencesBackend()\n)\ngradf1_FD(p) = ManifoldDiff.gradient(M, f1, p, r_backend)\n\np = zeros(n + 1)\np[1] = 1.0\nX1 = gradf1(p)\nX2 = gradf1_FD(p)\nnorm(M, p, X1 - X2) 1.0191005407991261e-12 We obtain quite a good approximation of the gradient."},{"id":2774,"pagetitle":"Use automatic differentiation","title":"2. Conversion of a Euclidean Gradient in the Embedding to a Riemannian Gradient of a (not Necessarily Isometrically) Embedded Manifold","ref":"/manopt/stable/tutorials/AutomaticDifferentiation/#EmbeddedGradient","content":" 2. Conversion of a Euclidean Gradient in the Embedding to a Riemannian Gradient of a (not Necessarily Isometrically) Embedded Manifold Let  $\\tilde f: ‚Ñù^m ‚Üí ‚Ñù$  be a function on the embedding of an  $n$ -dimensional manifold  $\\mathcal M \\subset ‚Ñù^m$ and let  $f: \\mathcal M ‚Üí ‚Ñù$  denote the restriction of  $\\tilde f$  to the manifold  $\\mathcal M$ . Since we can use the pushforward of the embedding to also embed the tangent space  $T_p\\mathcal M$ ,  $p‚àà\\mathcal M$ , we can similarly obtain the differential  $Df(p): T_p\\mathcal M ‚Üí ‚Ñù$  by restricting the differential  $D\\tilde f(p)$  to the tangent space. If both  $T_p\\mathcal M$  and  $T_p‚Ñù^m$  have the same inner product, or in other words the manifold is isometrically embedded in  $‚Ñù^m$  (like for example the sphere  $\\mathbb S^n\\subset‚Ñù^{m+1}$ ), then this restriction of the differential directly translates to a projection of the gradient \\[\\operatorname{grad}f(p) = \\operatorname{Proj}_{T_p\\mathcal M}(\\operatorname{grad} \\tilde f(p))\\] More generally take a change of the metric into account as \\[\\langle  \\operatorname{Proj}_{T_p\\mathcal M}(\\operatorname{grad} \\tilde f(p)), X \\rangle\n= Df(p)[X] = g_p(\\operatorname{grad}f(p), X)\\] or in words: we have to change the Riesz representer of the (restricted/projected) differential of  $f$  ( $\\tilde f$ ) to the one with respect to the Riemannian metric. This is done using  change_representer ."},{"id":2775,"pagetitle":"Use automatic differentiation","title":"A Continued Example","ref":"/manopt/stable/tutorials/AutomaticDifferentiation/#A-Continued-Example","content":" A Continued Example We continue with the Rayleigh Quotient from before, now just starting with the definition of the Euclidean case in the embedding, the function  $F$ . F(x) = x' * A * x / (x' * x); The cost function is the same by restriction f2(M, p) = F(p); The gradient is now computed combining our gradient scheme with FiniteDifferences. function grad_f2_AD(M, p)\n    return Manifolds.gradient(\n        M, F, p, Manifolds.RiemannianProjectionBackend(ManifoldDiff.FiniteDifferencesBackend())\n    )\nend\nX3 = grad_f2_AD(M, p)\nnorm(M, p, X1 - X3) 1.7411110029364861e-12"},{"id":2776,"pagetitle":"Use automatic differentiation","title":"An Example for a Non-isometrically Embedded Manifold","ref":"/manopt/stable/tutorials/AutomaticDifferentiation/#An-Example-for-a-Non-isometrically-Embedded-Manifold","content":" An Example for a Non-isometrically Embedded Manifold on the manifold  $\\mathcal P(3)$  of symmetric positive definite matrices. The following function computes (half) the distance squared (with respect to the linear affine metric) on the manifold  $\\mathcal P(3)$  to the identity matrix  $I_3$ . Denoting the unit matrix we consider the function \\[    G(q)\n    = \\frac{1}{2}d^2_{\\mathcal P(3)}(q,I_3)\n    = \\lVert \\operatorname{Log}(q) \\rVert_F^2,\\] where  $\\operatorname{Log}$  denotes the matrix logarithm and  $\\lVert \\cdot \\rVert_F$  is the Frobenius norm. This can be computed for symmetric positive definite matrices by summing the squares of the logarithms of the eigenvalues of  $q$  and dividing by two: G(q) = sum(log.(eigvals(Symmetric(q))) .^ 2) / 2 G (generic function with 1 method) We can also interpret this as a function on the space of matrices and apply the Euclidean finite differences machinery; in this way we can easily derive the Euclidean gradient. But when computing the Riemannian gradient, we have to change the representer (see again  change_representer ) after projecting onto the tangent space  $T_p\\mathcal P(n)$  at  $p$ . Let‚Äôs first define a point and the manifold  $N=\\mathcal P(3)$ . rotM(Œ±) = [1.0 0.0 0.0; 0.0 cos(Œ±) sin(Œ±); 0.0 -sin(Œ±) cos(Œ±)]\nq = rotM(œÄ / 6) * [1.0 0.0 0.0; 0.0 2.0 0.0; 0.0 0.0 3.0] * transpose(rotM(œÄ / 6))\nN = SymmetricPositiveDefinite(3)\nis_point(N, q) true We could first just compute the gradient using  FiniteDifferences.jl , but this yields the Euclidean gradient: FiniteDifferences.grad(central_fdm(5, 1), G, q) ([3.240417492806275e-14 -2.3531899864903462e-14 0.0; 0.0 0.3514812167654708 0.017000516835452926; 0.0 0.0 0.36129646973723023],) Instead, we use the  RiemannianProjectedBackend  of  Manifolds.jl , which in this case internally uses  FiniteDifferences.jl  to compute a Euclidean gradient but then uses the conversion explained above to derive the Riemannian gradient. We define this here again as a function  grad_G_FD  that could be used in the  Manopt.jl  framework within a gradient based optimization. function grad_G_FD(N, q)\n    return Manifolds.gradient(\n        N, G, q, ManifoldDiff.RiemannianProjectionBackend(ManifoldDiff.FiniteDifferencesBackend())\n    )\nend\nG1 = grad_G_FD(N, q) 3√ó3 Matrix{Float64}:\n  3.24042e-14  -2.64734e-14  -5.09481e-15\n -2.64734e-14   1.86368       0.826856\n -5.09481e-15   0.826856      2.81845 Now, we can again compare this to the (known) solution of the gradient, namely the gradient of (half of) the distance squared  $G(q) = \\frac{1}{2}d^2_{\\mathcal P(3)}(q,I_3)$  is given by  $\\operatorname{grad} G(q) = -\\operatorname{log}_q I_3$ , where  $\\operatorname{log}$  is the  logarithmic map  on the manifold. G2 = -log(N, q, Matrix{Float64}(I, 3, 3)) 3√ó3 Matrix{Float64}:\n -0.0  -0.0       -0.0\n -0.0   1.86368    0.826856\n -0.0   0.826856   2.81845 Both terms agree up to  $1.8√ó10^{-12}$ : norm(G1 - G2)\nisapprox(M, q, G1, G2; atol=2 * 1e-12) true"},{"id":2777,"pagetitle":"Use automatic differentiation","title":"Summary","ref":"/manopt/stable/tutorials/AutomaticDifferentiation/#Summary","content":" Summary This tutorial illustrates how to use tools from Euclidean spaces, finite differences or automatic differentiation, to compute gradients on Riemannian manifolds. The scheme allows to use  any  differentiation framework within the embedding to derive a Riemannian gradient."},{"id":2780,"pagetitle":"Do constrained optimization","title":"How to do constrained optimization","ref":"/manopt/stable/tutorials/ConstrainedOptimization/#How-to-do-constrained-optimization","content":" How to do constrained optimization Ronny Bergmann This tutorial is a short introduction to using solvers for constraint optimisation in  Manopt.jl ."},{"id":2781,"pagetitle":"Do constrained optimization","title":"Introduction","ref":"/manopt/stable/tutorials/ConstrainedOptimization/#Introduction","content":" Introduction A constraint optimisation problem is given by \\[\\tag{P}\n\\begin{align*}\n\\operatorname*{arg\\,min}_{p‚àà\\mathcal M} & f(p)\\\\\n\\text{such that} &\\quad g(p) \\leq 0\\\\\n&\\quad h(p) = 0,\\\\\n\\end{align*}\\] where  $f: \\mathcal M ‚Üí ‚Ñù$  is a cost function, and  $g: \\mathcal M ‚Üí ‚Ñù^m$  and  $h: \\mathcal M ‚Üí ‚Ñù^n$  are the inequality and equality constraints, respectively. The  $\\leq$  and  $=$  in (P) are meant element-wise. This can be seen as a balance between moving constraints into the geometry of a manifold  $\\mathcal M$  and keeping some, since they can be handled well in algorithms, see [ BH19 ], [ LB19 ] for details. using Distributions, LinearAlgebra, Manifolds, Manopt, Random\nRandom.seed!(42); In this tutorial we want to look at different ways to specify the problem and its implications. We start with specifying an example problems to illustrate the different available forms. We consider the problem of a Nonnegative PCA, cf.¬†Section 5.1.2 in [ LB19 ] let  $v_0 ‚àà ‚Ñù^d$ ,  $\\lVert v_0 \\rVert=1$  be given spike signal, that is a signal that is sparse with only  $s=\\lfloor Œ¥d \\rfloor$  nonzero entries. \\[Z = \\sqrt{œÉ} v_0v_0^{\\mathrm{T}}+N,\\] where  $\\sigma$  is a signal-to-noise ratio and  $N$  is a matrix with random entries, where the diagonal entries are distributed with zero mean and standard deviation  $1/d$  on the off-diagonals and  $2/d$  on the diagonal d = 150; # dimension of v0\nœÉ = 0.1^2; # SNR\nŒ¥ = 0.1; sp = Int(floor(Œ¥ * d)); # Sparsity\nS = sample(1:d, sp; replace=false);\nv0 =  [i ‚àà S ? 1 / sqrt(sp) : 0.0 for i in 1:d];\nN = rand(Normal(0, 1 / d), (d, d)); N[diagind(N, 0)] .= rand(Normal(0, 2 / d), d);\nZ = Z = sqrt(œÉ) * v0 * transpose(v0) + N; In order to recover  $v_0$  we consider the constrained optimisation problem on the sphere  $\\mathcal S^{d-1}$  given by \\[\\begin{align*}\n\\operatorname*{arg\\,min}_{p‚àà\\mathcal S^{d-1}} & -p^{\\mathrm{T}}Zp^{\\mathrm{T}}\\\\\n\\text{such that} &\\quad p \\geq 0\\\\\n\\end{align*}\\] or in the previous notation  $f(p) = -p^{\\mathrm{T}}Zp^{\\mathrm{T}}$  and  $g(p) = -p$ . We first initialize the manifold under consideration M = Sphere(d - 1) Sphere(149, ‚Ñù)"},{"id":2782,"pagetitle":"Do constrained optimization","title":"A first augmented Lagrangian run","ref":"/manopt/stable/tutorials/ConstrainedOptimization/#A-first-augmented-Lagrangian-run","content":" A first augmented Lagrangian run We first defined  $f$  and  $g$  as usual functions f(M, p) = -transpose(p) * Z * p;\ng(M, p) = -p; since  $f$  is a functions defined in the embedding  $‚Ñù^d$  as well, we obtain its gradient by projection. grad_f(M, p) = project(M, p, -transpose(Z) * p - Z * p); For the constraints this is a little more involved, since each function  $g_i = g(p)_i = p_i$  has to return its own gradient. These are again in the embedding just  $\\operatorname{grad} g_i(p) = -e_i$  the  $i$  th unit vector. We can project these again onto the tangent space at  $p$ : grad_g(M, p) = project.(\n    Ref(M), Ref(p), [[i == j ? -1.0 : 0.0 for j in 1:d] for i in 1:d]\n); We further start in a random point: p0 = rand(M); Let‚Äôs check a few things for the initial point f(M, p0) 0.0057476048331242344 How much the function g is positive maximum(g(M, p0)) 0.17885478285466855 Now as a first method we can just call the  Augmented Lagrangian Method  with a simple call: @time v1 = augmented_Lagrangian_method(\n    M, f, grad_f, p0; g=g, grad_g=grad_g,\n    debug=[:Iteration, :Cost, :Stop, \" | \", (:Change, \"Œîp : %1.5e\"), 20, \"\\n\"],\n    stopping_criterion = StopAfterIteration(300) | (\n        StopWhenSmallerOrEqual(:œµ, 1e-5) & StopWhenChangeLess(1e-8)\n    )\n); Initial f(x): 0.005748 | \n# 20    f(x): -0.123843 | Œîp : 1.00030e+00\n# 40    f(x): -0.123843 | Œîp : 4.46945e-04\n# 60    f(x): -0.123843 | Œîp : 3.87541e-04\nThe value of the variable (œµ) is smaller than or equal to its threshold (1.0e-5).\nThe algorithm performed a step with a change (7.466076176399011e-6) less than 9.120108393559073e-6.\n  4.757983 seconds (9.73 M allocations: 3.929 GiB, 8.49% gc time, 81.93% compilation time) Now we have both a lower function value and the point is nearly within the constraints, ‚Ä¶ up to numerical inaccuracies f(M, v1) -0.1238387017550424 maximum( g(M, v1) ) -7.042061792236086e-12"},{"id":2783,"pagetitle":"Do constrained optimization","title":"A faster augmented Lagrangian run","ref":"/manopt/stable/tutorials/ConstrainedOptimization/#A-faster-augmented-Lagrangian-run","content":" A faster augmented Lagrangian run Now this is a little slow, so we can modify two things: Gradients should be evaluated in place, so for example grad_f!(M, X, p) = project!(M, X, p, -transpose(Z) * p - Z * p); The constraints are currently always evaluated all together, since the function  grad_g  always returns a vector of gradients.  We first change the constraints function into a vector of functions.  We further change the gradient  both  into a vector of gradient functions  $\\operatorname{grad} g_i, i=1,\\ldots,d$ ,  as well as  gradients that are computed in place. g2 = [(M, p) -> -p[i] for i in 1:d];\ngrad_g2! = [\n    (M, X, p) -> project!(M, X, p, [i == j ? -1.0 : 0.0 for j in 1:d]) for i in 1:d\n]; We obtain @time v2 = augmented_Lagrangian_method(\n        M, f, grad_f!, p0; g=g2, grad_g=grad_g2!, evaluation=InplaceEvaluation(),\n        debug=[:Iteration, :Cost, :Stop, \" | \", (:Change, \"Œîp : %1.5e\"), 20, \"\\n\"],\n        stopping_criterion = StopAfterIteration(300) | (\n          StopWhenSmallerOrEqual(:œµ, 1e-5) & StopWhenChangeLess(1e-8)\n        )\n    ); Initial f(x): 0.005748 | \n# 20    f(x): -0.123843 | Œîp : 1.00019e+00\n# 40    f(x): -0.123843 | Œîp : 6.77478e-04\n# 60    f(x): -0.123843 | Œîp : 7.70563e-05\nThe value of the variable (œµ) is smaller than or equal to its threshold (1.0e-5).\nThe algorithm performed a step with a change (3.4787074961680085e-6) less than 6.456542290346536e-6.\n  1.877835 seconds (3.40 M allocations: 1.805 GiB, 2.78% gc time, 71.30% compilation time) As a technical remark: note that (by default) the change to  InplaceEvaluation s affects both the constrained solver as well as the inner solver of the subproblem in each iteration. f(M, v2) -0.12384008804682478 maximum(g(M, v2)) 5.039908187343563e-13 These are the very similar to the previous values but the solver took much less time and less memory allocations."},{"id":2784,"pagetitle":"Do constrained optimization","title":"Exact penalty method","ref":"/manopt/stable/tutorials/ConstrainedOptimization/#Exact-penalty-method","content":" Exact penalty method As a second solver, we have the  Exact Penalty Method , which currently is available with two smoothing variants, which make an inner solver for smooth optimization, that is by default again [quasi Newton] possible:  LogarithmicSumOfExponentials  and  LinearQuadraticHuber . We compare both here as well. The first smoothing technique is the default, so we can just call @time v3 = exact_penalty_method(\n    M, f, grad_f!, p0; g=g2, grad_g=grad_g2!, evaluation=InplaceEvaluation(),\n    debug=[:Iteration, :Cost, :Stop, \" | \", :Change, 50, \"\\n\"],\n); Initial f(x): 0.005748 | \n# 50    f(x): -0.123071 | Last Change: 0.981298\n# 100   f(x): -0.123840 | Last Change: 0.014479\nThe value of the variable (œµ) is smaller than or equal to its threshold (1.0e-6).\nThe algorithm performed a step with a change (2.3197576444804602e-7) less than 1.0e-6.\n  1.422785 seconds (3.81 M allocations: 1.802 GiB, 3.66% gc time, 77.26% compilation time) We obtain a similar cost value as for the Augmented Lagrangian Solver above, but here the constraint is actually fulfilled and not just numerically ‚Äúon the boundary‚Äù. f(M, v3) -0.1238403951818009 maximum(g(M, v3)) -3.5740153559377975e-6 The second smoothing technique is often beneficial, when we have a lot of constraints (in the above mentioned vectorial manner), since we can avoid several gradient evaluations for the constraint functions here. This leads to a faster iteration time. @time v4 = exact_penalty_method(\n    M, f, grad_f!, p0; g=g2, grad_g=grad_g2!,\n    evaluation=InplaceEvaluation(),\n    smoothing=LinearQuadraticHuber(),\n    debug=[:Iteration, :Cost, :Stop, \" | \", :Change, 50, \"\\n\"],\n); Initial f(x): 0.005748 | \n# 50    f(x): -0.123845 | Last Change: 0.009211\n# 100   f(x): -0.123843 | Last Change: 0.000348\nThe value of the variable (œµ) is smaller than or equal to its threshold (1.0e-6).\nThe algorithm performed a step with a change (8.969129273937203e-7) less than 1.0e-6.\n  1.151431 seconds (2.00 M allocations: 526.440 MiB, 2.39% gc time, 88.24% compilation time) For the result we see the same behaviour as for the other smoothing. f(M, v4) -0.12384258526239394 maximum(g(M, v4)) 2.7300637844646115e-8"},{"id":2785,"pagetitle":"Do constrained optimization","title":"Comparing to the unconstrained solver","ref":"/manopt/stable/tutorials/ConstrainedOptimization/#Comparing-to-the-unconstrained-solver","content":" Comparing to the unconstrained solver We can compare this to the  global  optimum on the sphere, which is the unconstrained optimisation problem, where we can just use Quasi Newton. Note that this is much faster, since every iteration of the algorithms above does a quasi-Newton call as well. @time w1 = quasi_Newton(\n    M, f, grad_f!, p0; evaluation=InplaceEvaluation()\n);   0.600164 seconds (669.96 k allocations: 61.457 MiB, 1.77% gc time, 98.42% compilation time) f(M, w1) -0.1402190180976313 But for sure here the constraints here are not fulfilled and we have quite positive entries in  $g(w_1)$ maximum(g(M, w1)) 0.11762276192957026"},{"id":2786,"pagetitle":"Do constrained optimization","title":"Literature","ref":"/manopt/stable/tutorials/ConstrainedOptimization/#Literature","content":" Literature [BH19] R.¬†Bergmann and R.¬†Herzog.  Intrinsic formulation of KKT conditions and constraint qualifications on smooth manifolds .  SIAM¬†Journal¬†on¬†Optimization  29 , 2423‚Äì2444  (2019),  arXiv:1804.06214 . [LB19] C.¬†Liu and N.¬†Boumal.  Simple algorithms for optimization on Riemannian manifolds with constraints .  Applied¬†Mathematics¬†&¬†Optimization  (2019),  arXiv:1091.10000 ."},{"id":2789,"pagetitle":"Count and use a cache","title":"How to count and cache function calls","ref":"/manopt/stable/tutorials/CountAndCache/#How-to-count-and-cache-function-calls","content":" How to count and cache function calls Ronny Bergmann In this tutorial, we want to investigate the caching and counting (statistics) features of  Manopt.jl . We will reuse the optimization tasks from the introductory tutorial  Get started: optimize! ."},{"id":2790,"pagetitle":"Count and use a cache","title":"Introduction","ref":"/manopt/stable/tutorials/CountAndCache/#Introduction","content":" Introduction There are surely many ways to keep track for example of how often the cost function is called, for example with a  functor , as we used in an example in  How to Record Data mutable struct MyCost{I<:Integer}\n    count::I\nend\nMyCost() = MyCost{Int64}(0)\nfunction (c::MyCost)(M, x)\n    c.count += 1\n    # [ .. Actual implementation of the cost here ]\nend This still leaves a bit of work to the user, especially for tracking more than just the number of cost function evaluations. When a function like the objective or gradient is expensive to compute, it may make sense to cache its results. Manopt.jl tries to minimize the number of repeated calls but sometimes they are necessary and harmless when the function is cheap to compute. Caching of expensive function calls can for example be added using  Memoize.jl  by the user. The approach in the solvers of  Manopt.jl  aims to simplify adding both these capabilities on the level of calling a solver."},{"id":2791,"pagetitle":"Count and use a cache","title":"Technical Background","ref":"/manopt/stable/tutorials/CountAndCache/#Technical-Background","content":" Technical Background The two ingredients for a solver in  Manopt.jl  are the  AbstractManoptProblem  and the  AbstractManoptSolverState , where the former consists of the domain, that is the  AsbtractManifold  and  AbstractManifoldObjective . Both recording and debug capabilities are implemented in a decorator pattern to the solver state. They can be easily added using the  record=  and  debug=  in any solver call. This pattern was recently extended, such that also the objective can be decorated. This is how both caching and counting are implemented, as decorators of the  AbstractManifoldObjective  and hence for example changing/extending the behaviour of a call to  get_cost . Let‚Äôs finish off the technical background by loading the necessary packages. Besides  Manopt.jl  and  Manifolds.jl  we also need  LRUCaches.jl  which are (since Julia 1.9) a weak dependency and provide the  least recently used  strategy for our caches. using Manopt, Manifolds, Random, LRUCache, LinearAlgebra, ManifoldDiff\nusing ManifoldDiff: grad_distance"},{"id":2792,"pagetitle":"Count and use a cache","title":"Counting","ref":"/manopt/stable/tutorials/CountAndCache/#Counting","content":" Counting We first define our task, the Riemannian Center of Mass from the  Get started: optimize!  tutorial. n = 100\nœÉ = œÄ / 8\nM = Sphere(2)\np = 1 / sqrt(2) * [1.0, 0.0, 1.0]\nRandom.seed!(42)\ndata = [exp(M, p,  œÉ * rand(M; vector_at=p)) for i in 1:n];\nf(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)\ngrad_f(M, p) = sum(1 / n * grad_distance.(Ref(M), data, Ref(p))); to now count how often the cost and the gradient are called, we use the  count=  keyword argument that works in any solver to specify the elements of the objective whose calls we want to count calls to. A full list is available in the documentation of the  AbstractManifoldObjective . To also see the result, we have to set  return_objective=true . This returns  (objective, p)  instead of just the solver result  p . We can further also set  return_state=true  to get even more information about the solver run. gradient_descent(M, f, grad_f, data[1]; count=[:Cost, :Gradient], return_objective=true, return_state=true) # Solver state for `Manopt.jl`s Gradient Descent\nAfter 66 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 200:  not reached\n    |grad f| < 1.0e-8: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Statistics on function calls\n  * :Gradient : 199\n  * :Cost     : 275 And we see that statistics are shown in the end."},{"id":2793,"pagetitle":"Count and use a cache","title":"Caching","ref":"/manopt/stable/tutorials/CountAndCache/#Caching","content":" Caching To now also cache these calls, we can use the  cache=  keyword argument. Since now both the cache and the count ‚Äúextend‚Äù the functionality of the objective, the order is important: on the high-level interface, the  count  is treated first, which means that only actual function calls and not cache look-ups are counted. With the proper initialisation, you can use any caches here that support the  get!(function, cache, key)!  update. All parts of the objective that can currently be cached are listed at  ManifoldCachedObjective . The solver call has a keyword  cache  that takes a tuple (c, vs, n)  of three arguments, where  c  is a symbol for the type of cache,  vs  is a vector of symbols, which calls to cache and  n  is the size of the cache. If the last element is not provided, a suitable default (currently n=10 ) is used. Here we want to use  c=:LRU  caches for  vs=[Cost, :Gradient]  with a size of  n=25 . r = gradient_descent(M, f, grad_f, data[1];\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 25),\n    return_objective=true, return_state=true) # Solver state for `Manopt.jl`s Gradient Descent\nAfter 66 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 200:  not reached\n    |grad f| < 1.0e-8: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Cache\n  * :Cost     : 25/25 entries of type Float64 used\n  * :Gradient : 25/25 entries of type Vector{Float64} used\n\n## Statistics on function calls\n  * :Gradient : 66\n  * :Cost     : 149 Since the default setup with  ArmijoLinesearch  needs the gradient and the cost, and similarly the stopping criterion might (independently) evaluate the gradient, the caching is quite helpful here. And of course also for this advanced return value of the solver, we can still access the result as usual: get_solver_result(r) 3-element Vector{Float64}:\n 0.6868392807355564\n 0.006531599748261925\n 0.7267799809043942"},{"id":2794,"pagetitle":"Count and use a cache","title":"Advanced Caching Examples","ref":"/manopt/stable/tutorials/CountAndCache/#Advanced-Caching-Examples","content":" Advanced Caching Examples There are more options other than caching single calls to specific parts of the objective. For example you may want to cache intermediate results of computing the cost and share that with the gradient computation. We will present three solutions to this: An easy approach from within  Manopt.jl : the  ManifoldCostGradientObjective A shared storage approach using a functor A shared (internal) cache approach also using a functor For that we switch to another example: The Rayleigh quotient. We aim to maximize the Rayleigh quotient  $\\displaystyle\\frac{x^{\\mathrm{T}}Ax}{x^{\\mathrm{T}}x}$ , for some  $A‚àà‚Ñù^{m+1\\times m+1}$  and  $x‚àà‚Ñù^{m+1}$  but since we consider this on the sphere and  Manopt.jl  (as many other optimization toolboxes) minimizes, we consider \\[g(p) = -p^{\\mathrm{T}}Ap,\\qquad p‚àà\\mathbb S^{m}\\] The Euclidean gradient (that is in  $  R^{m+1} $ ) is actually just  $\\nabla g(p) = -2Ap$ , the Riemannian gradient the projection of  $\\nabla g(p)$  onto the tangent space  $T_p\\mathbb S^{m}$ . m = 25\nRandom.seed!(42)\nA = randn(m + 1, m + 1)\nA = Symmetric(A)\np_star = eigvecs(A)[:, end] # minimizer (or similarly -p)\nf_star = -eigvals(A)[end] # cost (note that we get - the largest Eigenvalue)\n\nN = Sphere(m);\n\ng(M, p) = -p' * A*p\n‚àág(p) = -2 * A * p\ngrad_g(M,p) = project(M, p, ‚àág(p))\ngrad_g!(M,X, p) = project!(M, X, p, ‚àág(p)) grad_g! (generic function with 1 method) But since both the cost and the gradient require the computation of the matrix-vector product  $Ap$ , it might be beneficial to only compute this once."},{"id":2795,"pagetitle":"Count and use a cache","title":"The  ManifoldCostGradientObjective  approach","ref":"/manopt/stable/tutorials/CountAndCache/#The-[ManifoldCostGradientObjective](@ref)-approach","content":" The  ManifoldCostGradientObjective  approach The  ManifoldCostGradientObjective  uses a combined function to compute both the gradient and the cost at the same time. We define the in-place variant as function g_grad_g!(M::AbstractManifold, X, p)\n    X .= -A*p\n    c = p'*X\n    X .*= 2\n    project!(M, X, p, X)\n    return (c, X)\nend g_grad_g! (generic function with 1 method) where we only compute the matrix-vector product once. The small disadvantage might be, that we always compute  both , the gradient and the cost. Luckily, the cache we used before, takes this into account and caches both results, such that we indeed end up computing  A*p  only once when asking to a cost and a gradient. Let‚Äôs compare both methods p0 = [(1/5 .* ones(5))..., zeros(m-4)...];\n@time s1 = gradient_descent(N, g, grad_g!, p0;\n    stopping_criterion =¬†StopWhenGradientNormLess(1e-5),\n    evaluation=InplaceEvaluation(),\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 25),\n    return_objective=true,\n)   0.901452 seconds (1.05 M allocations: 71.294 MiB, 0.92% gc time, 99.46% compilation time)\n\n## Cache\n  * :Cost     : 25/25 entries of type Float64 used\n  * :Gradient : 25/25 entries of type Vector{Float64} used\n\n## Statistics on function calls\n  * :Gradient : 602\n  * :Cost     : 1449\n\nTo access the solver result, call `get_solver_result` on this variable. versus obj = ManifoldCostGradientObjective(g_grad_g!; evaluation=InplaceEvaluation())\n@time s2 = gradient_descent(N, obj, p0;\n    stopping_criterion=StopWhenGradientNormLess(1e-5),\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 25),\n    return_objective=true,\n)   0.739526 seconds (710.86 k allocations: 56.006 MiB, 2.05% gc time, 97.89% compilation time)\n\n## Cache\n  * :Cost     : 25/25 entries of type Float64 used\n  * :Gradient : 25/25 entries of type Vector{Float64} used\n\n## Statistics on function calls\n  * :Gradient : 1448\n  * :Cost     : 1448\n\nTo access the solver result, call `get_solver_result` on this variable. first of all both yield the same result p1 = get_solver_result(s1)\np2 = get_solver_result(s2)\n[distance(N, p1, p2), g(N, p1), g(N, p2), f_star] 4-element Vector{Float64}:\n  0.0\n -7.8032957637779\n -7.8032957637779\n -7.803295763793949 and we can see that the combined number of evaluations is once 2051, once just the number of cost evaluations 1449. Note that the involved additional 847 gradient evaluations are merely a multiplication with 2. On the other hand, the additional caching of the gradient in these cases might be less beneficial. It is beneficial, when the gradient and the cost are very often required together."},{"id":2796,"pagetitle":"Count and use a cache","title":"A shared storage approach using a functor","ref":"/manopt/stable/tutorials/CountAndCache/#A-shared-storage-approach-using-a-functor","content":" A shared storage approach using a functor An alternative to the previous approach is the usage of a functor that introduces a ‚Äúshared storage‚Äù of the result of computing  A*p . We additionally have to store  p  though, since we have to check that we are still evaluating the cost and/or gradient at the same point at which the cached  A*p  was computed. We again consider the (more efficient) in-place variant. This can be done as follows struct StorageG{T,M}\n    A::M\n    Ap::T\n    p::T\nend\nfunction (g::StorageG)(::Val{:Cost}, M::AbstractManifold, p)\n    if !(p==g.p) #We are at a new point -> Update\n        g.Ap .= g.A*p\n        g.p .= p\n    end\n    return -g.p'*g.Ap\nend\nfunction (g::StorageG)(::Val{:Gradient}, M::AbstractManifold, X, p)\n    if !(p==g.p) #We are at a new point -> Update\n        g.Ap .= g.A*p\n        g.p .= p\n    end\n    X .= -2 .* g.Ap\n    project!(M, X, p, X)\n    return X\nend Here we use the first parameter to distinguish both functions. For the mutating case the signatures are different regardless of the additional argument but for the allocating case, the signatures of the cost and the gradient function are the same. #Define the new functor\nstorage_g = StorageG(A, zero(p0), zero(p0))\n# and cost and gradient that use this functor as\ng3(M,p) = storage_g(Val(:Cost), M, p)\ngrad_g3!(M, X, p) = storage_g(Val(:Gradient), M, X, p)\n@time s3 = gradient_descent(N, g3, grad_g3!, p0;\n    stopping_criterion =¬†StopWhenGradientNormLess(1e-5),\n    evaluation=InplaceEvaluation(),\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 2),\n    return_objective=true#, return_state=true\n)   0.426491 seconds (301.58 k allocations: 21.769 MiB, 98.94% compilation time)\n\n## Cache\n  * :Cost     : 2/2 entries of type Float64 used\n  * :Gradient : 2/2 entries of type Vector{Float64} used\n\n## Statistics on function calls\n  * :Gradient : 602\n  * :Cost     : 1449\n\nTo access the solver result, call `get_solver_result` on this variable. This of course still yields the same result p3 = get_solver_result(s3)\ng(N, p3) - f_star 1.6049384043981263e-11 And while we again have a split off the cost and gradient evaluations, we can observe that the allocations are less than half of the previous approach."},{"id":2797,"pagetitle":"Count and use a cache","title":"A local cache approach","ref":"/manopt/stable/tutorials/CountAndCache/#A-local-cache-approach","content":" A local cache approach This variant is very similar to the previous one, but uses a whole cache instead of just one place to store  A*p . This makes the code a bit nicer, and it is possible to store more than just the last  p  either cost or gradient was called with. struct CacheG{C,M}\n    A::M\n    cache::C\nend\nfunction (g::CacheG)(::Val{:Cost}, M, p)\n    Ap = get!(g.cache, copy(M,p)) do\n        g.A*p\n    end\n    return -p'*Ap\nend\nfunction (g::CacheG)(::Val{:Gradient}, M, X, p)\n    Ap = get!(g.cache, copy(M,p)) do\n        g.A*p\n    end\n    X .= -2 .* Ap\n    project!(M, X, p, X)\n    return X\nend However, the resulting solver run is not always faster, since the whole cache instead of storing just  Ap  and  p  is a bit more costly. Then the tradeoff is, whether this pays off. #Define the new functor\ncache_g = CacheG(A, LRU{typeof(p0),typeof(p0)}(; maxsize=25))\n# and cost and gradient that use this functor as\ng4(M,p) = cache_g(Val(:Cost), M, p)\ngrad_g4!(M, X, p) = cache_g(Val(:Gradient), M, X, p)\n@time s4 = gradient_descent(N, g4, grad_g4!, p0;\n    stopping_criterion =¬†StopWhenGradientNormLess(1e-5),\n    evaluation=InplaceEvaluation(),\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 25),\n    return_objective=true,\n)   0.343276 seconds (302.50 k allocations: 22.214 MiB, 98.27% compilation time)\n\n## Cache\n  * :Cost     : 25/25 entries of type Float64 used\n  * :Gradient : 25/25 entries of type Vector{Float64} used\n\n## Statistics on function calls\n  * :Gradient : 602\n  * :Cost     : 1449\n\nTo access the solver result, call `get_solver_result` on this variable. and for safety let‚Äôs check that we are reasonably close p4 = get_solver_result(s4)\ng(N, p4) - f_star 1.6049384043981263e-11 For this example, or maybe even  gradient_descent  in general it seems, this additional (second, inner) cache does not improve the result further, it is about the same effort both time and allocation-wise."},{"id":2798,"pagetitle":"Count and use a cache","title":"Summary","ref":"/manopt/stable/tutorials/CountAndCache/#Summary","content":" Summary While the second approach of  ManifoldCostGradientObjective  is very easy to implement, both the storage and the (local) cache approach are more efficient. All three are an improvement over the first implementation without sharing interim results. The results with storage or cache have further advantage of being more flexible, since the stored information could also be reused in a third function, for example when also computing the Hessian."},{"id":2801,"pagetitle":"Define objectives in the embedding","title":"How to define the cost in the embedding","ref":"/manopt/stable/tutorials/EmbeddingObjectives/#How-to-define-the-cost-in-the-embedding","content":" How to define the cost in the embedding Ronny Bergmann Specifying a cost function  $f: \\mathcal M ‚Üí ‚Ñù$  on a manifold is usually the model one starts with. Specifying its gradient  $\\operatorname{grad} f: \\mathcal M ‚Üí T\\mathcal M$ , or more precisely  $\\operatorname{grad}f(p) ‚àà T_p\\mathcal M$ , and eventually a Hessian  $\\operatorname{Hess} f: T_p\\mathcal M ‚Üí T_p\\mathcal M$  are then necessary to perform optimization. Since these might be challenging to compute, especially when manifolds and differential geometry are not the main area of a user,¬†easier to use methods might be welcome. This tutorial discusses how to specify  $f$  in the embedding as  $\\tilde f$ , maybe only locally around the manifold, and use the Euclidean gradient  $‚àá \\tilde f$  and Hessian  $‚àá^2 \\tilde f$  within  Manopt.jl . For the theoretical background see  convert an Euclidean to an Riemannian Gradient , or Section 4.7 of [ Bou23 ] for the gradient part or Section 5.11 as well as [ Ngu23 ] for the background on converting Hessians. Here we use the Examples 9.40 and 9.49 of [ Bou23 ] and compare the different methods, one can call the solver, depending on which gradient and/or Hessian one provides. using Manifolds, Manopt, ManifoldDiff\nusing LinearAlgebra, Random, Colors, Plots\nRandom.seed!(123) We consider the cost function on the  Grassmann  manifold given by n = 5\nk = 2\nM = Grassmann(5,2)\nA = Symmetric(rand(n,n)); f(M, p) = 1 / 2 * tr(p' * A * p) Note that this implementation is already also a valid implementation / continuation of  $f$  into the (lifted) embedding of the Grassmann manifold. In the implementation we can use  f  for both the Euclidean  $\\tilde f$  and the Grassmann case  $f$ . Its Euclidean gradient  $\\nabla f$  and Hessian  $\\nabla^2f$  are easy to compute as ‚àáf(M, p) = A * p\n‚àá¬≤f(M,p,X) = A*X On the other hand, from the aforementioned Example 9.49 we can also state the Riemannian gradient and Hessian for comparison as grad_f(M, p) = A * p - p * (p' * A * p)\nHess_f(M, p, X) = A * X - p * p' * A * X - X * p' * A * p We can verify that these are the correct at least numerically by calling the  check_gradient check_gradient(M, f, grad_f; plot=true) and the  check_Hessian , which requires a bit more tolerance in its linearity check check_Hessian(M, f, grad_f, Hess_f; plot=true, throw_error=true, atol=1e-15) While they look reasonable here and were already derived, for the general case this derivation might be more complicated. Luckily there exist two functions in  ManifoldDiff.jl  that are implemented for several manifolds from  Manifolds.jl , namely  riemannian_gradient (M, p, eG)  that converts a Riemannian gradient  eG= $\\nabla \\tilde f(p)$  into a the Riemannian one  $\\operatorname{grad} f(p)$  and  riemannian_Hessian (M, p, eG, eH, X)  which converts the Euclidean Hessian  eH= $\\nabla^2 \\tilde f(p)[X]$  into  $\\operatorname{Hess} f(p)[X]$ , where we also require the Euclidean gradient  eG= $\\nabla \\tilde f(p)$ . So we can define grad2_f(M, p) = riemannian_gradient(M, p, ‚àáf(get_embedding(M), embed(M, p))) where only formally we here call  embed(M,p)  before passing  p  to the Euclidean gradient, though here (for the Grassmann manifold with Stiefel representation) the embedding function is the identity. Similarly for the Hessian, where in our example the embeddings of both the points and tangent vectors are the identity. function Hess2_f(M, p, X)\n    return riemannian_Hessian(\n        M,\n        p,\n        ‚àáf(get_embedding(M), embed(M, p)),\n        ‚àá¬≤f(get_embedding(M), embed(M, p), embed(M, p, X)),\n        X\n    )\nend And we can again verify these numerically, check_gradient(M, f, grad2_f; plot=true) and check_Hessian(M, f, grad2_f, Hess2_f; plot=true, throw_error=true, atol=1e-14) which yields the same result, but we see that the Euclidean conversion might be a bit less stable. Now if we want to use these in optimization we would require these two functions to call e.g. p0 = [1.0 0.0; 0.0 1.0; 0.0 0.0; 0.0 0.0; 0.0 0.0]\nr1 = adaptive_regularization_with_cubics(\n    M,\n    f,\n    grad_f,\n    Hess_f,\n    p0;\n    debug=[:Iteration, :Cost, \"\\n\"],\n    return_objective=true,\n    return_state=true,\n)\nq1 = get_solver_result(r1)\nr1 Initial f(x): 0.666814\n# 1     f(x): 0.333500\n# 2     f(x): -0.233216\n# 3     f(x): -0.440390\n# 4     f(x): -0.607973\n# 5     f(x): -0.608796\n# 6     f(x): -0.608797\n# 7     f(x): -0.608797\n\n# Solver state for `Manopt.jl`s Adaptive Regularization with Cubics (ARC)\nAfter 7 iterations\n\n## Parameters\n* Œ∑1 | Œ∑2              : 0.1 | 0.9\n* Œ≥1 | Œ≥2              : 0.1 | 2.0\n* œÉ (œÉmin)             : 0.0004082482904638632 (1.0e-10)\n* œÅ (œÅ_regularization) : 0.999799931549384 (1000.0)\n* retraction method    : PolarRetraction()\n* sub solver state     :\n    | # Solver state for `Manopt.jl`s Lanczos Iteration\n    | After 6 iterations\n    | \n    | ## Parameters\n    | * œÉ                         : 0.0040824829046386315\n    | * # of Lanczos vectors used : 6\n    | \n    | ## Stopping criteria\n    | (a) For the Lanczos Iteration\n    | Stop When _one_ of the following are fulfilled:\n    |     Max Iteration 6:  reached\n    |     First order progress with Œ∏=0.5:  not reached\n    | Overall: reached\n    | (b) For the Newton sub solver\n    | Max Iteration 200:    not reached\n    | This indicates convergence: No\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 40:   not reached\n    |grad f| < 1.0e-9: reached\n    All Lanczos vectors (5) used:   not reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Debug\n    :Iteration = [ (:Iteration, \"# %-6d\"), (:Cost, \"f(x): %f\"), \"\\n\" ] but if you choose to go for the conversions, then, thinking of the embedding and defining two new functions might be tedious. There is a shortcut for these, which performs the change internally, when necessary by specifying  objective_type=:Euclidean . r2 = adaptive_regularization_with_cubics(\n    M,\n    f,\n    ‚àáf,\n    ‚àá¬≤f,\n    p0;\n    # The one line different to specify our grad/Hess are Eucldiean:\n    objective_type=:Euclidean,\n    debug=[:Iteration, :Cost, \"\\n\"],\n    return_objective=true,\n    return_state=true,\n)\nq2 = get_solver_result(r2)\nr2 Initial f(x): 0.666814\n# 1     f(x): 0.333500\n# 2     f(x): -0.233216\n# 3     f(x): -0.440390\n# 4     f(x): -0.607973\n# 5     f(x): -0.608796\n# 6     f(x): -0.608797\n# 7     f(x): -0.608797\n\n# Solver state for `Manopt.jl`s Adaptive Regularization with Cubics (ARC)\nAfter 7 iterations\n\n## Parameters\n* Œ∑1 | Œ∑2              : 0.1 | 0.9\n* Œ≥1 | Œ≥2              : 0.1 | 2.0\n* œÉ (œÉmin)             : 0.0004082482904638632 (1.0e-10)\n* œÅ (œÅ_regularization) : 0.9988100306237745 (1000.0)\n* retraction method    : PolarRetraction()\n* sub solver state     :\n    | # Solver state for `Manopt.jl`s Lanczos Iteration\n    | After 6 iterations\n    | \n    | ## Parameters\n    | * œÉ                         : 0.0040824829046386315\n    | * # of Lanczos vectors used : 6\n    | \n    | ## Stopping criteria\n    | (a) For the Lanczos Iteration\n    | Stop When _one_ of the following are fulfilled:\n    |     Max Iteration 6:  reached\n    |     First order progress with Œ∏=0.5:  not reached\n    | Overall: reached\n    | (b) For the Newton sub solver\n    | Max Iteration 200:    not reached\n    | This indicates convergence: No\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 40:   not reached\n    |grad f| < 1.0e-9: reached\n    All Lanczos vectors (5) used:   not reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Debug\n    :Iteration = [ (:Iteration, \"# %-6d\"), (:Cost, \"f(x): %f\"), \"\\n\" ] which returns the same result, see distance(M, q1, q2) 4.0221650305342743e-16 This conversion also works for the gradients of constraints, and is passed down to subsolvers by default when these are created using the Euclidean objective  $f$ ,  $\\nabla f$  and  $\\nabla^2 f$ ."},{"id":2802,"pagetitle":"Define objectives in the embedding","title":"Summary","ref":"/manopt/stable/tutorials/EmbeddingObjectives/#Summary","content":" Summary If you have the Euclidean gradient (or Hessian) available for a solver call, all you need to provide is  objective_type=:Euclidean  to convert the objective to a Riemannian one."},{"id":2803,"pagetitle":"Define objectives in the embedding","title":"Literature","ref":"/manopt/stable/tutorials/EmbeddingObjectives/#Literature","content":" Literature [Bou23] N.¬†Boumal.  An Introduction to Optimization on Smooth Manifolds . First¬†Edition ( Cambridge University Press, 2023 ). [Ngu23] D.¬†Nguyen.  Operator-Valued Formulas for Riemannian Gradient and Hessian and Families of Tractable Metrics in Riemannian Optimization .  Journal¬†of¬†Optimization¬†Theory¬†and¬†Applications  198 , 135‚Äì164  (2023),  arXiv:2009.10159 ."},{"id":2804,"pagetitle":"Define objectives in the embedding","title":"Technical details","ref":"/manopt/stable/tutorials/EmbeddingObjectives/#Technical-details","content":" Technical details This notebook was rendered with the following environment Pkg.status() Status `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [6e4b80f9] BenchmarkTools v1.5.0\n  [5ae59095] Colors v0.12.10\n  [31c24e10] Distributions v0.25.107\n  [26cc04aa] FiniteDifferences v0.12.31\n  [7073ff75] IJulia v1.24.2\n  [8ac3fa9e] LRUCache v1.6.1\n  [af67fdf4] ManifoldDiff v0.3.10\n  [1cead3c2] Manifolds v0.9.14\n  [3362f125] ManifoldsBase v0.15.8\n  [0fc0a36d] Manopt v0.4.58 `~/work/Manopt.jl/Manopt.jl`\n  [91a5bcdd] Plots v1.40.2"},{"id":2807,"pagetitle":"Do geodesic regression","title":"How to perform Geodesic Regression","ref":"/manopt/stable/tutorials/GeodesicRegression/#How-to-perform-Geodesic-Regression","content":" How to perform Geodesic Regression Ronny Bergmann Geodesic regression generalizes  linear regression  to Riemannian manifolds. Let‚Äôs first phrase it informally as follows: For given data points  $d_1,\\ldots,d_n$  on a Riemannian manifold  $\\mathcal M$ , find the geodesic that ‚Äúbest explains‚Äù the data. The meaning of ‚Äúbest explain‚Äù has still to be clarified. We distinguish two cases: time labelled data and unlabelled data     using Manopt, ManifoldDiff, Manifolds, Random, Colors\n    using LinearAlgebra: svd\n    Random.seed!(42); We use the following data, where we want to highlight one of the points. n = 7\nœÉ = œÄ / 8\nS = Sphere(2)\nbase = 1 / sqrt(2) * [1.0, 0.0, 1.0]\ndir = [-0.75, 0.5, 0.75]\ndata_orig = [exp(S, base, dir, t) for t in range(-0.5, 0.5; length=n)]\n# add noise to the points on the geodesic\ndata = map(p -> exp(S, p, rand(S; vector_at=p, œÉ=œÉ)), data_orig)\nhighlighted = 4;"},{"id":2808,"pagetitle":"Do geodesic regression","title":"Time Labeled Data","ref":"/manopt/stable/tutorials/GeodesicRegression/#Time-Labeled-Data","content":" Time Labeled Data If for each data item  $d_i$  we are also given a time point  $t_i\\in\\mathbb R$ , which are pairwise different, then we can use the least squares error to state the objective function as [ Fle13 ] \\[F(p,X) = \\frac{1}{2}\\sum_{i=1}^n d_{\\mathcal M}^2(Œ≥_{p,X}(t_i), d_i),\\] where  $d_{\\mathcal M}$  is the Riemannian distance and  $Œ≥_{p,X}$  is the geodesic with  $Œ≥(0) = p$  and  $\\dot\\gamma(0) = X$ . For the real-valued case  $\\mathcal M = \\mathbb R^m$  the solution  $(p^*, X^*)$  is given in closed form as follows: with  $d^* = \\frac{1}{n}\\displaystyle\\sum_{i=1}^{n}d_i$  and  $t^* = \\frac{1}{n}\\displaystyle\\sum_{i=1}^n t_i$  we get \\[ X^* = \\frac{\\sum_{i=1}^n (d_i-d^*)(t-t^*)}{\\sum_{i=1}^n (t_i-t^*)^2}\n\\quad\\text{ and }\\quad\np^* = d^* - t^*X^*\\] and hence the linear regression result is the line  $Œ≥_{p^*,X^*}(t) = p^* + tX^*$ . On a Riemannian manifold we can phrase this as an optimization problem on the  tangent bundle , which is the disjoint union of all tangent spaces, as \\[\\operatorname*{arg\\,min}_{(p,X) \\in \\mathrm{T}\\mathcal M} F(p,X)\\] Due to linearity, the gradient of  $F(p,X)$  is the sum of the single gradients of \\[ \\frac{1}{2}d_{\\mathcal M}^2\\bigl(Œ≥_{p,X}(t_i),d_i\\bigr)\n = \\frac{1}{2}d_{\\mathcal M}^2\\bigl(\\exp_p(t_iX),d_i\\bigr)\n ,\\quad i‚àà\\{1,\\ldots,n\\}\\] which can be computed using a chain rule of the squared distance and the exponential map, see for example [ BG18 ] for details or Equations (7) and (8) of [ Fle13 ]: M = TangentBundle(S)\nstruct RegressionCost{T,S}\n    data::T\n    times::S\nend\nRegressionCost(data::T, times::S) where {T,S} = RegressionCost{T,S}(data, times)\nfunction (a::RegressionCost)(M, x)\n    pts = [geodesic(M.manifold, x[M, :point], x[M, :vector], ti) for ti in a.times]\n    return 1 / 2 * sum(distance.(Ref(M.manifold), pts, a.data) .^ 2)\nend\nstruct RegressionGradient!{T,S}\n    data::T\n    times::S\nend\nfunction RegressionGradient!(data::T, times::S) where {T,S}\n    return RegressionGradient!{T,S}(data, times)\nend\nfunction (a::RegressionGradient!)(M, Y, x)\n    pts = [geodesic(M.manifold, x[M, :point], x[M, :vector], ti) for ti in a.times]\n    gradients = grad_distance.(Ref(M.manifold), a.data, pts)\n    Y[M, :point] .= sum(\n        ManifoldDiff.adjoint_differential_exp_basepoint.(\n            Ref(M.manifold),\n            Ref(x[M, :point]),\n            [ti * x[M, :vector] for ti in a.times],\n            gradients,\n        ),\n    )\n    Y[M, :vector] .= sum(\n        ManifoldDiff.adjoint_differential_exp_argument.(\n            Ref(M.manifold),\n            Ref(x[M, :point]),\n            [ti * x[M, :vector] for ti in a.times],\n            gradients,\n        ),\n    )\n    return Y\nend For the Euclidean case, the result is given by the first principal component of a principal component analysis, see  PCR  which is given by  $p^* = \\frac{1}{n}\\displaystyle\\sum_{i=1}^n d_i$  and the direction  $X^*$  is obtained by defining the zero mean data matrix \\[D = \\bigl(d_1-p^*, \\ldots, d_n-p^*\\bigr) \\in \\mathbb R^{m,n}\\] and taking  $X^*$  as an eigenvector to the largest eigenvalue of  $D^{\\mathrm{T}}D$ . We can do something similar, when considering the tangent space at the (Riemannian) mean of the data and then do a PCA on the coordinate coefficients with respect to a basis. m = mean(S, data)\nA = hcat(\n    map(x -> get_coordinates(S, m, log(S, m, x), DefaultOrthonormalBasis()), data)...\n)\npca1 = get_vector(S, m, svd(A).U[:, 1], DefaultOrthonormalBasis())\nx0 = ArrayPartition(m, pca1) ([0.6998621681746481, -0.013681674945026638, 0.7141468737791822], [0.5931302057517893, -0.5459465115717783, -0.5917254139611094]) The optimal ‚Äútime labels‚Äù are then just the projections  $t_i = ‚ü®d_i,X^*‚ü©$ ,  $i=1,\\ldots,n$ . t = map(d -> inner(S, m, pca1, log(S, m, d)), data) 7-element Vector{Float64}:\n  1.0763904949888323\n  0.4594060193318443\n -0.5030195874833682\n  0.02135686940521725\n -0.6158692507563633\n -0.24431652575028764\n -0.2259012492666664 And we can call the gradient descent. Note that since  gradF!  works in place of  Y , we have to set the  evalutation  type accordingly. y = gradient_descent(\n    M,\n    RegressionCost(data, t),\n    RegressionGradient!(data, t),\n    x0;\n    evaluation=InplaceEvaluation(),\n    stepsize=ArmijoLinesearch(\n        M;\n        initial_stepsize=1.0,\n        contraction_factor=0.990,\n        sufficient_decrease=0.05,\n        stop_when_stepsize_less=1e-9,\n    ),\n    stopping_criterion=StopAfterIteration(200) |\n                        StopWhenGradientNormLess(1e-8) |\n                        StopWhenStepsizeLess(1e-9),\n    debug=[:Iteration, \" | \", :Cost, \"\\n\", :Stop, 50],\n) Initial  | f(x): 0.142862\n# 50     | f(x): 0.141113\n# 100    | f(x): 0.141113\n# 150    | f(x): 0.141113\n# 200    | f(x): 0.141113\nThe algorithm reached its maximal number of iterations (200).\n\n([0.7119768725361988, 0.009463059143003981, 0.7021391482357537], [0.590008151835008, -0.5543272518659472, -0.5908038715512287]) For the result, we can generate and plot all involved geodesics dense_t = range(-0.5, 0.5; length=100)\ngeo = geodesic(S, y[M, :point], y[M, :vector], dense_t)\ninit_geo = geodesic(S, x0[M, :point], x0[M, :vector], dense_t)\ngeo_pts = geodesic(S, y[M, :point], y[M, :vector], t)\ngeo_conn_highlighted = shortest_geodesic(\n    S, data[highlighted], geo_pts[highlighted], 0.5 .+ dense_t\n); In this image, together with the blue data points, you see the geodesic of the initialization in black (evaluated on  $[-\\frac{1}{2},\\frac{1}{2}]$ ), the final point on the tangent bundle in orange, as well as the resulting regression geodesic in teal, (on the same interval as the start) as well as small teal points indicating the time points on the geodesic corresponding to the data. Additionally, a thin blue line indicates the geodesic between a data point and its corresponding data point on the geodesic. While this would be the closest point in Euclidean space and hence the two directions (along the geodesic vs.¬†to the data point) orthogonal, here we have inner(\n    S,\n    geo_pts[highlighted],\n    log(S, geo_pts[highlighted], geo_pts[highlighted + 1]),\n    log(S, geo_pts[highlighted], data[highlighted]),\n) 0.002487393068917863 But we also started with one of the best scenarios of equally spaced points on a geodesic obstructed by noise. This gets worse if you start with less evenly distributed data data2 = [exp(S, base, dir, t) for t in [-0.5, -0.49, -0.48, 0.1, 0.48, 0.49, 0.5]]\ndata2 = map(p -> exp(S, p, rand(S; vector_at=p, œÉ=œÉ / 2)), data2)\nm2 = mean(S, data2)\nA2 = hcat(\n    map(x -> get_coordinates(S, m, log(S, m, x), DefaultOrthonormalBasis()), data2)...\n)\npca2 = get_vector(S, m, svd(A2).U[:, 1], DefaultOrthonormalBasis())\nx1 = ArrayPartition(m, pca2)\nt2 = map(d -> inner(S, m2, pca2, log(S, m2, d)), data2) 7-element Vector{Float64}:\n  0.8226008307680276\n  0.470952643700004\n  0.7974195537403082\n  0.01533949241264346\n -0.6546705405852389\n -0.8913273825362389\n -0.5775954445730889 then we run again y2 = gradient_descent(\n    M,\n    RegressionCost(data2, t2),\n    RegressionGradient!(data2, t2),\n    x1;\n    evaluation=InplaceEvaluation(),\n    stepsize=ArmijoLinesearch(\n        M;\n        initial_stepsize=1.0,\n        contraction_factor=0.990,\n        sufficient_decrease=0.05,\n        stop_when_stepsize_less=1e-9,\n    ),\n    stopping_criterion=StopAfterIteration(200) |\n                        StopWhenGradientNormLess(1e-8) |\n                        StopWhenStepsizeLess(1e-9),\n    debug=[:Iteration, \" | \", :Cost, \"\\n\", :Stop, 3],\n); Initial  | f(x): 0.089844\n# 3      | f(x): 0.085364\n# 6      | f(x): 0.085364\n# 9      | f(x): 0.085364\n# 12     | f(x): 0.085364\n# 15     | f(x): 0.085364\n# 18     | f(x): 0.085364\n# 21     | f(x): 0.085364\n# 24     | f(x): 0.085364\n# 27     | f(x): 0.085364\n# 30     | f(x): 0.085364\n# 33     | f(x): 0.085364\n# 36     | f(x): 0.085364\n# 39     | f(x): 0.085364\n# 42     | f(x): 0.085364\n# 45     | f(x): 0.085364\n# 48     | f(x): 0.085364\n# 51     | f(x): 0.085364\n# 54     | f(x): 0.085364\n# 57     | f(x): 0.085364\n# 60     | f(x): 0.085364\n# 63     | f(x): 0.085364\n# 66     | f(x): 0.085364\n# 69     | f(x): 0.085364\n# 72     | f(x): 0.085364\n# 75     | f(x): 0.085364\n# 78     | f(x): 0.085364\n# 81     | f(x): 0.085364\n# 84     | f(x): 0.085364\n# 87     | f(x): 0.085364\n# 90     | f(x): 0.085364\n# 93     | f(x): 0.085364\n# 96     | f(x): 0.085364\n# 99     | f(x): 0.085364\n# 102    | f(x): 0.085364\n# 105    | f(x): 0.085364\n# 108    | f(x): 0.085364\n# 111    | f(x): 0.085364\n# 114    | f(x): 0.085364\n# 117    | f(x): 0.085364\n# 120    | f(x): 0.085364\n# 123    | f(x): 0.085364\n# 126    | f(x): 0.085364\n# 129    | f(x): 0.085364\n# 132    | f(x): 0.085364\n# 135    | f(x): 0.085364\n# 138    | f(x): 0.085364\n# 141    | f(x): 0.085364\n# 144    | f(x): 0.085364\n# 147    | f(x): 0.085364\n# 150    | f(x): 0.085364\n# 153    | f(x): 0.085364\n# 156    | f(x): 0.085364\n# 159    | f(x): 0.085364\n# 162    | f(x): 0.085364\n# 165    | f(x): 0.085364\n# 168    | f(x): 0.085364\n# 171    | f(x): 0.085364\n# 174    | f(x): 0.085364\n# 177    | f(x): 0.085364\n# 180    | f(x): 0.085364\n# 183    | f(x): 0.085364\n# 186    | f(x): 0.085364\n# 189    | f(x): 0.085364\n# 192    | f(x): 0.085364\n# 195    | f(x): 0.085364\n# 198    | f(x): 0.085364\nThe algorithm reached its maximal number of iterations (200). For plotting we again generate all data geo2 = geodesic(S, y2[M, :point], y2[M, :vector], dense_t)\ninit_geo2 = geodesic(S, x1[M, :point], x1[M, :vector], dense_t)\ngeo_pts2 = geodesic(S, y2[M, :point], y2[M, :vector], t2)\ngeo_conn_highlighted2 = shortest_geodesic(\n    S, data2[highlighted], geo_pts2[highlighted], 0.5 .+ dense_t\n);"},{"id":2809,"pagetitle":"Do geodesic regression","title":"Unlabeled Data","ref":"/manopt/stable/tutorials/GeodesicRegression/#Unlabeled-Data","content":" Unlabeled Data If we are not given time points  $t_i$ , then the optimization problem extends, informally speaking, to also finding the ‚Äúbest fitting‚Äù (in the sense of smallest error). To formalize, the objective function here reads \\[F(p, X, t) = \\frac{1}{2}\\sum_{i=1}^n d_{\\mathcal M}^2(Œ≥_{p,X}(t_i), d_i),\\] where  $t = (t_1,\\ldots,t_n) \\in \\mathbb R^n$  is now an additional parameter of the objective function. We write  $F_1(p, X)$  to refer to the function on the tangent bundle for fixed values of  $t$  (as the one in the last part) and  $F_2(t)$  for the function  $F(p, X, t)$  as a function in  $t$  with fixed values  $(p, X)$ . For the Euclidean case, there is no necessity to optimize with respect to  $t$ , as we saw above for the initialization of the fixed time points. On a Riemannian manifold this can be stated as a problem on the product manifold  $\\mathcal N = \\mathrm{T}\\mathcal M \\times \\mathbb R^n$ , i.e. N = M √ó Euclidean(length(t2)) ProductManifold with 2 submanifolds:\n TangentBundle(Sphere(2, ‚Ñù))\n Euclidean(7; field=‚Ñù) \\[  \\operatorname*{arg\\,min}_{\\bigl((p,X),t\\bigr)\\in\\mathcal N} F(p, X, t).\\] In this tutorial we present an approach to solve this using an alternating gradient descent scheme. To be precise, we define the cost function now on the product manifold struct RegressionCost2{T}\n    data::T\nend\nRegressionCost2(data::T) where {T} = RegressionCost2{T}(data)\nfunction (a::RegressionCost2)(N, x)\n    TM = N[1]\n    pts = [\n        geodesic(TM.manifold, x[N, 1][TM, :point], x[N, 1][TM, :vector], ti) for\n        ti in x[N, 2]\n    ]\n    return 1 / 2 * sum(distance.(Ref(TM.manifold), pts, a.data) .^ 2)\nend The gradient in two parts, namely (a) the same gradient as before w.r.t.  $(p,X) ‚àà T\\mathcal M$ , just now with a fixed  t  in mind for the second component of the product manifold  $\\mathcal N$ struct RegressionGradient2a!{T}\n    data::T\nend\nRegressionGradient2a!(data::T) where {T} = RegressionGradient2a!{T}(data)\nfunction (a::RegressionGradient2a!)(N, Y, x)\n    TM = N[1]\n    p = x[N, 1]\n    pts = [geodesic(TM.manifold, p[TM, :point], p[TM, :vector], ti) for ti in x[N, 2]]\n    gradients = Manopt.grad_distance.(Ref(TM.manifold), a.data, pts)\n    Y[TM, :point] .= sum(\n        ManifoldDiff.adjoint_differential_exp_basepoint.(\n            Ref(TM.manifold),\n            Ref(p[TM, :point]),\n            [ti * p[TM, :vector] for ti in x[N, 2]],\n            gradients,\n        ),\n    )\n    Y[TM, :vector] .= sum(\n        ManifoldDiff.adjoint_differential_exp_argument.(\n            Ref(TM.manifold),\n            Ref(p[TM, :point]),\n            [ti * p[TM, :vector] for ti in x[N, 2]],\n            gradients,\n        ),\n    )\n    return Y\nend Finally, we additionally look for a fixed point  $x=(p,X) ‚àà \\mathrm{T}\\mathcal M$  at the gradient with respect to  $t‚àà\\mathbb R^n$ , the second component, which is given by \\[  (\\operatorname{grad}F_2(t))_i\n  = - ‚ü®\\dot Œ≥_{p,X}(t_i), \\log_{Œ≥_{p,X}(t_i)}d_i‚ü©_{Œ≥_{p,X}(t_i)}, i = 1, \\ldots, n.\\] struct RegressionGradient2b!{T}\n    data::T\nend\nRegressionGradient2b!(data::T) where {T} = RegressionGradient2b!{T}(data)\nfunction (a::RegressionGradient2b!)(N, Y, x)\n    TM = N[1]\n    p = x[N, 1]\n    pts = [geodesic(TM.manifold, p[TM, :point], p[TM, :vector], ti) for ti in x[N, 2]]\n    logs = log.(Ref(TM.manifold), pts, a.data)\n    pt = map(\n        d -> vector_transport_to(TM.manifold, p[TM, :point], p[TM, :vector], d), pts\n    )\n    Y .= -inner.(Ref(TM.manifold), pts, logs, pt)\n    return Y\nend We can reuse the computed initial values from before, just that now we are on a product manifold x2 = ArrayPartition(x1, t2)\nF3 = RegressionCost2(data2)\ngradF3_vector = [RegressionGradient2a!(data2), RegressionGradient2b!(data2)]; and we run the algorithm y3 = alternating_gradient_descent(\n    N,\n    F3,\n    gradF3_vector,\n    x2;\n    evaluation=InplaceEvaluation(),\n    debug=[:Iteration, \" | \", :Cost, \"\\n\", :Stop, 50],\n    stepsize=ArmijoLinesearch(\n        M;\n        contraction_factor=0.999,\n        sufficient_decrease=0.066,\n        stop_when_stepsize_less=1e-11,\n        retraction_method=ProductRetraction(SasakiRetraction(2), ExponentialRetraction()),\n    ),\n    inner_iterations=1,\n) Initial  | f(x): 0.089844\n# 50     | f(x): 0.091097\n# 100    | f(x): 0.091097\nThe algorithm reached its maximal number of iterations (100).\n\n(ArrayPartition{Float64, Tuple{Vector{Float64}, Vector{Float64}}}(([0.750222090700214, 0.031464227399200885, 0.6604368380243274], [0.6636489079535082, -0.3497538263293046, -0.737208025444054])), [0.7965909273713889, 0.43402264218923514, 0.755822122896529, 0.001059348203453764, -0.6421135044471217, -0.8635572995105818, -0.5546338813212247]) which we render can collect into an image creating the geodesics again geo3 = geodesic(S, y3[N, 1][M, :point], y3[N, 1][M, :vector], dense_t)\ninit_geo3 = geodesic(S, x1[M, :point], x1[M, :vector], dense_t)\ngeo_pts3 = geodesic(S, y3[N, 1][M, :point], y3[N, 1][M, :vector], y3[N, 2])\nt3 = y3[N, 2]\ngeo_conns = shortest_geodesic.(Ref(S), data2, geo_pts3, Ref(0.5 .+ 4*dense_t)); which yields Note that the geodesics from the data to the regression geodesic meet at a nearly orthogonal angle. Acknowledgement.  Parts of this tutorial are based on the bachelor thesis of  Jeremias Arf ."},{"id":2810,"pagetitle":"Do geodesic regression","title":"Literature","ref":"/manopt/stable/tutorials/GeodesicRegression/#Literature","content":" Literature [BG18] R.¬†Bergmann and P.-Y.¬†Gousenbourger.  A variational model for data fitting on manifolds by minimizing the acceleration of a B√©zier curve .  Frontiers¬†in¬†Applied¬†Mathematics¬†and¬†Statistics  4  (2018),  arXiv:1807.10090 . [Fle13] P.¬†T.¬†Fletcher.  Geodesic regression and the theory of least squares on Riemannian manifolds .  International¬†Journal¬†of¬†Computer¬†Vision  105 , 171‚Äì185  (2013)."},{"id":2813,"pagetitle":"Print debug output","title":"How to print debug output","ref":"/manopt/stable/tutorials/HowToDebug/#How-to-print-debug-output","content":" How to print debug output Ronny Bergmann This tutorial aims to illustrate how to perform debug output. For that we consider an example that includes a subsolver, to also consider their debug capabilities. The problem itself is hence not the main focus. We consider a nonnegative PCA which we can write as a constraint problem on the Sphere Let‚Äôs first load the necessary packages. using Manopt, Manifolds, Random, LinearAlgebra\nRandom.seed!(42); d = 4\nM = Sphere(d - 1)\nv0 = project(M, [ones(2)..., zeros(d - 2)...])\nZ = v0 * v0'\n#Cost and gradient\nf(M, p) = -tr(transpose(p) * Z * p) / 2\ngrad_f(M, p) = project(M, p, -transpose.(Z) * p / 2 - Z * p / 2)\n# Constraints\ng(M, p) = -p # now p ‚â• 0\nmI = -Matrix{Float64}(I, d, d)\n# Vector of gradients of the constraint components\ngrad_g(M, p) = [project(M, p, mI[:, i]) for i in 1:d] Then we can take a starting point p0 = project(M, [ones(2)..., zeros(d - 3)..., 0.1])"},{"id":2814,"pagetitle":"Print debug output","title":"Simple debug output","ref":"/manopt/stable/tutorials/HowToDebug/#Simple-debug-output","content":" Simple debug output Any solver accepts the keyword  debug= , which in the simplest case can be set to an array of strings, symbols and a number. Strings are printed in every iteration as is (cf.¬† DebugDivider ) and should be used to finish the array with a line break. the last number in the array is used with  DebugEvery  to print the debug only every  $i$ th iteration. Any Symbol is converted into certain debug prints Certain symbols starting with a capital letter are mapped to certain prints, for example  :Cost  is mapped to  DebugCost ()  to print the current cost function value. A full list is provided in the  DebugActionFactory . A special keyword is  :Stop , which is only added to the final debug hook to print the stopping criterion. Any symbol with a small letter is mapped to fields of the  AbstractManoptSolverState  which is used. This way you can easily print internal data, if you know their names. Let‚Äôs look at an example first: if we want to print the current iteration number, the current cost function value as well as the value  œµ  from the  ExactPenaltyMethodState . To keep the amount of print at a reasonable level, we want to only print the debug every 25th iteration. Then we can write p1 = exact_penalty_method(\n    M, f, grad_f, p0; g=g, grad_g=grad_g,\n    debug = [:Iteration, :Cost, \" | \", (:œµ,\"œµ: %.8f\"), 25, \"\\n\", :Stop]\n); Initial f(x): -0.497512 | œµ: 0.00100000\n# 25    f(x): -0.499449 | œµ: 0.00017783\n# 50    f(x): -0.499995 | œµ: 0.00003162\n# 75    f(x): -0.500000 | œµ: 0.00000562\n# 100   f(x): -0.500000 | œµ: 0.00000100\nThe value of the variable (œµ) is smaller than or equal to its threshold (1.0e-6).\nThe algorithm performed a step with a change (6.534762378320721e-9) less than 1.0e-6."},{"id":2815,"pagetitle":"Print debug output","title":"Specifying when to print something","ref":"/manopt/stable/tutorials/HowToDebug/#Specifying-when-to-print-something","content":" Specifying when to print something While in the last step, we specified what to print, this can be extend to even specify  when  to print it. Currently the following four ‚Äúplaces‚Äù are available, ordered by when they appear in an algorithm run. :Start  to print something at the start of the algorith. At this place all other (the following) places are ‚Äúreset‚Äù, by triggering each of them with an iteration number  0 :BeforeIteration  to print something before an iteration starts :Iteration  to print something  after  an iteration. For example the group of prints from the last codeblock  [:Iteration, :Cost, \" | \", :œµ, 25,]  is added to this entry. :Stop  to print something when the algorithm stops. In the example above, the  :Stop  adds the  DebugStoppingCriterion  is added to this place. Specifying something especially for one of these places is done by specifying a  Pair , so for example  :BeforeIteration => :Iteration  would add the display of the iteration number to be printed  before  the iteration is performed. Changing this in the above run will not change the output. being more precise for the other entries, we could also write p1 = exact_penalty_method(\n    M, f, grad_f, p0; g=g, grad_g=grad_g,\n    debug = [\n        :BeforeIteration => [:Iteration],\n        :Iteration => [:Cost, \" | \", :œµ, \"\\n\"],\n        :Stop => DebugStoppingCriterion(),\n        25,\n    ],\n); Initial f(x): -0.497512 | œµ: 0.001\n# 25    f(x): -0.499449 | œµ: 0.0001778279410038921\n# 50    f(x): -0.499995 | œµ: 3.1622776601683734e-5\n# 75    f(x): -0.500000 | œµ: 5.623413251903474e-6\n# 100   f(x): -0.500000 | œµ: 1.0e-6\nThe value of the variable (œµ) is smaller than or equal to its threshold (1.0e-6).\nThe algorithm performed a step with a change (6.534762378320721e-9) less than 1.0e-6. This also illustrates, that instead of  Symbol s we can also always pass down a  DebugAction  directly, for example when there is a reason to create or configure the action more individually thatn the default from the symbol. Note that the number ( 25 ) yields that all but  :Start  and  :Stop  are only displayed every 25th iteration."},{"id":2816,"pagetitle":"Print debug output","title":"Subsolver debug","ref":"/manopt/stable/tutorials/HowToDebug/#Subsolver-debug","content":" Subsolver debug Subsolvers have a  sub_kwargs  keyword, such that you can pass keywords to the sub solver as well. This works well if you do not plan to change the subsolver. If you do you can wrap your own  solver_state=  argument in a  decorate_state!  and pass a  debug=  password to this function call. Keywords in a keyword have to be passed as pairs ( :debug => [...] ). For most debugs, there further exists a longer form to specify the format to print. We want to ise this to specify the format to print  œµ . This is done by putting the corresponding symbol together with the string to use in formatting into a tuple like  (:œµ,\" | œµ: %.8f\") , where we can already include the divider as well. A main problem now is, that this debug is issued every sub solver call or initialisation, as the following print of just a  .  per sub solver test/call illustrates p3 = exact_penalty_method(\n    M, f, grad_f, p0; g=g, grad_g=grad_g,\n    debug = [\"\\n\",:Iteration, DebugCost(), (:œµ,\" | œµ: %.8f\"), 25, \"\\n\", :Stop],\n    sub_kwargs = [:debug => [\".\"]]\n); Initial f(x): -0.497512 | œµ: 0.00100000\n........................................................\n# 25    f(x): -0.499449 | œµ: 0.00017783\n..................................................\n# 50    f(x): -0.499995 | œµ: 0.00003162\n..................................................\n# 75    f(x): -0.500000 | œµ: 0.00000562\n..................................................\n# 100   f(x): -0.500000 | œµ: 0.00000100\n....The value of the variable (œµ) is smaller than or equal to its threshold (1.0e-6).\nThe algorithm performed a step with a change (6.534762378320721e-9) less than 1.0e-6. The different lengths of the dotted lines come from the fact that ‚Äîat least in the beginning‚Äî the subsolver performs a few steps and each subsolvers step prints a dot. For this issue, there is the next symbol (similar to the  :Stop ) to indicate that a debug set is a subsolver set  :Subsolver , which introduces a  DebugWhenActive  that is only activated when the outer debug is actually active, or inother words  DebugEvery  is active itself. Furthermore, we want to print the iteration number  before  printing the subsolvers steps, so we put this into a  Pair , but we can leave the remaining ones as single entries. Finally we also prefix  :Stop  with  \" | \"  and print the iteration number at the time we stop. We get p4 = exact_penalty_method(\n    M,\n    f,\n    grad_f,\n    p0;\n    g=g,\n    grad_g=grad_g,\n    debug=[\n        :BeforeIteration => [:Iteration, \"\\n\"],\n        :Iteration => [DebugCost(), (:œµ, \" | œµ: %.8f\"), \"\\n\"],\n        :Stop,\n        25,\n    ],\n    sub_kwargs=[\n        :debug => [\n            \" | \",\n            :Iteration,\n            :Cost,\n            \"\\n\",\n            :Subsolver,\n            :Stop => [(:Stop, \" | \"), \" | stopped after iteration \", :Iteration, \"\\n\"],\n        ],\n    ],\n); Initial \nf(x): -0.497512 | œµ: 0.00100000\n | Initial f(x): -0.498946\n | stopped after iteration Initial \n | # 1     f(x): -0.498969\n | The algorithm reached approximately critical point after 1 iterations; the gradient norm (0.00023391575013034365) is less than 0.001.\n | stopped after iteration # 1     \n# 25    \nf(x): -0.499449 | œµ: 0.00017783\n | Initial f(x): -0.499992\n | stopped after iteration Initial \n | # 1     f(x): -0.499992\n | The algorithm reached approximately critical point after 1 iterations; the gradient norm (1.7846628030624615e-5) is less than 0.001.\n | stopped after iteration # 1     \n# 50    \nf(x): -0.499995 | œµ: 0.00003162\n | Initial f(x): -0.500000\n | stopped after iteration Initial \n | # 1     f(x): -0.500000\n | The algorithm reached approximately critical point after 1 iterations; the gradient norm (1.1167747417418325e-6) is less than 0.001.\n | stopped after iteration # 1     \n# 75    \nf(x): -0.500000 | œµ: 0.00000562\n | Initial f(x): -0.500000\n | stopped after iteration Initial \n | # 1     f(x): -0.500000\n | The algorithm reached approximately critical point after 1 iterations; the gradient norm (6.172823903104852e-8) is less than 0.001.\n | stopped after iteration # 1     \n# 100   \nf(x): -0.500000 | œµ: 0.00000100\nThe value of the variable (œµ) is smaller than or equal to its threshold (1.0e-6).\nThe algorithm performed a step with a change (6.534762378320721e-9) less than 1.0e-6. where we now see that the subsolver always only requires one step. Note that since debug of an iteration is happening  after  a step, we see the sub solver run  before  the debug for an iteration number."},{"id":2817,"pagetitle":"Print debug output","title":"Advanced debug output","ref":"/manopt/stable/tutorials/HowToDebug/#Advanced-debug-output","content":" Advanced debug output There is two more advanced variants that can be used. The first is a tuple of a symbol and a string, where the string is used as the format print, that most  DebugAction s have. The second is, to directly provide a  DebugAction . We can for example change the way the  :œµ  is printed by adding a format string and use  DebugCost ()  which is equivalent to using  :Cost . Especially with the format change, the lines are more consistent in length. p2 = exact_penalty_method(\n    M, f, grad_f, p0; g=g, grad_g=grad_g,\n    debug = [:Iteration, DebugCost(), (:œµ,\" | œµ: %.8f\"), 25, \"\\n\", :Stop]\n); Initial f(x): -0.497512 | œµ: 0.00100000\n# 25    f(x): -0.499449 | œµ: 0.00017783\n# 50    f(x): -0.499995 | œµ: 0.00003162\n# 75    f(x): -0.500000 | œµ: 0.00000562\n# 100   f(x): -0.500000 | œµ: 0.00000100\nThe value of the variable (œµ) is smaller than or equal to its threshold (1.0e-6).\nThe algorithm performed a step with a change (6.534762378320721e-9) less than 1.0e-6. You can also write your own  DebugAction  functor, where the function to implement has the same signature as the  step  function, that is an  AbstractManoptProblem , an  AbstractManoptSolverState , as well as the current iterate. For example the already mentioned DebugDivider (s)  is given as mutable struct DebugDivider{TIO<:IO} <: DebugAction\n    io::TIO\n    divider::String\n    DebugDivider(divider=\" | \"; io::IO=stdout) = new{typeof(io)}(io, divider)\nend\nfunction (d::DebugDivider)(::AbstractManoptProblem, ::AbstractManoptSolverState, i::Int)\n    (i >= 0) && (!isempty(d.divider)) && (print(d.io, d.divider))\n    return nothing\nend or you could implement that of course just for your specific problem or state."},{"id":2820,"pagetitle":"Record values","title":"How to record data during the iterations","ref":"/manopt/stable/tutorials/HowToRecord/#How-to-record-data-during-the-iterations","content":" How to record data during the iterations Ronny Bergmann The recording and debugging features make it possible to record nearly any data during the iterations. This tutorial illustrates how to: record one value during the iterations; record multiple values during the iterations and access them afterwards; define an own  RecordAction  to perform individual recordings. Several predefined recordings exist, for example  RecordCost  or  RecordGradient , if the problem the solver uses provides a gradient. For fields of the  State  the recording can also be done  RecordEntry . For other recordings, for example more advanced computations before storing a value, an own  RecordAction  can be defined. We illustrate these using the gradient descent from the  Get started: optimize!  tutorial. Here the focus is put on ways to investigate the behaviour during iterations by using Recording techniques. Let‚Äôs first load the necessary packages. using Manopt, Manifolds, Random, ManifoldDiff\nusing ManifoldDiff: grad_distance\nRandom.seed!(42);"},{"id":2821,"pagetitle":"Record values","title":"The Objective","ref":"/manopt/stable/tutorials/HowToRecord/#The-Objective","content":" The Objective We generate data and define our cost and gradient: Random.seed!(42)\nm = 30\nM = Sphere(m)\nn = 800\nœÉ = œÄ / 8\nx = zeros(Float64, m + 1)\nx[2] = 1.0\ndata = [exp(M, x, œÉ * rand(M; vector_at=x)) for i in 1:n]\nf(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)\ngrad_f(M, p) = sum(1 / n * grad_distance.(Ref(M), data, Ref(p))) grad_f (generic function with 1 method)"},{"id":2822,"pagetitle":"Record values","title":"Plain Examples","ref":"/manopt/stable/tutorials/HowToRecord/#Plain-Examples","content":" Plain Examples For the high level interfaces of the solvers, like  gradient_descent  we have to set  return_state  to  true  to obtain the whole  solver state  and not only the resulting minimizer. Then we can easily use the  record=  option to add recorded values. This keyword accepts  RecordAction s as well as several symbols as shortcuts, for example  :Cost  to record the cost, or if your options have a field  f ,  :f  would record that entry. An overview of the symbols that can be used is given  here . We first just record the cost after every iteration R = gradient_descent(M, f, grad_f, data[1]; record=:Cost, return_state=true) # Solver state for `Manopt.jl`s Gradient Descent\nAfter 60 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 200:  not reached\n    |grad f| < 1.0e-8: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Record\n(Iteration = RecordCost(),) From the returned state, we see that the  GradientDescentState  are encapsulated (decorated) within a  RecordSolverState . For such a state, one can attach different recorders to some operations, currently to  :Start .  :Stop , and  :Iteration , where  :Iteration  is the default when using the  record=  keyword with a  RecordAction  as above. We can access all values recorded during the iterations by calling  get_record(R, :Iteation)  or since this is the default even shorter get_record(R) 60-element Vector{Float64}:\n 0.6868754085841272\n 0.6240211444102516\n 0.5900374782569905\n 0.5691425134106757\n 0.5512819383843195\n 0.542136810022984\n 0.5374585627386623\n 0.5350045365259574\n 0.5337243124406585\n 0.5330491236590466\n 0.5326944302021914\n 0.5325071127227716\n 0.5324084047176342\n ‚ãÆ\n 0.5322977905736846\n 0.5322977905736771\n 0.5322977905736733\n 0.5322977905736712\n 0.5322977905736699\n 0.5322977905736691\n 0.5322977905736687\n 0.5322977905736684\n 0.5322977905736683\n 0.5322977905736682\n 0.5322977905736681\n 0.5322977905736681 To record more than one value, you can pass an array of a mix of symbols and  RecordAction s which formally introduces  RecordGroup . Such a group records a tuple of values in every iteration: R2 = gradient_descent(M, f, grad_f, data[1]; record=[:Iteration, :Cost], return_state=true) # Solver state for `Manopt.jl`s Gradient Descent\nAfter 60 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 200:  not reached\n    |grad f| < 1.0e-8: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Record\n(Iteration = RecordGroup([RecordIteration(), RecordCost()]),) Here, the symbol  :Cost  is mapped to using the  RecordCost  action. The same holds for  :Iteration  obviously records the current iteration number  i . To access these you can first extract the group of records (that is where the  :Iteration s are recorded; note the plural) and then access the  :Cost  ‚Äú‚Äú‚Äù get_record_action(R2, :Iteration) RecordGroup([RecordIteration(), RecordCost()]) Since  iteration  is the default, we can also omit it here again. To access single recorded values, one can use get_record_action(R2)[:Cost] 60-element Vector{Float64}:\n 0.6868754085841272\n 0.6240211444102516\n 0.5900374782569905\n 0.5691425134106757\n 0.5512819383843195\n 0.542136810022984\n 0.5374585627386623\n 0.5350045365259574\n 0.5337243124406585\n 0.5330491236590466\n 0.5326944302021914\n 0.5325071127227716\n 0.5324084047176342\n ‚ãÆ\n 0.5322977905736846\n 0.5322977905736771\n 0.5322977905736733\n 0.5322977905736712\n 0.5322977905736699\n 0.5322977905736691\n 0.5322977905736687\n 0.5322977905736684\n 0.5322977905736683\n 0.5322977905736682\n 0.5322977905736681\n 0.5322977905736681 This can be also done by using a the high level interface  get_record get_record(R2, :Iteration, :Cost) 60-element Vector{Float64}:\n 0.6868754085841272\n 0.6240211444102516\n 0.5900374782569905\n 0.5691425134106757\n 0.5512819383843195\n 0.542136810022984\n 0.5374585627386623\n 0.5350045365259574\n 0.5337243124406585\n 0.5330491236590466\n 0.5326944302021914\n 0.5325071127227716\n 0.5324084047176342\n ‚ãÆ\n 0.5322977905736846\n 0.5322977905736771\n 0.5322977905736733\n 0.5322977905736712\n 0.5322977905736699\n 0.5322977905736691\n 0.5322977905736687\n 0.5322977905736684\n 0.5322977905736683\n 0.5322977905736682\n 0.5322977905736681\n 0.5322977905736681 Note that the first symbol again refers to the point where we record (not to the thing we record). We can also pass a tuple as second argument to have our own order within the tuples returned. Switching the order of recorded cost and Iteration can be done using ‚Äú‚Äú‚Äù get_record(R2, :Iteration, (:Iteration, :Cost)) 60-element Vector{Tuple{Int64, Float64}}:\n (1, 0.6868754085841272)\n (2, 0.6240211444102516)\n (3, 0.5900374782569905)\n (4, 0.5691425134106757)\n (5, 0.5512819383843195)\n (6, 0.542136810022984)\n (7, 0.5374585627386623)\n (8, 0.5350045365259574)\n (9, 0.5337243124406585)\n (10, 0.5330491236590466)\n (11, 0.5326944302021914)\n (12, 0.5325071127227716)\n (13, 0.5324084047176342)\n ‚ãÆ\n (49, 0.5322977905736846)\n (50, 0.5322977905736771)\n (51, 0.5322977905736733)\n (52, 0.5322977905736712)\n (53, 0.5322977905736699)\n (54, 0.5322977905736691)\n (55, 0.5322977905736687)\n (56, 0.5322977905736684)\n (57, 0.5322977905736683)\n (58, 0.5322977905736682)\n (59, 0.5322977905736681)\n (60, 0.5322977905736681)"},{"id":2823,"pagetitle":"Record values","title":"A more complex example","ref":"/manopt/stable/tutorials/HowToRecord/#A-more-complex-example","content":" A more complex example To illustrate a complicated example let‚Äôs record: the iteration number, cost and gradient field, but only every sixth iteration; the iteration at which we stop. We first generate the problem and the state, to also illustrate the low-level works when not using the high-level interface  gradient_descent . p = DefaultManoptProblem(M, ManifoldGradientObjective(f, grad_f))\ns = GradientDescentState(\n    M,\n    copy(data[1]);\n    stopping_criterion=StopAfterIteration(200) | StopWhenGradientNormLess(10.0^-9),\n) # Solver state for `Manopt.jl`s Gradient Descent\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 200:  not reached\n    |grad f| < 1.0e-9: not reached\nOverall: not reached\nThis indicates convergence: No We now first build a  RecordGroup  to group the three entries we want to record per iteration. We then put this into a  RecordEvery  to only record this every sixth iteration rI = RecordEvery(\n    RecordGroup([\n        :Iteration => RecordIteration(),\n        :Cost => RecordCost(),\n        :Gradient => RecordEntry(similar(data[1]), :X),\n    ]),\n    6,\n) RecordEvery(RecordGroup([RecordIteration(), RecordCost(), RecordEntry(:X)]), 6, true) and for recording the final iteration number sI = RecordIteration() RecordIteration() We now combine both into the  RecordSolverState  decorator. It acts completely the same as any  AbstractManoptSolverState  but records something in every iteration additionally. This is stored in a dictionary of  RecordAction s, where  :Iteration  is the action (here the only every sixth iteration group) and the  sI  which is executed at stop. Note that the keyword  record=  in the high level interface  gradient_descent  only would fill the  :Iteration  symbol of said dictionary. r = RecordSolverState(s, Dict(:Iteration => rI, :Stop => sI)) # Solver state for `Manopt.jl`s Gradient Descent\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 200:  not reached\n    |grad f| < 1.0e-9: not reached\nOverall: not reached\nThis indicates convergence: No\n\n## Record\n(Iteration = RecordEvery(RecordGroup([RecordIteration(), RecordCost(), RecordEntry(:X)]), 6, true), Stop = RecordIteration()) We now call the solver res = solve!(p, r) # Solver state for `Manopt.jl`s Gradient Descent\nAfter 65 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 200:  not reached\n    |grad f| < 1.0e-9: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Record\n(Iteration = RecordEvery(RecordGroup([RecordIteration(), RecordCost(), RecordEntry(:X)]), 6, true), Stop = RecordIteration()) And we can check the recorded value at  :Stop  to see how many iterations were performed get_record(res, :Stop) 1-element Vector{Int64}:\n 65 and the other values during the iterations are get_record(res, :Iteration, (:Iteration, :Cost)) 10-element Vector{Tuple{Int64, Float64}}:\n (6, 0.542136810022984)\n (12, 0.5325071127227716)\n (18, 0.5323023757104093)\n (24, 0.5322978928223224)\n (30, 0.5322977928970517)\n (36, 0.5322977906274986)\n (42, 0.5322977905749401)\n (48, 0.5322977905736989)\n (54, 0.5322977905736691)\n (60, 0.5322977905736681)"},{"id":2824,"pagetitle":"Record values","title":"Writing an own  RecordAction s","ref":"/manopt/stable/tutorials/HowToRecord/#Writing-an-own-[RecordAction](https://manoptjl.org/stable/plans/record/#Manopt.RecordAction)s","content":" Writing an own  RecordAction s Let‚Äôs investigate where we want to count the number of function evaluations, again just to illustrate, since for the gradient this is just one evaluation per iteration. We first define a cost, that counts its own calls. ‚Äú‚Äú‚Äù mutable struct MyCost{T}\n    data::T\n    count::Int\nend\nMyCost(data::T) where {T} = MyCost{T}(data, 0)\nfunction (c::MyCost)(M, x)\n    c.count += 1\n    return sum(1 / (2 * length(c.data)) * distance.(Ref(M), Ref(x), c.data) .^ 2)\nend and we define an own, new  RecordAction , which is a functor, that is a struct that is also a function. The function we have to implement is similar to a single solver step in signature, since it might get called every iteration: mutable struct RecordCount <: RecordAction\n    recorded_values::Vector{Int}\n    RecordCount() = new(Vector{Int}())\nend\nfunction (r::RecordCount)(p::AbstractManoptProblem, ::AbstractManoptSolverState, i)\n    if i > 0\n        push!(r.recorded_values, Manopt.get_cost_function(get_objective(p)).count)\n    elseif i < 0 # reset if negative\n        r.recorded_values = Vector{Int}()\n    end\nend Now we can initialize the new cost and call the gradient descent. Note that this illustrates also the last use case since you can pass symbol-action pairs into the  record= array. f2 = MyCost(data) MyCost{Vector{Vector{Float64}}}([[-0.054658825167894595, -0.5592077846510423, -0.04738273828111257, -0.04682080720921302, 0.12279468849667038, 0.07171438895366239, -0.12930045409417057, -0.22102081626380404, -0.31805333254577767, 0.0065859500152017645  ‚Ä¶  -0.21999168261518043, 0.19570142227077295, 0.340909965798364, -0.0310802190082894, -0.04674431076254687, -0.006088297671169996, 0.01576037011323387, -0.14523596850249543, 0.14526158060820338, 0.1972125856685378], [-0.08192376929745249, -0.5097715132187676, -0.008339904915541005, 0.07289741328038676, 0.11422036270613797, -0.11546739299835748, 0.2296996932628472, 0.1490467170835958, -0.11124820565850364, -0.11790721606521781  ‚Ä¶  -0.16421249630470344, -0.2450575844467715, -0.07570080850379841, -0.07426218324072491, -0.026520181327346338, 0.11555341205250205, -0.0292955762365121, -0.09012096853677576, -0.23470556634911574, -0.026214242996704013], [-0.22951484264859257, -0.6083825348640186, 0.14273766477054015, -0.11947823367023377, 0.05984293499234536, 0.058820835498203126, 0.07577331705863266, 0.1632847202946857, 0.20244385489915745, 0.04389826920203656  ‚Ä¶  0.3222365119325929, 0.009728730325524067, -0.12094785371632395, -0.36322323926212824, -0.0689253407939657, 0.23356953371702974, 0.23489531397909744, 0.078303336494718, -0.14272984135578806, 0.07844539956202407], [-0.0012588500237817606, -0.29958740415089763, 0.036738459489123514, 0.20567651907595125, -0.1131046432541904, -0.06032435985370224, 0.3366633723165895, -0.1694687746143405, -0.001987171245125281, 0.04933779858684409  ‚Ä¶  -0.2399584473006256, 0.19889267065775063, 0.22468755918787048, 0.1780090580180643, 0.023703860700539356, -0.10212737517121755, 0.03807004103115319, -0.20569120952458983, -0.03257704254233959, 0.06925473452536687], [-0.035534309946938375, -0.06645560787329002, 0.14823972268208874, -0.23913346587232426, 0.038347027875883496, 0.10453333143286662, 0.050933995140290705, -0.12319549375687473, 0.12956684644537844, -0.23540367869989412  ‚Ä¶  -0.41471772859912864, -0.1418984610380257, 0.0038321446836859334, 0.23655566917750157, -0.17500681300994742, -0.039189751036839374, -0.08687860620942896, -0.11509948162959047, 0.11378233994840942, 0.38739450723013735], [-0.3122539912469438, -0.3101935557860296, 0.1733113629107006, 0.08968593616209351, -0.1836344261367962, -0.06480023695256802, 0.18165070013886545, 0.19618275767992124, -0.07956460275570058, 0.0325997354656551  ‚Ä¶  0.2845492418767769, 0.17406455870721682, -0.053101230371568706, -0.1382082812981627, 0.005830071475508364, 0.16739264037923055, 0.034365814374995335, 0.09107702398753297, -0.1877250428700409, 0.05116494897806923], [-0.04159442361185588, -0.7768029783272633, 0.06303616666722486, 0.08070518925253539, -0.07396265237309446, -0.06008109299719321, 0.07977141629715745, 0.019511027129056415, 0.08629917589924847, -0.11156298867318722  ‚Ä¶  0.0792587504128044, -0.016444383900170008, -0.181746064577005, -0.01888129512990984, -0.13523922089388968, 0.11358102175659832, 0.07929049608459493, 0.1689565359083833, 0.07673657951723721, -0.1128480905648813], [-0.21221814304651335, -0.5031823821503253, 0.010326342133992458, -0.12438192100961257, 0.04004758695231872, 0.2280527500843805, -0.2096243232022162, -0.16564828762420294, -0.28325749481138984, 0.17033534605245823  ‚Ä¶  -0.13599096505924074, 0.28437770540525625, 0.08424426798544583, -0.1266207606984139, 0.04917635557603396, -0.00012608938533809706, -0.04283220254770056, -0.08771365647566572, 0.14750169103093985, 0.11601120086036351], [0.10683290707435536, -0.17680836277740156, 0.23767458301899405, 0.12011180867097299, -0.029404774462600154, 0.11522028383799933, -0.3318174480974519, -0.17859266746938374, 0.04352373642537759, 0.2530382802667988  ‚Ä¶  0.08879861736692073, -0.004412506987801729, 0.19786810509925895, -0.1397104682727044, 0.09482328498485094, 0.05108149065160893, -0.14578343506951633, 0.3167479772660438, 0.10422673169182732, 0.21573150015891313], [-0.024895624707466164, -0.7473912016432697, -0.1392537238944721, -0.14948896791465557, -0.09765393283580377, 0.04413059403279867, -0.13865379004720355, -0.071032040283992, 0.15604054722246585, -0.10744260463413555  ‚Ä¶  -0.14748067081342833, -0.14743635071251024, 0.0643591937981352, 0.16138827697852615, -0.12656652133603935, -0.06463635704869083, 0.14329582429103488, -0.01113113793821713, 0.29295387893749997, 0.06774523575259782]  ‚Ä¶  [0.011874845316569967, -0.6910596618389588, 0.21275741439477827, -0.014042545524367437, -0.07883613103495014, -0.0021900966696246776, -0.033836430464220496, 0.2925813113264835, -0.04718187201980008, 0.03949680289730036  ‚Ä¶  0.0867736586603294, 0.0404682510051544, -0.24779813848587257, -0.28631514602877145, -0.07211767532456789, -0.15072898498180473, 0.017855923621826746, -0.09795357710255254, -0.14755229203084924, 0.1305005778855436], [0.013457629515450426, -0.3750353654626534, 0.12349883726772073, 0.3521803555005319, 0.2475921439420274, 0.006088649842999206, 0.31203183112392907, -0.036869203979483754, -0.07475746464056504, -0.029297797064479717  ‚Ä¶  0.16867368684091563, -0.09450564983271922, -0.0587273302122711, -0.1326667940553803, -0.25530237980444614, 0.37556905374043376, 0.04922612067677609, 0.2605362549983866, -0.21871556587505667, -0.22915883767386164], [0.03295085436260177, -0.971861604433394, 0.034748713521512035, -0.0494065013245799, -0.01767479281403355, 0.0465459739459587, 0.007470494722096038, 0.003227960072276129, 0.0058328596338402365, -0.037591237446692356  ‚Ä¶  0.03205152122876297, 0.11331109854742015, 0.03044900529526686, 0.017971704993311105, -0.009329252062960229, -0.02939354719650879, 0.022088835776251863, -0.02546111553658854, -0.0026257225461427582, 0.005702111697172774], [0.06968243992532257, -0.7119502191435176, -0.18136614593117445, -0.1695926215673451, 0.01725015359973796, -0.00694164951158388, -0.34621134287344574, 0.024709256792651912, -0.1632255805999673, -0.2158226433583082  ‚Ä¶  -0.14153772108081458, -0.11256850346909901, 0.045109821764180706, -0.1162754336222613, -0.13221711766357983, 0.005365354776191061, 0.012750671705879105, -0.018208207549835407, 0.12458753932455452, -0.31843587960340897], [-0.19830349374441875, -0.6086693423968884, 0.08552341811170468, 0.35781519334042255, 0.15790663648524367, 0.02712571268324985, 0.09855601327331667, -0.05840653973421127, -0.09546429767790429, -0.13414717696055448  ‚Ä¶  -0.0430935804718714, 0.2678584478951765, 0.08780994289014614, 0.01613469379498457, 0.0516187906322884, -0.07383067566731401, -0.1481272738354552, -0.010532317187265649, 0.06555344745952187, -0.1506167863762911], [-0.04347524125197773, -0.6327981074196994, -0.221116680035191, 0.0282207467940456, -0.0855024881522933, 0.12821801740178346, 0.1779499563280024, -0.10247384887512365, 0.0396432464100116, -0.0582580338112627  ‚Ä¶  0.1253893207083573, 0.09628202269764763, 0.3165295473947355, -0.14915034201394833, -0.1376727867817772, -0.004153096613530293, 0.09277957650773738, 0.05917264554031624, -0.12230262590034507, -0.19655728521529914], [-0.10173946348675116, -0.6475660153977272, 0.1260284619729566, -0.11933160462857616, -0.04774310633937567, 0.09093928358804217, 0.041662676324043114, -0.1264739543938265, 0.09605293126911392, -0.16790474428001648  ‚Ä¶  -0.04056684573478108, 0.09351665120940456, 0.15259195558799882, 0.0009949298312580497, 0.09461980828206303, 0.3067004514287283, 0.16129258773733715, -0.18893664085007542, -0.1806865244492513, 0.029319680436405825], [-0.251780954320053, -0.39147463259941456, -0.24359579328578626, 0.30179309757665723, 0.21658893985206484, 0.12304585275893232, 0.28281133086451704, 0.029187615341955325, 0.03616243507191924, 0.029375588909979152  ‚Ä¶  -0.08071746662465404, -0.2176101928258658, 0.20944684921170825, 0.043033273425352715, -0.040505542460853576, 0.17935596149079197, -0.08454569418519972, 0.0545941597033932, 0.12471741052450099, -0.24314124407858329], [0.28156471341150974, -0.6708572780452595, -0.1410302363738465, -0.08322589397277698, -0.022772599832907418, -0.04447265789199677, -0.016448068022011157, -0.07490911512503738, 0.2778432295769144, -0.10191899088372378  ‚Ä¶  -0.057272155080983836, 0.12817478092201395, 0.04623814480781884, -0.12184190164369117, 0.1987855635987229, -0.14533603246124993, -0.16334072868597016, -0.052369977381939437, 0.014904286931394959, -0.2440882678882144], [0.12108727495744157, -0.714787344982596, 0.01632521838262752, 0.04437570556908449, -0.041199280304144284, 0.052984488452616, 0.03796520200156107, 0.2791785910964288, 0.11530429924056099, 0.12178223160398421  ‚Ä¶  -0.07621847481721669, 0.18353870423743013, -0.19066653731436745, -0.09423224997242206, 0.14596847781388494, -0.09747986927777111, 0.16041150122587072, -0.02296513951256738, 0.06786878373578588, 0.15296635978447756]], 0) Now for the plain gradient descent, we have to modify the step (to a constant stepsize) and remove the default check whether the cost increases (setting  debug  to  [] ). We also only look at the first 20 iterations to keep this example small in recorded values. We call R3 = gradient_descent(\n    M,\n    f2,\n    grad_f,\n    data[1];\n    record=[:Iteration, :Count => RecordCount(), :Cost],\n    stepsize = ConstantStepsize(1.0),\n    stopping_criterion=StopAfterIteration(20),\n    debug=[],\n    return_state=true,\n) # Solver state for `Manopt.jl`s Gradient Descent\nAfter 20 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nConstantStepsize(1.0, relative)\n\n## Stopping criterion\n\nMax Iteration 20:   reached\nThis indicates convergence: No\n\n## Record\n(Iteration = RecordGroup([RecordIteration(), RecordCount([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]), RecordCost()]),) For  :Cost  we already learned how to access them, the  :Count =>  introduces the following action to obtain the  :Count . We can again access the whole sets of records get_record(R3) 20-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 0, 0.5808287253777765)\n (2, 1, 0.5395268557323746)\n (3, 2, 0.5333529073733115)\n (4, 3, 0.5324514620174543)\n (5, 4, 0.5323201743667151)\n (6, 5, 0.5323010518577256)\n (7, 6, 0.5322982658416161)\n (8, 7, 0.532297859847447)\n (9, 8, 0.5322978006725337)\n (10, 9, 0.5322977920461375)\n (11, 10, 0.5322977907883957)\n (12, 11, 0.5322977906049865)\n (13, 12, 0.5322977905782369)\n (14, 13, 0.532297790574335)\n (15, 14, 0.5322977905737657)\n (16, 15, 0.5322977905736823)\n (17, 16, 0.5322977905736703)\n (18, 17, 0.5322977905736688)\n (19, 18, 0.5322977905736683)\n (20, 19, 0.5322977905736683) this is equivalent to calling  R[:Iteration] . Note that since we introduced  :Count  we can also access a single recorded value using R3[:Iteration, :Count] 20-element Vector{Int64}:\n  0\n  1\n  2\n  3\n  4\n  5\n  6\n  7\n  8\n  9\n 10\n 11\n 12\n 13\n 14\n 15\n 16\n 17\n 18\n 19 and we see that the cost function is called once per iteration. If we use this counting cost and run the default gradient descent with Armijo line search, we can infer how many Armijo line search backtracks are preformed: f3 = MyCost(data) MyCost{Vector{Vector{Float64}}}([[-0.054658825167894595, -0.5592077846510423, -0.04738273828111257, -0.04682080720921302, 0.12279468849667038, 0.07171438895366239, -0.12930045409417057, -0.22102081626380404, -0.31805333254577767, 0.0065859500152017645  ‚Ä¶  -0.21999168261518043, 0.19570142227077295, 0.340909965798364, -0.0310802190082894, -0.04674431076254687, -0.006088297671169996, 0.01576037011323387, -0.14523596850249543, 0.14526158060820338, 0.1972125856685378], [-0.08192376929745249, -0.5097715132187676, -0.008339904915541005, 0.07289741328038676, 0.11422036270613797, -0.11546739299835748, 0.2296996932628472, 0.1490467170835958, -0.11124820565850364, -0.11790721606521781  ‚Ä¶  -0.16421249630470344, -0.2450575844467715, -0.07570080850379841, -0.07426218324072491, -0.026520181327346338, 0.11555341205250205, -0.0292955762365121, -0.09012096853677576, -0.23470556634911574, -0.026214242996704013], [-0.22951484264859257, -0.6083825348640186, 0.14273766477054015, -0.11947823367023377, 0.05984293499234536, 0.058820835498203126, 0.07577331705863266, 0.1632847202946857, 0.20244385489915745, 0.04389826920203656  ‚Ä¶  0.3222365119325929, 0.009728730325524067, -0.12094785371632395, -0.36322323926212824, -0.0689253407939657, 0.23356953371702974, 0.23489531397909744, 0.078303336494718, -0.14272984135578806, 0.07844539956202407], [-0.0012588500237817606, -0.29958740415089763, 0.036738459489123514, 0.20567651907595125, -0.1131046432541904, -0.06032435985370224, 0.3366633723165895, -0.1694687746143405, -0.001987171245125281, 0.04933779858684409  ‚Ä¶  -0.2399584473006256, 0.19889267065775063, 0.22468755918787048, 0.1780090580180643, 0.023703860700539356, -0.10212737517121755, 0.03807004103115319, -0.20569120952458983, -0.03257704254233959, 0.06925473452536687], [-0.035534309946938375, -0.06645560787329002, 0.14823972268208874, -0.23913346587232426, 0.038347027875883496, 0.10453333143286662, 0.050933995140290705, -0.12319549375687473, 0.12956684644537844, -0.23540367869989412  ‚Ä¶  -0.41471772859912864, -0.1418984610380257, 0.0038321446836859334, 0.23655566917750157, -0.17500681300994742, -0.039189751036839374, -0.08687860620942896, -0.11509948162959047, 0.11378233994840942, 0.38739450723013735], [-0.3122539912469438, -0.3101935557860296, 0.1733113629107006, 0.08968593616209351, -0.1836344261367962, -0.06480023695256802, 0.18165070013886545, 0.19618275767992124, -0.07956460275570058, 0.0325997354656551  ‚Ä¶  0.2845492418767769, 0.17406455870721682, -0.053101230371568706, -0.1382082812981627, 0.005830071475508364, 0.16739264037923055, 0.034365814374995335, 0.09107702398753297, -0.1877250428700409, 0.05116494897806923], [-0.04159442361185588, -0.7768029783272633, 0.06303616666722486, 0.08070518925253539, -0.07396265237309446, -0.06008109299719321, 0.07977141629715745, 0.019511027129056415, 0.08629917589924847, -0.11156298867318722  ‚Ä¶  0.0792587504128044, -0.016444383900170008, -0.181746064577005, -0.01888129512990984, -0.13523922089388968, 0.11358102175659832, 0.07929049608459493, 0.1689565359083833, 0.07673657951723721, -0.1128480905648813], [-0.21221814304651335, -0.5031823821503253, 0.010326342133992458, -0.12438192100961257, 0.04004758695231872, 0.2280527500843805, -0.2096243232022162, -0.16564828762420294, -0.28325749481138984, 0.17033534605245823  ‚Ä¶  -0.13599096505924074, 0.28437770540525625, 0.08424426798544583, -0.1266207606984139, 0.04917635557603396, -0.00012608938533809706, -0.04283220254770056, -0.08771365647566572, 0.14750169103093985, 0.11601120086036351], [0.10683290707435536, -0.17680836277740156, 0.23767458301899405, 0.12011180867097299, -0.029404774462600154, 0.11522028383799933, -0.3318174480974519, -0.17859266746938374, 0.04352373642537759, 0.2530382802667988  ‚Ä¶  0.08879861736692073, -0.004412506987801729, 0.19786810509925895, -0.1397104682727044, 0.09482328498485094, 0.05108149065160893, -0.14578343506951633, 0.3167479772660438, 0.10422673169182732, 0.21573150015891313], [-0.024895624707466164, -0.7473912016432697, -0.1392537238944721, -0.14948896791465557, -0.09765393283580377, 0.04413059403279867, -0.13865379004720355, -0.071032040283992, 0.15604054722246585, -0.10744260463413555  ‚Ä¶  -0.14748067081342833, -0.14743635071251024, 0.0643591937981352, 0.16138827697852615, -0.12656652133603935, -0.06463635704869083, 0.14329582429103488, -0.01113113793821713, 0.29295387893749997, 0.06774523575259782]  ‚Ä¶  [0.011874845316569967, -0.6910596618389588, 0.21275741439477827, -0.014042545524367437, -0.07883613103495014, -0.0021900966696246776, -0.033836430464220496, 0.2925813113264835, -0.04718187201980008, 0.03949680289730036  ‚Ä¶  0.0867736586603294, 0.0404682510051544, -0.24779813848587257, -0.28631514602877145, -0.07211767532456789, -0.15072898498180473, 0.017855923621826746, -0.09795357710255254, -0.14755229203084924, 0.1305005778855436], [0.013457629515450426, -0.3750353654626534, 0.12349883726772073, 0.3521803555005319, 0.2475921439420274, 0.006088649842999206, 0.31203183112392907, -0.036869203979483754, -0.07475746464056504, -0.029297797064479717  ‚Ä¶  0.16867368684091563, -0.09450564983271922, -0.0587273302122711, -0.1326667940553803, -0.25530237980444614, 0.37556905374043376, 0.04922612067677609, 0.2605362549983866, -0.21871556587505667, -0.22915883767386164], [0.03295085436260177, -0.971861604433394, 0.034748713521512035, -0.0494065013245799, -0.01767479281403355, 0.0465459739459587, 0.007470494722096038, 0.003227960072276129, 0.0058328596338402365, -0.037591237446692356  ‚Ä¶  0.03205152122876297, 0.11331109854742015, 0.03044900529526686, 0.017971704993311105, -0.009329252062960229, -0.02939354719650879, 0.022088835776251863, -0.02546111553658854, -0.0026257225461427582, 0.005702111697172774], [0.06968243992532257, -0.7119502191435176, -0.18136614593117445, -0.1695926215673451, 0.01725015359973796, -0.00694164951158388, -0.34621134287344574, 0.024709256792651912, -0.1632255805999673, -0.2158226433583082  ‚Ä¶  -0.14153772108081458, -0.11256850346909901, 0.045109821764180706, -0.1162754336222613, -0.13221711766357983, 0.005365354776191061, 0.012750671705879105, -0.018208207549835407, 0.12458753932455452, -0.31843587960340897], [-0.19830349374441875, -0.6086693423968884, 0.08552341811170468, 0.35781519334042255, 0.15790663648524367, 0.02712571268324985, 0.09855601327331667, -0.05840653973421127, -0.09546429767790429, -0.13414717696055448  ‚Ä¶  -0.0430935804718714, 0.2678584478951765, 0.08780994289014614, 0.01613469379498457, 0.0516187906322884, -0.07383067566731401, -0.1481272738354552, -0.010532317187265649, 0.06555344745952187, -0.1506167863762911], [-0.04347524125197773, -0.6327981074196994, -0.221116680035191, 0.0282207467940456, -0.0855024881522933, 0.12821801740178346, 0.1779499563280024, -0.10247384887512365, 0.0396432464100116, -0.0582580338112627  ‚Ä¶  0.1253893207083573, 0.09628202269764763, 0.3165295473947355, -0.14915034201394833, -0.1376727867817772, -0.004153096613530293, 0.09277957650773738, 0.05917264554031624, -0.12230262590034507, -0.19655728521529914], [-0.10173946348675116, -0.6475660153977272, 0.1260284619729566, -0.11933160462857616, -0.04774310633937567, 0.09093928358804217, 0.041662676324043114, -0.1264739543938265, 0.09605293126911392, -0.16790474428001648  ‚Ä¶  -0.04056684573478108, 0.09351665120940456, 0.15259195558799882, 0.0009949298312580497, 0.09461980828206303, 0.3067004514287283, 0.16129258773733715, -0.18893664085007542, -0.1806865244492513, 0.029319680436405825], [-0.251780954320053, -0.39147463259941456, -0.24359579328578626, 0.30179309757665723, 0.21658893985206484, 0.12304585275893232, 0.28281133086451704, 0.029187615341955325, 0.03616243507191924, 0.029375588909979152  ‚Ä¶  -0.08071746662465404, -0.2176101928258658, 0.20944684921170825, 0.043033273425352715, -0.040505542460853576, 0.17935596149079197, -0.08454569418519972, 0.0545941597033932, 0.12471741052450099, -0.24314124407858329], [0.28156471341150974, -0.6708572780452595, -0.1410302363738465, -0.08322589397277698, -0.022772599832907418, -0.04447265789199677, -0.016448068022011157, -0.07490911512503738, 0.2778432295769144, -0.10191899088372378  ‚Ä¶  -0.057272155080983836, 0.12817478092201395, 0.04623814480781884, -0.12184190164369117, 0.1987855635987229, -0.14533603246124993, -0.16334072868597016, -0.052369977381939437, 0.014904286931394959, -0.2440882678882144], [0.12108727495744157, -0.714787344982596, 0.01632521838262752, 0.04437570556908449, -0.041199280304144284, 0.052984488452616, 0.03796520200156107, 0.2791785910964288, 0.11530429924056099, 0.12178223160398421  ‚Ä¶  -0.07621847481721669, 0.18353870423743013, -0.19066653731436745, -0.09423224997242206, 0.14596847781388494, -0.09747986927777111, 0.16041150122587072, -0.02296513951256738, 0.06786878373578588, 0.15296635978447756]], 0) To not get too many entries let‚Äôs just look at the first 20 iterations again R4 = gradient_descent(\n    M,\n    f3,\n    grad_f,\n    data[1];\n    record=[:Count => RecordCount()],\n    return_state=true,\n) # Solver state for `Manopt.jl`s Gradient Descent\nAfter 60 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 200:  not reached\n    |grad f| < 1.0e-8: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Record\n(Iteration = RecordGroup([RecordCount([25, 29, 33, 37, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 229, 232, 236, 240, 242, 246, 248, 254, 256])]),) get_record(R4) 60-element Vector{Tuple{Int64}}:\n (25,)\n (29,)\n (33,)\n (37,)\n (40,)\n (44,)\n (48,)\n (52,)\n (56,)\n (60,)\n (64,)\n (68,)\n (72,)\n ‚ãÆ\n (216,)\n (220,)\n (224,)\n (229,)\n (232,)\n (236,)\n (240,)\n (242,)\n (246,)\n (248,)\n (254,)\n (256,) We can see that the number of cost function calls varies, depending on how many line search backtrack steps were required to obtain a good stepsize."},{"id":2827,"pagetitle":"Implement a solver","title":"How to implementing your own solver","ref":"/manopt/stable/tutorials/ImplementASolver/#How-to-implementing-your-own-solver","content":" How to implementing your own solver Ronny Bergmann When you have used a few solvers from  Manopt.jl  for example like in the opening tutorial  Get started: optimize!  you might come to the idea of implementing a solver yourself. After a short introduction of the algorithm we aim to implement, this tutorial first discusses the structural details, for example what a solver consists of and ‚Äúworks with‚Äù. Afterwards, we show how to implement the algorithm. Finally, we discuss how to make the algorithm both nice for the user as well as initialized in a way, that it can benefit from features already available in  Manopt.jl . Note If you have implemented your own solver, we would be very happy to have that within  Manopt.jl  as well, so maybe consider  opening a Pull Request using Manopt, Manifolds, Random"},{"id":2828,"pagetitle":"Implement a solver","title":"Our guiding example: a random walk minimization","ref":"/manopt/stable/tutorials/ImplementASolver/#Our-guiding-example:-a-random-walk-minimization","content":" Our guiding example: a random walk minimization Since most serious algorithms should be implemented in  Manopt.jl  themselves directly, we implement a solver that randomly walks on the manifold and keeps track of the lowest point visited. As for algorithms in  Manopt.jl  we aim to implement this  generically  for any manifold that is implemented using  ManifoldsBase.jl . The random walk minimization Given: a manifold  $\\mathcal M$ a starting point  $p=p^{(0)}$ a cost function  $f: \\mathcal M ‚Üí ‚Ñù$ . a parameter  $\\sigma > 0$ . a retraction  $\\operatorname{retr}_p(X)$  that maps  $X ‚àà T_p\\mathcal M$  to the manifold. We can run the following steps of the algorithm set  $k=0$ set our best point  $q = p^{(0)}$ Repeat until a stopping criterion is fulfilled Choose a random tangent vector  $X^{(k)} ‚àà T_{p^{(k)}}\\mathcal M$  of length  $\\lVert X^{(k)} \\rVert = \\sigma$ ‚ÄúWalk‚Äù along this direction, that is  $p^{(k+1)} = \\operatorname{retr}_{p^{(k)}}(X^{(k)})$ If  $f(p^{(k+1)}) < f(q)$  set q = p^{(k+1)} $  as our new best visited point Return  $q$  as the resulting best point we visited"},{"id":2829,"pagetitle":"Implement a solver","title":"Preliminaries: elements a solver works on","ref":"/manopt/stable/tutorials/ImplementASolver/#Preliminaries:-elements-a-solver-works-on","content":" Preliminaries: elements a solver works on There are two main ingredients a solver needs: a problem to work on and the state of a solver, which ‚Äúidentifies‚Äù the solver and stores intermediate results."},{"id":2830,"pagetitle":"Implement a solver","title":"The ‚Äútask‚Äù: an  AbstractManoptProblem","ref":"/manopt/stable/tutorials/ImplementASolver/#The-‚Äútask‚Äù:-an-AbstractManoptProblem","content":" The ‚Äútask‚Äù: an  AbstractManoptProblem A problem in  Manopt.jl  usually consists of a manifold (an  AbstractManifold ) and an  AbstractManifoldObjective  describing the function we have and its features. In our case the objective is (just) a  ManifoldCostObjective  that stores cost function  f(M,p) -> R . More generally, it might for example store a gradient function or the Hessian or any other information we have about our task. This is something independent of the solver itself, since it only identifies the problem we want to solve independent of how we want to solve it,¬†or in other words, this type contains all information that is static and independent of the specific solver at hand. Usually the problems variable is called  mp ."},{"id":2831,"pagetitle":"Implement a solver","title":"The solver: an  AbstractManoptSolverState","ref":"/manopt/stable/tutorials/ImplementASolver/#The-solver:-an-AbstractManoptSolverState","content":" The solver: an  AbstractManoptSolverState Everything that is needed by a solver during the iterations, all its parameters, interim values that are needed beyond just one iteration, is stored in a subtype of the  AbstractManoptSolverState . This identifies the solver uniquely. In our case we want to store five things the current iterate  p $=p^{(k)}$ the best visited point  $q$ the variable  $\\sigma > 0$ the retraction  $\\operatorname{retr}$  to use (cf.¬† retractions and inverse retractions ) a criterion, when to stop: a  StoppingCriterion We can defined this as mutable struct RandomWalkState{\n    P,\n    R<:AbstractRetractionMethod,\n    S<:StoppingCriterion,\n} <: AbstractManoptSolverState\n  p::P\n  q::P\n  œÉ::Float64\n  retraction_method::R\n  stop::S\nend The stopping criterion is usually stored in the state‚Äôs  stop  field. If you have a reason to do otherwise, you have one more function to implement (see next section). For ease of use, a constructor can be provided, that for example chooses a good default for the retraction based on a given manifold. function RandomWalkState(M::AbstractManifold, p::P=rand(M);\n    œÉ = 0.1,\n    retraction_method::R=default_retraction_method(M),\n    stopping_criterion::S=StopAfterIteration(200)\n) where {P, R<:AbstractRetractionMethod, S<:StoppingCriterion}\n    return RandomWalkState{P,R,S}(p, copy(M, p), œÉ, retraction_method, stopping_criterion)\nend Parametrising the state avoid that we have abstract typed fields. The keyword arguments for the retraction and stopping criterion are the ones usually used in  Manopt.jl  and provide an easy way to construct this state now. States usually have a shortened name as their variable, we use  rws  for our state here."},{"id":2832,"pagetitle":"Implement a solver","title":"Implementing your solver","ref":"/manopt/stable/tutorials/ImplementASolver/#Implementing-your-solver","content":" Implementing your solver There is basically only two methods we need to implement for our solver initialize_solver!(mp, rws)  which initialises the solver before the first iteration step_solver!(mp, rws, i)  which implements the  i th iteration, where  i  is given to you as the third parameter get_iterate(rws)  which accesses the iterate from other places in the solver get_solver_result(rws)  returning the solvers final (best) point we reached. By default this would return the last iterate  rws.p  (or more precisely calls  get_iterate ), but since we randomly walk and remember our best point in  q , this has to return  rws.q . The first two functions are in-place functions, that is they modify our solver state  rws . You implement these by multiple dispatch on the types after importing said functions from Manopt: import Manopt: initialize_solver!, step_solver!, get_iterate, get_solver_result The state above has two fields where we use the common names used in  Manopt.jl , that is the  StoppingCriterion  is usually in  stop  and the iterate in  p . If your choice is different, you need to reimplement stop_solver!(mp, rws, i)  to determine whether or not to stop after the  i th iteration. get_iterate(rws)  to access the current iterate We recommend to follow the general scheme with the  stop  field. If you have specific criteria when to stop, consider implementing your own  stopping criterion  instead."},{"id":2833,"pagetitle":"Implement a solver","title":"Initialization and iterate access","ref":"/manopt/stable/tutorials/ImplementASolver/#Initialization-and-iterate-access","content":" Initialization and iterate access For our solver, there is not so much to initialize, just to be safe we should copy over the initial value in  p  we start with, to  q . We do not have to care about remembering the iterate, that is done by  Manopt.jl . For the iterate access we just have to pass  p . function initialize_solver!(mp::AbstractManoptProblem, rws::RandomWalkState)\n    copyto!(M, rws.q, rws.p) # Set p^{(0)} = q\n    return rws\nend\nget_iterate(rws::RandomWalkState) = rws.p\nget_solver_result(rws::RandomWalkState) = rws.q and similarly we implement the step. Here we make use of the fact that the problem (and also the objective in fact) have access functions for their elements, the one we need is  get_cost . function step_solver!(mp::AbstractManoptProblem, rws::RandomWalkState, i)\n    M = get_manifold(mp) # for ease of use get the manifold from the problem\n    X = rand(M; vector_at=p)     # generate a direction\n    X .*= rws.œÉ/norm(M, p, X)\n    # Walk\n    retract!(M, rws.p, rws.p, X, rws.retraction_method)\n    # is the new point better? Then store it\n    if get_cost(mp, rws.p) < get_cost(mp, rws.q)\n        copyto!(M, rws.p, rws.q)\n    end\n    return rws\nend Performance wise we could improve the number of allocations by making  X  also a field of our  rws  but let‚Äôs keep it simple here. We could also store the cost of  q  in the state, but we shall see how to easily also enable this solver to allow for  caching . In practice, however, it is preferable to cache intermediate values like cost of  q  in the state when it can be easily achieved. This way we do not have to deal with overheads of an external cache. Now we can just run the solver already. We take the same example as for the other tutorials We first define our task, the Riemannian Center of Mass from the  Get started: optimize!  tutorial. Random.seed!(23)\nn = 100\nœÉ = œÄ / 8\nM = Sphere(2)\np = 1 / sqrt(2) * [1.0, 0.0, 1.0]\ndata = [exp(M, p,  œÉ * rand(M; vector_at=p)) for i in 1:n];\nf(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2) We can now generate the problem with its objective and the state mp = DefaultManoptProblem(M, ManifoldCostObjective(f))\ns = RandomWalkState(M; œÉ = 0.2)\n\nsolve!(mp, s)\nget_solver_result(s) 3-element Vector{Float64}:\n -0.2412674850987521\n  0.8608618657176527\n -0.44800317943876844 The function  solve!  works also in place of  s , but the last line illustrates how to access the result in general; we could also just look at  s.p , but the function  get_iterate  is also used in several other places. We could for example easily set up a second solver to work from a specified starting point with a different  œÉ  like s2 = RandomWalkState(M, [1.0, 0.0, 0.0];  œÉ = 0.1)\nsolve!(mp, s2)\nget_solver_result(s2) 3-element Vector{Float64}:\n 1.0\n 0.0\n 0.0"},{"id":2834,"pagetitle":"Implement a solver","title":"Ease of use I: a high level interface","ref":"/manopt/stable/tutorials/ImplementASolver/#Ease-of-use-I:-a-high-level-interface","content":" Ease of use I: a high level interface Manopt.jl  offers a few additional features for solvers in their high level interfaces, for example  debug=  for debug ,  record=  keywords for debug and recording within solver states or  count=  and  cache  keywords for the objective. We can introduce these here as well with just a few lines of code. There are usually two steps. We further need three internal function from  Manopt.jl using Manopt: get_solver_return, indicates_convergence, status_summary"},{"id":2835,"pagetitle":"Implement a solver","title":"A high level interface using the objective","ref":"/manopt/stable/tutorials/ImplementASolver/#A-high-level-interface-using-the-objective","content":" A high level interface using the objective This could be considered as an interim step to the high-level interface: If objective,¬†a  ManifoldCostObjective  is already initialized, the high level interface consists of the steps possibly decorate the objective generate the problem generate and possibly generate the state call the solver determine the return value We illustrate the step with an in-place variant here. A variant that keeps the given start point unchanged would just add a  copy(M, p)  upfront.  Manopt.jl  provides both variants. function random_walk_algorithm!(\n    M::AbstractManifold,\n    mgo::ManifoldCostObjective,\n    p;\n    œÉ = 0.1,\n    retraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)),\n    stopping_criterion::StoppingCriterion=StopAfterIteration(200),\n    kwargs...,\n)\n    dmgo = decorate_objective!(M, mgo; kwargs...)\n    dmp = DefaultManoptProblem(M, dmgo)\n    s = RandomWalkState(M, [1.0, 0.0, 0.0];\n        œÉ=0.1,\n        retraction_method=retraction_method, stopping_criterion=stopping_criterion,\n    )\n    ds = decorate_state!(s; kwargs...)\n    solve!(dmp, ds)\n    return get_solver_return(get_objective(dmp), ds)\nend random_walk_algorithm! (generic function with 1 method)"},{"id":2836,"pagetitle":"Implement a solver","title":"The high level interface","ref":"/manopt/stable/tutorials/ImplementASolver/#The-high-level-interface","content":" The high level interface Starting from the last section, the usual call a user would prefer is just passing a manifold  M  the cost  f  and maybe a start point  p . function random_walk_algorithm!(M::AbstractManifold, f, p=rand(M); kwargs...)\n    mgo = ManifoldCostObjective(f)\n    return random_walk_algorithm!(M, mgo, p; kwargs...)\nend random_walk_algorithm! (generic function with 3 methods)"},{"id":2837,"pagetitle":"Implement a solver","title":"Ease of Use II: the State Summary","ref":"/manopt/stable/tutorials/ImplementASolver/#Ease-of-Use-II:-the-State-Summary","content":" Ease of Use II: the State Summary For the case that you set  return_state=true  the solver should return a summary of the run. When a  show  method is provided, users can easily read such summary in a terminal. It should reflect its main parameters, if they are not too verbose and provide information about the reason it stopped and whether this indicates convergence. Here it would for example look like import Base: show\nfunction show(io::IO, rws::RandomWalkState)\n    i = get_count(rws, :Iterations)\n    Iter = (i > 0) ? \"After $i iterations\\n\" : \"\"\n    Conv = indicates_convergence(rws.stop) ? \"Yes\" : \"No\"\n    s = \"\"\"\n    # Solver state for `Manopt.jl`s Tutorial Random Walk\n    $Iter\n    ## Parameters\n    * retraction method: $(rws.retraction_method)\n    * œÉ                : $(rws.œÉ)\n\n    ## Stopping criterion\n\n    $(status_summary(rws.stop))\n    This indicates convergence: $Conv\"\"\"\n    return print(io, s)\nend Now the algorithm can be easily called and provides all features of a  Manopt.jl  algorithm. For example to see the summary, we could now just call q = random_walk_algorithm!(M, f; return_state=true) # Solver state for `Manopt.jl`s Tutorial Random Walk\nAfter 200 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n* œÉ                : 0.1\n\n## Stopping criterion\n\nMax Iteration 200:  reached\nThis indicates convergence: No"},{"id":2838,"pagetitle":"Implement a solver","title":"Conclusion & Beyond","ref":"/manopt/stable/tutorials/ImplementASolver/#Conclusion-and-Beyond","content":" Conclusion & Beyond We saw in this tutorial how to implement a simple cost-based algorithm, to illustrate how optimization algorithms are covered in  Manopt.jl . One feature we did not cover is that most algorithms allow for in-place and allocation functions, as soon as they work on more than just the cost, for example use gradients, proximal maps or Hessians. This is usually a keyword argument of the objective and hence also part of the high-level interfaces."},{"id":2841,"pagetitle":"Optimize on your own manifold","title":"Optimize on your own manifold","ref":"/manopt/stable/tutorials/ImplementOwnManifold/#Optimize-on-your-own-manifold","content":" Optimize on your own manifold Ronny Bergmann When you have used a few solvers from  Manopt.jl  for example like in the opening tutorial  üèîÔ∏è Get started: optimize!  and also familiarized yourself with how to work with manifolds in general at  üöÄ Get Started with  Manifolds.jl , you might come across the point that you want to  implementing a manifold  yourself and use it within  Manopt.jl . A challenge might be, which functions are necessary, since the overall interface of  ManifoldsBase.jl  is maybe not completely necessary. This tutorial aims to help you through these steps to implement necessary parts of a manifold to get started with the  solver  you have in mind."},{"id":2842,"pagetitle":"Optimize on your own manifold","title":"An example problem","ref":"/manopt/stable/tutorials/ImplementOwnManifold/#An-example-problem","content":" An example problem We get started by loading the packages we need. using LinearAlgebra, Manifolds, ManifoldsBase, Random\nusing Manopt\nRandom.seed!(42) We also define the same manifold as in the  implementing a manifold  tutorial. \"\"\"\n    ScaledSphere <: AbstractManifold{‚Ñù}\n\nDefine a sphere of fixed radius\n\n# Fields\n\n* `dimension` dimension of the sphere\n* `radius` the radius of the sphere\n\n# Constructor\n\n    ScaledSphere(dimension,radius)\n\nInitialize the manifold to a certain `dimension` and `radius`,\nwhich by default is set to `1.0`\n\"\"\"\nstruct ScaledSphere <: AbstractManifold{‚Ñù}\n    dimension::Int\n    radius::Float64\nend We would like to compute a mean and/or median similar to  üèîÔ∏è Get started: optimize! . For given a set of points  $q_1,\\ldots,q_n$  we want to compute [ Kar77 ] \\[  \\operatorname*{arg\\,min}_{p‚àà\\mathcal M}\n  \\frac{1}{2n} \\sum_{i=1}^n d_{\\mathcal M}^2(p, q_i)\\] On the  ScaledSphere  we just defined above. We define a few parameters first d = 5  # dimension of the sphere - embedded in R^{d+1}\nr = 2.0 # radius of the sphere\nN = 100 # data set size\n\nM = ScaledSphere(d,r) ScaledSphere(5, 2.0) If we generate a few points # generate 100 points around the north pole\npts = [ [zeros(d)..., M.radius] .+ 0.5.*([rand(d)...,0.5] .- 0.5) for _=1:N]\n# project them onto the r-sphere\npts = [ r/norm(p) .* p for p in pts] Then, before starting with optimization, we need the distance on the manifold, to define the cost function, as well as the logarithmic map to defined the gradient. For both, we here use the ‚Äúlazy‚Äù approach of using the  Sphere  as a fallback. Finally, we have to provide information about how points and tangent vectors are stored on the manifold by implementing their  representation_size  function, which is often required when allocating memory. While we could import ManifoldsBase: distance, log, representation_size\nfunction distance(M::ScaledSphere, p, q)\n    return M.radius * distance(Sphere(M.dimension), p ./ M.radius, q ./ M.radius)\nend\nfunction log(M::ScaledSphere, p, q)\n    return M.radius * log(Sphere(M.dimension), p ./ M.radius, q ./ M.radius)\nend\nrepresentation_size(M::ScaledSphere) = (M.dimension+1,)"},{"id":2843,"pagetitle":"Optimize on your own manifold","title":"Define the cost and gradient","ref":"/manopt/stable/tutorials/ImplementOwnManifold/#Define-the-cost-and-gradient","content":" Define the cost and gradient f(M, q) = sum(distance(M, q, p)^2 for p in pts)\ngrad_f(M,q) = sum( - log(M, q, p) for p in pts)"},{"id":2844,"pagetitle":"Optimize on your own manifold","title":"Defining the necessary functions to run a solver","ref":"/manopt/stable/tutorials/ImplementOwnManifold/#Defining-the-necessary-functions-to-run-a-solver","content":" Defining the necessary functions to run a solver The documentation usually lists the necessary functions in a section ‚ÄúTechnical Details‚Äù close to the end of the documentation of a solver, for our case that is  The gradient descent‚Äôs Technical Details , They list all details, but we can start even step by step here if we are a bit careful."},{"id":2845,"pagetitle":"Optimize on your own manifold","title":"A retraction","ref":"/manopt/stable/tutorials/ImplementOwnManifold/#A-retraction","content":" A retraction We first implement a  retract ion. Informally,¬†given a current point and a direction to ‚Äúwalk into‚Äù we need a function that performs that walk. Since we take an easy one that just projects onto the sphere, we use the  ProjectionRetraction  type. To be precise, we have to implement the  in-place variant retract_project! import ManifoldsBase: retract_project!\nfunction retract_project!(M::ScaledSphere, q, p, X, t::Number)\n    q .= p .+ t .* X\n    q .*= M.radius / norm(q)\n    return q\nend retract_project! (generic function with 18 methods) The other two technical remarks refer to the step size and the stopping criterion, so if we set these to something simpler, we should already be able to do a first run. We have to specify that we want to use the new retraction, a simple step size and stopping criterion We start with a certain point of cost p0 = [zeros(d)...,1.0]\nf(M,p0) 444.60374551157634 Then we can run our first solver,¬†where we have to overwrite a few defaults, which would use functions we do not (yet) have. We will discuss these in the next steps. q1 = gradient_descent(M, f, grad_f, p0;\n    retraction_method = ProjectionRetraction(),   # state, that we use the retraction from above\n    stepsize = DecreasingStepsize(M; length=1.0), # A simple step size\n    stopping_criterion = StopAfterIteration(10),  # A simple stopping crtierion\n    X = zeros(d+1),                               # how we define/represent tangent vectors\n)\nf(M,q1) 162.4000287847332 We at least see, that the function value decreased."},{"id":2846,"pagetitle":"Optimize on your own manifold","title":"Norm and maximal step size.","ref":"/manopt/stable/tutorials/ImplementOwnManifold/#Norm-and-maximal-step-size.","content":" Norm and maximal step size. To use more advanced stopping criteria and step sizes we first need an  inner (M, p, X) . We also need a  max_stepsize (M) , to avoid having too large steps on positively curved manifolds like our scaled sphere in this example import ManifoldsBase: inner\nimport Manopt: max_stepsize\ninner(M::ScaledSphere, p, X,Y) = dot(X,Y) # inherited from the embedding\n # set the maximal allowed stepsize to injectivity radius.\nManopt.max_stepsize(M::ScaledSphere) = M.radius*œÄ Then we can use the default step size ( ArmijoLinesearch ) and the default stopping criterion, which checks for a small gradient Norm q2 = gradient_descent(M, f, grad_f, p0;\n    retraction_method = ProjectionRetraction(), # as before\n    X = zeros(d+1), # as before\n)\nf(M, q2) 9.772830131357024"},{"id":2847,"pagetitle":"Optimize on your own manifold","title":"Making life easier: default retraction and zero vector","ref":"/manopt/stable/tutorials/ImplementOwnManifold/#Making-life-easier:-default-retraction-and-zero-vector","content":" Making life easier: default retraction and zero vector To initialize tangent vector memory, the function  zero_vector (M,p)  is called. Similarly, the most-used retraction is returned by  default_retraction_method We can use both here, to make subsequent calls to the solver less verbose. We define import ManifoldsBase: zero_vector, default_retraction_method\nzero_vector(M::ScaledSphere, p) = zeros(M.dimension+1)\ndefault_retraction_method(M::ScaledSphere) = ProjectionRetraction() default_retraction_method (generic function with 20 methods) and now we can even just call q3 = gradient_descent(M, f, grad_f, p0)\nf(M, q3) 9.772830131357024 But we for example automatically also get the possibility to obtain debug information like gradient_descent(M, f, grad_f, p0; debug = [:Iteration, :Cost, :Stepsize, 25, :GradientNorm, :Stop, \"\\n\"]); Initial f(x): 444.603746\n# 25    f(x): 9.772836s:0.01851892669284175|grad f(p)|:0.027709997662907597\n# 50    f(x): 9.772830s:0.01851892669284175|grad f(p)|:0.00035050862606229735\n# 75    f(x): 9.772830s:0.01671333134028968|grad f(p)|:3.5186467891885363e-6\nThe algorithm reached approximately critical point after 81 iterations; the gradient norm (8.510619620990863e-9) is less than 1.0e-8. see  How to Print Debug Output  for more details."},{"id":2848,"pagetitle":"Optimize on your own manifold","title":"Literature","ref":"/manopt/stable/tutorials/ImplementOwnManifold/#Literature","content":" Literature [Kar77] H.¬†Karcher.  Riemannian center of mass and mollifier smoothing .  Communications¬†on¬†Pure¬†and¬†Applied¬†Mathematics  30 , 509‚Äì541  (1977)."},{"id":2851,"pagetitle":"Speedup using in-place computations","title":"Speedup using in-place evaluation","ref":"/manopt/stable/tutorials/InplaceGradient/#Speedup-using-in-place-evaluation","content":" Speedup using in-place evaluation Ronny Bergmann When it comes to time critical operations, a main ingredient in Julia is given by mutating functions, that is those that compute in place without additional memory allocations. In the following, we illustrate how to do this with  Manopt.jl . Let‚Äôs start with the same function as in  Get Started: Optimize!  and compute the mean of some points, only that here we use the sphere  $\\mathbb S^{30}$  and  $n=800$  points. From the aforementioned example. We first load all necessary packages. using Manopt, Manifolds, Random, BenchmarkTools\nRandom.seed!(42); And setup our data Random.seed!(42)\nm = 30\nM = Sphere(m)\nn = 800\nœÉ = œÄ / 8\np = zeros(Float64, m + 1)\np[2] = 1.0\ndata = [exp(M, p, œÉ * rand(M; vector_at=p)) for i in 1:n];"},{"id":2852,"pagetitle":"Speedup using in-place computations","title":"Classical Definition","ref":"/manopt/stable/tutorials/InplaceGradient/#Classical-Definition","content":" Classical Definition The variant from the previous tutorial defines a cost  $f(x)$  and its gradient  $\\operatorname{grad}f(p)$  ‚Äú‚Äú‚Äù f(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)\ngrad_f(M, p) = sum(1 / n * grad_distance.(Ref(M), data, Ref(p))) grad_f (generic function with 1 method) We further set the stopping criterion to be a little more strict. Then we obtain sc = StopWhenGradientNormLess(3e-10)\np0 = zeros(Float64, m + 1); p0[1] = 1/sqrt(2); p0[2] = 1/sqrt(2)\nm1 = gradient_descent(M, f, grad_f, p0; stopping_criterion=sc); We can also benchmark this as @benchmark gradient_descent($M, $f, $grad_f, $p0; stopping_criterion=$sc) BenchmarkTools.Trial: 100 samples with 1 evaluation.\n Range (min ‚Ä¶ max):  48.285 ms ‚Ä¶ 56.649 ms  ‚îä GC (min ‚Ä¶ max): 4.84% ‚Ä¶ 6.96%\n Time  (median):     49.552 ms              ‚îä GC (median):    5.41%\n Time  (mean ¬± œÉ):   50.151 ms ¬±  1.731 ms  ‚îä GC (mean ¬± œÉ):  5.56% ¬± 0.64%\n\n   ‚ñÇ‚ñÉ ‚ñà‚ñÉ‚ñÉ‚ñÜ    ‚ñÇ\n  ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñà‚ñá‚ñà‚ñÑ‚ñÖ‚ñá‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñá‚ñÑ‚ñá‚ñÖ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ ‚ñÑ\n  48.3 ms         Histogram: frequency by time        56.6 ms <\n\n Memory estimate: 194.10 MiB, allocs estimate: 655347."},{"id":2853,"pagetitle":"Speedup using in-place computations","title":"In-place Computation of the Gradient","ref":"/manopt/stable/tutorials/InplaceGradient/#In-place-Computation-of-the-Gradient","content":" In-place Computation of the Gradient We can reduce the memory allocations by implementing the gradient to be evaluated in-place. We do this by using a  functor . The motivation is twofold: on one hand, we want to avoid variables from the global scope, for example the manifold  M  or the  data , being used within the function. Considering to do the same for more complicated cost functions might also be worth pursuing. Here, we store the data (as reference) and one introduce temporary memory in order to avoid reallocation of memory per  grad_distance  computation. We get struct GradF!{TD,TTMP}\n    data::TD\n    tmp::TTMP\nend\nfunction (grad_f!::GradF!)(M, X, p)\n    fill!(X, 0)\n    for di in grad_f!.data\n        grad_distance!(M, grad_f!.tmp, di, p)\n        X .+= grad_f!.tmp\n    end\n    X ./= length(grad_f!.data)\n    return X\nend For the actual call to the solver, we first have to generate an instance of  GradF!  and tell the solver, that the gradient is provided in an  InplaceEvaluation . We can further also use  gradient_descent!  to even work in-place of the initial point we pass. grad_f2! = GradF!(data, similar(data[1]))\nm2 = deepcopy(p0)\ngradient_descent!(\n    M, f, grad_f2!, m2; evaluation=InplaceEvaluation(), stopping_criterion=sc\n); We can again benchmark this @benchmark gradient_descent!(\n    $M, $f, $grad_f2!, m2; evaluation=$(InplaceEvaluation()), stopping_criterion=$sc\n) setup = (m2 = deepcopy($p0)) BenchmarkTools.Trial: 176 samples with 1 evaluation.\n Range (min ‚Ä¶ max):  27.419 ms ‚Ä¶ 34.154 ms  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 0.00%\n Time  (median):     28.001 ms              ‚îä GC (median):    0.00%\n Time  (mean ¬± œÉ):   28.412 ms ¬±  1.079 ms  ‚îä GC (mean ¬± œÉ):  0.73% ¬± 2.24%\n\n    ‚ñÅ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÇ‚ñÑ ‚ñÅ\n  ‚ñÑ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñá‚ñà‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÉ ‚ñÉ\n  27.4 ms         Histogram: frequency by time        31.9 ms <\n\n Memory estimate: 3.76 MiB, allocs estimate: 5949. which is faster by about a factor of 2 compared to the first solver-call. Note that the results  m1  and  m2  are of course the same. distance(M, m1, m2) 2.0004809792350595e-10"},{"id":2856,"pagetitle":"üèîÔ∏è Get started: optimize.","title":"üèîÔ∏è Get started: optimize.","ref":"/manopt/stable/tutorials/Optimize/#Get-started:-optimize.","content":" üèîÔ∏è Get started: optimize. Ronny Bergmann This tutorial both introduces the basics of optimisation on manifolds as well as how to use  Manopt.jl  to perform optimisation on manifolds in  Julia . For more theoretical background, see for example [ Car92 ] for an introduction to Riemannian manifolds and [ AMS08 ] or [ Bou23 ] to read more about optimisation thereon. Let  $\\mathcal M$  denote a ( Riemannian manifold  and let  $f: \\mathcal M ‚Üí ‚Ñù$  be a cost function. The aim is to determine or obtain a point  $p^*$  where  $f$  is  minimal  or in other words  $p^*$  is a  minimizer  of  $f$ . This can also be written as \\[    \\operatorname*{arg\\,min}_{p ‚àà \\mathcal M} f(p)\\] where the aim is to compute the minimizer  $p^*$  numerically. As an example, consider the generalisation of the  (arithemtic) mean . In the Euclidean case with  $d‚àà\\mathbb N$ , that is for  $n‚àà\\mathbb N$  data points  $y_1,\\ldots,y_n ‚àà ‚Ñù^d$  the mean \\[  \\frac{1}{n}\\sum_{i=1}^n y_i\\] can not be directly generalised to data  $q_1,\\ldots,q_n ‚àà \\mathcal M$ , since on a manifold there is no addition available. But the mean can also be characterised as the following minimizer \\[  \\operatorname*{arg\\,min}_{x‚àà‚Ñù^d} \\frac{1}{2n}\\sum_{i=1}^n \\lVert x - y_i\\rVert^2\\] and using the Riemannian distance  $d_\\mathcal M$ , this can be written on Riemannian manifolds, which is the so called  Riemannian Center of Mass  [ Kar77 ] \\[  \\operatorname*{arg\\,min}_{p‚àà\\mathcal M}\n  \\frac{1}{2n} \\sum_{i=1}^n d_{\\mathcal M}^2(p, q_i)\\] Fortunately the gradient can be computed and is \\[ \\frac{1}{n} \\sum_{i=1}^n -\\log_p q_i\\]"},{"id":2857,"pagetitle":"üèîÔ∏è Get started: optimize.","title":"Loading the necessary packages","ref":"/manopt/stable/tutorials/Optimize/#Loading-the-necessary-packages","content":" Loading the necessary packages Let‚Äôs assume you have already installed both  Manopt.jl  and  Manifolds.jl  in Julia (using for example  using Pkg; Pkg.add([\"Manopt\", \"Manifolds\"]) ). Then we can get started by loading both packages as well as  Random.jl  for persistency in this tutorial. using Manopt, Manifolds, Random, LinearAlgebra, ManifoldDiff\nusing ManifoldDiff: grad_distance, prox_distance\nRandom.seed!(42); Now assume we are on the  Sphere $\\mathcal M = \\mathbb S^2$  and we generate some random points ‚Äúaround‚Äù some initial point  $p$ n = 100\nœÉ = œÄ / 8\nM = Sphere(2)\np = 1 / sqrt(2) * [1.0, 0.0, 1.0]\ndata = [exp(M, p,  œÉ * rand(M; vector_at=p)) for i in 1:n]; Now we can define the cost function  $f$  and its (Riemannian) gradient  $\\operatorname{grad} f$  for the Riemannian center of mass: f(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)\ngrad_f(M, p) = sum(1 / n * grad_distance.(Ref(M), data, Ref(p))); and just call  gradient_descent . For a first start, we do not have to provide more than the manifold, the cost, the gradient, and a starting point, which we just set to the first data point m1 = gradient_descent(M, f, grad_f, data[1]) 3-element Vector{Float64}:\n 0.6868392807355564\n 0.006531599748261925\n 0.7267799809043942 In order to get more details, we further add the  debug=  keyword argument, which act as a  decorator pattern . This way we can easily specify a certain debug to be printed. The goal is to get an output of the form # i | Last Change: [...] | F(x): [...] | but where we also want to fix the display format for the change and the cost numbers (the  [...] ) to have a certain format. Furthermore, the reason why the solver stopped should be printed at the end These can easily be specified using either a Symbol when using the default format for numbers, or a tuple of a symbol and a format-string in the  debug=  keyword that is available for every solver. We can also,¬†for illustration reasons,¬†just look at the first 6 steps by setting a  stopping_criterion= m2 = gradient_descent(M, f, grad_f, data[1];\n    debug=[:Iteration,(:Change, \"|Œîp|: %1.9f |\"),\n        (:Cost, \" F(x): %1.11f | \"), \"\\n\", :Stop],\n    stopping_criterion = StopAfterIteration(6)\n  ) Initial  F(x): 0.32487988924 | \n# 1     |Œîp|: 1.063609017 | F(x): 0.25232524046 | \n# 2     |Œîp|: 0.809858671 | F(x): 0.20966960102 | \n# 3     |Œîp|: 0.616665145 | F(x): 0.18546505598 | \n# 4     |Œîp|: 0.470841764 | F(x): 0.17121604104 | \n# 5     |Œîp|: 0.359345690 | F(x): 0.16300825911 | \n# 6     |Œîp|: 0.274597420 | F(x): 0.15818548927 | \nThe algorithm reached its maximal number of iterations (6).\n\n3-element Vector{Float64}:\n  0.7533872481682505\n -0.06053107055583637\n  0.6547851890466334 See  here  for the list of available symbols. Technical Detail The  debug=  keyword is actually a list of  DebugActions  added to every iteration, allowing you to write your own ones even. Additionally,  :Stop  is an action added to the end of the solver to display the reason why the solver stopped. The default stopping criterion for  gradient_descent  is, to either stop when the gradient is small ( <1e-9 ) or a max number of iterations is reached (as a fallback). Combining stopping-criteria can be done by  |  or  & . We further pass a number  25  to  debug=  to only an output every  25 th iteration: m3 = gradient_descent(M, f, grad_f, data[1];\n    debug=[:Iteration,(:Change, \"|Œîp|: %1.9f |\"),\n        (:Cost, \" F(x): %1.11f | \"), \"\\n\", :Stop, 25],\n    stopping_criterion = StopWhenGradientNormLess(1e-14) |¬†StopAfterIteration(400),\n) Initial  F(x): 0.32487988924 | \n# 25    |Œîp|: 0.459715605 | F(x): 0.15145076374 | \n# 50    |Œîp|: 0.000551270 | F(x): 0.15145051509 | \nThe algorithm reached approximately critical point after 73 iterations; the gradient norm (9.988871119384563e-16) is less than 1.0e-14.\n\n3-element Vector{Float64}:\n 0.6868392794788668\n 0.006531600680779286\n 0.7267799820836411 We can finally use another way to determine the stepsize, for example a little more expensive  ArmijoLineSeach  than the default  stepsize  rule used on the Sphere. m4 = gradient_descent(M, f, grad_f, data[1];\n    debug=[:Iteration,(:Change, \"|Œîp|: %1.9f |\"),\n        (:Cost, \" F(x): %1.11f | \"), \"\\n\", :Stop, 2],\n      stepsize = ArmijoLinesearch(M; contraction_factor=0.999, sufficient_decrease=0.5),\n    stopping_criterion = StopWhenGradientNormLess(1e-14) |¬†StopAfterIteration(400),\n) Initial  F(x): 0.32487988924 | \n# 2     |Œîp|: 0.001318138 | F(x): 0.15145051509 | \n# 4     |Œîp|: 0.000000004 | F(x): 0.15145051509 | \n# 6     |Œîp|: 0.000000000 | F(x): 0.15145051509 | \nThe algorithm reached approximately critical point after 7 iterations; the gradient norm (5.073696618059386e-15) is less than 1.0e-14.\n\n3-element Vector{Float64}:\n 0.6868392794788669\n 0.006531600680779358\n 0.7267799820836413 Then we reach approximately the same point as in the previous run, but in far less steps [f(M, m3)-f(M,m4), distance(M, m3, m4)] 2-element Vector{Float64}:\n 1.6653345369377348e-16\n 1.727269835930624e-16"},{"id":2858,"pagetitle":"üèîÔ∏è Get started: optimize.","title":"Using the ‚ÄúTutorial‚Äù mode","ref":"/manopt/stable/tutorials/Optimize/#Using-the-‚ÄúTutorial‚Äù-mode","content":" Using the ‚ÄúTutorial‚Äù mode Since a few things on manifolds are a bit different from (classical) Euclidean optimization,  Manopt.jl  has a mode to warn about a few pitfalls. It can be set using set_manopt_parameter!(:Mode, \"Tutorial\") [ Info: Setting the `Manopt.jl` parameter :Mode to Tutorial. to activate these. Continuing from the example before, one might argue, that the minimizer of  $f$  does not depend on the scaling of the function. In theory this is of course also the case on manifolds, but for the optimizations there is a caveat. When we define the Riemannian mean without the scaling f2(M, p) = sum(1 / 2 * distance.(Ref(M), Ref(p), data) .^ 2)\ngrad_f2(M, p) = sum(grad_distance.(Ref(M), data, Ref(p))); And we consider the gradient at the starting point in norm norm(M, data[1], grad_f2(M, data[1])) 57.47318616893399 On the sphere, when we follow a geodesic, we ‚Äúreturn‚Äù to the start point after length  $2œÄ$ . If we ‚Äúland‚Äù short before the starting point due to a gradient of length just shy of  $2œÄ$ , the line search would take the gradient direction (and not the negative gradient direction) as a start. The line search is still performed, but in this case returns a much too small, maybe even nearly zero step size. In other words ‚Äì¬†we have to be careful, that the optimisation stays a ‚Äúlocal‚Äù argument we use. This is also warned for in  \"Tutorial\"  mode. Calling mX = gradient_descent(M, f2, grad_f2, data[1]) ‚îå Warning: At iteration #0\n‚îÇ the gradient norm (57.47318616893399) is larger that 1.0 times the injectivity radius 3.141592653589793 at the current iterate.\n‚îî @ Manopt ~/work/Manopt.jl/Manopt.jl/src/plans/debug.jl:1049\n‚îå Warning: Further warnings will be suppressed, use DebugWarnIfGradientNormTooLarge(1.0, :Always) to get all warnings.\n‚îî @ Manopt ~/work/Manopt.jl/Manopt.jl/src/plans/debug.jl:1053\n\n3-element Vector{Float64}:\n 0.6868392794870684\n 0.006531600674920825\n 0.7267799820759485 So just by chance it seems we still got nearly the same point as before, but when we for example look when this one stops, that is takes more steps. gradient_descent(M, f2, grad_f2, data[1], debug=[:Stop]); The algorithm reached approximately critical point after 140 iterations; the gradient norm (6.807380063106406e-9) is less than 1.0e-8. This also illustrates one way to deactivate the hints, namely by overwriting the  debug=  keyword, that in  Tutorial  mode contains addional warnings.the other option is to globally reset the  :Mode  back to set_manopt_parameter!(:Mode, \"\") [ Info: Resetting the `Manopt.jl` parameter :Mode to default."},{"id":2859,"pagetitle":"üèîÔ∏è Get started: optimize.","title":"Example 2: computing the median of symmetric positive definite matrices.","ref":"/manopt/stable/tutorials/Optimize/#Example-2:-computing-the-median-of-symmetric-positive-definite-matrices.","content":" Example 2: computing the median of symmetric positive definite matrices. For the second example let‚Äôs consider the manifold of  $3 √ó 3$  symmetric positive definite matrices  and again 100 random points N = SymmetricPositiveDefinite(3)\nm = 100\nœÉ = 0.005\nq = Matrix{Float64}(I, 3, 3)\ndata2 = [exp(N, q, œÉ * rand(N; vector_at=q)) for i in 1:m]; Instead of the mean, let‚Äôs consider a non-smooth optimisation task: The median can be generalized to Manifolds as the minimiser of the sum of distances, see [ Bac14 ]. We define g(N, q) = sum(1 / (2 * m) * distance.(Ref(N), Ref(q), data2)) g (generic function with 1 method) Since the function is non-smooth, we can not use a gradient-based approach. But since for every summand the  proximal map  is available, we can use the  cyclic proximal point algorithm (CPPA) . We hence define the vector of proximal maps as proxes_g = Function[(N, Œª, q) -> prox_distance(N, Œª / m, di, q, 1) for di in data2]; Besides also looking at a some debug prints, we can also easily record these values. Similarly to  debug= ,  record=  also accepts Symbols, see list  here , to indicate things to record. We further set  return_state  to true to obtain not just the (approximate) minimizer. res = cyclic_proximal_point(N, g, proxes_g, data2[1];\n  debug=[:Iteration,\" | \",:Change,\" | \",(:Cost, \"F(x): %1.12f\"),\"\\n\", 1000, :Stop,\n        ],\n        record=[:Iteration, :Change, :Cost, :Iterate],\n        return_state=true,\n    ); Initial  |  | F(x): 0.005875512856\n# 1000   | Last Change: 0.003704 | F(x): 0.003239019699\n# 2000   | Last Change: 0.000015 | F(x): 0.003238996105\n# 3000   | Last Change: 0.000005 | F(x): 0.003238991748\n# 4000   | Last Change: 0.000002 | F(x): 0.003238990225\n# 5000   | Last Change: 0.000001 | F(x): 0.003238989520\nThe algorithm reached its maximal number of iterations (5000). Technical Detail The recording is realised by  RecordActions  that are (also) executed at every iteration. These can also be individually implemented and added to the  record=  array instead of symbols. First, the computed median can be accessed as median = get_solver_result(res) 3√ó3 Matrix{Float64}:\n 1.0          2.12236e-5   0.000398721\n 2.12236e-5   1.00044      0.000141798\n 0.000398721  0.000141798  1.00041 but we can also look at the recorded values. For simplicity (of output), lets just look at the recorded values at iteration 42 get_record(res)[42] (42, 1.0569455860769079e-5, 0.003252547739370045, [0.9998583866917449 0.0002098880312604301 0.0002895445818451581; 0.00020988803126037459 1.0000931572564762 0.0002084371501681892; 0.00028954458184524134 0.0002084371501681892 1.000070920743257]) But we can also access whole series and see that the cost does not decrease that fast; actually, the CPPA might converge relatively slow. For that we can for example access the  :Cost  that was recorded every  :Iterate  as well as the (maybe a little boring)  :Iteration -number in a semi-log-plot. x = get_record(res, :Iteration, :Iteration)\ny = get_record(res, :Iteration, :Cost)\nusing Plots\nplot(x,y,xaxis=:log, label=\"CPPA Cost\")"},{"id":2860,"pagetitle":"üèîÔ∏è Get started: optimize.","title":"Literature","ref":"/manopt/stable/tutorials/Optimize/#Literature","content":" Literature [AMS08] P.-A.¬†Absil, R.¬†Mahony and R.¬†Sepulchre.  Optimization Algorithms on Matrix Manifolds  (Princeton University Press, 2008), available online at  press.princeton.edu/chapters/absil/ . [Bac14] M.¬†Baƒç√°k.  Computing medians and means in Hadamard spaces .  SIAM¬†Journal¬†on¬†Optimization  24 , 1542‚Äì1566  (2014),  arXiv:1210.2145 . [Bou23] N.¬†Boumal.  An Introduction to Optimization on Smooth Manifolds . First¬†Edition ( Cambridge University Press, 2023 ). [Car92] M.¬†P.¬†do¬†Carmo.  Riemannian Geometry .  Mathematics: Theory & Applications  (Birkh√§user Boston, Inc., Boston, MA, 1992); p.¬†xiv+300. [Kar77] H.¬†Karcher.  Riemannian center of mass and mollifier smoothing .  Communications¬†on¬†Pure¬†and¬†Applied¬†Mathematics  30 , 509‚Äì541  (1977)."},{"id":2863,"pagetitle":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","ref":"/manopt/stable/tutorials/StochasticGradientDescent/#How-to-Run-Stochastic-Gradient-Descent","content":" How to Run Stochastic Gradient Descent Ronny Bergmann This tutorial illustrates how to use the  stochastic_gradient_descent  solver and different  DirectionUpdateRule s in order to introduce the average or momentum variant, see  Stochastic Gradient Descent . Computationally, we look at a very simple but large scale problem, the Riemannian Center of Mass or  Fr√©chet mean : for given points  $p_i ‚àà\\mathcal M$ ,  $i=1,‚Ä¶,N$  this optimization problem reads \\[\\operatorname*{arg\\,min}_{x‚àà\\mathcal M} \\frac{1}{2}\\sum_{i=1}^{N}\n  \\operatorname{d}^2_{\\mathcal M}(x,p_i),\\] which of course can be (and is) solved by a gradient descent, see the introductory tutorial or  Statistics in Manifolds.jl . If  $N$  is very large, evaluating the complete gradient might be quite expensive. A remedy is to evaluate only one of the terms at a time and choose a random order for these. We first initialize the packages using Manifolds, Manopt, Random, BenchmarkTools, ManifoldDiff\nusing ManifoldDiff: grad_distance\nRandom.seed!(42); We next generate a (little) large(r) data set n = 5000\nœÉ = œÄ / 12\nM = Sphere(2)\np = 1 / sqrt(2) * [1.0, 0.0, 1.0]\ndata = [exp(M, p,  œÉ * rand(M; vector_at=p)) for i in 1:n]; Note that due to the construction of the points as zero mean tangent vectors, the mean should be very close to our initial point  p . In order to use the stochastic gradient, we now need a function that returns the vector of gradients. There are two ways to define it in  Manopt.jl : either as a single function that returns a vector, or as a vector of functions. The first variant is of course easier to define, but the second is more efficient when only evaluating one of the gradients. For the mean, the gradient is \\[\\operatorname{grad}f(p) = \\sum_{i=1}^N \\operatorname{grad}f_i(x) \\quad \\text{where} \\operatorname{grad}f_i(x) = -\\log_x p_i\\] which we define in  Manopt.jl  in two different ways: either as one function returning all gradients as a vector (see  gradF ), or, maybe more fitting for a large scale problem, as a vector of small gradient functions (see  gradf ) F(M, p) = 1 / (2 * n) * sum(map(q -> distance(M, p, q)^2, data))\ngradF(M, p) = [grad_distance(M, p, q) for q in data]\ngradf = [(M, p) -> grad_distance(M, q, p) for q in data];\np0 = 1 / sqrt(3) * [1.0, 1.0, 1.0] 3-element Vector{Float64}:\n 0.5773502691896258\n 0.5773502691896258\n 0.5773502691896258 The calls are only slightly different, but notice that accessing the second gradient element requires evaluating all logs in the first function, while we only call  one  of the functions in the second array of functions. So while you can use both  gradF  and  gradf  in the following call, the second one is (much) faster: p_opt1 = stochastic_gradient_descent(M, gradF, p) 3-element Vector{Float64}:\n -0.19197815360666842\n  0.14005182005854327\n  0.026342223307325087 @benchmark stochastic_gradient_descent($M, $gradF, $p0) BenchmarkTools.Trial: 1 sample with 1 evaluation.\n Single result which took 6.647 s (3.28% GC) to evaluate,\n with a memory estimate of 7.83 GiB, over 100148148 allocations. p_opt2 = stochastic_gradient_descent(M, gradf, p0) 3-element Vector{Float64}:\n 0.09661685716733948\n 0.30673827339026233\n 0.9468774020688563 @benchmark stochastic_gradient_descent($M, $gradf, $p0) BenchmarkTools.Trial: 1328 samples with 1 evaluation.\n Range (min ‚Ä¶ max):  3.543 ms ‚Ä¶   6.571 ms  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 24.75%\n Time  (median):     3.625 ms               ‚îä GC (median):    0.00%\n Time  (mean ¬± œÉ):   3.764 ms ¬± 433.401 Œºs  ‚îä GC (mean ¬± œÉ):  2.95% ¬±  7.67%\n\n  ‚ñÇ‚ñá‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ  ‚ñÅ                                                   \n  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÑ‚ñá‚ñÜ‚ñà ‚ñà\n  3.54 ms      Histogram: log(frequency) by time      5.38 ms <\n\n Memory estimate: 3.13 MiB, allocs estimate: 40028. This result is reasonably close. But we can improve it by using a  DirectionUpdateRule , namely: On the one hand  MomentumGradient , which requires both the manifold and the initial value, in order to keep track of the iterate and parallel transport the last direction to the current iterate. The necessary  vector_transport_method  keyword is set to a suitable default on every manifold, see  default_vector_transport_method . We get ‚Äú‚Äú‚Äù p_opt3 = stochastic_gradient_descent(\n    M, gradf, p0; direction=MomentumGradient(M, p0; direction=StochasticGradient(M))\n) 3-element Vector{Float64}:\n 0.1171447617171425\n 0.05725413505115695\n 0.9914630950377215 MG = MomentumGradient(M, p0; direction=StochasticGradient(M));\n@benchmark stochastic_gradient_descent($M, $gradf, $p0; direction=$MG) BenchmarkTools.Trial: 395 samples with 1 evaluation.\n Range (min ‚Ä¶ max):  11.583 ms ‚Ä¶  16.517 ms  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 13.88%\n Time  (median):     12.170 ms               ‚îä GC (median):    0.00%\n Time  (mean ¬± œÉ):   12.672 ms ¬± 996.910 Œºs  ‚îä GC (mean ¬± œÉ):  4.15% ¬±  6.44%\n\n         ‚ñÉ‚ñà‚ñà‚ñÉ‚ñÇ                                                  \n  ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ ‚ñÉ\n  11.6 ms         Histogram: frequency by time         14.9 ms <\n\n Memory estimate: 10.75 MiB, allocs estimate: 229514. And on the other hand the  AverageGradient  computes an average of the last  n  gradients. This is done by p_opt4 = stochastic_gradient_descent(\n    M, gradf, p0; direction=AverageGradient(M, p0; n=10, direction=StochasticGradient(M))\n) 3-element Vector{Float64}:\n 0.7070861844343661\n 0.073684150141652\n 0.7032778780823064 AG = AverageGradient(M, p0; n=10, direction=StochasticGradient(M));\n@benchmark stochastic_gradient_descent($M, $gradf, $p0; direction=$AG) BenchmarkTools.Trial: 127 samples with 1 evaluation.\n Range (min ‚Ä¶ max):  37.134 ms ‚Ä¶ 43.508 ms  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 5.69%\n Time  (median):     39.725 ms              ‚îä GC (median):    5.16%\n Time  (mean ¬± œÉ):   39.552 ms ¬±  1.129 ms  ‚îä GC (mean ¬± œÉ):  4.15% ¬± 2.30%\n\n         ‚ñÉ                    ‚ñÇ‚ñÇ‚ñÉ ‚ñà                            \n  ‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñÜ‚ñá‚ñà‚ñÉ‚ñÜ‚ñÅ‚ñÉ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ ‚ñÉ\n  37.1 ms         Histogram: frequency by time        42.1 ms <\n\n Memory estimate: 33.64 MiB, allocs estimate: 549514. Note that the default  StoppingCriterion  is a fixed number of iterations which helps the comparison here. For both update rules we have to internally specify that we are still in the stochastic setting, since both rules can also be used with the  IdentityUpdateRule  within  gradient_descent . For this not-that-large-scale example we can of course also use a gradient descent with  ArmijoLinesearch , fullGradF(M, p) = sum(grad_distance(M, q, p) for q in data)\np_opt5 = gradient_descent(M, F, fullGradF, p0; stepsize=ArmijoLinesearch(M)) 3-element Vector{Float64}:\n  0.7290042250431187\n -0.025172376642359287\n  0.6840461909282558 but it will be a little slower usually AL = ArmijoLinesearch(M);\n@benchmark gradient_descent($M, $F, $fullGradF, $p0; stepsize=$AL) BenchmarkTools.Trial: 8 samples with 1 evaluation.\n Range (min ‚Ä¶ max):  626.993 ms ‚Ä¶ 638.446 ms  ‚îä GC (min ‚Ä¶ max): 4.49% ‚Ä¶ 4.30%\n Time  (median):     627.202 ms               ‚îä GC (median):    4.44%\n Time  (mean ¬± œÉ):   630.131 ms ¬±   5.093 ms  ‚îä GC (mean ¬± œÉ):  4.42% ¬± 0.07%\n\n  ‚ñà‚ñÉ                                                             \n  ‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá ‚ñÅ\n  627 ms           Histogram: frequency by time          638 ms <\n\n Memory estimate: 749.00 MiB, allocs estimate: 12025142. Note that all 5 runs are very close to each other, here we check the distance to the first"},{"id":2866,"pagetitle":"Error estimation","title":"Error estimation","ref":"/manifolddiffeq/stable/#Error-estimation","content":" Error estimation Methods with time step adaptation require estimating the error of the solution. The error is then forwarded to algorithms from OrdinaryDiffEq.jl, see  documentation ."},{"id":2867,"pagetitle":"Error estimation","title":"ManifoldDiffEq.calculate_eest","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.calculate_eest-Tuple{AbstractManifold, Any, Any, Any, Any, Any, Any, Any}","content":" ManifoldDiffEq.calculate_eest  ‚Äî  Method calculate_eest(M::AbstractManifold, utilde, uprev, u, abstol, reltol, internalnorm, t) Estimate error of a solution of an ODE on manifold  M . Arguments utilde  ‚Äì point on  M  for error estimation, uprev  ‚Äì point from before the current step, u  ‚Äì point after the current step`, abstol  - abolute tolerance, reltol  - relative tolerance, internalnorm  ‚Äì copied  internalnorm  from the integrator, t  ‚Äì time at which the error is estimated. source"},{"id":2868,"pagetitle":"Error estimation","title":"ManifoldDiffEq.reltol_norm","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.reltol_norm-Tuple{AbstractManifold, Any}","content":" ManifoldDiffEq.reltol_norm  ‚Äî  Method reltol_norm(M::AbstractManifold, u) Estimate the fraction  d_{min}/eps(number_eltype(u))  where  d_{min}  is the distance between  u , a point on  M , and the nearest distinct point on  M  representable in the representation of  u . source"},{"id":2869,"pagetitle":"Error estimation","title":"Literature","ref":"/manifolddiffeq/stable/#Literature","content":" Literature"},{"id":2872,"pagetitle":"Examples","title":"Examples","ref":"/manifolddiffeq/stable/#Examples","content":" Examples We take a look at the simple example from In the following code an ODE on a sphere is solved the introductionary example from the  lecture notes  by  E. Hairer . We solve the ODE system on the sphere  $\\mathbb S^2$  given by \\[\\begin{pmatrix}\n    \\dot x \\\\\n    \\dot y \\\\\n    \\dot z\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n    0 & z/I_3 & -y/I_2 \\\\\n    -z/I_3 & 0 & x/I_1 \\\\\n    y/I_2& -x/I_1 & 0\n\\end{pmatrix}\n\\begin{pmatrix}\n    x \\\\\n    y \\\\\n    z\n\\end{pmatrix}\\] using ManifoldDiffEq, OrdinaryDiffEq, Manifolds\nusing GLMakie, LinearAlgebra, Colors\n\nn = 25\n\nŒ∏ = [0;(0.5:n-0.5)/n;1]\nœÜ = [(0:2n-2)*2/(2n-1);2]\nx = [cospi(œÜ)*sinpi(Œ∏) for Œ∏ in Œ∏, œÜ in œÜ]\ny = [sinpi(œÜ)*sinpi(Œ∏) for Œ∏ in Œ∏, œÜ in œÜ]\nz = [cospi(Œ∏) for Œ∏ in Œ∏, œÜ in œÜ]\n\nfunction f2(x, y, z)\n    Iv = [1.6, 1.0, 2/3]\n    p = [x, y, z]\n    A = [0 -z y; z 0 -x; -y x 0]\n    return A * (p./Iv)\nend\n\ntans = f2.(vec(x), vec(y), vec(z))\nu = [a[1] for a in tans]\nv = [a[2] for a in tans]\nw = [a[3] for a in tans]\n\nf = Figure();\nAxis3(f[1,1])\n\narr = GLMakie.arrows!(\n           vec(x), vec(y), vec(z), u, v, w;\n           arrowsize = 0.02, linecolor = (:gray, 0.7), linewidth = 0.0075, lengthscale = 0.1\n)\nsave(\"docs/src/assets/img/first_example_vector_field.png\", f) which looks like Let's set up the manifold, the  sphere  and two different types of problems/solvers A first one that uses the Lie group action of the  Special orthogonal group  acting on data with 2 solvers and direct solvers on the sphere, using 3 other solvers using the idea of frozen coefficients. S2 = Manifolds.Sphere(2)\nu0 = [0.0, sqrt(9/10), sqrt(1/10)]\ntspan = (0, 20.0)\n\nA_lie = ManifoldDiffEq.LieManifoldDiffEqOperator{Float64}() do u, p, t\n    return hat(SpecialOrthogonal(3), Matrix(I(3)), cross(u, f2(u...)))\nend\nprob_lie = ManifoldDiffEq.ManifoldODEProblem(A_lie, u0, tspan, S2)\n\nA_frozen = ManifoldDiffEq.FrozenManifoldDiffEqOperator{Float64}() do u, p, t\n    return f2(u...)\nend\nprob_frozen = ManifoldDiffEq.ManifoldODEProblem(A_frozen, u0, tspan, S2)\n\naction = RotationAction(Euclidean(3), SpecialOrthogonal(3))\nalg_lie_euler = ManifoldDiffEq.ManifoldLieEuler(S2, ExponentialRetraction(), action)\nalg_lie_rkmk4 = ManifoldDiffEq.RKMK4(S2, ExponentialRetraction(), action)\n\nalg_manifold_euler = ManifoldDiffEq.ManifoldEuler(S2, ExponentialRetraction())\nalg_cg2 = ManifoldDiffEq.CG2(S2, ExponentialRetraction())\nalg_cg23 = ManifoldDiffEq.CG2_3(S2, ExponentialRetraction())\nalg_cg3 = ManifoldDiffEq.CG3(S2, ExponentialRetraction())\n\ndt = 0.1\nsol_lie = solve(prob_lie, alg_lie_euler, dt = dt)\nsol_rkmk4 = solve(prob_lie, alg_lie_rkmk4, dt = dt)\n\nsol_frozen = solve(prob_frozen, alg_manifold_euler, dt=dt)\nsol_frozen_cg2 = solve(prob_frozen, alg_cg2, dt = dt)\nsol_frozen_cg23 = solve(prob_frozen, alg_cg23)\nsol_frozen_cg3 = solve(prob_frozen, alg_cg3, dt = dt)\n\nplot_sol(sol, col) = GLMakie.lines!([u[1] for u in sol.u], [u[2] for u in sol.u], [u[3] for u in sol.u]; linewidth = 2, color=col)\n\nl1 = plot_sol(sol_lie, colorant\"#999933\")\nl2 = plot_sol(sol_rkmk4, colorant\"#DDCC77\")\nl3 = plot_sol(sol_frozen, colorant\"#332288\")\nl4 = plot_sol(sol_frozen_cg2, colorant\"#CCEE88\")\nl5 = plot_sol(sol_frozen_cg23, colorant\"#88CCEE\")\nl6 = plot_sol(sol_frozen_cg3, colorant\"#44AA99\")\nLegend(f[1, 2],\n    [l1, l2, l3, l4, l5, l6],\n    [\"Lie Euler\", \"RKMK4\", \"Euler\", \"CG2\", \"CG2(3)\", \"CG3\"]\n)\nsave(\"docs/src/assets/img/first_example_solutions.png\", f) And the solutions look like Note that  alg_cg23  uses adaptive time stepping."},{"id":2875,"pagetitle":"Frozen coefficients solvers","title":"Frozen coefficients solvers","ref":"/manifolddiffeq/stable/#Frozen-coefficients-solvers","content":" Frozen coefficients solvers An initial value problem manifold ordinary differential equation in the frozen coefficients formulation by Crouch and Grossman, see [ CG93 ]. A frozen coefficients ODE on manifold  $M$  is defined in terms a vector field  $F\\colon (M √ó P √ó ‚Ñù) \\to T_p M$  where  $p$  is the point given as the third argument to  $F$ , with an initial value  $y_0$  and  $P$  is the space of constant parameters. Frozen coefficients mean that we also have means to transport a vector  $X \\in T_p M$  obtained from  $F$  to a different point on a manifold or a different time (parameters are assumed to be constant). This is performed through  operator_vector_transport , an object of a subtype of  AbstractVectorTransportOperator , stored in  FrozenManifoldDiffEqOperator . A solution to this problem is a curve  $y\\colon ‚Ñù\\to M$  such that  $y(0)=y_0$  and for each  $t \\in [0, T]$  we have  $D_t y(t) = F(y(t), p, t)$ . The problem is usually studied for manifolds that are Lie groups or homogeneous manifolds, see[ CMO14 ]. Note that in this formulation  $s$ -stage explicit Runge-Kutta schemes that for  $\\mathbb{R}^n$  are defined by equations \\[\\begin{align*}\nX_1 &= f(u_n, p, t) \\\\\nX_2 &= f(u_n+h a_{2,1} X_1, p, t+c_2 h) \\\\\nX_3 &= f(u_n+h a_{3,1} X_1 + a_{3,2} X_2, p, t+c_3 h) \\\\\n&\\vdots \\\\\nX_s &= f(u_n+h a_{s,1} X_1 + a_{s,2} X_2 + \\dots + a_{s,s-1} X_{s-1}, p, t+c_s h) \\\\\nu_{n+1} &= u_n + h\\sum_{i=1}^s b_i X_i\n\\end{align*}\\] for general manifolds read \\[\\begin{align*}\nX_1 &= f(u_n, p, t) \\\\\nu_{n,2,1} &= \\exp_{u_n}(h a_{2,1} X_1) \\\\\nX_2 &= f(u_{n,2,1}, p, t+c_2 h) \\\\\nu_{n,3,1} &= \\exp_{u_n}(h a_{3,1} X_1) \\\\\nu_{n,3,2} &= \\exp_{u_{n,3,1}}(\\mathcal P_{u_{n,3,1}\\gets u_{n,2,1}} h a_{3,2} X_2) \\\\\nX_3 &= f(u_{n,3,2}, p, t+c_3 h) \\\\\n&\\vdots \\\\\nX_s &= f(u_{n,s,s-1}, p, t+c_s h) \\\\\nX_{b,1} &= X_1 \\\\\nu_{b,1} &= \\exp_{u_n}(h b_1 X_{b,1}) \\\\\nX_{b,2} &= \\mathcal P_{u_{b,1} \\gets u_{n,2,1}} X_2 \\\\\nu_{b,2} &= \\exp_{u_{b,1}}(h b_2 X_{b,2}) \\\\\n&\\vdots \\\\\nX_{b,s} &= \\mathcal P_{u_{b,s-1} \\gets u_{n,s,s-1}} X_s \\\\\nu_{n+1} &= \\exp_{u_{b,s-1}}(h b_s X_{b,s})\n\\end{align*}\\] Vector transports correspond to handling frozen coefficients. Note that the implementation allows for easy substitution of methods used for calculation of the exponential map (for example to use an approximation) and vector transport (if the default vector transport is not suitable for the problem). It is desirable to use a flat vector transport instead of a torsion-free one when available, for example the plus or minus Cartan-Schouten connections on Lie groups."},{"id":2876,"pagetitle":"Frozen coefficients solvers","title":"ManifoldDiffEq.CG2","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.CG2","content":" ManifoldDiffEq.CG2  ‚Äî  Type CG2 A Crouch-Grossmann algorithm of second order for problems in the  ExplicitManifoldODEProblemType  formulation. The Butcher tableau is identical to the Euclidean RK2: \\[\\begin{array}{c|cc}\n0 & 0 \\\\\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\hline\n& 0 & 1\n\\end{array}\\] source"},{"id":2877,"pagetitle":"Frozen coefficients solvers","title":"ManifoldDiffEq.CG2Cache","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.CG2Cache","content":" ManifoldDiffEq.CG2Cache  ‚Äî  Type CG2Cache Cache for  CG2 . source"},{"id":2878,"pagetitle":"Frozen coefficients solvers","title":"ManifoldDiffEq.CG2_3","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.CG2_3","content":" ManifoldDiffEq.CG2_3  ‚Äî  Type CG2_3 A Crouch-Grossmann algorithm of order 2(3) for problems in the  ExplicitManifoldODEProblemType  formulation. The Butcher tableau reads (see tableau (5) of [ EM98 ]): \\[\\begin{array}{c|ccc}\n0 & 0 \\\\\n\\frac{3}{4} & \\frac{3}{4} & 0 \\\\\n\\frac{17}{24} & \\frac{119}{216} & \\frac{17}{108} & 0\\\\\n\\hline\n& \\frac{3}{4} & \\frac{31}{4} & \\frac{-15}{2}\n& \\frac{13}{51} & -\\frac{2}{3} & \\frac{24}{17}\n\\end{array}\\] The last row is used for error estimation. source"},{"id":2879,"pagetitle":"Frozen coefficients solvers","title":"ManifoldDiffEq.CG2_3Cache","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.CG2_3Cache","content":" ManifoldDiffEq.CG2_3Cache  ‚Äî  Type CG2_3Cache Cache for  CG2_3 . source"},{"id":2880,"pagetitle":"Frozen coefficients solvers","title":"ManifoldDiffEq.CG3","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.CG3","content":" ManifoldDiffEq.CG3  ‚Äî  Type CG3 A Crouch-Grossmann algorithm of second order for problems in the  ExplicitManifoldODEProblemType  formulation. See tableau 6.1 of [ OM99 ]: \\[\\begin{array}{c|ccc}\n0 & 0 \\\\\n\\frac{3}{4} & \\frac{3}{4} & 0 \\\\\n\\frac{17}{24} & \\frac{119}{216} & \\frac{17}{108} & 0\\\\\n\\hline\n& \\frac{13}{51} & -\\frac{2}{3} & \\frac{24}{17}\n\\end{array}\\] source"},{"id":2881,"pagetitle":"Frozen coefficients solvers","title":"ManifoldDiffEq.CG3Cache","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.CG3Cache","content":" ManifoldDiffEq.CG3Cache  ‚Äî  Type CG3Cache Cache for  CG3 . source"},{"id":2882,"pagetitle":"Frozen coefficients solvers","title":"ManifoldDiffEq.CG4a","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.CG4a","content":" ManifoldDiffEq.CG4a  ‚Äî  Type CG4a A Crouch-Grossmann algorithm of second order for problems in the  ExplicitManifoldODEProblemType  formulation. See coefficients from Example 1 of [ JMO00 ]. source"},{"id":2883,"pagetitle":"Frozen coefficients solvers","title":"ManifoldDiffEq.CG4aCache","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.CG4aCache","content":" ManifoldDiffEq.CG4aCache  ‚Äî  Type CG4aCache Cache for  CG4a . source"},{"id":2884,"pagetitle":"Frozen coefficients solvers","title":"ManifoldDiffEq.ManifoldEuler","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.ManifoldEuler","content":" ManifoldDiffEq.ManifoldEuler  ‚Äî  Type ManifoldEuler The manifold Euler algorithm for problems in the  ExplicitManifoldODEProblemType  formulation. source"},{"id":2885,"pagetitle":"Frozen coefficients solvers","title":"ManifoldDiffEq.ManifoldEulerCache","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.ManifoldEulerCache","content":" ManifoldDiffEq.ManifoldEulerCache  ‚Äî  Type ManifoldEulerCache Cache for  ManifoldEuler . source"},{"id":2886,"pagetitle":"Frozen coefficients solvers","title":"ManifoldDiffEq.ManifoldEulerConstantCache","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.ManifoldEulerConstantCache","content":" ManifoldDiffEq.ManifoldEulerConstantCache  ‚Äî  Type ManifoldEulerConstantCache Cache for  ManifoldEuler . source"},{"id":2887,"pagetitle":"Frozen coefficients solvers","title":"ManifoldDiffEq.ExplicitManifoldODEProblemType","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.ExplicitManifoldODEProblemType","content":" ManifoldDiffEq.ExplicitManifoldODEProblemType  ‚Äî  Type ExplicitManifoldODEProblemType An initial value problem manifold ordinary differential equation in the frozen coefficients formulation by Crouch and Grossman, see [ CG93 ]. A frozen coefficients ODE on manifold  $M$  is defined in terms a vector field  $F: (M √ó P √ó ‚Ñù) \\to T_p M$  where  $p$  is the point given as the third argument to  $F$ , with an initial value  $y‚ÇÄ$  and  $P$  is the space of constant parameters. A solution to this problem is a curve  $y:‚Ñù\\to M$  such that  $y(0)=y‚ÇÄ$  and for each  $t ‚àà [0, T]$  we have  $D_t y(t) = F(y(t), p, t)$ , Note Proofs of convergence and order have several assumptions, including time-independence of  $F$ . Integrators may not work well if these assumptions do not hold. source"},{"id":2888,"pagetitle":"Frozen coefficients solvers","title":"ManifoldDiffEq.FrozenManifoldDiffEqOperator","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.FrozenManifoldDiffEqOperator","content":" ManifoldDiffEq.FrozenManifoldDiffEqOperator  ‚Äî  Type FrozenManifoldDiffEqOperator{T<:Number,TM<:AbstractManifold,TF,TVT} <: SciMLBase.AbstractDiffEqOperator{T} DiffEq operator on manifolds in the frozen vector field formulation. source"},{"id":2889,"pagetitle":"Frozen coefficients solvers","title":"ManifoldDiffEq.AbstractVectorTransportOperator","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.AbstractVectorTransportOperator","content":" ManifoldDiffEq.AbstractVectorTransportOperator  ‚Äî  Type AbstractVectorTransportOperator Abstract type for vector transport operators in the frozen coefficients formulation. source"},{"id":2890,"pagetitle":"Frozen coefficients solvers","title":"ManifoldDiffEq.DefaultVectorTransportOperator","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.DefaultVectorTransportOperator","content":" ManifoldDiffEq.DefaultVectorTransportOperator  ‚Äî  Type (vto::DefaultVectorTransportOperator)(M::AbstractManifold, p, X, q, params, t_from, t_to) In the frozen coefficient formulation, transport tangent vector  X  such that  X = f(p, params, t_from)  to point  q  at time  t_to . This provides a sort of estimation of  f(q, params, t_to) . source"},{"id":2891,"pagetitle":"Frozen coefficients solvers","title":"Literature","ref":"/manifolddiffeq/stable/#Literature","content":" Literature"},{"id":2894,"pagetitle":"Home","title":"ManifoldDiffEq","ref":"/manifolddiffeq/stable/#ManifoldDiffEq","content":" ManifoldDiffEq The package  ManifoldDiffEq  aims to provide a library of differential equation solvers on manifolds. The library is built on top of  Manifolds.jl  and follows the interface of  OrdinaryDiffEq.jl . The code below demonstrates usage of  ManifoldDiffEq  to solve a simple equation and visualize the results. Methods implemented in this library are described for example in[ HLW10 ]."},{"id":2895,"pagetitle":"Home","title":"ManifoldDiffEq.ManifoldODEProblem","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.ManifoldODEProblem","content":" ManifoldDiffEq.ManifoldODEProblem  ‚Äî  Type ManifoldODEProblem A general problem for ODE problems on Riemannian manifolds. Fields f  the tangent vector field  f(u,p,t) u0  the initial condition tspan  time interval for the solution p  constant parameters for  f ` kwargs  A callback to be applied to every solver which uses the problem. problem_type  type of problem manifold  the manifold the vector field is defined on source"},{"id":2896,"pagetitle":"Home","title":"Literature","ref":"/manifolddiffeq/stable/#Literature","content":" Literature"},{"id":2899,"pagetitle":"Lie group action solvers","title":"Lie group solvers","ref":"/manifolddiffeq/stable/#Lie-group-solvers","content":" Lie group solvers An initial value problem manifold ordinary differential equation in the Lie action formulation. A Lie ODE on manifold  $M$  is defined in terms a vector field  $F: (M √ó P √ó ‚Ñù) \\to ùî§$  where  $ùî§$  is the Lie algebra of a Lie group  $G$  acting on  $M$ , with an initial value  $y_0$  and  $P$  is the space of constant parameters. A solution to this problem is a curve  $y\\colon ‚Ñù\\to M$  such that  $y(0)=y_0$  and for each  $t \\in [0, T]$  we have  $D_t y(t) = f(y(t), p, t)\\circ y(t)$ , where the  $\\circ$  is defined as \\[X\\circ m = \\frac{d}{dt}\\vert_{t=0} \\exp(tZ)\\cdot m\\] and  $\\cdot$  is the group action of  $G$  on  $M$ . The Lie group  $G$  must act transitively on  $M$ , that is for each pair of points  $p, q$  on  $M$  there is an element  $a \\in G$  such that  $a\\cdot p = q$ . See for example [ CMO14 ] for details."},{"id":2900,"pagetitle":"Lie group action solvers","title":"ManifoldDiffEq.ManifoldLieEuler","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.ManifoldLieEuler","content":" ManifoldDiffEq.ManifoldLieEuler  ‚Äî  Type ManifoldLieEuler The manifold Lie-Euler algorithm for problems in the  LieODEProblemType  formulation. source"},{"id":2901,"pagetitle":"Lie group action solvers","title":"ManifoldDiffEq.ManifoldLieEulerCache","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.ManifoldLieEulerCache","content":" ManifoldDiffEq.ManifoldLieEulerCache  ‚Äî  Type ManifoldLieEulerCache Cache for  ManifoldLieEuler . source"},{"id":2902,"pagetitle":"Lie group action solvers","title":"ManifoldDiffEq.ManifoldLieEulerConstantCache","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.ManifoldLieEulerConstantCache","content":" ManifoldDiffEq.ManifoldLieEulerConstantCache  ‚Äî  Type ManifoldLieEulerConstantCache Constant cache for  ManifoldLieEuler . source"},{"id":2903,"pagetitle":"Lie group action solvers","title":"ManifoldDiffEq.RKMK4","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.RKMK4","content":" ManifoldDiffEq.RKMK4  ‚Äî  Type RKMK4 The Lie group variant of fourth-order Runge-Kutta algorithm for problems in the  LieODEProblemType  formulation, called Runge-Kutta Munthe-Kaas. The Butcher tableau is: \\[\\begin{array}{c|cccc}\n0 & 0 \\\\\n\\frac{1}{2} & 0 & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n1 & 0 & 0 & 1 & 0\\\\\n\\hline\n& \\frac{1}{6} & \\frac{1}{3} & \\frac{1}{6} & \\frac{1}{6}\n\\end{array}\\] For more details see [ MO99 ]. source"},{"id":2904,"pagetitle":"Lie group action solvers","title":"ManifoldDiffEq.RKMK4Cache","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.RKMK4Cache","content":" ManifoldDiffEq.RKMK4Cache  ‚Äî  Type RKMK4Cache Cache for  RKMK4 . source"},{"id":2905,"pagetitle":"Lie group action solvers","title":"ManifoldDiffEq.RKMK4ConstantCache","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.RKMK4ConstantCache","content":" ManifoldDiffEq.RKMK4ConstantCache  ‚Äî  Type RKMK4ConstantCache Constant cache for  RKMK4 . source"},{"id":2906,"pagetitle":"Lie group action solvers","title":"ManifoldDiffEq.LieODEProblemType","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.LieODEProblemType","content":" ManifoldDiffEq.LieODEProblemType  ‚Äî  Type LieODEProblemType An initial value problem manifold ordinary differential equation in the Lie action formulation. A Lie ODE on manifold  $M$  is defined in terms a vector field  $F: (‚Ñù √ó P √ó M) \\to ùî§$  where  $ùî§$  is the Lie algebra of a Lie group  $G$  acting on  $M$ , with an initial value  $y‚ÇÄ$  and  $P$  is the space of constant parameters. A solution to this problem is a curve  $y:‚Ñù\\to M$  such that  $y(0)=y‚ÇÄ$  and for each  $t ‚àà [0, T]$  we have  $D_t y(t) = F(y(t), p, t)‚àòy(t)$ , where the  $‚àò$  is defined as \\[X‚àòm = \\frac{d}{dt}\\vert_{t=0} \\exp(tZ)‚ãÖm\\] and  $‚ãÖ$  is the group action of  $G$  on  $M$ . Note Proofs of convergence and order have several assumptions, including time-independence of  $F$ . Integrators may not work well if these assumptions do not hold. source"},{"id":2907,"pagetitle":"Lie group action solvers","title":"ManifoldDiffEq.LieManifoldDiffEqOperator","ref":"/manifolddiffeq/stable/#ManifoldDiffEq.LieManifoldDiffEqOperator","content":" ManifoldDiffEq.LieManifoldDiffEqOperator  ‚Äî  Type LieManifoldDiffEqOperator{T<:Number,TF} <: AbstractDiffEqOperator{T} DiffEq operator on manifolds in the Lie group action formulation. source"},{"id":2908,"pagetitle":"Lie group action solvers","title":"Literature","ref":"/manifolddiffeq/stable/#Literature","content":" Literature"},{"id":2911,"pagetitle":"Notation","title":"Notation","ref":"/manifolddiffeq/stable/#Notation","content":" Notation Notation of ManifoldDiffEq.jl mostly follows the  notation of Manifolds.jl . There are, however, a few changes to more closely match the notation of the DiffEq ecosystem. Namely: u  is often used to denote points on a manifold. Tangent vectors are usually denoted by  $X$ ,  $Y$  but some places may use the symbol  $k$ . Parameters of the solved function are denoted either by  $p$  or  params , depending on the context."},{"id":2914,"pagetitle":"References","title":"Literature","ref":"/manifolddiffeq/stable/#Literature","content":" Literature [CMO14] E.¬†Celledoni, H.¬†Marthinsen and B.¬†Owren.  An introduction to Lie group integrators ‚Äì basics, new developments and applications .  Journal¬†of¬†Computational¬†Physics  257 , 1040‚Äì1061  (2014). Accessed on Jul 14, 2021, arXiv: 1207.0069. [CG93] P.¬†E.¬†Crouch and R.¬†Grossman.  Numerical integration of ordinary differential equations on manifolds .  Journal¬†of¬†Nonlinear¬†Science  3 , 1‚Äì33  (1993). Accessed on Jul 17, 2021. [EM98] K.¬†Eng√∏ and A.¬†Marthinsen.  Modeling and Solution of Some Mechanical Problems on Lie Groups .  Multibody¬†System¬†Dynamics  2 , 71‚Äì88  (1998). Accessed on Oct 13, 2021. [HLW10] E.¬†Hairer, C.¬†Lubich and G.¬†Wanner.  Geometric Numerical Integration: Structure-Preserving Algorithms for Ordinary Differential Equations . 2nd ed. 2006. 2nd printing 2010 edition¬†Edition (Springer, Heidelberg ; New York, 2010). [JMO00] Z.¬†Jackiewicz, A.¬†Marthinsen and B.¬†Owren.  Construction of Runge‚ÄìKutta methods of Crouch‚ÄìGrossman type of high order .  Advances¬†in¬†Computational¬†Mathematics  13 , 405‚Äì415  (2000). Accessed on Oct 15, 2021. [MO99] H.¬†Munthe‚ÄìKaas and B.¬†Owren.  Computations in a free Lie algebra .  Philosophical¬†Transactions¬†of¬†the¬†Royal¬†Society¬†of¬†London.¬†Series¬†A:¬†Mathematical,¬†Physical¬†and¬†Engineering¬†Sciences  357 , 957‚Äì981  (1999). Accessed on Jul 14, 2021. Publisher: Royal Society. [OM99] B.¬†Owren and A.¬†Marthinsen.  Runge-Kutta Methods Adapted to Manifolds and Based on Rigid Frames .  BIT¬†Numerical¬†Mathematics  39 , 116‚Äì142  (1999). Accessed on Jul 15, 2021."},{"id":2917,"pagetitle":"Home","title":"ManifoldDiff","ref":"/manifolddiff/stable/#ManifoldDiff","content":" ManifoldDiff The package  ManifoldDiff  aims to provide automatic calculation of Riemannian gradients of functions defined on manifolds. It builds upon  Manifolds.jl ."},{"id":2918,"pagetitle":"Home","title":"Naming scheme","ref":"/manifolddiff/stable/#Naming-scheme","content":" Naming scheme Providing a derivative, differential or gradient for a given function, this package adds that information to the function name. For example grad_f  for a gradient  $\\operatorname{grad} f$ subgrad_f  for a subgradient from the subdifferential $\\partial f$ differential_f  for  $Df$  (also called pushforward) differential_f_variable  if  f  has multiple variables / parameters, since a usual writing in math is  $f_x$  in this case adjoint_differential_f  for pullbacks adjoint_differential_f_variable  if  f  has multiple variables / parameters f_derivative  for  $f'$ the scheme is not completely fixed but tries to follow the mathematical notation."},{"id":2921,"pagetitle":"Backends","title":"Differentiation backends","ref":"/manifolddiff/stable/backends/#Differentiation-backends","content":" Differentiation backends"},{"id":2922,"pagetitle":"Backends","title":"ManifoldDiff.set_default_differential_backend!","ref":"/manifolddiff/stable/backends/#ManifoldDiff.set_default_differential_backend!","content":" ManifoldDiff.set_default_differential_backend!  ‚Äî  Function set_default_differential_backend!(backend::AbstractDiffBackend) Set current backend for differentiation to  backend . source"},{"id":2923,"pagetitle":"Backends","title":"ManifoldDiff.default_differential_backend","ref":"/manifolddiff/stable/backends/#ManifoldDiff.default_differential_backend","content":" ManifoldDiff.default_differential_backend  ‚Äî  Function default_differential_backend() -> AbstractDiffBackend Get the default differentiation backend. source"},{"id":2924,"pagetitle":"Backends","title":"EmbeddedDiff","ref":"/manifolddiff/stable/backends/#EmbeddedDiff","content":" EmbeddedDiff"},{"id":2925,"pagetitle":"Backends","title":"ManifoldDiff.ExplicitEmbeddedBackend","ref":"/manifolddiff/stable/backends/#ManifoldDiff.ExplicitEmbeddedBackend","content":" ManifoldDiff.ExplicitEmbeddedBackend  ‚Äî  Type ExplicitEmbeddedBackend{TF<:NamedTuple} <: AbstractDiffBackend A backend to use with the  RiemannianProjectionBackend  or the  TangentDiffBackend , when you have explicit formulae for the gradient in the embedding available. Constructor ExplicitEmbeddedBackend(M::AbstractManifold; kwargs) Construct an  ExplicitEmbeddedBackend  in the embedding  M , where currently the following keywords may be used gradient  for a(n allocating) gradient function  gradient(M, p)  defined in the embedding gradient!  for a mutating gradient function  gradient!(M, X, p) . Note that the gradient functions are defined on the embedding manifold  M  passed to the Backend as well source"},{"id":2926,"pagetitle":"Backends","title":"ForwardDiff.jl","ref":"/manifolddiff/stable/backends/#ForwardDiff.jl","content":" ForwardDiff.jl"},{"id":2927,"pagetitle":"Backends","title":"ManifoldDiff.ForwardDiffBackend","ref":"/manifolddiff/stable/backends/#ManifoldDiff.ForwardDiffBackend","content":" ManifoldDiff.ForwardDiffBackend  ‚Äî  Type ForwardDiffBackend <: AbstractDiffBackend Differentiation backend based on the ForwardDiff.jl package. source"},{"id":2928,"pagetitle":"Backends","title":"FiniteDiff.jl","ref":"/manifolddiff/stable/backends/#FiniteDiff.jl","content":" FiniteDiff.jl"},{"id":2929,"pagetitle":"Backends","title":"ManifoldDiff.FiniteDiffBackend","ref":"/manifolddiff/stable/backends/#ManifoldDiff.FiniteDiffBackend","content":" ManifoldDiff.FiniteDiffBackend  ‚Äî  Type FiniteDiffBackend <: AbstractDiffBackend A type to specify / use differentiation backend based on FiniteDiff.jl package. Constructor FiniteDiffBackend(method::Val{Symbol} = Val{:central}) source"},{"id":2930,"pagetitle":"Backends","title":"FiniteDifferenes.jl","ref":"/manifolddiff/stable/backends/#FiniteDifferenes.jl","content":" FiniteDifferenes.jl"},{"id":2931,"pagetitle":"Backends","title":"ManifoldDiff.FiniteDifferencesBackend","ref":"/manifolddiff/stable/backends/#ManifoldDiff.FiniteDifferencesBackend","content":" ManifoldDiff.FiniteDifferencesBackend  ‚Äî  Type FiniteDifferencesBackend(method::FiniteDifferenceMethod = central_fdm(5, 1)) Differentiation backend based on the FiniteDifferences.jl package. source"},{"id":2934,"pagetitle":"Internals","title":"Internal functions","ref":"/manifolddiff/stable/internals/#Internal-functions","content":" Internal functions"},{"id":2935,"pagetitle":"Internals","title":"ManifoldDiff.AbstractDiffBackend","ref":"/manifolddiff/stable/internals/#ManifoldDiff.AbstractDiffBackend","content":" ManifoldDiff.AbstractDiffBackend  ‚Äî  Type AbstractDiffBackend An abstract type for diff backends. See  FiniteDifferencesBackend  for an example. source"},{"id":2936,"pagetitle":"Internals","title":"ManifoldDiff.CurrentDiffBackend","ref":"/manifolddiff/stable/internals/#ManifoldDiff.CurrentDiffBackend","content":" ManifoldDiff.CurrentDiffBackend  ‚Äî  Type CurrentDiffBackend(backend::AbstractDiffBackend) A mutable struct for storing the current differentiation backend in a global constant  _current_default_differential_backend . See also AbstractDiffBackend ,  default_differential_backend ,  set_default_differential_backend! source"},{"id":2937,"pagetitle":"Internals","title":"ManifoldDiff._current_default_differential_backend","ref":"/manifolddiff/stable/internals/#ManifoldDiff._current_default_differential_backend","content":" ManifoldDiff._current_default_differential_backend  ‚Äî  Constant _current_default_differential_backend The instance of  CurrentDiffBackend  that stores the globally default differentiation backend. source"},{"id":2938,"pagetitle":"Internals","title":"ManifoldDiff._hessian","ref":"/manifolddiff/stable/internals/#ManifoldDiff._hessian","content":" ManifoldDiff._hessian  ‚Äî  Function _hessian(f, p[, backend::AbstractDiffBackend]) Compute the Hessian of a callable  f  at point  p  computed using the given  backend , an object of type  AbstractDiffBackend . If the backend is not explicitly specified, it is obtained using the function  default_differential_backend . This function calculates plain Euclidean Hessian. Note Not specifying the backend explicitly will usually result in a type instability and decreased performance. source"},{"id":2939,"pagetitle":"Internals","title":"ManifoldDiff._jacobian","ref":"/manifolddiff/stable/internals/#ManifoldDiff._jacobian","content":" ManifoldDiff._jacobian  ‚Äî  Function _jacobian(f, p[, backend::AbstractDiffBackend]) Compute the Jacobian of a callable  f  at point  p  computed using the given  backend , an object of type  AbstractDiffBackend . If the backend is not explicitly specified, it is obtained using the function  default_differential_backend . This function calculates plain Euclidean Jacobians, for Riemannian Jacobian calculation see for example  gradient . Note Not specifying the backend explicitly will usually result in a type instability and decreased performance. source"},{"id":2940,"pagetitle":"Internals","title":"ManifoldDiff._gradient","ref":"/manifolddiff/stable/internals/#ManifoldDiff._gradient","content":" ManifoldDiff._gradient  ‚Äî  Function _gradient(f, p[, backend::AbstractDiffBackend]) Compute the gradient of a callable  f  at point  p  computed using the given  backend , an object of type  AbstractDiffBackend . If the backend is not explicitly specified, it is obtained using the function  default_differential_backend . This function calculates plain Euclidean gradients, for Riemannian gradient calculation see for example  gradient . Note Not specifying the backend explicitly will usually result in a type instability and decreased performance. source"},{"id":2941,"pagetitle":"Internals","title":"ManifoldDiff._derivative","ref":"/manifolddiff/stable/internals/#ManifoldDiff._derivative","content":" ManifoldDiff._derivative  ‚Äî  Function _derivative(f, t[, backend::AbstractDiffBackend]) Compute the derivative of a callable  f  at time  t  computed using the given  backend , an object of type  AbstractDiffBackend . If the backend is not explicitly specified, it is obtained using the function  default_differential_backend . This function calculates plain Euclidean derivatives, for Riemannian differentiation see for example  differential . Note Not specifying the backend explicitly will usually result in a type instability and decreased performance. source"},{"id":2944,"pagetitle":"Library of functions","title":"Different library functions","ref":"/manifolddiff/stable/library/#Different-library-functions","content":" Different library functions Documentation for  ManifoldDiff.jl 's methods and types for finite differences and automatic differentiation."},{"id":2945,"pagetitle":"Library of functions","title":"Derivatives","ref":"/manifolddiff/stable/library/#Derivatives","content":" Derivatives"},{"id":2946,"pagetitle":"Library of functions","title":"ManifoldDiff.geodesic_derivative","ref":"/manifolddiff/stable/library/#ManifoldDiff.geodesic_derivative-Tuple{Any, Any, Any, Number}","content":" ManifoldDiff.geodesic_derivative  ‚Äî  Method Y = geodesic_derivative(M, p, X, t::Number; Œ≥t = geodesic(M, p, X, t))\ngeodesic_derivative!(M, Y, p, X, t::Number; Œ≥t = geodesic(M, p, X, t)) Evaluate the derivative of the geodesic  $Œ≥(t)$  with  $Œ≥_{p,X}(0) = p$  and  $\\dot Œ≥_{p,X}(0) = X$  at  $t$ . The formula reads \\[\\dot Œ≥(t) = \\mathcal P_{Œ≥(t) \\gets p} X\\] where  $\\mathcal P$  denotes the parallel transport. This computation can also be done in-place of  $Y$ . Optional Parameters Œ≥t  ‚Äì ( geodesic(M, p, X, t) ) the point on the geodesic at  $t$ . This way if the point was computed earlier it can be resued here. source"},{"id":2947,"pagetitle":"Library of functions","title":"ManifoldDiff.shortest_geodesic_derivative","ref":"/manifolddiff/stable/library/#ManifoldDiff.shortest_geodesic_derivative-Tuple{Any, Any, Any, Number}","content":" ManifoldDiff.shortest_geodesic_derivative  ‚Äî  Method Y = shortest_geodesic_derivative(M, p, X, t::Number; Œ≥t = shortest_geodesic(M, p, q, t))\nshortest_geodesic_derivative!(M, Y, p, X, t::Number; Œ≥t = shortest_geodesic(M, p, q, t)) Evaluate the derivative of the shortest geodesic  $Œ≥(t)$  with  $Œ≥_{p,q}(0) = p$  and  $\\dot Œ≥_{p,q}(1) = q$  at  $t$ . The formula reads \\[\\dot Œ≥(t) = \\mathcal P_{Œ≥(t) \\gets p} \\log_pq\\] where  $\\mathcal P$  denotes the parallel transport. This computation can also be done in-place of  $Y$ . Optional Parameters Œ≥t = geodesic(M, p, X, t)  the point on the geodesic at  $t$ . This way if the point was computed earlier it can be resued here. source"},{"id":2948,"pagetitle":"Library of functions","title":"Differentials and their adjoints","ref":"/manifolddiff/stable/library/#Differentials-and-their-adjoints","content":" Differentials and their adjoints"},{"id":2949,"pagetitle":"Library of functions","title":"ManifoldDiff.adjoint_differential_exp_argument","ref":"/manifolddiff/stable/library/#ManifoldDiff.adjoint_differential_exp_argument-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldDiff.adjoint_differential_exp_argument  ‚Äî  Method adjoint_differential_exp_argument(M, p, X, Y)\nadjoint_differential_exp_argument!(M, Z, p, X, Y) Compute the adjoint of  $D_X\\exp_p X[Y]$  (in place of  Z ). Note that  $X ‚àà  T_p(T_p\\mathcal M) = T_p\\mathcal M$  is still a tangent vector. See also differential_exp_argument ,  adjoint_Jacobi_field source"},{"id":2950,"pagetitle":"Library of functions","title":"ManifoldDiff.adjoint_differential_exp_basepoint","ref":"/manifolddiff/stable/library/#ManifoldDiff.adjoint_differential_exp_basepoint-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldDiff.adjoint_differential_exp_basepoint  ‚Äî  Method adjoint_differential_exp_basepoint(M, p, X, Y)\nadjoint_differential_exp_basepoint!(M, Z, p, X, Y) Computes the adjoint of  $D_p \\exp_p X[Y]$  (in place of  Z ). See also differential_exp_basepoint ,  adjoint_Jacobi_field source"},{"id":2951,"pagetitle":"Library of functions","title":"ManifoldDiff.adjoint_differential_log_argument","ref":"/manifolddiff/stable/library/#ManifoldDiff.adjoint_differential_log_argument-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldDiff.adjoint_differential_log_argument  ‚Äî  Method adjoint_differential_log_argument(M, p, q, X)\nadjoint_differential_log_argument!(M, Y, p, q, X) Compute the adjoint of  $D_q log_p q[X]$  (in place of  Y ). See also differential_log_argument ,  adjoint_Jacobi_field source"},{"id":2952,"pagetitle":"Library of functions","title":"ManifoldDiff.adjoint_differential_log_basepoint","ref":"/manifolddiff/stable/library/#ManifoldDiff.adjoint_differential_log_basepoint-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldDiff.adjoint_differential_log_basepoint  ‚Äî  Method adjoint_differential_log_basepoint(M, p, q, X)\nadjoint_differential_log_basepoint!(M, Y, p, q, X) computes the adjoint of  $D_p log_p q[X]$  (in place of  Y ). See also differential_log_basepoint ,  adjoint_Jacobi_field source"},{"id":2953,"pagetitle":"Library of functions","title":"ManifoldDiff.adjoint_differential_shortest_geodesic_endpoint","ref":"/manifolddiff/stable/library/#ManifoldDiff.adjoint_differential_shortest_geodesic_endpoint-Tuple{AbstractManifold, Any, Any, Any, Any}","content":" ManifoldDiff.adjoint_differential_shortest_geodesic_endpoint  ‚Äî  Method adjoint_differential_shortest_geodesic_endpoint(M, p, q, t, X)\nadjoint_differential_shortest_geodesic_endpoint!(M, Y, p, q, t, X) Compute the adjoint of  $D_q Œ≥(t; p, q)[X]$  (in place of  Y ). See also differential_shortest_geodesic_endpoint ,  adjoint_Jacobi_field source"},{"id":2954,"pagetitle":"Library of functions","title":"ManifoldDiff.adjoint_differential_shortest_geodesic_startpoint","ref":"/manifolddiff/stable/library/#ManifoldDiff.adjoint_differential_shortest_geodesic_startpoint-Tuple{AbstractManifold, Any, Any, Any, Any}","content":" ManifoldDiff.adjoint_differential_shortest_geodesic_startpoint  ‚Äî  Method adjoint_differential_shortest_geodesic_startpoint(M, p, q, t, X)\nadjoint_differential_shortest_geodesic_startpoint!(M, Y, p, q, t, X) Compute the adjoint of  $D_p Œ≥(t; p, q)[X]$  (in place of  Y ). See also differential_shortest_geodesic_startpoint ,  adjoint_Jacobi_field source"},{"id":2955,"pagetitle":"Library of functions","title":"ManifoldDiff.differential_exp_argument","ref":"/manifolddiff/stable/library/#ManifoldDiff.differential_exp_argument-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldDiff.differential_exp_argument  ‚Äî  Method Z = differential_exp_argument(M, p, X, Y)\ndifferential_exp_argument!(M, Z, p, X, Y) computes  $D_X\\exp_pX[Y]$  (in place of  Z ). Note that  $X ‚àà  T_X(T_p\\mathcal M) = T_p\\mathcal M$  is still a tangent vector. See also differential_exp_basepoint ,  jacobi_field source"},{"id":2956,"pagetitle":"Library of functions","title":"ManifoldDiff.differential_exp_argument_lie_approx","ref":"/manifolddiff/stable/library/#ManifoldDiff.differential_exp_argument_lie_approx-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldDiff.differential_exp_argument_lie_approx  ‚Äî  Method differential_exp_argument_lie_approx(M::AbstractManifold, p, X, Y; n) Approximate differential of exponential map based on Lie group exponential. The formula reads (see Theorem 1.7 of  [Helgason1978] ) \\[D_X \\exp_{p}(X)[Y] = (\\mathrm{d}L_{\\exp_e(X)})_e\\left(\\sum_{k=0}^{n}\\frac{(-1)^k}{(k+1)!}(\\operatorname{ad}_X)^k(Y)\\right)\\] where  $(\\operatorname{ad}_X)^k(Y)$  is defined recursively as  $(\\operatorname{ad}_X)^0(Y) = Y$ ,  $\\operatorname{ad}_X^{k+1}(Y) = [X, \\operatorname{ad}_X^k(Y)]$ . source"},{"id":2957,"pagetitle":"Library of functions","title":"ManifoldDiff.differential_exp_basepoint","ref":"/manifolddiff/stable/library/#ManifoldDiff.differential_exp_basepoint-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldDiff.differential_exp_basepoint  ‚Äî  Method Z = differential_exp_basepoint(M, p, X, Y)\ndifferential_exp_basepoint!(M, Z, p, X, Y) Compute  $D_p\\exp_p X[Y]$  (in place of  Z ). See also differential_exp_argument ,  jacobi_field source"},{"id":2958,"pagetitle":"Library of functions","title":"ManifoldDiff.differential_inverse_retract_argument_fd_approx","ref":"/manifolddiff/stable/library/#ManifoldDiff.differential_inverse_retract_argument_fd_approx-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldDiff.differential_inverse_retract_argument_fd_approx  ‚Äî  Method differential_inverse_retract_argument_fd_approx(\n    M::AbstractManifold,\n    p,\n    q,\n    X;\n    retr::AbstractRetractionMethod = default_retraction_method(M),\n    invretr::AbstractInverseRetractionMethod = default_inverse_retraction_method(M),\n    h::Real=sqrt(eps(eltype(X))),\n) Approximate the differential of the inverse retraction  invretr  using a finite difference formula (see Eq. (16) in [ Zim20 ] \\[\\frac{\\operatorname{retr}^{-1}_q(\\operatorname{retr}_p(hX)) - \\operatorname{retr}^{-1}_q(\\operatorname{retr}_p(-hX))}{2h}\\] where  $h$  is the finite difference step  h ,  $\\operatorname{retr}^{-1}$  is the inverse retraction  invretr  and  $\\operatorname{retr}$  is the retraction  retr . source"},{"id":2959,"pagetitle":"Library of functions","title":"ManifoldDiff.differential_log_argument","ref":"/manifolddiff/stable/library/#ManifoldDiff.differential_log_argument-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldDiff.differential_log_argument  ‚Äî  Method Y = differential_log_argument(M, p, q, X)\ndifferential_log_argument!(M, Y, p, q, X) computes  $D_q\\log_pq[X]$  (in place of  Y ). See also differential_log_basepoint ,  jacobi_field source"},{"id":2960,"pagetitle":"Library of functions","title":"ManifoldDiff.differential_log_basepoint","ref":"/manifolddiff/stable/library/#ManifoldDiff.differential_log_basepoint-Tuple{AbstractManifold, Any, Any, Any}","content":" ManifoldDiff.differential_log_basepoint  ‚Äî  Method Y = differential_log_basepoint(M, p, q, X)\ndifferential_log_basepoint!(M, Y, p, q, X) computes  $D_p\\log_pq[X]$  (in place of  Y ). See also differential_log_argument ,  jacobi_field source"},{"id":2961,"pagetitle":"Library of functions","title":"ManifoldDiff.differential_shortest_geodesic_endpoint","ref":"/manifolddiff/stable/library/#ManifoldDiff.differential_shortest_geodesic_endpoint-Tuple{AbstractManifold, Any, Any, Any, Any}","content":" ManifoldDiff.differential_shortest_geodesic_endpoint  ‚Äî  Method Y = differential_shortest_geodesic_endpoint(M, p, q, t, X)\ndifferential_shortest_geodesic_endpoint!(M, Y, p, q, t, X) Compute  $D_qŒ≥(t;p,q)[X]$  (in place of  Y ). See also differential_shortest_geodesic_startpoint ,  jacobi_field source"},{"id":2962,"pagetitle":"Library of functions","title":"ManifoldDiff.differential_shortest_geodesic_startpoint","ref":"/manifolddiff/stable/library/#ManifoldDiff.differential_shortest_geodesic_startpoint-Tuple{AbstractManifold, Any, Any, Any, Any}","content":" ManifoldDiff.differential_shortest_geodesic_startpoint  ‚Äî  Method Y = differential_shortest_geodesic_startpoint(M, p, q, t, X)\ndifferential_shortest_geodesic_startpoint!(M, Y, p, q, t, X) Compute  $D_p Œ≥(t;p,q)[Œ∑]$  (in place of  Y ). See also differential_shortest_geodesic_endpoint ,  jacobi_field source"},{"id":2963,"pagetitle":"Library of functions","title":"ManifoldDiff.AbstractProjector","ref":"/manifolddiff/stable/library/#ManifoldDiff.AbstractProjector","content":" ManifoldDiff.AbstractProjector  ‚Äî  Type abstract type AbstractProjector end An abstract type for projectors on a tangent space  $T_pM$  for fixed values of  p  and  M . Calling a projector on a tangent vector returns a new tangent vector: (Œ†::AbstractProjector)(X) -> Y Projectors assume that  X  is a valid vector from  $T_pM$ . source"},{"id":2964,"pagetitle":"Library of functions","title":"ManifoldDiff.CoprojectorOntoVector","ref":"/manifolddiff/stable/library/#ManifoldDiff.CoprojectorOntoVector","content":" ManifoldDiff.CoprojectorOntoVector  ‚Äî  Type CoprojectorOntoVector{TM<:AbstractManifold,TP,TX} A structure that represents projector onto the subspace of the tangent space at  p  from manifold  M  othogonal to vector  X  of unit norm. Constructor CoprojectorOntoVector(M::AbstractManifold, p, X) source"},{"id":2965,"pagetitle":"Library of functions","title":"ManifoldDiff.ProjectorOntoVector","ref":"/manifolddiff/stable/library/#ManifoldDiff.ProjectorOntoVector","content":" ManifoldDiff.ProjectorOntoVector  ‚Äî  Type ProjectorOntoVector{TM<:AbstractManifold,TP,TX} A structure that represents projector onto the subspace of the tangent space at  p  from manifold  M  spanned by tangent vector  X  of unit norm. Constructor ProjectorOntoVector(M::AbstractManifold, p, X) source"},{"id":2966,"pagetitle":"Library of functions","title":"ManifoldDiff.diagonalizing_projectors","ref":"/manifolddiff/stable/library/#ManifoldDiff.diagonalizing_projectors-Tuple{AbstractManifold, Any, Any}","content":" ManifoldDiff.diagonalizing_projectors  ‚Äî  Method diagonalizing_projectors(M::AbstractManifold, p, X) Compute eigenvalues of the Jacobi operator  $Y ‚Üí R(Y,X)X$ , where  $R$  is the curvature endomorphism, together with projectors onto eigenspaces of the operator. Projectors are objects of subtypes of  AbstractProjector . By default constructs projectors using the  DiagonalizingOrthonormalBasis . source"},{"id":2967,"pagetitle":"Library of functions","title":"Gradients","ref":"/manifolddiff/stable/library/#Gradients","content":" Gradients"},{"id":2968,"pagetitle":"Library of functions","title":"ManifoldDiff.grad_distance","ref":"/manifolddiff/stable/library/#ManifoldDiff.grad_distance","content":" ManifoldDiff.grad_distance  ‚Äî  Function grad_distance(M, q, p[, c=2])\ngrad_distance!(M, X, q, p[, c=2]) compute the (sub)gradient of the distance (default: squared), in place of  X . \\[f(p) = \\frac{1}{c} d^c_{\\mathcal M}(p, q)\\] to a fixed point  q  on the manifold  M  and  c  is an integer. The (sub-)gradient reads \\[\\operatorname{grad}f(p) = -d_{\\mathcal M}^{c-2}(p, q)\\log_pq\\] for  $c\\neq 1$  or  $p\\neq  q$ . Note that for the remaining case  $c=1$ ,  $p=q$ , the function is not differentiable. In this case, the function returns the corresponding zero tangent vector, since this is an element of the subdifferential. Optional c  ‚Äì ( 2 ) the exponent of the distance,  i.e. the default is the squared distance source"},{"id":2969,"pagetitle":"Library of functions","title":"ManifoldDiff.subgrad_distance","ref":"/manifolddiff/stable/library/#ManifoldDiff.subgrad_distance","content":" ManifoldDiff.subgrad_distance  ‚Äî  Function subgrad_distance(M, q, p[, c = 2; atol = 0])\nsubgrad_distance!(M, X, q, p[, c = 2; atol = 0]) compute the subgradient of the distance (in place of  X ) \\[f(p) = \\frac{1}{c} d^c_{\\mathcal M}(p, q)\\] to a fixed point  q  on the manifold  M  and  c  is an integer. The subgradient reads \\[\\partial f(p) = -d_{\\mathcal M}^{c-2}(p, q)\\log_pq\\] for  $c\\neq 1$  or  $p\\neq  q$ . Note that for the remaining case  $c=1$ ,  $p=q$ , the function is not differentiable. In this case, the subgradient is given by a tangent vector at  p  with norm less than or equal to one. Optional c  ‚Äì ( 2 ) the exponent of the distance,  i.e. the default is the distance atol  ‚Äì ( 0 ) the tolerance to use when evaluating the distance between  p  and  q . source"},{"id":2970,"pagetitle":"Library of functions","title":"Jacobi fields","ref":"/manifolddiff/stable/library/#Jacobi-fields","content":" Jacobi fields"},{"id":2971,"pagetitle":"Library of functions","title":"ManifoldDiff.adjoint_Jacobi_field","ref":"/manifolddiff/stable/library/#ManifoldDiff.adjoint_Jacobi_field-Union{Tuple{TŒ≤}, Tuple{AbstractManifold, Any, Any, Any, Any, TŒ≤}} where TŒ≤","content":" ManifoldDiff.adjoint_Jacobi_field  ‚Äî  Method Y = adjoint_Jacobi_field(M, p, q, t, X, Œ≤)\nadjoint_Jacobi_field!(M, Y, p, q, t, X, Œ≤) Compute the AdjointJacobiField  $J$  along the geodesic  $Œ≥_{p,q}$  on the manifold  $\\mathcal M$  with initial conditions (depending on the application)  $X ‚àà T_{Œ≥_{p,q}(t)}\\mathcal M$  and weights  $Œ≤$ . The result is a vector  $Y ‚àà T_p\\mathcal M$ . The main difference to  jacobi_field  is the, that the input  X  and the output  Y  switched tangent spaces. The computation can be done in place of  Y . For details see  jacobi_field source"},{"id":2972,"pagetitle":"Library of functions","title":"ManifoldDiff.jacobi_field","ref":"/manifolddiff/stable/library/#ManifoldDiff.jacobi_field-Union{Tuple{TŒ≤}, Tuple{AbstractManifold, Any, Any, Any, Any, TŒ≤}} where TŒ≤","content":" ManifoldDiff.jacobi_field  ‚Äî  Method Y = jacobi_field(M, p, q, t, X, Œ≤)\njacobi_field!(M, Y, p, q, t, X, Œ≤) compute the Jacobi field  $J$  along the geodesic  $Œ≥_{p,q}$  on the manifold  $\\mathcal M$  with initial conditions (depending on the application)  $X ‚àà T_p\\mathcal M$  and weights  $Œ≤$ . The result is a tangent vector  Y  from  $T_{Œ≥_{p,q}(t)}\\mathcal M$ . The computation can be done in place of  Y . See also adjoint_Jacobi_field source"},{"id":2973,"pagetitle":"Library of functions","title":"ManifoldDiff.Œ≤differential_exp_argument","ref":"/manifolddiff/stable/library/#ManifoldDiff.Œ≤differential_exp_argument-Tuple{Any, Number, Any}","content":" ManifoldDiff.Œ≤differential_exp_argument  ‚Äî  Method Œ≤differential_exp_argument(Œ∫,t,d) weights for the  jacobi_field  corresponding to the differential of the geodesic with respect to its start point  $D_X \\exp_p X[Y]$ . They are \\[Œ≤(Œ∫) = \\begin{cases}\n\\frac{\\sinh(d\\sqrt{-Œ∫})}{d\\sqrt{-Œ∫}}&\\text{ if }Œ∫ < 0,\\\\\n1 & \\text{ if } Œ∫ = 0,\\\\\n\\frac{\\sin(d\\sqrt{Œ∫})}{d\\sqrt{Œ∫}}&\\text{ if }Œ∫ > 0.\n\\end{cases}\\] See also differential_exp_argument ,  jacobi_field source"},{"id":2974,"pagetitle":"Library of functions","title":"ManifoldDiff.Œ≤differential_exp_basepoint","ref":"/manifolddiff/stable/library/#ManifoldDiff.Œ≤differential_exp_basepoint-Tuple{Any, Number, Any}","content":" ManifoldDiff.Œ≤differential_exp_basepoint  ‚Äî  Method Œ≤differential_exp_basepoint(Œ∫,t,d) weights for the  jacobi_field  corresponding to the differential of the geodesic with respect to its start point  $D_p \\exp_p X [Y]$ . They are \\[Œ≤(Œ∫) = \\begin{cases}\n\\cosh(\\sqrt{-Œ∫})&\\text{ if }Œ∫ < 0,\\\\\n1 & \\text{ if } Œ∫ = 0,\\\\\n\\cos(\\sqrt{Œ∫}) &\\text{ if }Œ∫ > 0.\n\\end{cases}\\] See also differential_exp_basepoint ,  jacobi_field source"},{"id":2975,"pagetitle":"Library of functions","title":"ManifoldDiff.Œ≤differential_log_argument","ref":"/manifolddiff/stable/library/#ManifoldDiff.Œ≤differential_log_argument-Tuple{Any, Number, Any}","content":" ManifoldDiff.Œ≤differential_log_argument  ‚Äî  Method Œ≤differential_log_argument(Œ∫,t,d) weights for the JacobiField corresponding to the differential of the logarithmic map with respect to its argument  $D_q \\log_p q[X]$ . They are \\[Œ≤(Œ∫) = \\begin{cases}\n\\frac{ d\\sqrt{-Œ∫} }{\\sinh(d\\sqrt{-Œ∫})}&\\text{ if }Œ∫ < 0,\\\\\n1 & \\text{ if } Œ∫ = 0,\\\\\n\\frac{ d\\sqrt{Œ∫} }{\\sin(d\\sqrt{Œ∫})}&\\text{ if }Œ∫ > 0.\n\\end{cases}\\] See also differential_log_basepoint ,  jacobi_field source"},{"id":2976,"pagetitle":"Library of functions","title":"ManifoldDiff.Œ≤differential_log_basepoint","ref":"/manifolddiff/stable/library/#ManifoldDiff.Œ≤differential_log_basepoint-Tuple{Any, Number, Any}","content":" ManifoldDiff.Œ≤differential_log_basepoint  ‚Äî  Method Œ≤differential_log_basepoint(Œ∫,t,d) weights for the  jacobi_field  corresponding to the differential of the geodesic with respect to its start point  $D_p \\log_p q[X]$ . They are \\[Œ≤(Œ∫) = \\begin{cases}\n-\\sqrt{-Œ∫}d\\frac{\\cosh(d\\sqrt{-Œ∫})}{\\sinh(d\\sqrt{-Œ∫})}&\\text{ if }Œ∫ < 0,\\\\\n-1 & \\text{ if } Œ∫ = 0,\\\\\n-\\sqrt{Œ∫}d\\frac{\\cos(d\\sqrt{Œ∫})}{\\sin(d\\sqrt{Œ∫})}&\\text{ if }Œ∫ > 0.\n\\end{cases}\\] See also differential_log_argument ,  differential_log_argument ,  jacobi_field source"},{"id":2977,"pagetitle":"Library of functions","title":"ManifoldDiff.Œ≤differential_shortest_geodesic_startpoint","ref":"/manifolddiff/stable/library/#ManifoldDiff.Œ≤differential_shortest_geodesic_startpoint-Tuple{Any, Any, Any}","content":" ManifoldDiff.Œ≤differential_shortest_geodesic_startpoint  ‚Äî  Method Œ≤differential_shortest_geodesic_startpoint(Œ∫,t,d) weights for the  jacobi_field  corresponding to the differential of the geodesic with respect to its start point  $D_x g(t;p,q)[X]$ . They are \\[Œ≤(Œ∫) = \\begin{cases}\n\\frac{\\sinh(d(1-t)\\sqrt{-Œ∫})}{\\sinh(d\\sqrt{-Œ∫})}\n&\\text{ if }Œ∫ < 0,\\\\\n1-t & \\text{ if } Œ∫ = 0,\\\\\n\\frac{\\sin((1-t)d\\sqrt{Œ∫})}{\\sinh(d\\sqrt{Œ∫})}\n&\\text{ if }Œ∫ > 0.\n\\end{cases}\\] Due to a symmetry argument, these are also used to compute  $D_q g(t; p,q)[Œ∑]$ See also differential_shortest_geodesic_endpoint ,  differential_shortest_geodesic_startpoint ,  jacobi_field source"},{"id":2978,"pagetitle":"Library of functions","title":"Riemannian differentials","ref":"/manifolddiff/stable/library/#Riemannian-differentials","content":" Riemannian differentials"},{"id":2979,"pagetitle":"Library of functions","title":"ManifoldDiff.AbstractRiemannianDiffBackend","ref":"/manifolddiff/stable/library/#ManifoldDiff.AbstractRiemannianDiffBackend","content":" ManifoldDiff.AbstractRiemannianDiffBackend  ‚Äî  Type AbstractRiemannianDiffBackend An abstract type for backends for differentiation. source"},{"id":2980,"pagetitle":"Library of functions","title":"ManifoldDiff.RiemannianProjectionBackend","ref":"/manifolddiff/stable/library/#ManifoldDiff.RiemannianProjectionBackend","content":" ManifoldDiff.RiemannianProjectionBackend  ‚Äî  Type RiemannianProjectionBackend <: AbstractRiemannianDiffBackend This backend computes the differentiation in the embedding, which is currently limited to the gradient. Let  $mathcal M$  denote a manifold embedded in some  $R^m$ , where  $m$  is usually (much) larger than the manifold dimension. Then we require three tools A function  $fÃÉ: ‚Ñù^m ‚Üí ‚Ñù$  such that its restriction to the manifold yields the cost function  $f$  of interest. A  project  function to project tangent vectors from the embedding (at  $T_p‚Ñù^m$ ) back onto the tangent space  $T_p\\mathcal M$ . This also includes possible changes of the representation of the tangent vector (e.g. in the Lie algebra or in a different data format). A  change_representer  for non-isometrically embedded manifolds, i.e. where the tangent space  $T_p\\mathcal M$  of the manifold does not inherit the inner product from restriction of the inner product from the tangent space  $T_p‚Ñù^m$  of the embedding see also  riemannian_gradient  and [ AMS08 ], Section 3.6.1 for a derivation on submanifolds. source"},{"id":2981,"pagetitle":"Library of functions","title":"ManifoldDiff.TangentDiffBackend","ref":"/manifolddiff/stable/library/#ManifoldDiff.TangentDiffBackend","content":" ManifoldDiff.TangentDiffBackend  ‚Äî  Type TangentDiffBackend <: AbstractRiemannianDiffBackend A backend that uses tangent spaces and bases therein to derive an intrinsic differentiation scheme. Since it works in tangent spaces at argument and function value, methods might require a retraction and an inverse retraction as well as a basis. In the tangent space itself, this backend then employs an (Euclidean)  AbstractDiffBackend Constructor TangentDiffBackend(diff_backend) where  diff_backend  is an  AbstractDiffBackend  to be used on the tangent space. With the keyword arguments retraction  an  AbstractRetractionMethod  ( ExponentialRetraction  by default) inverse_retraction  an  AbstractInverseRetractionMethod LogarithmicInverseRetraction  by default) basis_arg  an  AbstractBasis  ( DefaultOrthogonalBasis  by default) basis_val  an  AbstractBasis  ( DefaultOrthogonalBasis  by default) source"},{"id":2982,"pagetitle":"Library of functions","title":"ManifoldDiff.differential","ref":"/manifolddiff/stable/library/#ManifoldDiff.differential-Tuple{AbstractManifold, Any, Real, ManifoldDiff.AbstractRiemannianDiffBackend}","content":" ManifoldDiff.differential  ‚Äî  Method differential(M::AbstractManifold, f, t::Real, backend::AbstractDiffBackend)\ndifferential!(M::AbstractManifold, f, X, t::Real, backend::AbstractDiffBackend) Compute the Riemannian differential of a curve  $f: ‚Ñù\\to M$  on a manifold  M  represented by function  f  at time  t  using the given backend. It is calculated as the tangent vector equal to  $\\mathrm{d}f_t(t)[1]$ . The mutating variant computes the differential in place of  X . source"},{"id":2983,"pagetitle":"Library of functions","title":"ManifoldDiff.gradient","ref":"/manifolddiff/stable/library/#ManifoldDiff.gradient-Tuple{AbstractManifold, Any, Any, ManifoldDiff.AbstractRiemannianDiffBackend}","content":" ManifoldDiff.gradient  ‚Äî  Method gradient(M::AbstractManifold, f, p, backend::AbstractRiemannianDiffBackend)\ngradient!(M::AbstractManifold, f, X, p, backend::AbstractRiemannianDiffBackend) Compute the Riemannian gradient  $‚àáf(p)$  of a real-valued function  $f:\\mathcal M \\to ‚Ñù$  at point  p  on the manifold  M  using the specified  AbstractRiemannianDiffBackend . The mutating variant computes the gradient in place of  X . source"},{"id":2984,"pagetitle":"Library of functions","title":"ManifoldDiff.gradient","ref":"/manifolddiff/stable/library/#ManifoldDiff.gradient-Tuple{AbstractManifold, Any, Any, ManifoldDiff.TangentDiffBackend}","content":" ManifoldDiff.gradient  ‚Äî  Method gradient(M, f, p, backend::TangentDiffBackend) This method uses the internal  backend.diff_backend  (Euclidean) on the function \\[    f(\\operatorname{retr}_p(\\cdot))\\] which is given on the tangent space. In detail, the gradient can be written in terms of the  backend.basis_arg . We illustrate it here for an  AbstractOrthonormalBasis , since that simplifies notations: \\[\\operatorname{grad}f(p) = \\operatorname{grad}f(p) = \\sum_{i=1}^{d} g_p(\\operatorname{grad}f(p),X_i)X_i\n\t= \\sum_{i=1}^{d} Df(p)[X_i]X_i\\] where the last equality is due to the definition of the gradient as the Riesz representer of the differential. If the backend is a forward (or backward) finite difference, these coefficients in the sum can be approximates as \\[DF(p)[Y] ‚âà \\frac{1}{h}\\bigl( f(\\exp_p(hY)) - f(p) \\bigr)\\] writing  $p=\\exp_p(0)$  we see that this is a finite difference of  $f\\circ\\exp_p$ , i.e. for a function on the tangent space, so we can also use other (Euclidean) backends source"},{"id":2985,"pagetitle":"Library of functions","title":"ManifoldDiff.hessian","ref":"/manifolddiff/stable/library/#ManifoldDiff.hessian-Tuple{AbstractManifold, Any, Any, ManifoldDiff.TangentDiffBackend}","content":" ManifoldDiff.hessian  ‚Äî  Method hessian(M::AbstractManifold, f, p, backend::TangentDiffBackend) Compute the Hessian of function  f  at point  p  using the given  backend . The formula for normal coordinate systems from [SommerFletcherPennec2020]  is used. source"},{"id":2986,"pagetitle":"Library of functions","title":"ManifoldDiff.riemannian_Hessian","ref":"/manifolddiff/stable/library/#ManifoldDiff.riemannian_Hessian-Tuple{AbstractManifold, Any, Any, Any, Any}","content":" ManifoldDiff.riemannian_Hessian  ‚Äî  Method riemannian_Hessian(M, p, eG, eH, X)\nriemannian_Hessian!(M, Y, p, eG, eH, X) Convert the Euclidean Hessian  eH= $\\operatorname{Hess} \\tilde f(p) [X]$  of a function  $f \\colon \\mathcal M \\to \\mathbb R$ , which is the restriction of  $\\tilde f$  to  $\\mathcal M$ , given additionally the (Euclidean) gradient  $\\operatorname{grad} \\tilde f(p)$ . The Riemannian Hessian is then computed by \\[\\operatorname{Hess} f(p)[X]\n= \\operatorname{proj}_{T_p\\mathcal M}\\bigl(\\operatorname{Hess} \\tilde f(p)[X])\n+ \\mathcal W_p\\Bigl( X, \\operatorname{proj}_{N_p\\mathcal M}\\bigl( \\operatorname{grad} \\tilde f (p) \\bigr) \\Bigr),\\] where  $N_p\\mathcal M$  denotes the normal space, i.e. the orthogonal complement of the tangent space in the embedding, and  $\\mathcal W_p$  denotes the  Weingarten  map. See [ Bou23 ] for more details The function is inspired by  ehess2rhess  in the  Matlab package Manopt . source"},{"id":2987,"pagetitle":"Library of functions","title":"ManifoldDiff.riemannian_gradient","ref":"/manifolddiff/stable/library/#ManifoldDiff.riemannian_gradient-Tuple{AbstractManifold, Any, Any}","content":" ManifoldDiff.riemannian_gradient  ‚Äî  Method riemannian_gradient(M, p, Y; embedding_metric=EuclideanMetric())\nriemannian_gradient!(M, X, p, Y; embedding_metric=EuclideanMetric()) For a given gradient  $Y = \\operatorname{grad} \\tilde f(p)$  in the embedding of a manifold, this function computes the Riemannian gradient  $\\operatorname{grad} f(p)$  of the function  $\\tilde f$  restricted to the manifold  $M$ . This can also be done in place of  X . By default it uses the following computation: Let the projection  $Z = \\operatorname{proj}_{T_p\\mathcal M}(Y)$  of  $Y$  onto the tangent space at  $p$  be given, that is with respect to the inner product in the embedding. Then \\[‚ü®Z-Y, W‚ü© = 0 \\text{ for all } W \\in T_p\\mathcal M,\\] or rearranged  $‚ü®Y,W‚ü© = ‚ü®Z,W‚ü©$ . We then use the definition of the Riemannian gradient \\[‚ü®\\operatorname{grad} f(p), W‚ü©_p = Df(p)[X] = ‚ü®\\operatorname{grad}f(p), W‚ü© = ‚ü®\\operatorname{proj}_{T_p\\mathcal M}(\\operatorname{grad}f(p)),W‚ü©\n\\quad\\text{for all } W \\in T_p\\mathcal M.\\] Comparing the first and the last term, the remaining computation is the function  change_representer . This method can also be implemented directly, if a more efficient/stable version is known. The function is inspired by  egrad2rgrad  in the  Matlab package Manopt . source"},{"id":2988,"pagetitle":"Library of functions","title":"Proximal Maps","ref":"/manifolddiff/stable/library/#Proximal-Maps","content":" Proximal Maps Given a convex, lower semi-continuous function  $f\\colon \\mathcal M \\to \\mathbb R$ , its proximal map is defined for some  $Œª>0$  as [ Bac14 ] \\[\\operatorname{prox}_{Œªf}(p) := \\operatorname*{arg\\,min}_{q\\in\\mathcal M} \\frac{1}{2Œª}d^2_{\\mathcal M}(p,q) + f(q).\\] Another name for the proximal map is  resolvent . Intuitively this means to minimize the function  $f$  while at the same timme ‚Äústaying close‚Äù to the argument  $p$ ."},{"id":2989,"pagetitle":"Library of functions","title":"ManifoldDiff.prox_distance","ref":"/manifolddiff/stable/library/#ManifoldDiff.prox_distance","content":" ManifoldDiff.prox_distance  ‚Äî  Function y = prox_distance(M::AbstractManifold, Œª::Real, p_data, p [, r=2])\nprox_distance!(M::AbstractManifold, q, Œª::Real, p_data, p [, r=2]) Compute the proximal map  $\\operatorname{prox}_{Œªf}$  with parameter Œª of  $f(p) = \\frac{1}{r}d_{\\mathcal M}^r(p_{\\mathrm{data}},p)$ . For the in-place variant the computation is done in place of  q . Input M       a manifold  M Œª       the prox parameter, a positive real number. p_data  a point on  M . p       the argument of the proximal map r       ( 2 ) exponent of the distance. Output q  ‚Äì the result of the proximal map of  $f$ For more details see [ WDS14 ] source Helgason1978 S. Helgason, Differential Geometry, Lie Groups, and Symmetric Spaces, First Edition. Academic Press, 1978. SommerFletcherPennec2020 S. Sommer, T. Fletcher, and X. Pennec, ‚Äú1 - Introduction to differential and Riemannian geometry,‚Äù in Riemannian Geometric Statistics in Medical Image Analysis, X. Pennec, S. Sommer, and T. Fletcher, Eds. Academic Press, 2020, pp. 3‚Äì37. doi: 10.1016/B978-0-12-814725-2.00008-X."},{"id":2992,"pagetitle":"Literature","title":"Literature","ref":"/manifolddiff/stable/references/#Literature","content":" Literature [AMS08] P.-A.¬†Absil, R.¬†Mahony and R.¬†Sepulchre.  Optimization Algorithms on Matrix Manifolds  (Princeton University Press, 2008), available online at  press.princeton.edu/chapters/absil/ . [Bac14] M.¬†Baƒç√°k.  Computing medians and means in Hadamard spaces .  SIAM¬†Journal¬†on¬†Optimization  24 , 1542‚Äì1566  (2014). [Bou23] N.¬†Boumal.  An Introduction to Optimization on Smooth Manifolds . First¬†Edition (Cambridge University Press, 2023). Homepage to the book:  nicolasboumal.net/book/index.html . [WDS14] A.¬†Weinmann, L.¬†Demaret and M.¬†Storath.  Total variation regularization for manifold-valued data .  SIAM¬†Journal¬†on¬†Imaging¬†Sciences  7 , 2226‚Äì2257  (2014). [Zim20] R.¬†Zimmermann.  Hermite Interpolation and Data Processing Errors on Riemannian Matrix Manifolds .  SIAM¬†Journal¬†on¬†Scientific¬†Computing  42 , A2593-A2619  (2020)."},{"id":2995,"pagetitle":"Home","title":"Welcome to ManoptExample.jl","ref":"/manoptexamples/stable/#Welcome-to-ManoptExample.jl","content":" Welcome to ManoptExample.jl"},{"id":2996,"pagetitle":"Home","title":"ManoptExamples.ManoptExamples","ref":"/manoptexamples/stable/#ManoptExamples.ManoptExamples","content":" ManoptExamples.ManoptExamples  ‚Äî  Module üèîÔ∏è‚õ∑Ô∏è ManoptExamples.jl ‚Äì A collection of research and tutorial example problems for  Manopt.jl üìö Documentation:  juliamanifolds.github.io/ManoptExamples.jl üì¶ Repository:  github.com/JuliaManifolds/ManoptExamples.jl üí¨ Discussions:  github.com/JuliaManifolds/ManoptExamples.jl/discussions üéØ Issues:  github.com/JuliaManifolds/ManoptExamples.jl/issues source This package provides a set of example tasks for  Manopt.jl  based on either generic manifolds from the  ManifoldsBase.jl  interface or specific manifolds from  Manifolds.jl . Each example usually consists of a cost function and additional objects, like the gradient or proximal maps, see  objectives an example explaining how to use these, see  examples Helping functions that are used in one or more examples can be found in the section of functions in the menu."},{"id":2999,"pagetitle":"Changelog","title":"Changelog","ref":"/manoptexamples/stable/changelog/#Changelog","content":" Changelog All notable changes to this Julia package will be documented in this file. The format is based on  Keep a Changelog , and this project adheres to  Semantic Versioning ."},{"id":3000,"pagetitle":"Changelog","title":"[0.1.6] ‚Äì unreleased","ref":"/manoptexamples/stable/changelog/#[0.1.6]-‚Äì-unreleased","content":" [0.1.6] ‚Äì unreleased"},{"id":3001,"pagetitle":"Changelog","title":"Added","ref":"/manoptexamples/stable/changelog/#Added","content":" Added Hyperparameter optimization example."},{"id":3002,"pagetitle":"Changelog","title":"[0.1.3] ‚Äì 11/12/2023","ref":"/manoptexamples/stable/changelog/#[0.1.3]-‚Äì-11/12/2023","content":" [0.1.3] ‚Äì 11/12/2023"},{"id":3003,"pagetitle":"Changelog","title":"Added","ref":"/manoptexamples/stable/changelog/#Added-2","content":" Added Total variation Minimization cost, proxes, and an example B√©zier curve cost, gradients, and an example."},{"id":3004,"pagetitle":"Changelog","title":"[0.1.3] ‚Äì 16/09/2023","ref":"/manoptexamples/stable/changelog/#[0.1.3]-‚Äì-16/09/2023","content":" [0.1.3] ‚Äì 16/09/2023"},{"id":3005,"pagetitle":"Changelog","title":"Added","ref":"/manoptexamples/stable/changelog/#Added-3","content":" Added Rayleigh Quotient functions added an example illustrating Euclidean gradient/HEssian conversion Add Literature with DocumenterCitations"},{"id":3006,"pagetitle":"Changelog","title":"[0.1.2] ‚Äì 13/06/2023","ref":"/manoptexamples/stable/changelog/#[0.1.2]-‚Äì-13/06/2023","content":" [0.1.2] ‚Äì 13/06/2023"},{"id":3007,"pagetitle":"Changelog","title":"Added","ref":"/manoptexamples/stable/changelog/#Added-4","content":" Added Update examples to use Quarto Add DC examples"},{"id":3008,"pagetitle":"Changelog","title":"[0.1.1] ‚Äì 01/03/2023","ref":"/manoptexamples/stable/changelog/#[0.1.1]-‚Äì-01/03/2023","content":" [0.1.1] ‚Äì 01/03/2023"},{"id":3009,"pagetitle":"Changelog","title":"Added","ref":"/manoptexamples/stable/changelog/#Added-5","content":" Added Rosenbrock function and examples"},{"id":3010,"pagetitle":"Changelog","title":"[0.1.0] ‚Äì 18/02/2023","ref":"/manoptexamples/stable/changelog/#[0.1.0]-‚Äì-18/02/2023","content":" [0.1.0] ‚Äì 18/02/2023"},{"id":3011,"pagetitle":"Changelog","title":"Added","ref":"/manoptexamples/stable/changelog/#Added-6","content":" Added Setup the project to collect example objectives for  Manopt.jl  which are well-documented and well-tested Setup Documentation to provide one example Quarto file for every example objective to illustrate how to use them."},{"id":3014,"pagetitle":"Contributing to ManoptExamples.jl","title":"Contributing to  Manopt.jl","ref":"/manoptexamples/stable/contributing/#Contributing-to-Manopt.jl","content":" Contributing to  Manopt.jl First, thanks for taking the time to contribute. Any contribution is appreciated and welcome. The following is a set of guidelines to  ManoptExamples.jl ."},{"id":3015,"pagetitle":"Contributing to ManoptExamples.jl","title":"Table of Contents","ref":"/manoptexamples/stable/contributing/#Table-of-Contents","content":" Table of Contents Contributing to  Manopt.jl Table of Contents I just have a question How can I file an issue? How can I contribute? Add an objective Code style"},{"id":3016,"pagetitle":"Contributing to ManoptExamples.jl","title":"I just have a question","ref":"/manoptexamples/stable/contributing/#I-just-have-a-question","content":" I just have a question The developer can most easily be reached in the Julia Slack channel  #manifolds . You can apply for the Julia Slack workspace  here  if you haven't joined yet. You can also ask your question on  our GitHub discussion ."},{"id":3017,"pagetitle":"Contributing to ManoptExamples.jl","title":"How can I file an issue?","ref":"/manoptexamples/stable/contributing/#How-can-I-file-an-issue?","content":" How can I file an issue? If you found a bug or want to propose a feature, we track our issues within the  GitHub repository ."},{"id":3018,"pagetitle":"Contributing to ManoptExamples.jl","title":"How can I contribute?","ref":"/manoptexamples/stable/contributing/#How-can-I-contribute?","content":" How can I contribute?"},{"id":3019,"pagetitle":"Contributing to ManoptExamples.jl","title":"Add an objective","ref":"/manoptexamples/stable/contributing/#Add-an-objective","content":" Add an objective The  objective  in  Manopt.jl  represents the task to be optimised, usually phrased on an arbitrary manifold. The manifold is later specified when wrapping the objective inside a  Problem . If you have a specific objective you would like to provide here, feel free to start a new file in the  src/objectives/  folder in your own fork and propose it later as a  Pull Request . If you objective works without reusing any other objective functions, then they can all just be placed in this one file. If you notice, that you are reusing for example another objectives gradient as part of your objective, please refactor the code, such that the gradient, or other function is in the corresponding file in  src/functions/  and follows the naming scheme: cost functions are always of the form  cost_  and a fitting name gradient functions are always of the  gradient_  and a fitting name, followed by an  ! for in-place gradients and by  !!  if it is a  struct  that can provide both. It would be great if you could also add a small test for the functions and the problem you defined in the  test/  section."},{"id":3020,"pagetitle":"Contributing to ManoptExamples.jl","title":"Add an example","ref":"/manoptexamples/stable/contributing/#Add-an-example","content":" Add an example If you have used one of the problems from here in an example or you are providing a problem together with an example, please add a corresponding  Quarto  Markdown file to the  examples/  folder. The Markdown file should provide a short introduction to the problem and provide links to further details, maybe a paper or a preprint. Use the  bib/literature.yaml  file to add references (in  CSL_YAML , which can for example be exported e.g. from Zotero). Add any packages you need to the  examples/  environment (see the containting  Project.toml ). The examples will not be run on CI, but their rendered  CommonMark  outpout should be included in the list of examples in the documentation of this package."},{"id":3021,"pagetitle":"Contributing to ManoptExamples.jl","title":"Code style","ref":"/manoptexamples/stable/contributing/#Code-style","content":" Code style We try to follow the  documentation guidelines  from the Julia documentation as well as  Blue Style . We run  JuliaFormatter.jl  on the repo in the way set in the  .JuliaFormatter.toml  file, which enforces a number of conventions consistent with the Blue Style. We also follow a few internal conventions: Any implemented function should be accompanied by its mathematical formulae if a closed form exists. within a file the structs should come first and functions second. The only exception are constructors for the structs within both blocks an alphabetical order is preferable. The above implies that the mutating variant of a function follows the non-mutating variant. There should be no dangling  =  signs. Always add a newline between things of different types (struct/method/const). Always add a newline between methods for different functions (including in-place/non-mutating variants). Prefer to have no newline between methods for the same function; when reasonable, merge the docstrings into a generic function signature. All  import / using / include  should be in the main module file. There should only be a minimum of  export s within this file, all problems should usually be later addressed as  ManoptExamples.[...] the Quarto Markdown files are excluded from this formatting."},{"id":3024,"pagetitle":"Data","title":"Data sets","ref":"/manoptexamples/stable/data/#Data-sets","content":" Data sets"},{"id":3025,"pagetitle":"Data","title":"Signals on manifolds","ref":"/manoptexamples/stable/data/#Signals-on-manifolds","content":" Signals on manifolds"},{"id":3026,"pagetitle":"Data","title":"ManoptExamples.Lemniscate","ref":"/manoptexamples/stable/data/#ManoptExamples.Lemniscate-Tuple{Number}","content":" ManoptExamples.Lemniscate  ‚Äî  Method Lemniscate(t::Float; kwargs...)\nLemniscate(n::integer; interval=[0.0, 2œÄ], kwargs...) generate the  Lemniscate of Bernoulli  as a curve on a manifold, by generating the curve emplying the keyword arguments below. To be precise on the manifold  M  we use the tangent space at  p  and generate the curve \\[Œ≥(t) \\frac{a}{}\\sin^2(t) + 1 \\begin{pmatrix} \\cos(t) \\\\ \\cos(t)\\sin(t) \\end{pmatrix}\\] in the plane spanned by  X  and  Y  in the tangent space. Note that this curve is  $2œÄ$ -periodic and  a  is the  half-width  of the curve. To reproduce the first examples from [ BBSW16 ] as a default, on the sphere  p  defaults to the North pole. THe second variant generates  n  points equispaced in √¨nterval` and calls the first variant. Keywords manifold  - ( Sphere (2) ) the manifold to build the lemniscate on p         - ( [0.0, 0.0, 1.0]  on the sphere, `rand(M) else) the center point of the Lemniscate a         ‚Äì ( œÄ/2.0 ) half-width of the Lemniscate X         ‚Äì ( [1.0, 0.0, 0.0]  for the 2-sphere with default p, the first  DefaultOrthonormalBasis ()  vector otherwise) first direction for the plane to define the Lemniscate in, unit vector recommended. Y         ‚Äì ( [0.0, 1.0, 0.0]  if p is the default, the second  DefaultOrthonormalBasis ()  vector otherwise) second direction for the plane to define the Lemniscate in, unit vector orthogonal to  X  recommended. source"},{"id":3027,"pagetitle":"Data","title":"ManoptExamples.artificial_S1_signal","ref":"/manoptexamples/stable/data/#ManoptExamples.artificial_S1_signal","content":" ManoptExamples.artificial_S1_signal  ‚Äî  Function artificial_S1_signal([pts=500]) generate a real-valued signal having piecewise constant, linear and quadratic intervals with jumps in between. If the resulting manifold the data lives on, is the  Circle  the data is also wrapped to ``[ BLSW14 ]. Optional pts : ( 500 ) number of points to sample the function source"},{"id":3028,"pagetitle":"Data","title":"ManoptExamples.artificial_S1_signal","ref":"/manoptexamples/stable/data/#ManoptExamples.artificial_S1_signal-Tuple{Real}","content":" ManoptExamples.artificial_S1_signal  ‚Äî  Method artificial_S1_signal(x) evaluate the example signal  $f(x), x ‚àà  [0,1]$ , of phase-valued data introduces in Sec. 5.1 of  [ BLSW14 ] for values outside that interval, this Signal is  missing . source"},{"id":3029,"pagetitle":"Data","title":"ManoptExamples.artificial_S1_slope_signal","ref":"/manoptexamples/stable/data/#ManoptExamples.artificial_S1_slope_signal","content":" ManoptExamples.artificial_S1_slope_signal  ‚Äî  Function artificial_S1_slope_signal([pts=500, slope=4.]) Creates a Signal of (phase-valued) data represented on the  Circle  with increasing slope. Optional pts :    ( 500 ) number of points to sample the function. slope :  ( 4.0 ) initial slope that gets increased afterwards This data set was introduced for the numerical examples in [ BLSW14 ] source"},{"id":3030,"pagetitle":"Data","title":"ManoptExamples.artificial_S2_composite_Bezier_curve","ref":"/manoptexamples/stable/data/#ManoptExamples.artificial_S2_composite_Bezier_curve-Tuple{}","content":" ManoptExamples.artificial_S2_composite_Bezier_curve  ‚Äî  Method artificial_S2_composite_Bezier_curve() Generate a composite B√©zier curve on the [ BG18 ]. It consists of 4 egments connecting the points \\[\\mathbf d_0 = \\begin{pmatrix} 0\\\\0\\\\1\\end{pmatrix},\\quad\n\\mathbf d_1 = \\begin{pmatrix} 0\\\\-1\\\\0\\end{pmatrix},\\quad\n\\mathbf d_2 = \\begin{pmatrix} -1\\\\0\\\\0\\end{pmatrix},\\text{ and }\n\\mathbf d_3 = \\begin{pmatrix} 0\\\\0\\\\-1\\end{pmatrix}.\\] where instead of providing the two center control points explicitly we provide them as velocities from the corresponding points, such thtat we can directly define the curve to be  $C^1$ . We define \\[X_0 = \\frac{œÄ}{8\\sqrt{2}}\\begin{pmatrix}1\\\\-1\\\\0\\end{pmatrix},\\quad\nX_1 = \\frac{œÄ}{4\\sqrt{2}}\\begin{pmatrix}1\\\\0\\\\1\\end{pmatrix},\\quad\nX_2 = \\frac{œÄ}{4\\sqrt{2}}\\begin{pmatrix}0\\\\1\\\\-1\\end{pmatrix},\\text{ and }\nX_3 = \\frac{œÄ}{8\\sqrt{2}}\\begin{pmatrix}-1\\\\1\\\\0\\end{pmatrix},\\] where we defined each  $X_i \\in T_{d_i}\\mathbb S^2$ . We defined three  BezierSegment s of cubic B√©zier curves as follows \\[\\begin{align*}\nb_{0,0} &= d_0, \\quad & b_{1,0} &= \\exp_{d_0}X_0, \\quad & b_{2,0} &= \\exp_{d_1}X_1, \\quad & b_{3,0} &= d_1\\\\\nb_{0,1} &= d_1, \\quad & b_{1,1} &= \\exp_{d_1}(-X_1), \\quad & b_{2,1} &= \\exp_{d_2}X_2, \\quad & b_{3,1} &= d_2\\\\\nb_{0,2} &= d_2, \\quad & b_{1,1} &= \\exp_{d_2}(-X_2), \\quad & b_{2,2} &= \\exp_{d_3}X_3, \\quad & b_{3,2} &= d_3.\n\\end{align*}\\] source"},{"id":3031,"pagetitle":"Data","title":"images on manifolds","ref":"/manoptexamples/stable/data/#images-on-manifolds","content":" images on manifolds"},{"id":3032,"pagetitle":"Data","title":"ManoptExamples.artificialIn_SAR_image","ref":"/manoptexamples/stable/data/#ManoptExamples.artificialIn_SAR_image-Tuple{Integer}","content":" ManoptExamples.artificialIn_SAR_image  ‚Äî  Method artificialIn_SAR_image([pts=500]) generate an artificial InSAR image, i.e. phase valued data, of size  pts  x  pts  points. This data set was introduced for the numerical examples in [ BLSW14 ]. source"},{"id":3033,"pagetitle":"Data","title":"ManoptExamples.artificial_S2_rotation_image","ref":"/manoptexamples/stable/data/#ManoptExamples.artificial_S2_rotation_image","content":" ManoptExamples.artificial_S2_rotation_image  ‚Äî  Function artificial_S2_rotation_image([pts=64, rotations=(.5,.5)]) Create an image with a rotation on each axis as a parametrization. Optional Parameters pts :       ( 64 ) number of pixels along one dimension rotations : ( (.5,.5) ) number of total rotations performed on the axes. This dataset was used in the numerical example of Section 5.1 of [ BBSW16 ]. source"},{"id":3034,"pagetitle":"Data","title":"ManoptExamples.artificial_S2_whirl_image","ref":"/manoptexamples/stable/data/#ManoptExamples.artificial_S2_whirl_image","content":" ManoptExamples.artificial_S2_whirl_image  ‚Äî  Function artificial_S2_whirl_image([pts::Int=64]) Generate an artificial image of data on the 2 sphere, Arguments pts : ( 64 ) size of the image in  pts √ó pts  pixel. This example dataset was used in the numerical example in Section 5.5 of [ LNPS17 ] It is based on  artificial_S2_rotation_image  extended by small whirl patches. source"},{"id":3035,"pagetitle":"Data","title":"ManoptExamples.artificial_S2_whirl_patch","ref":"/manoptexamples/stable/data/#ManoptExamples.artificial_S2_whirl_patch","content":" ManoptExamples.artificial_S2_whirl_patch  ‚Äî  Function artificial_S2_whirl_patch([pts=5]) create a whirl within the  pts √ó pts  patch of  Sphere (@ref) (2) -valued image data. These patches are used within  artificial_S2_whirl_image . Optional Parameters pts : ( 5 ) size of the patch. If the number is odd, the center is the north pole. source"},{"id":3036,"pagetitle":"Data","title":"ManoptExamples.artificial_SPD_image","ref":"/manoptexamples/stable/data/#ManoptExamples.artificial_SPD_image","content":" ManoptExamples.artificial_SPD_image  ‚Äî  Function artificial_SPD_image([pts=64, stepsize=1.5]) create an artificial image of symmetric positive definite matrices of size  pts √ó pts  pixel with a jump of size  stepsize . This dataset was used in the numerical example of Section 5.2 of [ BBSW16 ]. source"},{"id":3037,"pagetitle":"Data","title":"ManoptExamples.artificial_SPD_image2","ref":"/manoptexamples/stable/data/#ManoptExamples.artificial_SPD_image2","content":" ManoptExamples.artificial_SPD_image2  ‚Äî  Function artificial_SPD_image2([pts=64, fraction=.66]) create an artificial image of symmetric positive definite matrices of size  pts √ó pts  pixel with right hand side  fraction  is moved upwards. This data set was introduced in the numerical examples of Section of [ BPS16 ] source"},{"id":3038,"pagetitle":"Data","title":"Literature","ref":"/manoptexamples/stable/data/#Literature","content":" Literature [BBSW16] M.¬†Baƒç√°k, R.¬†Bergmann, G.¬†Steidl and A.¬†Weinmann.  A second order non-smooth variational model for restoring manifold-valued images .  SIAM¬†Journal¬†on¬†Scientific¬†Computing  38 , A567‚ÄìA597  (2016),  arXiv:1506.02409 . [BG18] R.¬†Bergmann and P.-Y.¬†Gousenbourger.  A variational model for data fitting on manifolds by minimizing the acceleration of a B√©zier curve .  Frontiers¬†in¬†Applied¬†Mathematics¬†and¬†Statistics  4  (2018),  arXiv:1807.10090 . [BLSW14] R.¬†Bergmann, F.¬†Laus, G.¬†Steidl and A.¬†Weinmann.  Second order differences of cyclic data and applications in variational denoising .  SIAM¬†Journal¬†on¬†Imaging¬†Sciences  7 , 2916‚Äì2953  (2014),  arXiv:1405.5349 . [BPS16] R.¬†Bergmann, J.¬†Persch and G.¬†Steidl.  A parallel Douglas Rachford algorithm for minimizing ROF-like functionals on images with values in symmetric Hadamard manifolds .  SIAM¬†Journal¬†on¬†Imaging¬†Sciences  9 , 901‚Äì937  (2016),  arXiv:1512.02814 . [LNPS17] F.¬†Laus, M.¬†Nikolova, J.¬†Persch and G.¬†Steidl.  A nonlocal denoising algorithm for manifold-valued images using second order statistics .  SIAM¬†Journal¬†on¬†Imaging¬†Sciences  10 , 416‚Äì448  (2017)."},{"id":3041,"pagetitle":"Overview","title":"List of Examples","ref":"/manoptexamples/stable/examples/#List-of-Examples","content":" List of Examples Name provides Documentation Comment A Benchmark for Difference of Convex contains a few simple functions B√©zier Curves and Minimizing their Acceleration tools B√©zier curves and their acceleration üìö Solving Rosenbrock with Difference of Convex DoC split of Rosenbrock üìö uses a Rosenbrock based metric Difference of Convex vs. Frank-Wolfe closed-form sub solver Riemannian Mean $f$ ,  $\\operatorname{grad}f$  (A/I), objective üìö Robust PCA $f$ ,  $\\operatorname{grad}f$  (A/I), objective üìö Rosenbrock $f$ ,  $\\operatorname{grad}f$  (A/I), objective, minimizer üìö The Rayleigh Quotient $f$ ,  $\\operatorname{grad}f$  (A/I),  $\\operatorname{Hess}f$  (A/I), objective üìö Total Variation Minimization $f$ ,  $\\operatorname{prox}f$  (A/I), objective üìö Symbols: A  Allocating variant I  In-place variant üìö  link to documented functions in the documentation"},{"id":3044,"pagetitle":"Minimizing the Acceleration of B√©zier Curves on the Sphere","title":"Minimizing the Acceleration of B√©zier Curves on the Sphere","ref":"/manoptexamples/stable/examples/Bezier-curves/#Minimizing-the-Acceleration-of-B√©zier-Curves-on-the-Sphere","content":" Minimizing the Acceleration of B√©zier Curves on the Sphere Ronny Bergmann 2023-06-06 using Manifolds, Manopt, ManoptExamples"},{"id":3045,"pagetitle":"Minimizing the Acceleration of B√©zier Curves on the Sphere","title":"Introduction","ref":"/manoptexamples/stable/examples/Bezier-curves/#Introduction","content":" Introduction B√©zier Curves can be generalized to manifolds by generalizing the  de Casteljau algorithm üìñ  to work with geodesics instead of straight lines. An implementation in just a few lines as we demonstrated in [ ABBR23 ] as function bezier(M::AbstractManifold, t, pts::NTuple)\n    p = bezier(M, t, pts[1:(end - 1)])\n    q = bezier(M, t, pts[2:end])\n    return shortest_geodesic(M, p, q, t)\nend\nfunction bezier(M::AbstractManifold, t, pts::NTuple{2})\n    return shortest_geodesic(M, pts[1], pts[2], t)\nend which is also available within this package as  de_Casteljau  using a simple  BezierSegment struct  to make it easier to also discuss the case where we compose a set of segments into a composite B√©zier course. In the following we will need the following packages and functions. They are documented in the section on  Bezier Curves  and were derived in [ BG18 ] based on [ PN07 ]. using ManoptExamples:\n    artificial_S2_composite_Bezier_curve,\n    BezierSegment,\n    de_Casteljau,\n    get_Bezier_degrees,\n    get_Bezier_inner_points,\n    get_Bezier_junctions,\n    get_Bezier_junction_tangent_vectors,\n    get_Bezier_points,\n    get_Bezier_segments,\n    grad_L2_acceleration_Bezier,\n    L2_acceleration_Bezier This notebook reproduces the example form Section 5.2 in [ BG18 ]. The following image illustrates how the de-Casteljau algorithm works for one segment."},{"id":3046,"pagetitle":"Minimizing the Acceleration of B√©zier Curves on the Sphere","title":"Approximating data by a curve with minimal accelartion","ref":"/manoptexamples/stable/examples/Bezier-curves/#Approximating-data-by-a-curve-with-minimal-accelartion","content":" Approximating data by a curve with minimal accelartion We first load our example data M = Sphere(2)\nB = artificial_S2_composite_Bezier_curve()\ndata_points = get_Bezier_junctions(M, B) Which is the following cure, which clearly starts and ends slower than its speed in the middle, which can be seen by the increasing length of the gangent vectors in the middle. We continue to recude the points, since we ‚Äúknow‚Äù sme points due to the  $C^1$  property: the second to last control point of the first segment  $b_{0,2}$ , the joint junction point connecting both segments  $b_{0,3}=b_{1,0}$  and the second control point  $b_{1,1}$  of the second segment have to line in the tangent space of the joint junction point. Hence we only have to store one of the control points. We can use this reduced form as the variable to optimize and the one from the data as our initial point. pB = get_Bezier_points(M, B, :differentiable)\nN = PowerManifold(M, NestedPowerRepresentation(), length(pB)) PowerManifold(Sphere(2, ‚Ñù), NestedPowerRepresentation(), 8) And we further define the acceleration of the curve as our cost function, where we discretize the acceleration at a certain set of points and set the  $Œª=10$ curve_samples = [range(0, 3; length=101)...] # sample curve for the gradient\nŒª = 10.0\nfunction f(M, pB)\n    return L2_acceleration_Bezier(\n        M.manifold, pB, get_Bezier_degrees(M.manifold, B), curve_samples, Œª, data_points\n    )\nend\nfunction grad_f(M, pB)\n    return grad_L2_acceleration_Bezier(\n        M.manifold, pB, get_Bezier_degrees(M.manifold, B), curve_samples, Œª, data_points\n    )\nend grad_f (generic function with 1 method) Then we can optimize x0 = pB\npB_opt = gradient_descent(\n    N,\n    f,\n    grad_f,\n    x0;\n    stepsize=ArmijoLinesearch(N;\n        initial_stepsize=1.0,\n        retraction_method=ExponentialRetraction(),\n        contraction_factor=0.5,\n        sufficient_decrease=0.001,\n    ),\n    stopping_criterion=StopWhenChangeLess(1e-5) |\n                       StopWhenGradientNormLess(1e-7) |\n                       StopAfterIteration(300),\n    debug=[\n        :Iteration,\n        \" | \",\n        :Cost,\n        \" | \",\n        DebugGradientNorm(),\n        \" | \",\n        DebugStepsize(),\n        \" | \",\n        :Change,\n        \"\\n\",\n        25,\n        :Stop,\n    ],\n); Initial  | f(x): 10.647244 |  |  | \n# 25     | f(x): 2.667564 | |grad f(p)|:0.890845571434862 | s:0.01326670131422904 | Last Change: 0.763281\n# 50     | f(x): 2.650064 | |grad f(p)|:0.05536989605165708 | s:0.05306680525691616 | Last Change: 0.081780\n# 75     | f(x): 2.649707 | |grad f(p)|:0.02135638585837997 | s:0.01326670131422904 | Last Change: 0.011590\n# 100    | f(x): 2.649700 | |grad f(p)|:0.0012887575647752057 | s:0.05306680525691616 | Last Change: 0.001745\nThe algorithm performed a step with a change (2.9063044690733034e-7) less than 1.0e-5. And we can again look at the result The result looks as where all control points are evenly spaced and we hence have less acceleration as the final cost compared to the initial one indicates. Note that the cost is not zero, since we always have a tradeoff between approximating the initial junctinons (data points) and minimizing the acceleration. [ABBR23] S.¬†D.¬†Axen, M.¬†Baran, R.¬†Bergmann and K.¬†Rzecki.  Manifolds.jl: An Extensible Julia Framework for Data Analysis on Manifolds .  ACM¬†Transactions¬†on¬†Mathematical¬†Software  (2023),  arXiv:2021.08777 . [BG18] R.¬†Bergmann and P.-Y.¬†Gousenbourger.  A variational model for data fitting on manifolds by minimizing the acceleration of a B√©zier curve .  Frontiers¬†in¬†Applied¬†Mathematics¬†and¬†Statistics  4  (2018),  arXiv:1807.10090 . [PN07] T.¬†Popiel and L.¬†Noakes.  B√©zier curves and  $C^2$  interpolation in Riemannian manifolds .  Journal¬†of¬†Approximation¬†Theory  148 , 111‚Äì127  (2007)."},{"id":3049,"pagetitle":"A Benchmark","title":"Benchmark of the Difference of Convex Algorithms","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Benchmark/#Benchmark-of-the-Difference-of-Convex-Algorithms","content":" Benchmark of the Difference of Convex Algorithms Ronny Bergmann 2023-06-06"},{"id":3050,"pagetitle":"A Benchmark","title":"Introduction","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Benchmark/#Introduction","content":" Introduction In this Benchmark we compare the Difference of Convex Algprithm (DCA) [ BFSS23 ] and the Difference of Convex Proximal Point Algorithm (DCPPA) [ SO15 ] which solve Difference of Convex (DC) problems of the form. This Benchmark reproduces the results from [ BFSS23 ], Section 7.1. \\[\\operatorname*{arg\\,min}_{p\\in\\mathcal M}\\ \\  g(p) - h(p)\\] where  $g,h\\colon \\mathcal M \\to \\mathbb R$  are geodesically convex function on the Riemannian manifold  $\\mathcal M$ . using LinearAlgebra, Random, Statistics, BenchmarkTools\nusing Manifolds, Manopt, ManoptExamples\nusing NamedColors, Plots\nRandom.seed!(42) and we load a few nice colors paul_tol = load_paul_tol()\nindigo = paul_tol[\"mutedindigo\"]\nteal = paul_tol[\"mutedteal\"]"},{"id":3051,"pagetitle":"A Benchmark","title":"The DC Problem","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Benchmark/#The-DC-Problem","content":" The DC Problem We start with defining the two convex functions  $g,h$  and their gradients as well as the DC problem  $f$  and its gradient for the problem \\[    \\operatorname*{arg\\,min}_{p\\in\\mathcal M}\\ \\ \\bigl( \\log\\bigr(\\det(p)\\bigr)\\bigr)^4 - \\bigl(\\log \\det(p) \\bigr)^2.\\] where the critical points obtain a functional value of  $-\\frac{1}{4}$ . where  $\\mathcal M$  is the manifold of  symmetric positive definite (SPD) matrices  with the  affine invariant metric , which is the default. We first define the corresponding functions g(M, p) = log(det(p))^4\nh(M, p) = log(det(p))^2\nf(M, p) = g(M, p) - h(M, p) and their gradients grad_g(M, p) = 4 * (log(det(p)))^3 * p\ngrad_h(M, p) = 2 * log(det(p)) * p\ngrad_f(M, p) = grad_g(M, p) - grad_h(M, p) which we can use to verify that the gradients of  $g$  and  $h$  are correct. We use for that n = 6\nM = SymmetricPositiveDefinite(n)\np0 = log(n) * Matrix{Float64}(I, n, n);\nX0 = 1 / n * Matrix{Float64}(I, n, n); to tall both checks check_gradient(M, g, grad_g, p0, X0; plot=true) and check_gradient(M, h, grad_h, p0, X0; plot=true) which both pass the test. We continue to define their inplace variants function grad_g!(M, X, p)\n    copyto!(M, X, p)\n    X .*= 4 * (log(det(p)))^3\n    return X\nend\nfunction grad_h!(M, X, p)\n    copyto!(M, X, p)\n    X .*= 2 * (log(det(p)))\n    return X\nend\nfunction grad_f!(M, X, p)\n    grad_g!(M, X, p)\n    Y = copy(M, p, X)\n    grad_h!(M, Y, p)\n    X .-= Y\n    return X\nend And compare times for both algorithms, with a bit of debug output. @time p_min_dca = difference_of_convex_algorithm(\n    M,\n    f,\n    g,\n    grad_h!,\n    p0;\n    grad_g=grad_g!,\n    gradient=grad_f!,\n    evaluation=InplaceEvaluation(),\n    debug=[\n        :Iteration,\n        (:Cost, \"f(p): %1.9f\"),\n        (:GradientNorm, \" |grad_f(p)|: %1.9f\"),\n        (:Change, \" |Œ¥p|: %1.9f\"),\n        :Stop,\n        5,\n        \"\\n\",\n    ],\n    stopping_criterion=StopAfterIteration(5000) | StopWhenGradientNormLess(1e-10),\n    sub_stopping_criterion=StopAfterIteration(100) | StopWhenGradientNormLess(1e-10),\n); Initial f(p): 137.679053470\n# 5     f(p): -0.249956120 |grad_f(p)|: 0.046196628 |Œ¥p|: 0.201349127\n# 10    f(p): -0.249999999 |grad_f(p)|: 0.000187633 |Œ¥p|: 0.000626103\n# 15    f(p): -0.250000000 |grad_f(p)|: 0.000000772 |Œ¥p|: 0.000002574\n# 20    f(p): -0.250000000 |grad_f(p)|: 0.000000005 |Œ¥p|: 0.000000011\nThe algorithm reached approximately critical point after 24 iterations; the gradient norm (7.619584706652929e-11) is less than 1.0e-10.\n  3.531235 seconds (8.71 M allocations: 628.709 MiB, 3.52% gc time, 67.16% compilation time) The cost is f(M, p_min_dca) -0.25000000000000006 Similarly the DCPPA performs @time p_min_dcppa = difference_of_convex_proximal_point(\n    M,\n    grad_h!,\n    p0;\n    g=g,\n    grad_g=grad_g!,\n    Œª=i -> 1 / (2 * n),\n    cost=f,\n    gradient=grad_f!,\n    debug=[\n        :Iteration,\n        (:Cost, \"f(p): %1.9f\"),\n        \" \",\n        (:GradientNorm, \"|grad_f(p)|: %1.10f\"),\n        (:Change, \"|Œ¥p|: %1.10f\"),\n        :Stop,\n        5,\n        \"\\n\",\n    ],\n    evaluation=InplaceEvaluation(),\n    stepsize=ConstantStepsize(1.0),\n    stopping_criterion=StopAfterIteration(5000) | StopWhenGradientNormLess(1e-10),\n    sub_stopping_criterion=StopAfterIteration(100) | StopWhenGradientNormLess(1e-10),\n); Initial f(p): 137.679053470 \n# 5     f(p): -0.248491803 |grad_f(p)|: 0.2793140152|Œ¥p|: 0.2753827692\n# 10    f(p): -0.249998655 |grad_f(p)|: 0.0080437374|Œ¥p|: 0.0050891316\n# 15    f(p): -0.249999999 |grad_f(p)|: 0.0002507329|Œ¥p|: 0.0001567676\n# 20    f(p): -0.250000000 |grad_f(p)|: 0.0000078348|Œ¥p|: 0.0000048968\n# 25    f(p): -0.250000000 |grad_f(p)|: 0.0000002448|Œ¥p|: 0.0000001530\n# 30    f(p): -0.250000000 |grad_f(p)|: 0.0000000076|Œ¥p|: 0.0000000048\n# 35    f(p): -0.250000000 |grad_f(p)|: 0.0000000002|Œ¥p|: 0.0000000001\nThe algorithm reached approximately critical point after 37 iterations; the gradient norm (5.458071707233144e-11) is less than 1.0e-10.\n  1.341931 seconds (2.55 M allocations: 180.474 MiB, 2.46% gc time, 59.94% compilation time) It needs a few more iterations, but the single iterations are slightly faster. Both obtain the same cost f(M, p_min_dcppa) -0.25"},{"id":3052,"pagetitle":"A Benchmark","title":"Benchmark I: Time comparison","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Benchmark/#Benchmark-I:-Time-comparison","content":" Benchmark I: Time comparison We compare both solvers first with respect to time. We initialise two vectors to collect the results and a range of natrix sizes to test dca_benchmarks = Dict{Int,BenchmarkTools.Trial}()\ndcppa_benchmarks = Dict{Int, BenchmarkTools.Trial}()\nN_max=14\nN = 2:N_max and run a benchmark for both algorithms for n in N\n    Mn = SymmetricPositiveDefinite(n)\n    pn = log(n) * Matrix{Float64}(I, n, n)\n    bdca = @benchmark difference_of_convex_algorithm(\n        $Mn,\n        $f,\n        $g,\n        $grad_h!,\n        $pn;\n        grad_g=$grad_g!,\n        gradient=$grad_f!,\n        evaluation=InplaceEvaluation(),\n        stopping_criterion=StopAfterIteration(5000) | StopWhenGradientNormLess(1e-10),\n        sub_stopping_criterion=StopAfterIteration(100) | StopWhenGradientNormLess(1e-10),\n    )\n    dca_benchmarks[n] = bdca\n    bdcppa = @benchmark difference_of_convex_proximal_point(\n        $Mn,\n        $grad_h!,\n        $pn;\n        g=$g,\n        grad_g=$grad_g!,\n        Œª=i -> 1 / (2 * n),\n        cost=f,\n        gradient=grad_f!,\n        evaluation=InplaceEvaluation(),\n        stepsize=ConstantStepsize(1.0),\n        stopping_criterion=StopAfterIteration(5000) | StopWhenGradientNormLess(1e-10),\n        sub_stopping_criterion=StopAfterIteration(100) | StopWhenGradientNormLess(1e-10),\n    )\n    dcppa_benchmarks[n] = bdcppa\nend Since we want to plot this versus the manifold dimension, we also create a vector for those and convert the times to seconds dims = [manifold_dimension(SymmetricPositiveDefinite(n)) for n in N]\ndca_times = [mean(dca_benchmarks[n]).time / 1e9 for n in N]\ndcppa_times = [mean(dcppa_benchmarks[n]).time / 1e9 for n in N] plot(; legend=:bottomright, xlabel=\"manifold dimension\", ylabel=\"Time (sec.)\")\nplot!(dims, dca_times; label=\"DCA\", color=indigo, linewidth=2)\nplot!(dims, dcppa_times; label=\"DCPPA\", color=teal, linewidth=2)"},{"id":3053,"pagetitle":"A Benchmark","title":"Benchmark II: Iterations and cost.","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Benchmark/#Benchmark-II:-Iterations-and-cost.","content":" Benchmark II: Iterations and cost. As a second benchmark, let‚Äôs collect the number of iterations needed and the development of the cost over dimensions. N2 = [5,10,20,40,80]\ndims2 = [manifold_dimension(SymmetricPositiveDefinite(n)) for n in N2]\ndca_iterations = Dict{Int,Int}()\ndca_costs = Dict{Int,Vector{Float64}}()\ndcppa_iterations = Dict{Int,Int}()\ndcppa_costs = Dict{Int,Vector{Float64}}() @time for n in N2\n    println(n)\n    Mn = SymmetricPositiveDefinite(n)\n    pn = log(n) * Matrix{Float64}(I,n,n);\n    @time dca_st = difference_of_convex_algorithm(\n        Mn, f, g, grad_h!, pn;\n        grad_g=grad_g!,\n        gradient=grad_f!,\n        evaluation = InplaceEvaluation(),\n        stopping_criterion = StopAfterIteration(5000) | StopWhenGradientNormLess(1e-10),\n        sub_stopping_criterion = StopAfterIteration(100) | StopWhenGradientNormLess(1e-10),\n        record = [:Iteration, :Cost],\n        return_state = true,\n    );\n    dca_costs[n] = get_record(dca_st, :Iteration, :Cost)\n    dca_iterations[n] = length(dca_costs[n])\n    @time dcppa_st = difference_of_convex_proximal_point(\n        Mn, grad_h!, pn;\n        g=g,\n        grad_g=grad_g!,\n        Œª = i -> 1/(2*n),\n        cost = f,\n        gradient= grad_f!,\n        evaluation = InplaceEvaluation(),\n        stepsize = ConstantStepsize(1.0),\n        stopping_criterion = StopAfterIteration(5000) | StopWhenGradientNormLess(1e-10),\n        sub_stopping_criterion = StopAfterIteration(100) | StopWhenGradientNormLess(1e-10),\n        record = [:Iteration, :Cost],\n        return_state = true,\n    );\n    dcppa_costs[n] = get_record(dcppa_st, :Iteration, :Cost)\n    dcppa_iterations[n] = length(dcppa_costs[n])\nend The iterations are like plot(; legend=:bottomright, xlabel=\"manifold dimension\", ylabel=\"Iterations\")\nplot!(dims2, [values(dca_iterations)...]; label=\"DCA\", color=indigo, linewidth=2)\nplot!(dims2, [values(dcppa_iterations)...]; label=\"DCPPA\", color=teal, linewidth=2) And for the developtment of the cost where we can see that the DCA needs less iterations than the DCPPA."},{"id":3054,"pagetitle":"A Benchmark","title":"Literature","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Benchmark/#Literature","content":" Literature [BFSS23] R.¬†Bergmann, O.¬†P.¬†Ferreira, E.¬†M.¬†Santos and J.¬†C.¬†Souza.  The difference of convex algorithm on Hadamard manifolds . Preprint (2023),  arXiv:2112.05250 . [SO15] J.¬†C.¬†Souza and P.¬†R.¬†Oliveira.  A proximal point algorithm for DC fuctions on Hadamard manifolds .  Journal¬†of¬†Global¬†Optimization  63 , 797‚Äì810  (2015)."},{"id":3057,"pagetitle":"Frank Wolfe comparison","title":"A comparison of the Difference of Convex and Frank Wolfe Algorithm","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Frank-Wolfe/#A-comparison-of-the-Difference-of-Convex-and-Frank-Wolfe-Algorithm","content":" A comparison of the Difference of Convex and Frank Wolfe Algorithm Ronny Bergmann 2023-11-06"},{"id":3058,"pagetitle":"Frank Wolfe comparison","title":"Introduction","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Frank-Wolfe/#Introduction","content":" Introduction In this example we compare the Difference of Convex Algprithm (DCA) [ BFSS23 ] with the Frank-Wolfe Algorithm, which was introduced in [ WS22 ]. This example reproduces the results from [ BFSS23 ], Section 7.3. using LinearAlgebra, Random, Statistics, BenchmarkTools\nusing ManifoldsBase, Manifolds, Manopt, ManoptExamples\nusing NamedColors, Plots and we load a few nice colors paul_tol = load_paul_tol()\nindigo = paul_tol[\"mutedindigo\"]\nteal = paul_tol[\"mutedteal\"] We consider the collowing constraint maximimization problem of the Fr√©chet mean on the  symmetric positive definite matrices $\\mathcal P(n)$  with the  affine invariant metric . Let  $q_1,\\ldots,q_m \\in \\mathcal P(n)$  be a set of points and  $\\mu_1,\\ldots,\\mu_m$  be a set of weights, such that they sum to one. We consider then \\[\\operatorname*{arg\\,max}_{p\\in\\mathcal C}\\ \\ h(p)\\] with \\[h(p) =\n\\sum_{j=1}^m \\mu_j d^2(p,q_i),\n\\quad \\text{ where }\nd^2(p,q_i) = \\operatorname{tr}\\bigl(\n  \\log^2(p^{-\\frac{1}{2}}q_jp^{-\\frac{1}{2}})\n\\big)\n\\qquad\\text{and}\\qquad\n\\mathcal C = \\{ p\\in {\\mathcal M}\\ |\\ \\bar L\\preceq p \\preceq \\bar U \\},\\] for a lower bound  $L$  and an upper bound  $U$  for the matrices in the positive definite sense  $A \\preceq B \\Leftrightarrow (B-A)$  is positive semi-definite When every one of the weights  ${\\mu}_1, \\ldots {\\mu}_m$  are equal, this function  $h$  is known as the of the set  $\\{q_1, \\dots, q_m\\}$ . And for our example we set Random.seed!(42)\nn = 20\nm = 100\nM = SymmetricPositiveDefinite(n)\nq = [rand(M) for _ in 1:m];\nw = rand(m)\nw ./=sum(w) We use as lower and upper bound the arithmetic and geometric mean  $L$  and  $U$ , respectively. L = inv( sum( wi * inv(qi) for (wi, qi) in zip(w,q) ) )\nU = sum( wi * qi for (wi, qi) in zip(w,q) ) As a starting point, the Frank-Wolfe algorithm requires a feasible point. We use p0 = (L+U)/2 And we can check that it is feasible"},{"id":3059,"pagetitle":"Frank Wolfe comparison","title":"Common Functions","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Frank-Wolfe/#Common-Functions","content":" Common Functions Given  $p \\in \\mathcal M$ ,  $X \\in T_p\\mathcal M$  on the symmetric positive definite matrices  M , this method computes the closed form solution to \\[\\operatorname*{arg\\,min}_{q\\in  {\\mathcal C}}\\ \\langle X, \\log_p q\\rangle\n  = \\operatorname*{arg\\,min}_{q\\in  {\\mathcal C}}\\ \\operatorname{tr}(S\\log(YqY))\\] where  $\\mathcal C = \\{ q | L \\preceq q \\preceq U \\}$ ,  $S = p^{-1/2}Xp^{-1/2}$ , and  $Y=p^{-1/2}$ . The solution is given by  $Z=X^{-1}Q\\bigl( P^{\\mathrm{T}}[-\\operatorname{sgn}(D)]_{+}P+\\hat{L}\\bigr)Q^{\\mathrm{T}}X^{-1}$ ,@ where  $S=QDQ^{\\mathrm{T}}$  is a diagonalization of  $S$ ,  $\\hat{U}-\\hat{L}=P^{\\mathrm{T}}P$  with  $\\hat{L}=Q^{\\mathrm{T}}XLXQ$  and  $\\hat{U}=Q^{\\mathrm{T}}XUXQ$ , where  $[-\\mbox{sgn}(D)]_{+}$  is the diagonal matrix \\[\\operatorname{diag}\\bigl(\n  [-\\operatorname{sgn}(d_{11})]_{+}, \\ldots, [-\\operatorname{sgn}(d_{nn})]_{+}\n\\bigr)\\] and  $D=(d_{ij})$ . @doc raw\"\"\"\n    closed_form_solution!(M, q, L, U, p X)\n\nCompute the closeed form solution of the constraint sub problem in place of ``q``.\n\"\"\"\nfunction closed_form_solution!(M::SymmetricPositiveDefinite, q, L, U, p, X)\n    # extract p^1/2 and p^{-1/2}\n    (p_sqrt_inv, p_sqrt) = Manifolds.spd_sqrt_and_sqrt_inv(p)\n    # Compute D & Q\n    e2 = eigen(p_sqrt_inv * X * p_sqrt_inv) # decompose Sk  = QDQ'\n    D = Diagonal(1.0 .* (e2.values .< 0))\n    Q = e2.vectors\n    #println(p)\n    Uprime = Q' * p_sqrt_inv * U * p_sqrt_inv * Q\n    Lprime = Q' * p_sqrt_inv * L * p_sqrt_inv * Q\n    P = cholesky(Hermitian(Uprime - Lprime))\n    z = P.U' * D * P.U + Lprime\n    copyto!(M, q, p_sqrt * Q * z * Q' * p_sqrt)\n    return q\nend"},{"id":3060,"pagetitle":"Frank Wolfe comparison","title":"The Difference of Convex Formulation","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Frank-Wolfe/#The-Difference-of-Convex-Formulation","content":" The Difference of Convex Formulation We use  $g(p) = \\iota_{\\mathcal C}(p)$  as the indicator funtion of the set  $\\mathcal C$ . We use function is_pos_def(p; atol=5e-13)\n    e = eigen(Symmetric(p))\n    return all((e.values .+ atol) .> 0)\nend\nfunction g(p, L, U)\n    return (is_pos_def(p-L) && is_pos_def(U-p)) ? 0.0 : Inf\nend\nh(M, p, w, q) = sum(wi * distance(M, p, qi)^2 for (wi, qi) in zip(w,q) ) So we can first check that  p0  is feasible g(p0,L,U) == 0.0 true Now setting \\[\\operatorname*{arg\\,min}_{p\\in\\mathcal M}\\ g(p) - h(p)\\] We look for a maximum of  $h$ , where  $g$  is minimal, i.e.¬† $g(p)$  is zero or in other words  $p \\in \\mathcal C$ . The gradient of  $h$  can also be implemented in closed form as grad_h(M, p, w, q) = -2.0 * sum(wi * log(M, p, qi) for (wi, qi) in zip(w, q))\nfunction grad_h!(M, X, p, w, q)\n    Y = copy(M, p, X)\n    zero_vector!(M, X, p)\n    for (wi, qi) in zip(w,q)\n        log!(M, Y, p, qi)\n        Y .*= - 2.0*wi\n        X .+= Y\n    end\n    return X\nend And we can further define the cost, which will just be  $+\\infty$  outside of  $\\mathcal C$ . We define f_dc(M, p) = g(p, L, U) - h(M, p, w, q)\ngrad_h!(M, X, p) = grad_h!(M, X, p, w, q)\nfunction grad_f_dc!(M,X, p)\n    grad_h!(M, X, p, w, q)\n    X .*= -1.0\n    return X\nend Here we can omit the gradient of  $g$  in the definition of  $\\operatorname{grad} f$ , since the gradient is zero at the points there it is defined, that is on any point that is not on the boundary of  $\\mathcal C$ . As the last step, we can provide the closed form solver for the DC sub problem given at iteration  $k$  by \\[\\operatorname*{arg\\,min}_{p\\in \\mathcal C}\\\n  \\big\\langle -\\operatorname{grad} h(p^{(k)}), \\exp^{-1}_{p^{(k)}}p\\big\\rangle.\\] Which we con compute function dc_sub_solution!(M, q, p, X)\n    closed_form_solution!(M, q, L, U, p, -X)\n    return q\nend For safety, we might want to avoid ending up at the boundary of  $\\mathcal C$ . That is we reduce the distance we walk towards the solution  $q$  a bit. function dc_sub_solution_safe!(M, q, p, X)\n    p_last = copy(M,p) # since p=q might be in place\n    closed_form_solution!(M, q, L, U, p, -X)\n    q_orig = copy(M,q) # since we do the following in place of q\n    a = minimum(real.(eigen(q-L).values))\n    b = minimum(real.(eigen(U-q).values))\n    s = 1.0\n    d = distance(M, p_last, q_orig);\n    # if we are close to zero, we reduce faster.\n    Œ± = d < 1/(n^2) ? 0.66 : 0.9995;\n    i=0\n    while (a < 0) || (b < 0)\n        s *= Œ±\n        shortest_geodesic!(M, q, p_last, q_orig, s)\n        a = minimum(real.(eigen(q-L).values))\n        b = minimum(real.(eigen(U-q).values))\n        #println(\"$i a: $a, b = $b with s=$s\")\n        i=i+1\n        if (i>100) # safety fallback\n            #@warn \" $i steps where not enough $s ($Œ±)\\n$a $b\\n $(distance(M, p_last, q_orig)). Fixing by shifting EVs\"\n            qe = eigen(q)\n            if a < 0\n                qe.values .+= min(1e-8, n*abs(min(a,b)))\n            else\n                qe.values .-= min(1e-8, n*abs(min(a,b)))\n            end\n            q .= qe.vectors * Diagonal(qe.values) * (qe.vectors)'\n            a = minimum(real.(eigen(q-L).values))\n            b = minimum(real.(eigen(U-q).values))\n            return q\n        end\n    end\n    return q\nend"},{"id":3061,"pagetitle":"Frank Wolfe comparison","title":"The DoC solver run","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Frank-Wolfe/#The-DoC-solver-run","content":" The DoC solver run Let‚Äôs compare both methods when they have the same stopping criteria @time state1_dc = difference_of_convex_algorithm(M, f_dc, g, grad_h!, p0;\n    gradient=grad_f_dc!,\n    sub_problem=dc_sub_solution_safe!,\n    evaluation=InplaceEvaluation(),\n    stopping_criterion = StopAfterIteration(300) |\n        StopWhenChangeLess(1e-14) | StopWhenGradientChangeLess(M, 1e-9),\n    debug = [\n        (:Iteration, \"# %-8d \"), (:Cost, \"F(p): %0.14f\"), (:Change, \" |Œîp|: %0.14f \"),\n        (:GradientNorm, \" |grad f(p)|: %0.8f \"),\n        (:GradientChange, \" |Œîgrad f(p)|: %0.8f\"),\n        30, :Stop, \"\\n\"],\n    record = [:Iteration, :Iterate, :Cost, RecordGradientNorm(), :Change],\n    return_state=true,\n) Initial F(p): -0.77661458292831\nAt iteration 23 the change of the gradient (3.192989916935325e-13) was less than 1.0e-9.\n 17.041637 seconds (16.55 M allocations: 1.629 GiB, 3.09% gc time, 92.32% compilation time)\n\n# Solver state for `Manopt.jl`s Difference of Convex Algorithm\nAfter 23 iterations\n\n## Parameters\n* sub solver state:\n    | InplaceEvaluation()\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 300:  not reached\n    |Œîp| < 1.0e-14: not reached\n    |Œîgrad f| < 1.0e-9: reached\nOverall: reached\nThis indicates convergence: No\n\n## Debug\n    :Iteration = [(:Iteration, \"# %-8d \"), (:Cost, \"F(p): %0.14f\"), (:Change, \" |Œîp|: %0.14f \"), (:GradientNorm, \" |grad f(p)|: %0.8f \"), (:GradientChange, \" |Œîgrad f(p)|: %0.8f\"), \"\\n\", 30]\n    :Stop = :Stop\n\n## Record\n(Iteration = RecordGroup([RecordIteration(), RecordIterate(Matrix{Float64}), RecordCost(), RecordGradientNorm(), RecordChange(; inverse_retraction_method=LogarithmicInverseRetraction())]),) Let‚Äôs extract the final point and look at its cost p1_dc = get_solver_result(state1_dc);\nf_dc(M, p1_dc) -0.784425242474807 As well as whether (and how well) it is feasible, that is the following values should all be larger than zero. [ extrema(eigen(p1_dc-L).values), extrema(eigen(U-p1_dc).values)] 2-element Vector{Tuple{Float64, Float64}}:\n (1.1886583723800445e-12, 0.06669240322431051)\n (1.3411042178831775e-5, 0.0671353506908023) For the statistics we extract the recordings from the state"},{"id":3062,"pagetitle":"Frank Wolfe comparison","title":"Define the Frank-Wolfe functions","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Frank-Wolfe/#Define-the-Frank-Wolfe-functions","content":" Define the Frank-Wolfe functions For Frank wolfe, the cost is just defined as  $-h(p)$  but the minimisation is constraint to  $\\mathcal C$ , which is enfored by the oracle. f_fw(M, p) = -h(M, p, w, q)\nfunction grad_f_fw!(M,X, p)\n    grad_h!(M, X, p, w, q)\n    X .*= -1.0\n    return X\nend\noracle_fw!(M, q, p, X) = closed_form_solution!(M, q, L, U, p, X)"},{"id":3063,"pagetitle":"Frank Wolfe comparison","title":"The FW Solver Run","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Frank-Wolfe/#The-FW-Solver-Run","content":" The FW Solver Run Similarly we can run the Frank-Wolfe algorithm with @time state1_fw = Frank_Wolfe_method(M, f_fw, grad_f_fw!, p0;\n    sub_problem=oracle_fw!,\n    evaluation=InplaceEvaluation(),\n    stopping_criterion = StopAfterIteration(10^4) |\n        StopWhenChangeLess(1e-14) |¬†StopWhenGradientChangeLess(M, 1e-9),\n    debug = [\n        (:Iteration, \"# %-8d \"), :Cost, (:Change, \" |Œîp|: %0.14f \"),\n        (:GradientNorm, \" |grad f(p)|: %0.8f \"),\n        (:GradientChange, \" |Œîgrad f(p)|: %0.8f\"),\n        2*10^3, :Stop, \"\\n\"],\n    record = [:Iteration, :Iterate, :Cost, RecordGradientNorm(), :Change],\n    return_state=true,\n) Initial f(x): -0.776615\n# 2000     f(x): -0.784420 |Œîp|: 0.04611942377596  |grad f(p)|: 0.17693408  |Œîgrad f(p)|: 0.17555618\n# 4000     f(x): -0.784421 |Œîp|: 0.00372201632005  |grad f(p)|: 0.17694619  |Œîgrad f(p)|: 0.00749427\n# 6000     f(x): -0.784422 |Œîp|: 0.00205683506784  |grad f(p)|: 0.17695204  |Œîgrad f(p)|: 0.00414088\n# 8000     f(x): -0.784422 |Œîp|: 0.00140675676260  |grad f(p)|: 0.17695565  |Œîgrad f(p)|: 0.00283200\n# 10000    f(x): -0.784422 |Œîp|: 0.00106177438611  |grad f(p)|: 0.17695815  |Œîgrad f(p)|: 0.00213746\nThe algorithm reached its maximal number of iterations (10000).\n155.661032 seconds (55.49 M allocations: 94.001 GiB, 2.24% gc time, 0.56% compilation time)\n\n# Solver state for `Manopt.jl`s Frank Wolfe Method\nAfter 10000 iterations\n\n## Parameters\n* inverse retraction method: LogarithmicInverseRetraction()\n* retraction method: ExponentialRetraction()\n* sub solver state:\n    | InplaceEvaluation()\n\n## Stepsize\nDecreasingStepsize(; length=2.0,  factor=1.0,  subtrahend=0.0,  shift=2)\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 10000:    reached\n    |Œîp| < 1.0e-14: not reached\n    |Œîgrad f| < 1.0e-9: not reached\nOverall: reached\nThis indicates convergence: No\n\n## Debug\n    :Iteration = [(:Iteration, \"# %-8d \"), (:Cost, \"f(x): %f\"), (:Change, \" |Œîp|: %0.14f \"), (:GradientNorm, \" |grad f(p)|: %0.8f \"), (:GradientChange, \" |Œîgrad f(p)|: %0.8f\"), \"\\n\", 2000]\n    :Stop = :Stop\n\n## Record\n(Iteration = RecordGroup([RecordIteration(), RecordIterate(Matrix{Float64}), RecordCost(), RecordGradientNorm(), RecordChange(; inverse_retraction_method=LogarithmicInverseRetraction())]),) And we take a look at this result as well p1_fw = get_solver_result(state1_fw);\nf_dc(M, p1_fw) -0.7844220281765162 And its feasibility [extrema(eigen(p1_fw-L).values), extrema(eigen(U-p1_fw).values)] 2-element Vector{Tuple{Float64, Float64}}:\n (4.904818928410655e-10, 0.06659173821656107)\n (3.245654983213335e-5, 0.06713970236096602)"},{"id":3064,"pagetitle":"Frank Wolfe comparison","title":"Statistics","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Frank-Wolfe/#Statistics","content":" Statistics We extract the recorded values # DoC\niter1_dc = get_record(state1_dc, :Iteration, :Iteration)\npk_dc = get_record(state1_dc,:Iteration,:Iterate)\ncosts1_dc = -h.(Ref(M), pk_dc, Ref(w), Ref(q))\ndc_min = minimum(costs1_dc)\n# FW\niter1_fw = get_record(state1_fw,:Iteration,:Iteration)[1:5:end]\npk_fw = get_record(state1_fw,:Iteration,:Iterate)[1:5:end]\ncosts1_fw = -h.(Ref(M), pk_fw, Ref(w), Ref(q)) And let‚Äôs plot the result, where we measure the cost versus the minimum the difference of convex algorithm attains. fig = plot(;\n    legend=:topright,\n    xlabel=raw\"Iterations $k$ (log. scale)\", ylabel=raw\"Cost $f(x_k)-f^*$ (log. scale)\",\n    yaxis=:log,\n    ylims=(1e-8, 10^-2),\n    xaxis=:log,\n    xlims=(1,10^4),\n)\nplot!(fig, iter1_dc, costs1_dc .- dc_min, color=indigo, label=\"Difference of Convex\")\nplot!(fig, iter1_fw, costs1_fw .- dc_min, color=teal, label=\"Frank-Wolfe\") This indicates, that the difference off convex algorithm could even stop earlier with a proper stopping criterion, since after that the cost increases a bit again. On the other hand, Frank-Wolfe still has not reached this level function value after  10^4  iterations."},{"id":3065,"pagetitle":"Frank Wolfe comparison","title":"Literature","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Frank-Wolfe/#Literature","content":" Literature [BFSS23] R.¬†Bergmann, O.¬†P.¬†Ferreira, E.¬†M.¬†Santos and J.¬†C.¬†Souza.  The difference of convex algorithm on Hadamard manifolds . Preprint (2023),  arXiv:2112.05250 . [WS22] M.¬†Weber and S.¬†Sra.  Riemannian Optimization via Frank-Wolfe Methods .  Mathematical¬†Programming  199 , 525‚Äì556  (2022)."},{"id":3068,"pagetitle":"Rosenbrock Metric","title":"Solving Rosenbrock with the Difference of Convex Algorithm","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Rosenbrock/#Solving-Rosenbrock-with-the-Difference-of-Convex-Algorithm","content":" Solving Rosenbrock with the Difference of Convex Algorithm Ronny Bergmann 2023-06-06"},{"id":3069,"pagetitle":"Rosenbrock Metric","title":"Introduction","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Rosenbrock/#Introduction","content":" Introduction This example illustrates how the  üìñ Rosenbrock  problem can be rephrased as a difference of convex problem and with a new metric on Euclidean space. This example is the code that produces the results in [ BFSS23 ], Section 7.2. Both the Rosenbrock problem \\[    \\operatorname*{argmin}_{x\\in ‚Ñù^2} a\\bigl( x_1^2-x_2\\bigr)^2 + \\bigl(x_1-b\\bigr)^2,\\] where  $a,b>0$  and usually  $b=1$  and  $a \\gg b$ , we know the minimizer  $x^* = (b,b^2)^\\mathrm{T}$ , and also the (Euclidean) gradient \\[\\nabla f(x) =\n  \\begin{pmatrix}\n  4a(x_1^2-x_2)\\\\ -2a(x_1^2-x_2)\n  \\end{pmatrix}\n  +\n  \\begin{pmatrix}\n  2(x_1-b)\\\\ 0\n  \\end{pmatrix}.\\] They are even available already here in  ManifoldExamples.jl , see  RosenbrockCost  and  RosenbrockGradient!! . Furthermore, the  RosenbrockMetric  can be used on  $‚Ñù^2$ , that is \\[‚ü®X,Y‚ü©_{\\mathrm{Rb},p} = X^\\mathrm{T}G_pY, \\qquad\nG_p = \\begin{pmatrix}\n  1+4p_1^2 & -2p_1 \\\\\n  -2p_1 & 1\n\\end{pmatrix},\\] In this example we want to explore four different approaches to minimizing the Rosenbrock example, that are all based on first-order methods, i.e.¬†using a gradient but not a Hessian. The Euclidean Gradient The Riemannian gradient descent with respect to the  RosenbrockMetric The Euclidean Difference of Convex Algorithm The Riemannian Difference of Convex Algorithm respect to the  RosenbrockMetric Where we obtain a difference of convex problem by writing \\[f(x) = a\\bigl( x_1^2-x_2\\bigr)^2 + \\bigl(x_1-b\\bigr)^2\n = a\\bigl( x_1^2-x_2\\bigr)^2 + 2\\bigl(x_1-b\\bigr)^2 - \\bigl(x_1-b\\bigr)^2\\] that is \\[g(x) = a\\bigl( x_1^2-x_2\\bigr)^2 + 2\\bigl(x_1-b\\bigr)^2 \\quad\\text{ and }\\quad h(x) = \\bigl(x_1-b\\bigr)^2\\] using LinearAlgebra, Random, Statistics\nusing Manifolds, Manopt, ManoptExamples\nusing NamedColors, Plots\nimport Manopt: set_manopt_parameter!\nRandom.seed!(42) paul_tol = load_paul_tol()\nindigo = paul_tol[\"mutedindigo\"]\ngreen = paul_tol[\"mutedgreen\"]\nsand = paul_tol[\"mutedsand\"]\nteal = paul_tol[\"mutedteal\"]\ngrey = paul_tol[\"mutedgrey\"] To emphasize the effect, we choose a quite large value of  a . a = 2*10^5\nb = 1 and use the starting point and a direction to check gradients p0 = [0.1, 0.2]"},{"id":3070,"pagetitle":"Rosenbrock Metric","title":"The Euclidean Gradient Descent.","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Rosenbrock/#The-Euclidean-Gradient-Descent.","content":" The Euclidean Gradient Descent. For the Euclidean gradient we can just use the same approach as in the  Rosenbrock example M = ‚Ñù^2\nf = ManoptExamples.RosenbrockCost(M; a=a, b=b)\n‚àáf!! = ManoptExamples.RosenbrockGradient!!(M; a=a, b=b) define a common debug vector debug_vec = [\n        (:Iteration, \"# %-8d \"),\n        (:Cost, \"F(x): %1.4e\"),\n        \" \",\n        (:Change, \"|Œ¥p|: %1.4e | \"),\n        (:GradientNorm, \"|grad f|: %1.6e\"),\n        :Stop,\n        \"\\n\",\n    ] and call the  gradient descent algorithm Eucl_GD_state = gradient_descent(M, f, ‚àáf!!, p0;\n    evaluation=InplaceEvaluation(),\n    debug=[debug_vec...,10^7],\n    stopping_criterion=StopAfterIteration(10^8) | StopWhenChangeLess(1e-16),\n    record=[:Iteration, :Cost],\n    return_state=true,\n) Initial F(x): 7.2208e+03 \n# 10000000 F(x): 8.9937e-06 |Œ¥p|: 1.3835e+00 | |grad f|: 8.170355e-03\n# 20000000 F(x): 2.9474e-09 |Œ¥p|: 6.5764e-03 | |grad f|: 1.419191e-04\n# 30000000 F(x): 9.8376e-13 |Œ¥p|: 1.1918e-04 | |grad f|: 2.526295e-06\n# 40000000 F(x): 3.2830e-16 |Œ¥p|: 2.1773e-06 | |grad f|: 4.526313e-08\n# 50000000 F(x): 1.0154e-19 |Œ¥p|: 3.9803e-08 | |grad f|: 6.838240e-10\nThe algorithm performed a step with a change (0.0) less than 1.0e-16.\n\n# Solver state for `Manopt.jl`s Gradient Descent\nAfter 53073227 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 100000000:    not reached\n    |Œîp| < 1.0e-16: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Debug\n    :Iteration = [(:Iteration, \"# %-8d \"), (:Cost, \"F(x): %1.4e\"), \" \", (:Change, \"|Œ¥p|: %1.4e | \"), (:GradientNorm, \"|grad f|: %1.6e\"), \"\\n\", 10000000]\n    :Stop = :Stop\n\n## Record\n(Iteration = RecordGroup([RecordIteration(), RecordCost()]),)"},{"id":3071,"pagetitle":"Rosenbrock Metric","title":"The Riemannian Gradient Descent.","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Rosenbrock/#The-Riemannian-Gradient-Descent.","content":" The Riemannian Gradient Descent. For the Riemannian case, we define M_rb = MetricManifold(M, ManoptExamples.RosenbrockMetric()) MetricManifold(Euclidean(2; field=‚Ñù), ManoptExamples.RosenbrockMetric()) and the gradient is now adopted to the new metric function grad_f!(M, X, p)\n    ‚àáf!!(M, X, p)\n    riemannian_gradient!(M, X, p, X)\n    return X\nend\nfunction grad_f(M, p)\n    X = zero_vector(M, p)\n    return grad_f!(M, X, p)\nend R_GD_state = gradient_descent(M_rb, f, grad_f!, p0;\n    evaluation=InplaceEvaluation(),\n    debug=[debug_vec...,10^6],\n    stopping_criterion=StopAfterIteration(10^8) | StopWhenChangeLess(1e-16),\n    record=[:Iteration, :Cost],\n    return_state=true,\n) Initial F(x): 7.2208e+03 \n# 1000000  F(x): 1.3571e-09 |Œ¥p|: 9.1006e-01 | |grad f|: 1.974939e-04\n# 2000000  F(x): 2.7921e-18 |Œ¥p|: 3.6836e-05 | |grad f|: 9.240792e-09\nThe algorithm performed a step with a change (0.0) less than 1.0e-16.\n\n# Solver state for `Manopt.jl`s Gradient Descent\nAfter 2443750 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 100000000:    not reached\n    |Œîp| < 1.0e-16: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Debug\n    :Iteration = [(:Iteration, \"# %-8d \"), (:Cost, \"F(x): %1.4e\"), \" \", (:Change, \"|Œ¥p|: %1.4e | \"), (:GradientNorm, \"|grad f|: %1.6e\"), \"\\n\", 1000000]\n    :Stop = :Stop\n\n## Record\n(Iteration = RecordGroup([RecordIteration(), RecordCost()]),)"},{"id":3072,"pagetitle":"Rosenbrock Metric","title":"The Euclidean Difference of Convex","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Rosenbrock/#The-Euclidean-Difference-of-Convex","content":" The Euclidean Difference of Convex For the convex case, we have to first introduce the two parts of the cost. f1(M, p; a=100, b=1) = a * (p[1]^2 - p[2])^2;\nf2(M, p; a=100, b=1) = (p[1] - b[1])^2;\ng(M, p; a=100, b=1) = f1(M, p; a=a, b=b) + 2 * f2(M, p; a=a, b=b)\nh(M, p; a=100, b=1) = f2(M, p; a=a, b=b) and their (Euclidan) gradients function ‚àáh!(M, X, p; a=100, b=1)\n    X[1] = 2*(p[1]-b)\n    X[2] = 0\n    return X\nend\nfunction ‚àáh(M, p; a=100, b=1)\n    X = zero(p)\n    ‚àáh!(M, X, p; a=a, b=b)\n    return X\nend\nfunction ‚àág!(M, X, p; a=100, b=1)\n    X[1] = 4*a*(p[1]^2-p[2])*p[1] + 2*2*(p[1]-b)\n    X[2] = -2*a*(p[1]^2-p[2])\n    return X\nend\nfunction ‚àág(M, p; a=100, b=1)\n    X = zero(p)\n    ‚àág!(M, X, p; a=a, b=b)\n    return X\nend and we define for convenience docE_g(M, p) = g(M, p; a=a, b=b)\ndocE_f(M,p) = docE_g(M,p) - h(M, p; a=a, b=b)\ndocE_‚àáh!(M, X, p) = ‚àáh!(M, X, p; a=a, b=b)\ndocE_‚àág!(M, X, p) = ‚àág!(M, X, p; a=a, b=b)\nfunction docE_‚àáf!(M, X, p)\n  Y = zero_vector(M, p)\n  docE_‚àág!(M, X, p)\n  docE_‚àáh!(M, Y, p)\n  X .-= Y\n  return X\nend Then we call the  difference of convex algorithm  on Eucldiean space  $‚Ñù^2$ . E_doc_state = difference_of_convex_algorithm(\n    M, docE_f, docE_g, docE_‚àáh!, p0;\n    gradient=docE_‚àáf!,\n    grad_g = docE_‚àág!,\n    debug=[debug_vec..., 10^4],\n    evaluation=InplaceEvaluation(),\n    record=[:Iteration, :Cost],\n    stopping_criterion=StopAfterIteration(10^8) | StopWhenChangeLess(1e-16),\n    sub_hess=nothing, # Use gradient descent\n    sub_stopping_criterion=StopAfterIteration(2000) | StopWhenGradientNormLess(1e-16),\n    return_state=true,\n) Initial F(x): 7.2208e+03 \n# 10000    F(x): 2.9705e-09 |Œ¥p|: 1.3270e+00 | |grad f|: 1.388203e-04\n# 20000    F(x): 3.3302e-16 |Œ¥p|: 1.2173e-04 | |grad f|: 4.541087e-08\nThe algorithm performed a step with a change (0.0) less than 1.0e-16.\n\n# Solver state for `Manopt.jl`s Difference of Convex Algorithm\nAfter 26549 iterations\n\n## Parameters\n* sub solver state:\n    | # Solver state for `Manopt.jl`s Gradient Descent\n    | After 2000 iterations\n    | \n    | ## Parameters\n    | * retraction method: ExponentialRetraction()\n    | \n    | ## Stepsize\n    | ArmijoLinesearch() with keyword parameters\n    |   * initial_stepsize    = 1.0\n    |   * retraction_method   = ExponentialRetraction()\n    |   * contraction_factor  = 0.95\n    |   * sufficient_decrease = 0.1\n    | \n    | ## Stopping criterion\n    | \n    | Stop When _one_ of the following are fulfilled:\n    |     Max Iteration 2000:   reached\n    |     |grad f| < 1.0e-16: not reached\n    | Overall: reached\n    | This indicates convergence: No\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 100000000:    not reached\n    |Œîp| < 1.0e-16: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Debug\n    :Iteration = [(:Iteration, \"# %-8d \"), (:Cost, \"F(x): %1.4e\"), \" \", (:Change, \"|Œ¥p|: %1.4e | \"), (:GradientNorm, \"|grad f|: %1.6e\"), \"\\n\", 10000]\n    :Stop = :Stop\n\n## Record\n(Iteration = RecordGroup([RecordIteration(), RecordCost()]),)"},{"id":3073,"pagetitle":"Rosenbrock Metric","title":"The Riemannian Difference of Convex","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Rosenbrock/#The-Riemannian-Difference-of-Convex","content":" The Riemannian Difference of Convex We first have to again defined the gradients with respect to the new metric function grad_h!(M, X, p; a=100, b=1)\n    ‚àáh!(M, X, p; a=a, b=b)\n    riemannian_gradient!(M, X, p, X)\n    return X\nend\nfunction grad_h(M, p; a=100, b=1)\n    X = zero(p)\n    grad_h!(M, X, p; a=a, b=b)\n    return X\nend\nfunction grad_g!(M, X, p; a=100, b=1)\n    ‚àág!(M, X, p; a=a,b=b)\n    riemannian_gradient!(M, X, p, X)\n    return X\nend\nfunction grad_g(M, p; a=100, b=1)\n    X = zero(p)\n    grad_g!(M, X, p; a=a, b=b)\n    return X\nend While the cost of the subgradient can be infered automaticallty, we also have to provide the gradient of the sub problem. For  $X \\in ‚àÇh(p^{(k)})$  the sunproblem top determine  $p^{(k+1)}$  reads \\[\\operatorname*{argmin}_{p\\in\\mathcal M} g(p) - \\langle X, \\log_{p^{(k)}}p\\rangle\\] for which usually the cost and gradient functions are computed automatically in the difference of convex algorithm. However, in our case first the closed form solution for the adjoint differential of the logaithmic map is complicated to compute and second the gradint can even be given in a nicer form. We can first simplify in our case with  $X = \\operatorname{grad} h(p^{(k)})$  that \\[\\phi(p) = g(p) - \\langle X, \\log_{p^{(k)}}p\\rangle\n= a\\bigl( p_{1}^2-p_{2}\\bigr)^2\n        + 2\\bigl(p_{1}-b\\bigr)^2 - 2(p^{(k)}_1-b)p_1 + 2(p^{(k)}_1-b)p^{(k)}_1,\\] its Euclidean gradient reads \\[\\operatorname{grad}\\phi(p) =\n    \\nabla \\varphi(p)\n    = \\begin{pmatrix}\n        4a p_1(p_1^2-p_2) + 4(p_1-b) - 2(p^{(k)}_1-b)\\\\\n        -2a(p_1^2-p_2)\n    \\end{pmatrix}\\] where we can again employ the gradient conversion from before to obtain the Riemannian gradient. mutable struct SubGrad{P,T,V}\n    pk::P\n    Xk::T\n    a::V\n    b::V\nend\nfunction (œï::SubGrad)(M, p)\n    X = zero_vector(M, p)\n    œï(M, X, p)\n    return X\nend\nfunction (œï::SubGrad)(M, X, p)\n    X .= [\n        4 * œï.a * p[1] * (p[1]^2 - p[2]) + 4 * (p[1] - œï.b) - 2 * (œï.pk[1] - œï.b),\n        -2 * œï.a * (p[1]^2 - p[2]),\n    ]\n    riemannian_gradient!(M, X, p, X) # convert\n    return X\nend And in orer to update the subsolvers gradient correctly, we have to overwrite set_manopt_parameter!(œï::SubGrad, ::Val{:p}, p) = (œï.pk .= p)\nset_manopt_parameter!(œï::SubGrad, ::Val{:X}, X) = (œï.Xk .= X) And we again introduce for ease of use docR_g(M, p) = g(M, p; a=a, b=b)\ndocR_f(M, p) = docR_g(M, p) - h(M, p; a=a, b=b)\ndocR_grad_h!(M, X, p) = grad_h!(M, X, p; a=a, b=b)\ndocR_grad_g!(M, X, p) = grad_g!(M, X, p; a=a, b=b)\nfunction docR_grad_f!(M, X, p)\n    Y = zero_vector(M, p)\n    docR_grad_g!(M, X, p)\n    docR_grad_h!(M, Y, p)\n    X .-= Y\n    return X\nend\ndocR_sub_grad = SubGrad(copy(M, p0), zero_vector(M, p0), a, b) Then we can finally call the last of our four algorithms to compare, the difference of convex algorithm with the Riemannian metric. R_doc_state = difference_of_convex_algorithm(\n    M_rb, docR_f, docR_g, docR_grad_h!, p0;\n    gradient=docR_grad_f!,\n    grad_g = docR_grad_g!,\n    debug=[debug_vec..., 10^6],\n    evaluation=InplaceEvaluation(),\n    record=[:Iteration, :Cost],\n    stopping_criterion=StopAfterIteration(10^8) | StopWhenChangeLess(1e-16),\n    sub_grad=docR_sub_grad,\n    sub_hess = nothing, # Use gradient descent\n    sub_stopping_criterion=StopAfterIteration(2000) | StopWhenGradientNormLess(1e-16),\n    return_state=true,\n) Initial F(x): 7.2208e+03 \nThe algorithm performed a step with a change (0.0) less than 1.0e-16.\n\n# Solver state for `Manopt.jl`s Difference of Convex Algorithm\nAfter 1235 iterations\n\n## Parameters\n* sub solver state:\n    | # Solver state for `Manopt.jl`s Gradient Descent\n    | After 2000 iterations\n    | \n    | ## Parameters\n    | * retraction method: ExponentialRetraction()\n    | \n    | ## Stepsize\n    | ArmijoLinesearch() with keyword parameters\n    |   * initial_stepsize    = 1.0\n    |   * retraction_method   = ExponentialRetraction()\n    |   * contraction_factor  = 0.95\n    |   * sufficient_decrease = 0.1\n    | \n    | ## Stopping criterion\n    | \n    | Stop When _one_ of the following are fulfilled:\n    |     Max Iteration 2000:   reached\n    |     |grad f| < 1.0e-16: not reached\n    | Overall: reached\n    | This indicates convergence: No\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 100000000:    not reached\n    |Œîp| < 1.0e-16: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Debug\n    :Iteration = [(:Iteration, \"# %-8d \"), (:Cost, \"F(x): %1.4e\"), \" \", (:Change, \"|Œ¥p|: %1.4e | \"), (:GradientNorm, \"|grad f|: %1.6e\"), \"\\n\", 1000000]\n    :Stop = :Stop\n\n## Record\n(Iteration = RecordGroup([RecordIteration(), RecordCost()]),)"},{"id":3074,"pagetitle":"Rosenbrock Metric","title":"Comparison in Iterations","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Rosenbrock/#Comparison-in-Iterations","content":" Comparison in Iterations fig = plot(;\n    legend=:topright,\n    xlabel=raw\"Iterations $k$ (log. scale)\", ylabel=raw\"Cost $f(x)$ (log. scale)\",\n    yaxis=:log,\n    ylims=(1e-16, 5*1e5),\n    xaxis=:log,\n    xlims=(1,10^8),\n)\nscatter!(fig, [1,], [f(M,p0),], label=raw\"$f(p_0)$\", markercolor=grey)\negi = get_record(Eucl_GD_state, :Iteration, :Iteration)[1:10000:end] #5308 entries\negc = get_record(Eucl_GD_state, :Iteration, :Cost)[1:10000:end] #5308 entries\nplot!(fig, egi, egc, color=teal, label=\"Euclidean GD\")\n#\nrgi = get_record(R_GD_state, :Iteration, :Iteration)[1:1000:end] # 2444 entries\nrgc = get_record(R_GD_state, :Iteration, :Cost)[1:1000:end] # 2444 entries\nplot!(fig, rgi, rgc, color=indigo, label=\"Riemannian GD\")\n#\nedi = get_record(E_doc_state, :Iteration, :Iteration) #26549 entries\nedc = get_record(E_doc_state, :Iteration, :Cost) #26549 entries\nplot!(fig, edi, edc, color=sand, label=\"Euclidean DoC\")\n#\nrdi = get_record(R_doc_state, :Iteration, :Iteration) # 1235 entries\nrdc = get_record(R_doc_state, :Iteration, :Cost) # 1235 entries\nplot!(fig, rdi, rdc, color=green, label=\"Riemannian DoC\") And we can see that using difference of convex outperforms gradient descent, and using the Riemannian approach required less iterations than their Euclidean counterparts."},{"id":3075,"pagetitle":"Rosenbrock Metric","title":"Literature","ref":"/manoptexamples/stable/examples/Difference-of-Convex-Rosenbrock/#Literature","content":" Literature [BFSS23] R.¬†Bergmann, O.¬†P.¬†Ferreira, E.¬†M.¬†Santos and J.¬†C.¬†Souza.  The difference of convex algorithm on Hadamard manifolds . Preprint (2023),  arXiv:2112.05250 ."},{"id":3078,"pagetitle":"Hyperparameter optimziation","title":"Hyperparameter optimization","ref":"/manoptexamples/stable/examples/HyperparameterOptimization/#Hyperparameter-optimization","content":" Hyperparameter optimization Mateusz Baran 2024-08-03"},{"id":3079,"pagetitle":"Hyperparameter optimziation","title":"Introduction","ref":"/manoptexamples/stable/examples/HyperparameterOptimization/#Introduction","content":" Introduction This example shows how to automatically select the best values of hyperparameters of optimization procedures such as retraction, vector transport, size of memory in L-BFGS or line search coefficients. Hyperparameter optimization relies on the  Optuna  [ ASY+19 ] Python library because it is much more advanced than similar Julia projects, offering Bayesian optimization with conditional hyperparameters and early stopping."},{"id":3080,"pagetitle":"Hyperparameter optimziation","title":"General definitions","ref":"/manoptexamples/stable/examples/HyperparameterOptimization/#General-definitions","content":" General definitions Here are some general definitions that you will most likely be able to directly use for your problem without any changes. Just remember to install  optuna , for example using  CondaPkg  Julia library. using Manifolds, Manopt\nusing PythonCall\nusing BenchmarkTools\nusing LineSearches\n\n# This script requires optuna to be available through PythonCall\n# You can install it for example using\n# using CondaPkg\n# ]conda add optuna\n\noptuna = pyimport(\"optuna\")\n\nnorm_inf(M::AbstractManifold, p, X) = norm(X, Inf)\n\n# TTsuggest_ structs collect data from a calibrating optimization run\n# that is handled by compute_pruning_losses function\n\nstruct TTsuggest_int\n    suggestions::Dict{String,Int}\nend\nfunction (s::TTsuggest_int)(name::String, a, b)\n    return s.suggestions[name]\nend\nstruct TTsuggest_float\n    suggestions::Dict{String,Float64}\nend\nfunction (s::TTsuggest_float)(name::String, a, b; log::Bool=false)\n    return s.suggestions[name]\nend\nstruct TTsuggest_categorical\n    suggestions::Dict{String,Any}\nend\nfunction (s::TTsuggest_categorical)(name::String, vals)\n    return s.suggestions[name]\nend\nstruct TTreport\n    reported_vals::Vector{Float64}\nend\nfunction (r::TTreport)(val, i)\n    return push!(r.reported_vals, val)\nend\nstruct TTshould_prune end\n(::TTshould_prune)() = Py(false)\nstruct TracingTrial\n    suggest_int::TTsuggest_int\n    suggest_float::TTsuggest_float\n    suggest_categorical::TTsuggest_categorical\n    report::TTreport\n    should_prune::TTshould_prune\nend\n\nfunction compute_pruning_losses(\n    od,\n    int_suggestions::Dict{String,Int},\n    float_suggestions::Dict{String,Float64},\n    categorical_suggestions::Dict{String,Int},\n)\n    tt = TracingTrial(\n        TTsuggest_int(int_suggestions),\n        TTsuggest_float(float_suggestions),\n        TTsuggest_categorical(categorical_suggestions),\n        TTreport(Float64[]),\n        TTshould_prune(),\n    )\n    od(tt)\n    return tt.report.reported_vals\nend The next part is your hyperparameter optimization objective. The  ObjectiveData  struct contains all relevant information about the sequence of specific problems. The outermost key part is the  N_range  field. Early stopping requires a series of progressively more complex problems. They will be attempted from the most simple one to the most complex one, and are specified by the values of  N  in that vector. mutable struct ObjectiveData{TObj,TGrad}\n    obj::TObj\n    grad::TGrad\n    N_range::Vector{Int}\n    gtol::Float64\n    vts::Vector{AbstractVectorTransportMethod}\n    retrs::Vector{AbstractRetractionMethod}\n    manifold_constructors::Vector{Tuple{String,Any}}\n    pruning_losses::Vector{Float64}\n    manopt_stepsize::Vector{Tuple{String,Any}}\n    obj_loss_coeff::Float64\nend In the example below we optimize hyperparameters on a sequence of Rosenbrock-type problems restricted to spheres: \\[\\arg\\min_{p \\in S^{N-1}} \\sum_{i=1}^{N/2} (1-p_{2i})^2 + 100 (p_{2i+1} - p_{2i}^2)^2,\\] where  $N \\in [2, 16, 128, 1024, 8192, 65536]$ . obj  and  grad  are the objective and gradient, here defined as below. Note that gradient works in-place and variants without manifolds are also provided for easier comparison with other libraries like  Optim.jl . It is easiest when problems for different values  N  can be distinguished by being defined on successively larger manifolds but the script could be modified so that it‚Äôs not necessary. pruning_losses  and  compute_pruning_losses  are related to early pruning used in Optuna and you shouldn‚Äôt have to modify them. function f_rosenbrock(x)\n    result = 0.0\n    for i in 1:2:length(x)\n        result += (1.0 - x[i])^2 + 100.0 * (x[i + 1] - x[i]^2)^2\n    end\n    return result\nend\nfunction f_rosenbrock(::AbstractManifold, x)\n    return f_rosenbrock(x)\nend\n\nfunction g_rosenbrock!(storage, x)\n    for i in 1:2:length(x)\n        storage[i] = -2.0 * (1.0 - x[i]) - 400.0 * (x[i + 1] - x[i]^2) * x[i]\n        storage[i + 1] = 200.0 * (x[i + 1] - x[i]^2)\n    end\n    return storage\nend\nfunction g_rosenbrock!(M::AbstractManifold, storage, x)\n    g_rosenbrock!(storage, x)\n    riemannian_gradient!(M, storage, x, storage)\n    return storage\nend Next,  gtol  is the tolerance used for the stopping criterion in optimization.  vts  and  retrs  are, respectively, vector transports and retraction methods selected through hyperparameter optimization. Some items need to be different for different values of  N , for example the manifold over which the problem is defined. This is handled by  manifold_constructors  which is then defined as  Tuple{String,Any}[(\"Sphere\", N -> Manifolds.Sphere(N - 1))] , where the string  \"Sphere\"  is used to identify the manifold family and the next element is a function that transforms the value of  N  to the manifold for the problem of size  N . Similarly, different stepsize selection methods may be considered. This is handled by the field  manopt_stepsize . It will be easiest to see how it works by looking at how it is initialized: Tuple{String,Any}[\n    (\"LS-HZ\", M -> Manopt.LineSearchesStepsize(ls_hz)),\n    (\"Wolfe-Powell\", (M, c1, c2) -> Manopt.WolfePowellLinesearch(M, c1, c2)),\n] We have a string that identifies the line search method name and a constructor of the line search which takes relevant arguments like the manifold or a numerical parameter. The next part is the trial evaluation procedure. This is one of the more important places which need to be customized to your problem. This is the point where we tell Optuna about the relevant optimization hyperparameters and use them to define specific problems. The hyperparameter optimization is a multiobjective problem: we want as good problem objectives as possible and as low times as possible. As Optuna doesn‚Äôt currently support multicriteria pruning, which is important for obtaining a solution in a reasonable amount of time, we use a linear combination of sub-objectives to turn the problem into a single-criterion optimization. The hyperparameter optimization objective is a linear combination of achieved objectives the relative weight is controlled by  objective.obj_loss_coeff . function (objective::ObjectiveData)(trial)\n    # Here we use optuna to select memory length for L-BFGS -- an integer in the range between 2 and 30, referenced by name \"mem_len\"\n    mem_len = trial.suggest_int(\"mem_len\", 2, 30)\n\n    # Here we select a vector transport and retraction methods, one of those specified in the `ObjectiveData`.\n    vt = objective.vts[pyconvert(\n        Int,\n        trial.suggest_categorical(\n            \"vector_transport_method\", Vector(eachindex(objective.vts))\n        ),\n    )]\n    retr = objective.retrs[pyconvert(\n        Int,\n        trial.suggest_categorical(\"retraction_method\", Vector(eachindex(objective.retrs))),\n    )]\n\n    # Here we select the manifold constructor, in case we want to try different manifolds for our problem. For example one could try defining a problem with orthogonality constraints on Stiefel, Grassmann or flag manifold.\n    manifold_name, manifold_constructor = objective.manifold_constructors[pyconvert(\n        Int,\n        trial.suggest_categorical(\n            \"manifold\", Vector(eachindex(objective.manifold_constructors))\n        ),\n    )]\n\n    # Here the stepsize selection method type is selected.\n    manopt_stepsize_name, manopt_stepsize_constructor = objective.manopt_stepsize[pyconvert(\n        Int,\n        trial.suggest_categorical(\n            \"manopt_stepsize\", Vector(eachindex(objective.manopt_stepsize))\n        ),\n    )]\n\n    # This parametrizes stepsize selection methods with relevant numerical parameters.\n    local c1_val, c2_val, hz_sigma\n    if manopt_stepsize_name == \"Wolfe-Powell\"\n        c1_val = pyconvert(\n            Float64, trial.suggest_float(\"Wolfe-Powell c1\", 1e-5, 1e-2; log=true)\n        )\n        c2_val =\n            1.0 - pyconvert(\n                Float64, trial.suggest_float(\"Wolfe-Powell 1-c2\", 1e-4, 1e-2; log=true)\n            )\n    elseif manopt_stepsize_name == \"Improved HZ\"\n        hz_sigma = pyconvert(Float64, trial.suggest_float(\"Improved HZ sigma\", 0.1, 0.9))\n    end\n\n    # The current loss estimate, taking into account estimated loss values for larger, not-yet-evaluated values of `N`.\n    loss = sum(objective.pruning_losses)\n\n    # Here iterate over problems we want to optimize for\n    # from smallest to largest; pruning should stop the iteration early\n    # if the hyperparameter set is not promising\n    cur_i = 0\n    for N in objective.N_range\n        # Here we define the initial point for the optimization procedure\n        p0 = zeros(N)\n        p0[1] = 1\n        M = manifold_constructor(N)\n        # Here we construct the specific line search to be used\n        local ls\n        if manopt_stepsize_name == \"Wolfe-Powell\"\n            ls = manopt_stepsize_constructor(M, c1_val, c2_val)\n        elseif manopt_stepsize_name == \"Improved HZ\"\n            ls = manopt_stepsize_constructor(M, hz_sigma)\n        else\n            ls = manopt_stepsize_constructor(M)\n        end\n        manopt_time, manopt_iters, manopt_obj = benchmark_time_state(\n            ManoptQN(),\n            M,\n            N,\n            objective.obj,\n            objective.grad,\n            p0,\n            ls,\n            pyconvert(Int, mem_len),\n            objective.gtol;\n            vector_transport_method=vt,\n            retraction_method=retr,\n        )\n        # TODO: turn this into multi-criteria optimization when Optuna starts supporting\n        # pruning in such problems\n        loss -= objective.pruning_losses[cur_i + 1]\n        loss += manopt_time + objective.obj_loss_coeff * manopt_obj\n        trial.report(loss, cur_i)\n        if pyconvert(Bool, trial.should_prune().__bool__())\n            throw(PyException(optuna.TrialPruned()))\n        end\n        cur_i += 1\n    end\n    return loss\nend In the following benchmarking code you will most likely have to adapt solver parameters. This is designed around  quasi_Newton  but can be adapted to any solver as needed. The example below performs a small number of trials for quick rendering but in practice you should aim for at least a few thousand trials (the  n_trials  parameter). # An abstract type in case we want to try different optimization packages.\nabstract type AbstractOptimConfig end\nstruct ManoptQN <: AbstractOptimConfig end\n\n# Benchmark that evaluates hyperparameters. Returns time to reach the solution, number of iterations and final value of the objective.\nfunction benchmark_time_state(\n    ::ManoptQN,\n    M::AbstractManifold,\n    N,\n    f,\n    g!,\n    p0,\n    stepsize::Manopt.Stepsize,\n    mem_len::Int,\n    gtol::Real;\n    kwargs...,\n)\n    manopt_sc = StopWhenGradientNormLess(gtol; norm=norm_inf) | StopAfterIteration(1000)\n    mem_len = min(mem_len, manifold_dimension(M))\n    manopt_state = quasi_Newton(\n        M,\n        f,\n        g!,\n        p0;\n        stepsize=stepsize,\n        evaluation=InplaceEvaluation(),\n        return_state=true,\n        memory_size=mem_len,\n        stopping_criterion=manopt_sc,\n        debug=[],\n        kwargs...,\n    )\n    bench_manopt = @benchmark quasi_Newton(\n        $M,\n        $f,\n        $g!,\n        $p0;\n        stepsize=$(stepsize),\n        evaluation=$(InplaceEvaluation()),\n        memory_size=$mem_len,\n        stopping_criterion=$(manopt_sc),\n        debug=[],\n        $kwargs...,\n    )\n    iters = get_count(manopt_state, :Iterations)\n    final_val = f(M, manopt_state.p)\n    return median(bench_manopt.times) / 1000, iters, final_val\nend\n\n\"\"\"\n    lbfgs_study(; pruning_coeff::Float64=0.95)\n\nSet up the example hyperparameter optimization study.\n\"\"\"\nfunction lbfgs_study(; pruning_coeff::Float64=0.95)\n    Ns = [2^n for n in 1:3:12]\n    ls_hz = LineSearches.HagerZhang()\n    od = ObjectiveData(\n        f_rosenbrock,\n        g_rosenbrock!,\n        Ns,\n        1e-5,\n        AbstractVectorTransportMethod[ParallelTransport(), ProjectionTransport()],\n        [ExponentialRetraction(), ProjectionRetraction()],\n        Tuple{String,Any}[(\"Sphere\", N -> Manifolds.Sphere(N - 1))],\n        zeros(Float64, eachindex(Ns)),\n        Tuple{String,Any}[\n            (\"LS-HZ\", M -> Manopt.LineSearchesStepsize(ls_hz)),\n            #(\"Improved HZ\", (M, sigma) -> HagerZhangLinesearch(M; sigma=sigma)),\n            (\"Wolfe-Powell\", (M, c1, c2) -> Manopt.WolfePowellLinesearch(M, c1, c2)),\n        ],\n        10.0,\n    )\n\n    # Here you need to define baseline values of all hyperparameters\n    baseline_pruning_losses = compute_pruning_losses(\n        od,\n        Dict(\"mem_len\" => 4),\n        Dict(\n            \"Wolfe-Powell c1\" => 1e-4,\n            \"Wolfe-Powell 1-c2\" => 1e-3,\n            \"Improved HZ sigma\" => 0.9,\n        ),\n        Dict(\n            \"vector_transport_method\" => 1,\n            \"retraction_method\" => 1,\n            \"manifold\" => 1,\n            \"manopt_stepsize\" => 1,\n        ),\n    )\n    od.pruning_losses = pruning_coeff * baseline_pruning_losses\n\n    study = optuna.create_study(; study_name=\"L-BFGS\")\n    # Here you can specify number of trials and timeout (in seconds).\n    study.optimize(od; n_trials=1000, timeout=500)\n    println(\"Best params is $(study.best_params) with value $(study.best_value)\")\n    selected_manifold = od.manifold_constructors[pyconvert(Int, study.best_params[\"manifold\"])][1]\n    selected_retraction_method = od.retrs[pyconvert(Int, study.best_params[\"retraction_method\"])]\n    selected_vector_transport = od.vts[pyconvert(Int, study.best_params[\"vector_transport_method\"])]\n    println(\"Selected manifold: $(selected_manifold)\")\n    println(\"Selected retraction method: $(selected_retraction_method)\")\n    println(\"Selected vector transport method: $(selected_vector_transport)\")\n    return study\nend\n\nlbfgs_study() Best params is {'mem_len': 3, 'vector_transport_method': 2, 'retraction_method': 1, 'manifold': 1, 'manopt_stepsize': 2, 'Wolfe-Powell c1': 0.0006125542888545935, 'Wolfe-Powell 1-c2': 0.0010744467792321093} with value 5510.963227438757\nSelected manifold: Sphere\nSelected retraction method: ExponentialRetraction()\nSelected vector transport method: ProjectionTransport()\n\n[I 2024-03-16 18:04:17,965] A new study created in memory with name: L-BFGS\n[I 2024-03-16 18:04:45,996] Trial 0 finished with value: 5639.789870295856 and parameters: {'mem_len': 26, 'vector_transport_method': 1, 'retraction_method': 1, 'manifold': 1, 'manopt_stepsize': 2, 'Wolfe-Powell c1': 0.00027288064367948073, 'Wolfe-Powell 1-c2': 0.00026503788892114045}. Best is trial 0 with value: 5639.789870295856.\n[I 2024-03-16 18:05:11,860] Trial 1 finished with value: 5635.936370295855 and parameters: {'mem_len': 11, 'vector_transport_method': 1, 'retraction_method': 1, 'manifold': 1, 'manopt_stepsize': 2, 'Wolfe-Powell c1': 0.002743250060163298, 'Wolfe-Powell 1-c2': 0.00037986521186922096}. Best is trial 1 with value: 5635.936370295855.\n[I 2024-03-16 18:05:39,386] Trial 2 finished with value: 5673.101441724422 and parameters: {'mem_len': 26, 'vector_transport_method': 2, 'retraction_method': 2, 'manifold': 1, 'manopt_stepsize': 2, 'Wolfe-Powell c1': 0.00043339485784312605, 'Wolfe-Powell 1-c2': 0.0027302649933974173}. Best is trial 1 with value: 5635.936370295855.\n[I 2024-03-16 18:06:10,279] Trial 3 finished with value: 7410.818084581564 and parameters: {'mem_len': 26, 'vector_transport_method': 1, 'retraction_method': 2, 'manifold': 1, 'manopt_stepsize': 1}. Best is trial 1 with value: 5635.936370295855.\n[I 2024-03-16 18:06:37,995] Trial 4 finished with value: 5756.566226449636 and parameters: {'mem_len': 25, 'vector_transport_method': 1, 'retraction_method': 1, 'manifold': 1, 'manopt_stepsize': 1}. Best is trial 1 with value: 5635.936370295855.\n[I 2024-03-16 18:06:42,755] Trial 5 pruned. \n[I 2024-03-16 18:06:58,577] Trial 6 pruned. \n[I 2024-03-16 18:07:15,366] Trial 7 pruned. \n[I 2024-03-16 18:07:40,605] Trial 8 finished with value: 5581.7437274386975 and parameters: {'mem_len': 7, 'vector_transport_method': 1, 'retraction_method': 1, 'manifold': 1, 'manopt_stepsize': 2, 'Wolfe-Powell c1': 0.0010567355712112379, 'Wolfe-Powell 1-c2': 0.003948002490203636}. Best is trial 8 with value: 5581.7437274386975.\n[I 2024-03-16 18:07:46,021] Trial 9 pruned. \n[I 2024-03-16 18:08:11,512] Trial 10 finished with value: 5510.963227438757 and parameters: {'mem_len': 3, 'vector_transport_method': 2, 'retraction_method': 1, 'manifold': 1, 'manopt_stepsize': 2, 'Wolfe-Powell c1': 0.0006125542888545935, 'Wolfe-Powell 1-c2': 0.0010744467792321093}. Best is trial 10 with value: 5510.963227438757.\n[I 2024-03-16 18:08:35,914] Trial 11 finished with value: 5521.388656010121 and parameters: {'mem_len': 2, 'vector_transport_method': 2, 'retraction_method': 1, 'manifold': 1, 'manopt_stepsize': 2, 'Wolfe-Powell c1': 0.0006738829952322474, 'Wolfe-Powell 1-c2': 0.0010639659137420014}. Best is trial 10 with value: 5510.963227438757.\n[I 2024-03-16 18:09:00,317] Trial 12 finished with value: 5521.36958458155 and parameters: {'mem_len': 2, 'vector_transport_method': 2, 'retraction_method': 1, 'manifold': 1, 'manopt_stepsize': 2, 'Wolfe-Powell c1': 0.00010975606104676191, 'Wolfe-Powell 1-c2': 0.0007663843095951679}. Best is trial 10 with value: 5510.963227438757.\n[I 2024-03-16 18:09:24,680] Trial 13 finished with value: 5520.7020845815505 and parameters: {'mem_len': 2, 'vector_transport_method': 2, 'retraction_method': 1, 'manifold': 1, 'manopt_stepsize': 2, 'Wolfe-Powell c1': 6.743450835567536e-05, 'Wolfe-Powell 1-c2': 0.0008779759729737719}. Best is trial 10 with value: 5510.963227438757.\n[I 2024-03-16 18:09:50,268] Trial 14 pruned. \n[I 2024-03-16 18:10:15,494] Trial 15 finished with value: 5595.119584581556 and parameters: {'mem_len': 6, 'vector_transport_method': 2, 'retraction_method': 1, 'manifold': 1, 'manopt_stepsize': 2, 'Wolfe-Powell c1': 8.147444451747575e-05, 'Wolfe-Powell 1-c2': 0.00012268601197923553}. Best is trial 10 with value: 5510.963227438757.\n[I 2024-03-16 18:10:25,264] Trial 16 pruned. \n[I 2024-03-16 18:10:50,209] Trial 17 finished with value: 5572.474513153012 and parameters: {'mem_len': 5, 'vector_transport_method': 2, 'retraction_method': 1, 'manifold': 1, 'manopt_stepsize': 2, 'Wolfe-Powell c1': 0.0015998473664092935, 'Wolfe-Powell 1-c2': 0.0005109172020536229}. Best is trial 10 with value: 5510.963227438757.\n[I 2024-03-16 18:10:54,772] Trial 18 pruned. \n[I 2024-03-16 18:11:04,534] Trial 19 pruned. \n[I 2024-03-16 18:11:28,873] Trial 20 finished with value: 5512.3824417244705 and parameters: {'mem_len': 3, 'vector_transport_method': 2, 'retraction_method': 1, 'manifold': 1, 'manopt_stepsize': 2, 'Wolfe-Powell c1': 1.1581668103921961e-05, 'Wolfe-Powell 1-c2': 0.0002691056199427656}. Best is trial 10 with value: 5510.963227438757.\n[I 2024-03-16 18:11:53,327] Trial 21 finished with value: 5529.088227438692 and parameters: {'mem_len': 4, 'vector_transport_method': 2, 'retraction_method': 1, 'manifold': 1, 'manopt_stepsize': 2, 'Wolfe-Powell c1': 1.3645031886009879e-05, 'Wolfe-Powell 1-c2': 0.0001863385753491203}. Best is trial 10 with value: 5510.963227438757.\n[I 2024-03-16 18:12:17,911] Trial 22 finished with value: 5522.041370295835 and parameters: {'mem_len': 2, 'vector_transport_method': 2, 'retraction_method': 1, 'manifold': 1, 'manopt_stepsize': 2, 'Wolfe-Powell c1': 1.0030173525937465e-05, 'Wolfe-Powell 1-c2': 0.000543991948003312}. Best is trial 10 with value: 5510.963227438757.\n[I 2024-03-16 18:12:27,645] Trial 23 pruned. \n[I 2024-03-16 18:12:52,163] Trial 24 finished with value: 5528.840941724406 and parameters: {'mem_len': 4, 'vector_transport_method': 2, 'retraction_method': 1, 'manifold': 1, 'manopt_stepsize': 2, 'Wolfe-Powell c1': 0.000245400433292576, 'Wolfe-Powell 1-c2': 0.000133639324295565}. Best is trial 10 with value: 5510.963227438757.\n\nPython: <optuna.study.study.Study object at 0x70dd985d9b50>"},{"id":3081,"pagetitle":"Hyperparameter optimziation","title":"Summary","ref":"/manoptexamples/stable/examples/HyperparameterOptimization/#Summary","content":" Summary We‚Äôve shown how to automatically select the best hyperparameter values for your optimization problem."},{"id":3082,"pagetitle":"Hyperparameter optimziation","title":"Literature","ref":"/manoptexamples/stable/examples/HyperparameterOptimization/#Literature","content":" Literature [ASY+19] T.¬†Akiba, S.¬†Sano, T.¬†Yanase, T.¬†Ohta and M.¬†Koyama.  Optuna: A Next-generation Hyperparameter Optimization Framework . In:  Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining  (2019),  arXiv:1907.10902 ."},{"id":3085,"pagetitle":"The Rayleigh Quotient","title":"The Rayleigh Quotient","ref":"/manoptexamples/stable/examples/RayleighQuotient/#The-Rayleigh-Quotient","content":" The Rayleigh Quotient Ronny Bergmann 2024-03-09"},{"id":3086,"pagetitle":"The Rayleigh Quotient","title":"Introduction","ref":"/manoptexamples/stable/examples/RayleighQuotient/#Introduction","content":" Introduction This example reproduces a few conceptual ideas of Optimization on Manifolds that are used throughout [ Bou23 ] using the Rayleigh quotient and explores several different ways to use the algorithms from  Manopt.jl . For a symmetric matrix  $A \\in \\mathbb R^{n\\times n}$  we consider the  üìñ Rayleigh Quotient \\[\\operatorname*{arg\\,min}_{x \\in \\mathbb R^n \\backslash \\{0\\}}\n\\frac{x^{\\mathrm{T}}Ax}{\\lVert x¬†\\rVert^2}.\\] On the sphere we can omit the denominator and obtain \\[f(p) = p^{\\mathrm{T}}Ap,\\qquad p ‚àà ùïä^{n-1},\\] which by itself we can again continue in the embedding as \\[\\tilde f(x) = x^{\\mathrm{T}}Ax,\\qquad x \\in \\mathbb R^n.\\] This cost has the nice feature that at the minimizer  $p^*\\in\\mathbb S^{n-1}$  the function falue  $f(p^*)$  is the smalles eigenvalue of  $A$ . For the embedded function  $\\tilde f$  the gradient and Hessian can be computed with classical methods as \\[\\begin{align*}\n‚àá\\tilde f(x) &= 2Ax, \\qquad x ‚àà ‚Ñù^n,\n\\\\\n‚àá^2\\tilde f(x)[V] &= 2AV, \\qquad x, V ‚àà ‚Ñù^n.\n\\end{align*}\\] Similarly, cf.¬†Examples 3.62 and 5.27 of [ Bou23 ], the Riemannian gradient and Hessian on the manifold  $\\mathcal M = \\mathbb S^{n-1}$  are given by \\[\\begin{align*}\n\\operatorname{grad} f(p) &= 2Ap - 2(p^{\\mathrm{T}}Ap)*p,\\qquad p ‚àà ùïä^{n-1},\n\\\\\n\\operatorname{Hess} f(p)[X] &=  2AX - 2(p^{\\mathrm{T}}AX)p - 2(p^{\\mathrm{T}}Ap)X,\\qquad p ‚àà ùïä^{n-1}, X \\in T_pùïä^{n-1}\n\\end{align*}\\] Let‚Äôs first generate an example martrx  $A$ . using Pkg;\ncd(@__DIR__)\nPkg.activate(\".\"); # use the example environment, using LRUCache, BenchmarkTools, LinearAlgebra, Manifolds, ManoptExamples, Manopt, Random\nRandom.seed!(42)\nn = 500\nA = Symmetric(randn(n, n) / n) And the manifolds M = Sphere(n-1) Sphere(499, ‚Ñù) E = get_embedding(M) Euclidean(500; field=‚Ñù)"},{"id":3087,"pagetitle":"The Rayleigh Quotient","title":"Setup the corresponding functions","ref":"/manoptexamples/stable/examples/RayleighQuotient/#Setup-the-corresponding-functions","content":" Setup the corresponding functions Since  RayleighQuotientCost ,  RayleighQuotientGrad!! , and  RayleighQuotientHess!!  are themselves manifold agnostic we only need to initialize them once. Agnostic here means that they would compute  $f$  is called with  M  as their first argument and  $\\tilde f$  if called with  E . We instantiate f = ManoptExamples.RayleighQuotientCost(A)\ngrad_f = ManoptExamples.RayleighQuotientGrad!!(A)\nHess_f = ManoptExamples.RayleighQuotientHess!!(A) the suffix  !!  also indicates that these functions both work as allocating and in-place variants. Given a starting point and some memory p0 = [1.0, zeros(n-1)...]\nX = zero_vector(M, p0) we can both call Y = grad_f(M, p0)  # Allocates memory\ngrad_f(M, X, p0)    # Computes in place of X and returns the result in X.\nnorm(M, p0, X-Y) 0.0 Now we can use a few different variants of solvers to approaach this and this tutorial will walk you through a few of them. First of all let‚Äôs construct the actual result ‚Äì¬†since Rayleigh quotient minimization is not necessarily the best way to compute the smallest Eigenvalue. We can also compute Œª = min(eigvals(A)...) -0.08967721009388108"},{"id":3088,"pagetitle":"The Rayleigh Quotient","title":"A Solver based on gradient information","ref":"/manoptexamples/stable/examples/RayleighQuotient/#A-Solver-based-on-gradient-information","content":" A Solver based on gradient information Let‚Äôs first just use first-order information and since we are just starting, maybe we only derived the Euclidean gradient  $\\nabla \\tilde f$ . We can ‚Äútell‚Äù the solver, that the provided function and the gradient are defined as the Euclidean variants in the embedding. internally,  Manopt.jl  then issues the conversion for Euclidean gradients to the corresponding Riemannian one, cf.¬†e.g.¬† this tutorial section  or Section 3.8 or more precisely Example 3.62 in [ Bou23 ]. But instead of diving into all the tecnical details, we can just specify  objective_type=:Euclidean  to trigger the conversion. We start with a simple  gradient descent s = gradient_descent(M, f, grad_f, p0; objective_type=:Euclidean,\n    debug = [:Iteration, :Cost, :GradientNorm, 50, \"\\n\"],\n    return_state=true,\n)\nq1 = get_solver_result(s)\ns Initial f(x): -0.000727\n# 50    f(x): -0.088415|grad f(p)|:0.004530500043902619\n# 100   f(x): -0.089097|grad f(p)|:0.004589417101266096\n# 150   f(x): -0.089530|grad f(p)|:0.0026028331895358247\n# 200   f(x): -0.089650|grad f(p)|:0.0012359084298719039\n\n# Solver state for `Manopt.jl`s Gradient Descent\nAfter 200 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 200:  reached\n    |grad f| < 1.0e-8: not reached\nOverall: reached\nThis indicates convergence: No\n\n## Debug\n    :Iteration = [(:Iteration, \"# %-6d\"), (:Cost, \"f(x): %f\"), (:GradientNorm, \"|grad f(p)|:%s\"), \"\\n\", 50] From the final cost we can already see that  q1  is an eigenvector to the smallest eigenvalue we obtaines above. And we can compare this to running with the Riemannian gradient, since the  RayleighQuotientGrad!!  returns this one as well, when just called with the sphere as first Argument, we just have to remove the  objective_type . q2 = gradient_descent(M, f, grad_f, p0;\n    debug = [:Iteration, :Cost, :GradientNorm, 50, \"\\n\"],\n)\n#Test that both are the same\nisapprox(M, q1,q2) Initial f(x): -0.000727\n# 50    f(x): -0.088415|grad f(p)|:0.004530500043902567\n# 100   f(x): -0.089097|grad f(p)|:0.004589417101266063\n# 150   f(x): -0.089530|grad f(p)|:0.002602833189535808\n# 200   f(x): -0.089650|grad f(p)|:0.0012359084298719097\n\ntrue We can also benchmark both @benchmark gradient_descent($M, $f, $grad_f, $p0; objective_type=:Euclidean) BenchmarkTools.Trial: 22 samples with 1 evaluation.\n Range (min ‚Ä¶ max):  230.735 ms ‚Ä¶ 247.927 ms  ‚îä GC (min ‚Ä¶ max): 2.85% ‚Ä¶ 2.57%\n Time  (median):     231.768 ms               ‚îä GC (median):    2.78%\n Time  (mean ¬± œÉ):   234.409 ms ¬±   5.319 ms  ‚îä GC (mean ¬± œÉ):  2.81% ¬± 0.27%\n\n  ‚ñÑ‚ñà‚ñÑ‚ñÅ    ‚ñÅ                                     ‚ñÅ                \n  ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÅ‚ñÜ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ ‚ñÅ\n  231 ms           Histogram: frequency by time          248 ms <\n\n Memory estimate: 1.13 GiB, allocs estimate: 3613. @benchmark gradient_descent($M, $f, $grad_f, $p0) BenchmarkTools.Trial: 159 samples with 1 evaluation.\n Range (min ‚Ä¶ max):  30.890 ms ‚Ä¶ 40.010 ms  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 0.00%\n Time  (median):     31.134 ms              ‚îä GC (median):    0.00%\n Time  (mean ¬± œÉ):   31.598 ms ¬±  1.285 ms  ‚îä GC (mean ¬± œÉ):  0.57% ¬± 0.96%\n\n  ‚ñÉ‚ñà‚ñÖ                                                          \n  ‚ñà‚ñà‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñá‚ñÑ‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ ‚ñÇ\n  30.9 ms         Histogram: frequency by time        36.7 ms <\n\n Memory estimate: 11.38 MiB, allocs estimate: 3006. From these results we see, that the conversion from the Euclidean to the Riemannian gradient does require a small amount of effort and hence reduces the performance slighly. Still, if the Euclidean Gradient is easier to compute or already available, this is in terms of coding the faster way. Finally this is a tradeoff between derivation and implementation efforts for the Riemannian gradient and a slight performance reduction when using the Euclidean one."},{"id":3089,"pagetitle":"The Rayleigh Quotient","title":"A Solver based (also) on (approximate) Hessian information","ref":"/manoptexamples/stable/examples/RayleighQuotient/#A-Solver-based-(also)-on-(approximate)-Hessian-information","content":" A Solver based (also) on (approximate) Hessian information To also involve the Hessian, we consider the  trust regions  solver with three cases: Euclidean, approximating the Hessian Euclidean, providing the Hessian Riemannian, providing the Hessian but also using in-place evaluations. q3 = trust_regions(M, f, grad_f, p0; objective_type=:Euclidean,\n    debug = [:Iteration, :Cost, :GradientNorm, 10, \"\\n\"],\n); Initial f(x): -0.000727\n# 10    f(x): -0.088106|grad f(p)|:0.01903913659588686\n# 20    f(x): -0.089023|grad f(p)|:0.007792334296299116\n# 30    f(x): -0.089501|grad f(p)|:0.008034300330026467\n# 40    f(x): -0.089842|grad f(p)|:0.008125526728200166\n# 50    f(x): -0.089890|grad f(p)|:0.0031244752821335416\n# 60    f(x): -0.089925|grad f(p)|:0.0029682862637714163\n# 70    f(x): -0.089962|grad f(p)|:0.002811722437216778\n# 80    f(x): -0.089997|grad f(p)|:0.0026658493010157363\n# 90    f(x): -0.090032|grad f(p)|:0.0025418974797659266\n# 100   f(x): -0.090067|grad f(p)|:0.0024485809550738955\n# 110   f(x): -0.090108|grad f(p)|:0.0023894008071780747\n# 120   f(x): -0.090155|grad f(p)|:0.002362317662908117\n# 130   f(x): -0.090208|grad f(p)|:0.0023611301647631484\n# 140   f(x): -0.090262|grad f(p)|:0.00237797866404072\n# 150   f(x): -0.090314|grad f(p)|:0.002405563029627607\n# 160   f(x): -0.090362|grad f(p)|:0.002438250821406204\n# 170   f(x): -0.090404|grad f(p)|:0.002472221074327323\n# 180   f(x): -0.090441|grad f(p)|:0.0025051377726827166\n# 190   f(x): -0.090472|grad f(p)|:0.002535721310831389\n# 200   f(x): -0.090498|grad f(p)|:0.0025633813700434637\n# 210   f(x): -0.090513|grad f(p)|:0.0025832821804127513\n# 220   f(x): -0.090513|grad f(p)|:0.0025832821804127513\n# 230   f(x): -0.090513|grad f(p)|:0.0025832821792817493\n# 240   f(x): -0.090513|grad f(p)|:0.0025832821770197098\n# 250   f(x): -0.090513|grad f(p)|:0.0025832821747576924\n# 260   f(x): -0.090513|grad f(p)|:0.002583282172495683\n# 270   f(x): -0.090513|grad f(p)|:0.0025832821702336567\n# 280   f(x): -0.090513|grad f(p)|:0.002583282167971658\n# 290   f(x): -0.090513|grad f(p)|:0.002583282165709656\n# 300   f(x): -0.090513|grad f(p)|:0.002583282163447637\n# 310   f(x): -0.090513|grad f(p)|:0.0025832821611855928\n# 320   f(x): -0.090513|grad f(p)|:0.0025832821589235814\n# 330   f(x): -0.090513|grad f(p)|:0.002583282156661572\n# 340   f(x): -0.090513|grad f(p)|:0.0025832821543995727\n# 350   f(x): -0.090513|grad f(p)|:0.002583282152137569\n# 360   f(x): -0.090513|grad f(p)|:0.0025832821498755487\n# 370   f(x): -0.090513|grad f(p)|:0.0025832821476135036\n# 380   f(x): -0.090513|grad f(p)|:0.0025832821453515035\n# 390   f(x): -0.090513|grad f(p)|:0.0025832821430894675\n# 400   f(x): -0.090513|grad f(p)|:0.0025832821408274405\n# 410   f(x): -0.090513|grad f(p)|:0.002583282138565445\n# 420   f(x): -0.090513|grad f(p)|:0.002583282136303441\n# 430   f(x): -0.090513|grad f(p)|:0.00258328213404143\n# 440   f(x): -0.090513|grad f(p)|:0.002583282131779385\n# 450   f(x): -0.090513|grad f(p)|:0.0025832821295174104\n# 460   f(x): -0.090513|grad f(p)|:0.002583282127255372\n# 470   f(x): -0.090513|grad f(p)|:0.002583282124993372\n# 480   f(x): -0.090513|grad f(p)|:0.0025832821227313313\n# 490   f(x): -0.090513|grad f(p)|:0.0025832821204693065\n# 500   f(x): -0.090513|grad f(p)|:0.002583282118207321\n# 510   f(x): -0.090513|grad f(p)|:0.0025832821159453034\n# 520   f(x): -0.090513|grad f(p)|:0.0025832821136832665\n# 530   f(x): -0.090513|grad f(p)|:0.0025832821114212673\n# 540   f(x): -0.090513|grad f(p)|:0.002583282109159243\n# 550   f(x): -0.090513|grad f(p)|:0.002583282106897217\n# 560   f(x): -0.090513|grad f(p)|:0.002583282104635213\n# 570   f(x): -0.090513|grad f(p)|:0.0025832821023731955\n# 580   f(x): -0.090513|grad f(p)|:0.0025832821001112094\n# 590   f(x): -0.090513|grad f(p)|:0.002583282097849167\n# 600   f(x): -0.090513|grad f(p)|:0.0025832820955871503\n# 610   f(x): -0.090513|grad f(p)|:0.0025832820933251325\n# 620   f(x): -0.090513|grad f(p)|:0.002583282091063122\n# 630   f(x): -0.090513|grad f(p)|:0.0025832820888010873\n# 640   f(x): -0.090513|grad f(p)|:0.0025832820865390785\n# 650   f(x): -0.090513|grad f(p)|:0.0025832820842770442\n# 660   f(x): -0.090513|grad f(p)|:0.0025832820820150576\n# 670   f(x): -0.090513|grad f(p)|:0.0025832820797530767\n# 680   f(x): -0.090513|grad f(p)|:0.0025832820774910523\n# 690   f(x): -0.090513|grad f(p)|:0.0025832820752290362\n# 700   f(x): -0.090513|grad f(p)|:0.002583282072966992\n# 710   f(x): -0.090513|grad f(p)|:0.002583282070704973\n# 720   f(x): -0.090513|grad f(p)|:0.0025832820684429532\n# 730   f(x): -0.090513|grad f(p)|:0.002583282066180946\n# 740   f(x): -0.090513|grad f(p)|:0.0025832820639189306\n# 750   f(x): -0.090513|grad f(p)|:0.0025832820616569214\n# 760   f(x): -0.090513|grad f(p)|:0.00258328205939488\n# 770   f(x): -0.090513|grad f(p)|:0.002583282057132884\n# 780   f(x): -0.090513|grad f(p)|:0.0025832820548708406\n# 790   f(x): -0.090513|grad f(p)|:0.002583282052608873\n# 800   f(x): -0.090513|grad f(p)|:0.002583282050346837\n# 810   f(x): -0.090513|grad f(p)|:0.0025832820480848214\n# 820   f(x): -0.090513|grad f(p)|:0.0025832820458228205\n# 830   f(x): -0.090513|grad f(p)|:0.0025832820435608087\n# 840   f(x): -0.090513|grad f(p)|:0.0025832820412987944\n# 850   f(x): -0.090513|grad f(p)|:0.0025832820390367726\n# 860   f(x): -0.090513|grad f(p)|:0.002583282036774768\n# 870   f(x): -0.090513|grad f(p)|:0.002583282034512706\n# 880   f(x): -0.090513|grad f(p)|:0.002583282032250709\n# 890   f(x): -0.090513|grad f(p)|:0.0025832820299886896\n# 900   f(x): -0.090513|grad f(p)|:0.002583282027726701\n# 910   f(x): -0.090513|grad f(p)|:0.002583282025464682\n# 920   f(x): -0.090513|grad f(p)|:0.0025832820232026517\n# 930   f(x): -0.090513|grad f(p)|:0.002583282020940619\n# 940   f(x): -0.090513|grad f(p)|:0.0025832820186786334\n# 950   f(x): -0.090513|grad f(p)|:0.002583282016416595\n# 960   f(x): -0.090513|grad f(p)|:0.0025832820141545986\n# 970   f(x): -0.090513|grad f(p)|:0.0025832820118925717\n# 980   f(x): -0.090513|grad f(p)|:0.0025832820096305525\n# 990   f(x): -0.090513|grad f(p)|:0.002583282007368543\n# 1000  f(x): -0.090513|grad f(p)|:0.0025832820051065217 To provide the Hessian in the high-level interface we need to prodive it as an anonymous function, since any  struct  is considered to (eventually) be the also optional starting point. For space reasons, let‚Äôs also shorten the debug print to only iterations 7 and 14. q4 = trust_regions(M, f, grad_f, (E, p, X) -> Hess_f(E, p, X), p0; objective_type=:Euclidean,\n    debug = [:Iteration, :Cost, :GradientNorm, 10, \"\\n\"],\n); Initial f(x): -0.000727\n# 10    f(x): -0.089673|grad f(p)|:0.0033633987039373655 q5 = trust_regions(M, f, grad_f, (M, Y, p, X) -> Hess_f(M, Y, p, X), p0;\n    evaluation=InplaceEvaluation(),\n    debug = [:Iteration, :Cost, :GradientNorm, 10, \"\\n\"],\n); Initial f(x): -0.000727\n# 10    f(x): -0.089673|grad f(p)|:0.00336339870393737 Let‚Äôs also here compare them in benchmarks. Let‚Äôs here compare all variants in their (more performant) in-place versions. @benchmark trust_regions($M, $f, $grad_f, $p0;\n  objective_type=:Euclidean,\n  evaluation=InplaceEvaluation(),\n) BenchmarkTools.Trial: 10 samples with 1 evaluation.\n Range (min ‚Ä¶ max):  504.514 ms ‚Ä¶ 539.614 ms  ‚îä GC (min ‚Ä¶ max): 2.83% ‚Ä¶ 2.64%\n Time  (median):     508.900 ms               ‚îä GC (median):    2.81%\n Time  (mean ¬± œÉ):   512.978 ms ¬±  10.540 ms  ‚îä GC (mean ¬± œÉ):  2.79% ¬± 0.06%\n\n  ‚ñÅ‚ñà   ‚ñÅ ‚ñà         ‚ñÅ   ‚ñÅ ‚ñÅ                                    ‚ñÅ  \n  ‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà ‚ñÅ\n  505 ms           Histogram: frequency by time          540 ms <\n\n Memory estimate: 1.97 GiB, allocs estimate: 60518. @benchmark trust_regions($M, $f, $grad_f, $((E, Y, p, X) -> Hess_f(E, Y, p, X)), $p0;\n  evaluation=InplaceEvaluation(),\n  objective_type=:Euclidean\n) BenchmarkTools.Trial: 311 samples with 1 evaluation.\n Range (min ‚Ä¶ max):  13.541 ms ‚Ä¶ 21.282 ms  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 2.10%\n Time  (median):     15.376 ms              ‚îä GC (median):    3.11%\n Time  (mean ¬± œÉ):   16.099 ms ¬±  1.516 ms  ‚îä GC (mean ¬± œÉ):  3.90% ¬± 2.90%\n\n               ‚ñÉ‚ñà‚ñÇ                                             \n  ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñá‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ ‚ñÉ\n  13.5 ms         Histogram: frequency by time        20.3 ms <\n\n Memory estimate: 37.53 MiB, allocs estimate: 4527. @benchmark trust_regions($M, $f, $grad_f, $((M, Y, p, X) -> Hess_f(M, Y, p, X)), $p0;\n    evaluation=InplaceEvaluation(),\n) BenchmarkTools.Trial: 522 samples with 1 evaluation.\n Range (min ‚Ä¶ max):  9.178 ms ‚Ä¶  13.930 ms  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 0.00%\n Time  (median):     9.331 ms               ‚îä GC (median):    0.00%\n Time  (mean ¬± œÉ):   9.569 ms ¬± 495.194 Œºs  ‚îä GC (mean ¬± œÉ):  1.76% ¬± 2.89%\n\n  ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ                   ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ                          \n  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÑ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÖ ‚ñà\n  9.18 ms      Histogram: log(frequency) by time        11 ms <\n\n Memory estimate: 10.86 MiB, allocs estimate: 4506. We see that Hessian approximation is quite costly, and Gradient and Hessian conversion somewhat costly; still, they also might serve as a good starting point, before deciding to delve into computing Riemannian gradients and Hessians. Of course all 5 runs obtained solutions close by; one might consider the gradient based runs to not have fully converged. [distance(M, q1, q) for q ‚àà [q2,q3] ] 2-element Vector{Float64}:\n 4.471485799821605e-15\n 0.048047538209352994 [distance(M, q3, q) for q ‚àà [q4,q5] ] 2-element Vector{Float64}:\n 0.08269488012454579\n 0.08269488012454579 Which we can also see in the final cost, comparing it to the Eigenvalue [f(M, q) - Œª for q ‚àà [q1, q2, q3, q4, q5] ] 5-element Vector{Float64}:\n  2.76900562450888e-5\n  2.769005624428389e-5\n -0.000836208332542443\n  3.191891195797325e-16\n  3.191891195797325e-16"},{"id":3090,"pagetitle":"The Rayleigh Quotient","title":"Summary","ref":"/manoptexamples/stable/examples/RayleighQuotient/#Summary","content":" Summary We illustrated several possibilities to call solvers, with both Euclidean gradient and Hessian and Riemannian gradient and Hessian, allocating and in-place function. While the performance is better for the Riemannian case, the Euclidean one is a worthy alternative, when those are easier to compute."},{"id":3091,"pagetitle":"The Rayleigh Quotient","title":"Literature","ref":"/manoptexamples/stable/examples/RayleighQuotient/#Literature","content":" Literature [Bou23] N.¬†Boumal.  An Introduction to Optimization on Smooth Manifolds . First¬†Edition ( Cambridge University Press, 2023 )."},{"id":3094,"pagetitle":"Riemannian Mean","title":"The Riemannian Center of Mass (mean)","ref":"/manoptexamples/stable/examples/Riemannian-mean/#The-Riemannian-Center-of-Mass-(mean)","content":" The Riemannian Center of Mass (mean) Ronny Bergmann 2023-07-02"},{"id":3095,"pagetitle":"Riemannian Mean","title":"Preliminary Notes","ref":"/manoptexamples/stable/examples/Riemannian-mean/#Preliminary-Notes","content":" Preliminary Notes Each of the example objectives or problems stated in this package should be accompanied by a  Quarto  notebook that illustrates their usage, like this one. For this first example, the objective is a very common one, for example also used in the  Get started: optimize!  tutorial of  Manopt.jl . The second goal of this tutorial is to also illustrate how this package provides these examples, namely in both an easy-to-use and a performant way. There are two recommended ways to activate a reproducible environment. For most cases the recommended environment is the one in  examples/ . If you are programming a new, relatively short example, consider using the packages main environment, which is the same as having  ManoptExamples.jl  in development mode. this requires that your example does not have any (additional) dependencies beyond the ones  ManoptExamples.jl  has anyways. For registered versions of  ManoptExamples.jl  use the environment of  examples/  and ‚Äì under development ‚Äì add  ManoptExamples.jl  in development mode from the parent folder. This should be changed after a new example is within a registered version to just use the  examples/  environment again. using Pkg;\ncd(@__DIR__)\nPkg.activate(\".\"); # use the example environment,"},{"id":3096,"pagetitle":"Riemannian Mean","title":"Loading packages and defining data","ref":"/manoptexamples/stable/examples/Riemannian-mean/#Loading-packages-and-defining-data","content":" Loading packages and defining data Loading the necessary packages and defining a data set on a manifold using ManoptExamples, Manopt, Manifolds, ManifoldDiff, Random\nRandom.seed!(42)\nM = Sphere(2)\nn = 100\nœÉ = œÄ / 8\np = 1 / sqrt(2) * [1.0, 0.0, 1.0]\ndata = [exp(M, p,  œÉ * rand(M; vector_at=p)) for i in 1:n];"},{"id":3097,"pagetitle":"Riemannian Mean","title":"Variant 1: Using the functions","ref":"/manoptexamples/stable/examples/Riemannian-mean/#Variant-1:-Using-the-functions","content":" Variant 1: Using the functions We can define both the cost and gradient,  RiemannianMeanCost  and  RiemannianMeanGradient!! , respectively. For their mathematical derivation and further explanations, we again refer to  Get started: optimize! . f = ManoptExamples.RiemannianMeanCost(data)\ngrad_f = ManoptExamples.RiemannianMeanGradient!!(M, data) Then we can for example directly call a  gradient descent  as x1 = gradient_descent(M, f, grad_f, first(data)) 3-element Vector{Float64}:\n 0.6868392794567202\n 0.006531600696673591\n 0.7267799821044285"},{"id":3098,"pagetitle":"Riemannian Mean","title":"Variant 2: Using the objective","ref":"/manoptexamples/stable/examples/Riemannian-mean/#Variant-2:-Using-the-objective","content":" Variant 2: Using the objective A shorter way to directly obtain the  Manifold objective  including these two functions. Here, we want to specify that the objective can do in-place-evaluations using the  evaluation= -keyword. The objective can be obtained calling  Riemannian_mean_objective  as rmo = ManoptExamples.Riemannian_mean_objective(\n    M, data,\n    evaluation=InplaceEvaluation(),\n) Together with a manifold, this forms a  Manopt Problem , which would usually enable to switch manifolds between solver runs. Here we could for example switch to using  Euclidean(3)  instead for the same data the objective is build upon. rmp = DefaultManoptProblem(M, rmo) This enables us to for example solve the task with different, gradient based, solvers. The first is the same as above, just not using the high-level interface s1 = GradientDescentState(M, copy(M, first(data)))\nsolve!(rmp, s1)\nx2 = get_solver_result(s1) 3-element Vector{Float64}:\n 0.6868392794567202\n 0.006531600696673591\n 0.7267799821044285 but we can easily use a conjugate gradient instead s2 = ConjugateGradientDescentState(\n    M,\n    copy(M, first(data)),\n    StopAfterIteration(100),\n    ArmijoLinesearch(M),\n    FletcherReevesCoefficient(),\n)\nsolve!(rmp, s2)\nx3 = get_solver_result(s2) 3-element Vector{Float64}:\n 0.6868393613136017\n 0.006531541407458413\n 0.7267799052788726"},{"id":3101,"pagetitle":"Robust PCA","title":"The Robust PCA computed on the Grassmann manifold","ref":"/manoptexamples/stable/examples/Robust-PCA/#The-Robust-PCA-computed-on-the-Grassmann-manifold","content":" The Robust PCA computed on the Grassmann manifold Ronny BergmannLaura Weigl 2023-07-02 For this example we first load the necessary packages. using Pkg;\ncd(@__DIR__)\nPkg.activate(\".\"); # use the example environment, using LinearAlgebra, Random, Statistics\nusing Manifolds, Manopt, ManoptExamples\nusing Plots\nRandom.seed!(42)"},{"id":3102,"pagetitle":"Robust PCA","title":"Computing a Robust PCA","ref":"/manoptexamples/stable/examples/Robust-PCA/#Computing-a-Robust-PCA","content":" Computing a Robust PCA For a given matrix  $D ‚àà ‚Ñù^{d√ón}$  whose columns represent points in  $‚Ñù^d$ , a matrix  $p ‚àà ‚Ñù^{d√óm}$  is computed for a given dimension  $m < n$ :  $p$  represents an ONB of  $‚Ñù^{d√óm}$  such that the column space of  $p$  approximates the points (columns of  $D$ ), i.e.¬†the vectors  $D_i$  as well as possible. We compute  $p$  as a minimizer over the Grassmann manifold of the cost function: \\[\\begin{split}\nf(p)\n& = \\frac{1}{n}\\sum_{i=1}^{n}{\\operatorname{dist}(D_i, \\operatorname{span}(p))}\n\\\\\n& = \\frac{1}{n} \\sum_{i=1}^{n}\\lVert pp^TD_i - D_i\\rVert\n\\end{split}\\] The output cost represents the average distance achieved with the returned  $p$ , an orthonormal basis (or a point on the Stiefel manifold) representing the subspace (a point on the Grassmann manifold). Notice that norms are not squared, so we have a robust cost function. This means that  $f$  is nonsmooth, therefore we regularize with a pseudo-Huber loss function of smoothing parameter  $Œµ$ . \\[f_œµ(p) = \\frac{1}{n} \\sum_{i=1}^n{‚Ñì_œµ(\\lVert pp^{\\mathrm{T}}D_i - D_i\\rVert)},\\] where  $‚Ñì_œµ(x) = \\sqrt{x^2 + œµ^2} - œµ$ . The smoothing parameter is iteratively reduced in the final optimisation runs(with warm starts). First, we generate random data. For illustration purposes we take points in  $\\mathbb R^2$  and  $m=1$ , that is we aim to find a robust regression line. n = 40\nd = 2\noutliers = 15\ndata = randn(d, 1) * (1:n)' + 0.05 * randn(2, n) .* [1:n 1:n]'\n# Outliers:\npermute = shuffle(1:size(data, 2))'\ndata[:, permute[1:outliers]] = 30 * randn(2, outliers)\n# We are looking for a line here so we set\nm = 1 We use the Manopt toolbox to optimize the regularized cost function over the Grassmann manifold. To do this, we first need to define the problem structure. M = Grassmann(d,m); For the initial matrix  $p_0$  we use classical PCA via singular value decomposition. Thus, we use the first  $d$  left singular vectors. Then, we compute an optimum of the cost function over the Grassmann manifold. We use a trust-region method which is implemented in  Manopt.jl . Furthermore the cost and gradient are implemented in  ManoptExamples.jl . Since these are Huber regularized, both functors have the  œµ  as a parameter. To compute the Riemannian gradient we first compute the Euclidian gradient. Afterwards it is projected onto the tangent space by using the orthogonal projection  $pp^T - I$ , which converts the Euclidean to the Riemannian gradient. The trust-region method also requires the Hessian Matrix. By using  ApproxHessianFiniteDifference  using a finite difference scheme we get an approximation of the Hessian Matrix. We run the procedure several times, where the smoothing parameter  $Œµ$  is reduced iteratively. Œµ = 1.0\niterations = 6\nreduction = 0.5\nU, S, V = svd(data);\np0 = U[:, 1:m] 2√ó1 Matrix{Float64}:\n -0.7494248652139397\n  0.6620893983436593 Let‚Äôs generate the cost and gradient we aim to use here f = ManoptExamples.RobustPCACost(M, data, Œµ)\ngrad_f = ManoptExamples.RobustPCAGrad!!(M, data, Œµ) ManoptExamples.RobustPCAGrad!!{Matrix{Float64}, Float64}([9.537606557855465 1.6583418797018163 ‚Ä¶ 30.833523701909474 30.512999245062304; -45.34339972619071 -1.7120433539256108 ‚Ä¶ -35.85943792458936 -32.93976007215313], 1.0, [0.0 0.0 ‚Ä¶ 0.0 0.0; 0.0 0.0 ‚Ä¶ 0.0 0.0]) and check the initial cost f(M, p0) 9.430690947905521 Now we iterate the opimization with reducing  Œµ  after every iteration, which we update in  f  and  grad_f . q = copy(M, p0)\nŒµi = Œµ\nfor i in 1:iterations\n    f.Œµ = Œµi\n    grad_f.Œµ = Œµi\n    global q = trust_regions(\n        M,\n        f,\n        grad_f,\n        ApproxHessianFiniteDifference(\n            M, q, f;\n            vector_transport_method=ProjectionTransport(),\n            retraction_method=PolarRetraction(),\n        ),\n        q;\n        (project!)=project!,\n    )\n    global Œµi *= reduction\nend When finally setting  Œµ  we can investigate the final cost f.Œµ = 0.0\nf(M, q) 9.412961981726742 Finally, the results are presented visually. The data points are visualized in a scatter plot. The result of the robust PCA and (for comparison) the standard SVD solution are plotted as straight lines. fig = plot(data[1, :], data[2, :]; seriestype=:scatter, label=\"Data points\");\nplot!(\n    fig,\n    q[1] * [-1, 1] * 100,\n    q[2] * [-1, 1] * 100;\n    linecolor=:red,\n    linewidth=2,\n    label=\"Robust PCA\",\n);\nplot!(\n    fig,\n    p0[1] * [-1, 1] * 100,\n    p0[2] * [-1, 1] * 100;\n    xlims=1.1 * [minimum(data[1, :]), maximum(data[1, :])],\n    ylims=1.1 * [minimum(data[2, :]), maximum(data[2, :])],\n    linewidth=2,\n    linecolor=:black,\n    label=\"Standard SVD\",\n)"},{"id":3105,"pagetitle":"Rosenbrock","title":"The Rosenbrock Function","ref":"/manoptexamples/stable/examples/Rosenbrock/#The-Rosenbrock-Function","content":" The Rosenbrock Function Ronny Bergmann 2023-01-03 After loading the necessary packages using Pkg;\ncd(@__DIR__)\nPkg.activate(\".\"); # use the example environment, using Manifolds, Manopt, ManoptExamples\nusing Plots We fix the parameters for the  üìñ Rosenbrock  (where the wikipedia page has a slightly different parameter naming). a = 100.0\nb = 1.0\np0 = [1/10, 2/10] which is defined on  $\\mathbb R^2$ , so we need M = ‚Ñù^2 Euclidean(2; field=‚Ñù) and can then generate both the cost and the gradient f = ManoptExamples.RosenbrockCost(M; a=a, b=b)\ngrad_f = ManoptExamples.RosenbrockGradient!!(M; a=a, b=b) ManoptExamples.RosenbrockGradient!!{Float64}(100.0, 1.0) For comparison, we look at the initial cost f(M, p0) 4.42 And to illustrate, we run two small solvers with their default settings as a comparison."},{"id":3106,"pagetitle":"Rosenbrock","title":"Gradient Descent","ref":"/manoptexamples/stable/examples/Rosenbrock/#Gradient-Descent","content":" Gradient Descent We start with the  gradient descent solver . Since we need the state anyways to access the record, we also get from the  return_state=true  a short summary of the solver run. gd_state = gradient_descent(M, f, grad_f, p0; record = [:Iteration, :Cost], return_state=true) # Solver state for `Manopt.jl`s Gradient Descent\nAfter 200 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 200:  reached\n    |grad f| < 1.0e-8: not reached\nOverall: reached\nThis indicates convergence: No\n\n## Record\n(Iteration = RecordGroup([RecordIteration(), RecordCost()]),) From the summary we see, that the gradient is not yet small enough, but we hit the 200 iterations (default) iteration limit. Collecting the cost recording and printing the final cost gd_x = get_record(gd_state, :Iteration, :Iteration)\ngd_y =  get_record(gd_state, :Iteration, :Cost)\nf(M, get_solver_result(gd_state)) 0.10562873187751265"},{"id":3107,"pagetitle":"Rosenbrock","title":"Quasi Newton","ref":"/manoptexamples/stable/examples/Rosenbrock/#Quasi-Newton","content":" Quasi Newton We can improve this using the  quasi Newton  algorithm qn_state = quasi_Newton(M, f, grad_f, p0;\n    record = [:Iteration, :Cost], return_state=true\n) # Solver state for `Manopt.jl`s Quasi Newton Method\nAfter 26 iterations\n\n## Parameters\n* direction update:        limited memory InverseBFGS (size 2), projections, and ParallelTransport() as vector transport.\n* retraction method:       ExponentialRetraction()\n* vector transport method: ParallelTransport()\n\n## Stepsize\nWolfePowellLinesearch(DefaultManifold(), 0.0001, 0.999) with keyword arguments\n  * retraction_method = ExponentialRetraction()\n  * vector_transport_method = ParallelTransport()\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n    Max Iteration 1000: not reached\n    |grad f| < 1.0e-6: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Record\n(Iteration = RecordGroup([RecordIteration(), RecordCost()]),) And we see it stops far earlier, after 45 Iterations. We again collect the recorded values qn_x = get_record(qn_state, :Iteration, :Iteration)\nqn_y =  get_record(qn_state, :Iteration, :Cost)\nf(M, get_solver_result(qn_state)) 1.4404666436813376e-18 and see that the final value is close to the one of the minimizer f(M, ManoptExamples.minimizer(f)) 0.0 which we also see if we plot the recorded cost. fig = plot(gd_x, gd_y; linewidth=1, label=\"Gradient Descent\");\nplot!(fig, qn_x, qn_y; linewidth=1, label=\"Quasi Newton\")"},{"id":3110,"pagetitle":"Total Variation","title":"Total Variation Minimization","ref":"/manoptexamples/stable/examples/Total-Variation/#Total-Variation-Minimization","content":" Total Variation Minimization Ronny Bergmann 2023-06-06"},{"id":3111,"pagetitle":"Total Variation","title":"Introduction","ref":"/manoptexamples/stable/examples/Total-Variation/#Introduction","content":" Introduction Total Variation denoising  is an optimization problem used to denoise signals and images. The corresponding (Euclidean) objective is often called Rudin-Osher-Fatemi (ROF) model based on the paper [ ROF92 ]. This was generalized to manifolds in [ WDS14 ]. In this short example we will look at the ROF model for manifold-valued data, its generalizations, and how they can be solved using  Manopt.jl ."},{"id":3112,"pagetitle":"Total Variation","title":"The manifold-valued ROF model","ref":"/manoptexamples/stable/examples/Total-Variation/#The-manifold-valued-ROF-model","content":" The manifold-valued ROF model Generalizing the ROF model to manifolds can be phrased as follows: Given a (discrete) signal on a manifold  $s = (s_i)_{i=1}^N \\in \\mathbb M^n$  of length  $n \\in \\mathbb N$ , we usually assume that this signal might be noisy. For the (Euclidean) ROF model we assume that the noise is Gaussian. Then variational models for denoising usually consist of a data term  $D(p,s)$  to ‚Äústay close to‚Äù  $s$  and a regularizer  $R(p)$ . For TV regularization the data term is the squared distance and the regularizer models that without noise, neighboring values are close. We obtain \\[\\operatorname*{arg\\,min}_{p\\in\\mathcal M^n}\nf(p),\n\\qquad\nf(p) = D(p,s) + Œ± R(p) = \\sum_{i=1}^n d_{\\mathcal M}^2(s_i,p_i) + Œ±\\sum_{i=1}^{n-1} d_{\\mathcal M}(p_i,p_{i+1}),\\] where  $Œ± > 0$  is a weight parameter. The challenge here is that most classical algorithm, like gradient descent or Quasi Newton, assume the cost  $f(p)$  to be smooth such that the gradient exists at every point. In our setting that is not the case since the distacen is not differentiable for any  $p_i=p_{i+1}$ . So we have to use another technique."},{"id":3113,"pagetitle":"Total Variation","title":"The Cyclic Proximal Point algorithm","ref":"/manoptexamples/stable/examples/Total-Variation/#The-Cyclic-Proximal-Point-algorithm","content":" The Cyclic Proximal Point algorithm If the cost consists of a sum of functions, where each of the proximal maps is ‚Äúeasy to evaluate‚Äù, for best of cases in closed form, we can ‚Äúapply the proximal maps in a cyclic fashion‚Äù and optain the  Cyclic Proximal Point Algorithm  [ Bac14 ]. Both for the distance and the squared distance, we have  generic implementations ; since this happens in a cyclic manner, there is also always one of the arguments involved in the prox and never both. We can improve the performance slightly by computing all proes in parallel that do not interfer. To be precise we can compute first all proxes of distances in the regularizer that start with an odd index in parallel. Afterwards all that start with an even index."},{"id":3114,"pagetitle":"Total Variation","title":"The Optimsation","ref":"/manoptexamples/stable/examples/Total-Variation/#The-Optimsation","content":" The Optimsation using Manifolds, Manopt, ManoptExamples, ManifoldDiff\nusing ManifoldDiff: prox_distance\nusing ManoptExamples: prox_Total_Variation\nn = 500 #Signal length\nœÉ = 0.2 # amount of noise\nŒ± = 0.5# in the TV model We define a few colors using Colors, NamedColors, ColorSchemes, Plots, Random\ndata_color = RGBA{Float64}(colorant\"black\")\nlight_color = RGBA{Float64}(colorant\"brightgrey\")\nrecon_color = RGBA{Float64}(colorant\"vibrantorange\")\nnoisy_color = RGBA{Float64}(colorant\"vibrantteal\") And we generate our data on the  Circle , since that is easy to plot and nice to compare to the Euclidean case of a real-valued signal. Random.seed!(23)\nM = Circle()\nN = PowerManifold(M, n)\ndata = ManoptExamples.artificial_S1_signal(n)\ns = [exp(M, d, rand(M; vector_at=d, œÉ=0.2)) for d in data]\nt = range(0.0, 1.0; length=n)\nscene = scatter(\n    t,\n    data;\n    markercolor=data_color,\n    markerstrokecolor=data_color,\n    markersize=2,\n    lab=\"original\",\n)\nscatter!(\n    scene,\n    t,\n    s;\n    markersize=2,\n    markercolor=noisy_color,\n    markerstrokecolor=noisy_color,\n    lab=\"noisy\",\n)\nyticks!(\n    [-œÄ, -œÄ / 2, 0, œÄ / 2, œÄ],\n    [raw\"$-\\pi$\", raw\"$-\\frac{\\pi}{2}$\", raw\"$0$\", raw\"$\\frac{\\pi}{2}$\", raw\"$\\pi$\"],\n) As mentioned above, total variation now minimized different neighbors ‚Äì¬†while keeping jumps if the are large enough. One notable difference between Euclidean and Cyclic data is, that the y-axis is in our case periodic, hence the first jump is actually not a jump but a ‚Äúlinear increase‚Äù that ‚Äúwraps around‚Äù and the second large jump ‚Äìor third overall‚Äì is actually only as small as the second jump. Defining cost and the proximal maps, which are actually 3 proxes to be precise. f(N, p) = ManoptExamples.L2_Total_Variation(N, s, Œ±, p)\nproxes_f = ((N, Œª, p) -> prox_distance(N, Œª, s, p, 2), (N, Œª, p) -> prox_Total_Variation(N, Œ± * Œª, p)) We run the algorithm o = cyclic_proximal_point(\n    N,\n    f,\n    proxes_f,\n    s;\n    Œª=i -> œÄ / (2 * i),\n    debug=[\n        :Iteration,\n        \" | \",\n        DebugProximalParameter(),\n        \" | \",\n        :Cost,\n        \" | \",\n        :Change,\n        \"\\n\",\n        1000,\n        :Stop,\n    ],\n    record=[:Iteration, :Cost, :Change, :Iterate],\n    return_state=true,\n); Initial  |  | f(x): 59.187445 | \n# 1000   | Œª:0.0015707963267948967 | f(x): 13.963912 | Last Change: 1.773283\n# 2000   | Œª:0.0007853981633974483 | f(x): 13.947124 | Last Change: 0.011678\n# 3000   | Œª:0.0005235987755982988 | f(x): 13.941538 | Last Change: 0.003907\n# 4000   | Œª:0.00039269908169872416 | f(x): 13.938748 | Last Change: 0.001957\n# 5000   | Œª:0.0003141592653589793 | f(x): 13.937075 | Last Change: 0.001175\nThe algorithm reached its maximal number of iterations (5000). We can see that the cost reduces nicely. Let‚Äôs extract the result an the recorded values recon = get_solver_result(o)\nrecord = get_record(o) We get scene = scatter(\n    t,\n    data;\n    markercolor=data_color,\n    markerstrokecolor=data_color,\n    markersize=2,\n    lab=\"original\",\n)\nscatter!(\n    scene,\n    t,\n    s;\n    markersize=2,\n    markercolor=light_color,\n    markerstrokecolor=light_color,\n    lab=\"noisy\",\n)\nscatter!(\n    scene,\n    t,\n    recon;\n    markersize=2,\n    markercolor=recon_color,\n    markerstrokecolor=recon_color,\n    lab=\"reconstruction\",\n) Which contains the usual stair casing one expects for TV regularization, but here in a ‚Äúcyclic manner‚Äù"},{"id":3115,"pagetitle":"Total Variation","title":"Outlook","ref":"/manoptexamples/stable/examples/Total-Variation/#Outlook","content":" Outlook We can generalize the total variation also to a second order total variation. Again intuitively, while TV prefers constant areas, the  $\\operatorname{TV}_2$  yields a cost 0 for anything linear, which on manifolds can be generalized to equidistant on a geodesic [ BBSW16 ]. Here we can again derive proximal maps, which for the circle again have a closed form solutoin [ BLSW14 ] but on general manifolds these have again to be approximated. Another extension for both first and second order TV is to apply this for manifold-valued images  $S = (S_{i,j})_{i,j=1}^{m,n} \\in \\mathcal M^{m,n}$ , where the distances in the regularizer are then used in both the first dimension  $i$  and the second dimension  $j$  in the data."},{"id":3116,"pagetitle":"Total Variation","title":"Technical details","ref":"/manoptexamples/stable/examples/Total-Variation/#Technical-details","content":" Technical details This version of the example was generated with the following package versions. Pkg.status() Status `~/work/ManoptExamples.jl/ManoptExamples.jl/examples/Project.toml`\n  [6e4b80f9] BenchmarkTools v1.5.0\n  [35d6a980] ColorSchemes v3.24.0\n  [5ae59095] Colors v0.12.10\n  [7073ff75] IJulia v1.24.2\n  [8ac3fa9e] LRUCache v1.6.1\n  [d3d80556] LineSearches v7.2.0\n  [af67fdf4] ManifoldDiff v0.3.10\n  [1cead3c2] Manifolds v0.9.14\n  [3362f125] ManifoldsBase v0.15.8\n  [0fc0a36d] Manopt v0.4.58\n  [5b8d5e80] ManoptExamples v0.1.6 `..`\n  [51fcb6bd] NamedColors v0.2.2\n  [91a5bcdd] Plots v1.40.2\n  [6099a3de] PythonCall v0.9.19"},{"id":3117,"pagetitle":"Total Variation","title":"Literature","ref":"/manoptexamples/stable/examples/Total-Variation/#Literature","content":" Literature [Bac14] M.¬†Baƒç√°k.  Computing medians and means in Hadamard spaces .  SIAM¬†Journal¬†on¬†Optimization  24 , 1542‚Äì1566  (2014),  arXiv:1210.2145 . [BBSW16] M.¬†Baƒç√°k, R.¬†Bergmann, G.¬†Steidl and A.¬†Weinmann.  A second order non-smooth variational model for restoring manifold-valued images .  SIAM¬†Journal¬†on¬†Scientific¬†Computing  38 , A567‚ÄìA597  (2016),  arXiv:1506.02409 . [BLSW14] R.¬†Bergmann, F.¬†Laus, G.¬†Steidl and A.¬†Weinmann.  Second order differences of cyclic data and applications in variational denoising .  SIAM¬†Journal¬†on¬†Imaging¬†Sciences  7 , 2916‚Äì2953  (2014),  arXiv:1405.5349 . [ROF92] L.¬†I.¬†Rudin, S.¬†Osher and E.¬†Fatemi.  Nonlinear total variation based noise removal algorithms .  Physica¬†D:¬†Nonlinear¬†Phenomena  60 , 259‚Äì268  (1992). [WDS14] A.¬†Weinmann, L.¬†Demaret and M.¬†Storath.  Total variation regularization for manifold-valued data .  SIAM¬†Journal¬†on¬†Imaging¬†Sciences  7 , 2226‚Äì2257  (2014)."},{"id":3120,"pagetitle":"Error measures","title":"Error measures","ref":"/manoptexamples/stable/helpers/error_measures/#Error-measures","content":" Error measures"},{"id":3121,"pagetitle":"Error measures","title":"ManoptExamples.mean_average_error","ref":"/manoptexamples/stable/helpers/error_measures/#ManoptExamples.mean_average_error-Tuple{ManifoldsBase.AbstractManifold, Any, Any}","content":" ManoptExamples.mean_average_error  ‚Äî  Method mean_average_error(M,x,y) Compute the (mean) squared error between the two points  x  and  y  on the  PowerManifold  manifold  M . source"},{"id":3122,"pagetitle":"Error measures","title":"ManoptExamples.mean_squared_error","ref":"/manoptexamples/stable/helpers/error_measures/#ManoptExamples.mean_squared_error-Union{Tuple{mT}, Tuple{mT, Any, Any}} where mT<:ManifoldsBase.AbstractManifold","content":" ManoptExamples.mean_squared_error  ‚Äî  Method mean_squared_error(M, p, q) Compute the (mean) squared error between the two points  p  and  q  on the (power) manifold  M . source"},{"id":3125,"pagetitle":"Objectives","title":"List of Objectives defined for the Examples","ref":"/manoptexamples/stable/objectives/#List-of-Objectives-defined-for-the-Examples","content":" List of Objectives defined for the Examples"},{"id":3126,"pagetitle":"Objectives","title":"Rayleigh Quotient on the Sphere","ref":"/manoptexamples/stable/objectives/#Rayleigh","content":" Rayleigh Quotient on the Sphere See the Rayleigh example (TODO) to see these in use."},{"id":3127,"pagetitle":"Objectives","title":"ManoptExamples.RayleighQuotientCost","ref":"/manoptexamples/stable/objectives/#ManoptExamples.RayleighQuotientCost","content":" ManoptExamples.RayleighQuotientCost  ‚Äî  Type RayleighQuotientCost A functor representing the Rayleigh Quotient cost function. Let  $A ‚àà ‚Ñù^{n√ón}$  be a symmetric matrix. Then we can specify the  Rayleigh Quotient  in two forms. Either \\[f(p) = p^{\\mathrm{T}}Ap,\\qquad p ‚àà ùïä^{n-1},\\] or extended into the embedding as \\[f(x) = x^{\\mathrm{T}}Ax, \\qquad x ‚àà ‚Ñù^n,\\] which is not the orignal Rayleigh quotient for performance reasons, but useful if you want to use this as the Euclidean cost in the emedding of  $ùïä^{n-1}$ . Fields A  ‚Äì storing the matrix internally Constructor RayleighQuotientCost(A) Create the Rayleigh cost function. See also RayleighQuotientGrad!! ,  RayleighQuotientHess!! source"},{"id":3128,"pagetitle":"Objectives","title":"ManoptExamples.RayleighQuotientGrad!!","ref":"/manoptexamples/stable/objectives/#ManoptExamples.RayleighQuotientGrad!!","content":" ManoptExamples.RayleighQuotientGrad!!  ‚Äî  Type RayleighQuotientGrad!! A functor representing the Rayleigh Quotient gradient function. Let  $A ‚àà ‚Ñù^{n√ón}$  be a symmetric matrix. Then we can specify the gradient of the  Rayleigh Quotient  in two forms. Either \\[\\operatorname{grad} f(p) = 2 Ap - 2 (p^{\\mathrm{T}}Ap)*p,\\qquad p ‚àà ùïä^{n-1},\\] or taking the Euclidean gradient of the Rayleigh quotient on the sphere as \\[‚àáf(x) = 2Ax, \\qquad x ‚àà ‚Ñù^n.\\] For details, see Example 3.62 of [ Bou23 ]. Fields A  ‚Äì storing the matrix internally Constructor RayleighQuotientGrad!!(A) Create the Rayleigh quotient gradient function. See also RayleighQuotientCost ,  RayleighQuotientHess!! source"},{"id":3129,"pagetitle":"Objectives","title":"ManoptExamples.RayleighQuotientHess!!","ref":"/manoptexamples/stable/objectives/#ManoptExamples.RayleighQuotientHess!!","content":" ManoptExamples.RayleighQuotientHess!!  ‚Äî  Type RayleighQuotientHess!! A functor representing the Rayleigh Quotient Hessian. Let  $A ‚àà ‚Ñù^{n√ón}$  be a symmetric matrix. Then we can specify the Hessian of the  Rayleigh Quotient  in two forms. Either \\[\\operatorname{Hess} f(p)[X] = 2 \\bigl(AX - (p^{mathrm{T}}AX)p - (p^{\\mathrm{T}}Ap)X\\bigr),\\qquad p ‚àà ùïä^{n-1}, X \\in T_pùïä^{n-1}\\] or taking the Euclidean Hessian of the Rayleigh quotient on the sphere as \\[‚àá^2f(x)[V] = 2AV, \\qquad x, V ‚àà ‚Ñù^n.\\] For details, see Example 5.27 of [ Bou23 ]. Fields A  ‚Äì storing the matrix internally Constructor RayleighQuotientHess!!(A) Create the Rayleigh quotient Hessian function. See also RayleighQuotientCost ,  RayleighQuotientGrad!! source"},{"id":3130,"pagetitle":"Objectives","title":"B√©zier Curves","ref":"/manoptexamples/stable/objectives/#BezierCurves","content":" B√©zier Curves See the  Bezier Curves example  to see these in use."},{"id":3131,"pagetitle":"Objectives","title":"ManoptExamples.BezierSegment","ref":"/manoptexamples/stable/objectives/#ManoptExamples.BezierSegment","content":" ManoptExamples.BezierSegment  ‚Äî  Type BezierSegment A type to capture a Bezier segment. With  $n$  points, a B√©zier segment of degree  $n-1$  is stored. On the Euclidean manifold, this yields a polynomial of degree  $n-1$ . This type is mainly used to encapsulate the points within a composite Bezier curve, which consist of an  AbstractVector  of  BezierSegments  where each of the points might be a nested array on a  PowerManifold  already. Not that this can also be used to represent tangent vectors on the control points of a segment. See also:  de_Casteljau . Constructor BezierSegment(pts::AbstractVector) Given an abstract vector of  pts  generate the corresponding B√©zier segment. source"},{"id":3132,"pagetitle":"Objectives","title":"ManoptExamples.L2_acceleration_Bezier","ref":"/manoptexamples/stable/objectives/#ManoptExamples.L2_acceleration_Bezier-Union{Tuple{P}, Tuple{ManifoldsBase.AbstractManifold, AbstractVector{P}, AbstractVector{<:Integer}, AbstractVector{<:AbstractFloat}, AbstractFloat, AbstractVector{P}}} where P","content":" ManoptExamples.L2_acceleration_Bezier  ‚Äî  Method L2_acceleration_Bezier(M,B,pts,Œª,d) compute the value of the discrete Acceleration of the composite Bezier curve together with a data term, i.e. \\[\\frac{Œª}{2}\\sum_{i=0}^{N} d_{\\mathcal M}(d_i, c_B(i))^2+\n\\sum_{i=1}^{N-1}\\frac{d^2_2 [ B(t_{i-1}), B(t_{i}), B(t_{i+1})]}{\\Delta_t^3}\\] where for this formula the  pts  along the curve are equispaced and denoted by  $t_i$  and  $d_2$  refers to the second order absolute difference  second_order_Total_Variation  (squared), the junction points are denoted by  $p_i$ , and to each  $p_i$  corresponds one data item in the manifold points given in  d . For details on the acceleration approximation, see  acceleration_Bezier . Note that the B√©zier-curve is given in reduces form as a point on a  PowerManifold , together with the  degrees  of the segments and assuming a differentiable curve, the segments can internally be reconstructed. See also grad_L2_acceleration_Bezier ,  acceleration_Bezier ,  grad_acceleration_Bezier source"},{"id":3133,"pagetitle":"Objectives","title":"ManoptExamples.acceleration_Bezier","ref":"/manoptexamples/stable/objectives/#ManoptExamples.acceleration_Bezier-Union{Tuple{P}, Tuple{ManifoldsBase.AbstractManifold, AbstractVector{P}, AbstractVector{<:Integer}, AbstractVector{<:AbstractFloat}}} where P","content":" ManoptExamples.acceleration_Bezier  ‚Äî  Method acceleration_Bezier(\n    M::AbstractManifold,\n    B::AbstractVector{P},\n    degrees::AbstractVector{<:Integer},\n    T::AbstractVector{<:AbstractFloat},\n) where {P} compute the value of the discrete Acceleration of the composite Bezier curve \\[\\sum_{i=1}^{N-1}\\frac{d^2_2 [ B(t_{i-1}), B(t_{i}), B(t_{i+1})]}{\\Delta_t^3}\\] where for this formula the  pts  along the curve are equispaced and denoted by  $t_i$ ,  $i=1,‚Ä¶,N$ , and  $d_2$  refers to the second order absolute difference  second_order_Total_Variation  (squared). Note that the B√©zier-curve is given in reduces form as a point on a  PowerManifold , together with the  degrees  of the segments and assuming a differentiable curve, the segments can internally be reconstructed. This acceleration discretization was introduced in  Bergmann, Gousenbourger, Front. Appl. Math. Stat., 2018 . See also grad_acceleration_Bezier ,  L2_acceleration_Bezier ,  grad_L2_acceleration_Bezier source"},{"id":3134,"pagetitle":"Objectives","title":"ManoptExamples.adjoint_differential_Bezier_control_points","ref":"/manoptexamples/stable/objectives/#ManoptExamples.adjoint_differential_Bezier_control_points-Tuple{ManifoldsBase.AbstractManifold, AbstractVector{<:ManoptExamples.BezierSegment}, AbstractVector, AbstractVector}","content":" ManoptExamples.adjoint_differential_Bezier_control_points  ‚Äî  Method adjoint_differential_Bezier_control_points(\n    M::AbstractManifold,\n    T::AbstractVector,\n    X::AbstractVector,\n)\nadjoint_differential_Bezier_control_points!(\n    M::AbstractManifold,\n    Y::AbstractVector{<:BezierSegment},\n    T::AbstractVector,\n    X::AbstractVector,\n) Evaluate the adjoint of the differential with respect to the controlpoints at several times  T . This can be computed in place of  Y . See  de_Casteljau  for more details on the curve. source"},{"id":3135,"pagetitle":"Objectives","title":"ManoptExamples.adjoint_differential_Bezier_control_points","ref":"/manoptexamples/stable/objectives/#ManoptExamples.adjoint_differential_Bezier_control_points-Tuple{ManifoldsBase.AbstractManifold, AbstractVector{<:ManoptExamples.BezierSegment}, Any, Any}","content":" ManoptExamples.adjoint_differential_Bezier_control_points  ‚Äî  Method adjoint_differential_Bezier_control_points(\n    M::AbstractManifold,\n    B::AbstractVector{<:BezierSegment},\n    t,\n    X\n)\nadjoint_differential_Bezier_control_points!(\n    M::AbstractManifold,\n    Y::AbstractVector{<:BezierSegment},\n    B::AbstractVector{<:BezierSegment},\n    t,\n    X\n) evaluate the adjoint of the differential of a composite B√©zier curve on the manifold  M  with respect to its control points  b  based on a points  T $=(t_i)_{i=1}^n$  that are pointwise in  $t_i‚àà[0,1]$  on the curve and given corresponding tangential vectors  $X = (Œ∑_i)_{i=1}^n$ ,  $Œ∑_i‚ààT_{Œ≤(t_i)}\\mathcal M$  This can be computed in place of  Y . See  de_Casteljau  for more details on the curve. source"},{"id":3136,"pagetitle":"Objectives","title":"ManoptExamples.adjoint_differential_Bezier_control_points","ref":"/manoptexamples/stable/objectives/#ManoptExamples.adjoint_differential_Bezier_control_points-Tuple{ManifoldsBase.AbstractManifold, ManoptExamples.BezierSegment, AbstractVector, AbstractVector}","content":" ManoptExamples.adjoint_differential_Bezier_control_points  ‚Äî  Method adjoint_differential_Bezier_control_points(\n    M::AbstractManifold,\n    b::BezierSegment,\n    t::AbstractVector,\n    X::AbstractVector,\n)\nadjoint_differential_Bezier_control_points!(\n    M::AbstractManifold,\n    Y::BezierSegment,\n    b::BezierSegment,\n    t::AbstractVector,\n    X::AbstractVector,\n) evaluate the adjoint of the differential of a B√©zier curve on the manifold  M  with respect to its control points  b  based on a points  T $=(t_i)_{i=1}^n$  that are pointwise in  $t_i‚àà[0,1]$  on the curve and given corresponding tangential vectors  $X = (Œ∑_i)_{i=1}^n$ ,  $Œ∑_i‚ààT_{Œ≤(t_i)}\\mathcal M$  This can be computed in place of  Y . See  de_Casteljau  for more details on the curve and  Bergmann, Gousenbourger, Front. Appl. Math. Stat., 2018 source"},{"id":3137,"pagetitle":"Objectives","title":"ManoptExamples.adjoint_differential_Bezier_control_points","ref":"/manoptexamples/stable/objectives/#ManoptExamples.adjoint_differential_Bezier_control_points-Tuple{ManifoldsBase.AbstractManifold, ManoptExamples.BezierSegment, Any, Any}","content":" ManoptExamples.adjoint_differential_Bezier_control_points  ‚Äî  Method adjoint_differential_Bezier_control_points(M::AbstractManifold, b::BezierSegment, t, Œ∑)\nadjoint_differential_Bezier_control_points!(\n    M::AbstractManifold,\n    Y::BezierSegment,\n    b::BezierSegment,\n    t,\n    Œ∑,\n) evaluate the adjoint of the differential of a B√©zier curve on the manifold  M  with respect to its control points  b  based on a point  t $‚àà[0,1]$  on the curve and a tangent vector  $Œ∑‚ààT_{Œ≤(t)}\\mathcal M$ . This can be computed in place of  Y . See  de_Casteljau  for more details on the curve. source"},{"id":3138,"pagetitle":"Objectives","title":"ManoptExamples.de_Casteljau","ref":"/manoptexamples/stable/objectives/#ManoptExamples.de_Casteljau-Tuple{ManifoldsBase.AbstractManifold, Vararg{Any}}","content":" ManoptExamples.de_Casteljau  ‚Äî  Method de_Casteljau(M::AbstractManifold, b::BezierSegment NTuple{N,P}) -> Function return the  B√©zier curve $Œ≤(‚ãÖ;b_0,‚Ä¶,b_n): [0,1] ‚Üí \\mathcal M$  defined by the control points  $b_0,‚Ä¶,b_n‚àà\\mathcal M$ ,  $n‚àà\\mathbb N$ , as a  BezierSegment . This function implements de Casteljau's algorithm  Casteljau, 1959 ,  Casteljau, 1963  generalized to manifolds by  Popiel, Noakes, J Approx Theo, 2007 : Let  $Œ≥_{a,b}(t)$  denote the shortest geodesic connecting  $a,b‚àà\\mathcal M$ . Then the curve is defined by the recursion \\[\\begin{aligned}\n    Œ≤(t;b_0,b_1) &= \\gamma_{b_0,b_1}(t)\\\\\n    Œ≤(t;b_0,‚Ä¶,b_n) &= \\gamma_{Œ≤(t;b_0,‚Ä¶,b_{n-1}), Œ≤(t;b_1,‚Ä¶,b_n)}(t),\n\\end{aligned}\\] and  P  is the type of a point on the  Manifold M . de_Casteljau(M::AbstractManifold, B::AbstractVector{<:BezierSegment}) -> Function Given a vector of B√©zier segments, i.e. a vector of control points  $B=\\bigl( (b_{0,0},‚Ä¶,b_{n_0,0}),‚Ä¶,(b_{0,m},‚Ä¶ b_{n_m,m}) \\bigr)$ , where the different segments might be of different degree(s)  $n_0,‚Ä¶,n_m$ . The resulting composite B√©zier curve  $c_B:[0,m] ‚Üí \\mathcal M$  consists of  $m$  segments which are B√©zier curves. \\[c_B(t) :=\n    \\begin{cases}\n        Œ≤(t; b_{0,0},‚Ä¶,b_{n_0,0}) & \\text{ if } t ‚àà[0,1]\\\\\n        Œ≤(t-i; b_{0,i},‚Ä¶,b_{n_i,i}) & \\text{ if }\n            t‚àà(i,i+1], \\quad i‚àà\\{1,‚Ä¶,m-1\\}.\n    \\end{cases}\\] de_Casteljau(M::AbstractManifold, b::BezierSegment, t::Real)\nde_Casteljau(M::AbstractManifold, B::AbstractVector{<:BezierSegment}, t::Real)\nde_Casteljau(M::AbstractManifold, b::BezierSegment, T::AbstractVector) -> AbstractVector\nde_Casteljau(\n    M::AbstractManifold,\n    B::AbstractVector{<:BezierSegment},\n    T::AbstractVector\n) -> AbstractVector Evaluate the B√©zier curve at time  t  or at times  t  in  T . source"},{"id":3139,"pagetitle":"Objectives","title":"ManoptExamples.differential_Bezier_control_points","ref":"/manoptexamples/stable/objectives/#ManoptExamples.differential_Bezier_control_points-Tuple{ManifoldsBase.AbstractManifold, AbstractVector{<:ManoptExamples.BezierSegment}, AbstractVector, AbstractVector{<:ManoptExamples.BezierSegment}}","content":" ManoptExamples.differential_Bezier_control_points  ‚Äî  Method differential_Bezier_control_points(\n    M::AbstractManifold,\n    B::AbstractVector{<:BezierSegment},\n    T::AbstractVector\n    Œû::AbstractVector{<:BezierSegment}\n)\ndifferential_Bezier_control_points!(\n    M::AbstractManifold,\n    Œò::AbstractVector{<:BezierSegment}\n    B::AbstractVector{<:BezierSegment},\n    T::AbstractVector\n    Œû::AbstractVector{<:BezierSegment}\n) evaluate the differential of the composite B√©zier curve with respect to its control points  B  and tangent vectors  Œû  in the tangent spaces of the control points. The result is the ‚Äúchange‚Äù of the curve at the points in  T , which are elementwise in  $[0,N]$ , and each depending the corresponding segment(s). Here,  $N$  is the length of  B . For the mutating variant the result is computed in  Œò . See  de_Casteljau  for more details on the curve and  Bergmann, Gousenbourger, Front. Appl. Math. Stat., 2018 . source"},{"id":3140,"pagetitle":"Objectives","title":"ManoptExamples.differential_Bezier_control_points","ref":"/manoptexamples/stable/objectives/#ManoptExamples.differential_Bezier_control_points-Tuple{ManifoldsBase.AbstractManifold, AbstractVector{<:ManoptExamples.BezierSegment}, Any, AbstractVector{<:ManoptExamples.BezierSegment}}","content":" ManoptExamples.differential_Bezier_control_points  ‚Äî  Method differential_Bezier_control_points(\n    M::AbstractManifold,\n    B::AbstractVector{<:BezierSegment},\n    t,\n    X::AbstractVector{<:BezierSegment}\n)\ndifferential_Bezier_control_points!(\n    M::AbstractManifold,\n    Y::AbstractVector{<:BezierSegment}\n    B::AbstractVector{<:BezierSegment},\n    t,\n    X::AbstractVector{<:BezierSegment}\n) evaluate the differential of the composite B√©zier curve with respect to its control points  B  and tangent vectors  Œû  in the tangent spaces of the control points. The result is the ‚Äúchange‚Äù of the curve at  t $‚àà[0,N]$ , which depends only on the corresponding segment. Here,  $N$  is the length of  B . The computation can be done in place of  Y . See  de_Casteljau  for more details on the curve. source"},{"id":3141,"pagetitle":"Objectives","title":"ManoptExamples.differential_Bezier_control_points","ref":"/manoptexamples/stable/objectives/#ManoptExamples.differential_Bezier_control_points-Tuple{ManifoldsBase.AbstractManifold, ManoptExamples.BezierSegment, AbstractVector, ManoptExamples.BezierSegment}","content":" ManoptExamples.differential_Bezier_control_points  ‚Äî  Method differential_Bezier_control_points(\n    M::AbstractManifold,\n    b::BezierSegment,\n    T::AbstractVector,\n    X::BezierSegment,\n)\ndifferential_Bezier_control_points!(\n    M::AbstractManifold,\n    Y,\n    b::BezierSegment,\n    T::AbstractVector,\n    X::BezierSegment,\n) evaluate the differential of the B√©zier curve with respect to its control points  b  and tangent vectors  X  in the tangent spaces of the control points. The result is the ‚Äúchange‚Äù of the curve at the points  T , elementwise in  $t‚àà[0,1]$ . The computation can be done in place of  Y . See  de_Casteljau  for more details on the curve. source"},{"id":3142,"pagetitle":"Objectives","title":"ManoptExamples.differential_Bezier_control_points","ref":"/manoptexamples/stable/objectives/#ManoptExamples.differential_Bezier_control_points-Tuple{ManifoldsBase.AbstractManifold, ManoptExamples.BezierSegment, Any, ManoptExamples.BezierSegment}","content":" ManoptExamples.differential_Bezier_control_points  ‚Äî  Method differential_Bezier_control_points(M::AbstractManifold, b::BezierSegment, t::Float, X::BezierSegment)\ndifferential_Bezier_control_points!(\n    M::AbstractManifold,\n    Y,\n    b::BezierSegment,\n    t,\n    X::BezierSegment\n) evaluate the differential of the B√©zier curve with respect to its control points  b  and tangent vectors  X  given in the tangent spaces of the control points. The result is the ‚Äúchange‚Äù of the curve at  t $‚àà[0,1]$ . The computation can be done in place of  Y . See  de_Casteljau  for more details on the curve. source"},{"id":3143,"pagetitle":"Objectives","title":"ManoptExamples.get_Bezier_degree","ref":"/manoptexamples/stable/objectives/#ManoptExamples.get_Bezier_degree-Tuple{ManifoldsBase.AbstractManifold, ManoptExamples.BezierSegment}","content":" ManoptExamples.get_Bezier_degree  ‚Äî  Method get_Bezier_degree(M::AbstractManifold, b::BezierSegment) return the degree of the B√©zier curve represented by the tuple  b  of control points on the manifold  M , i.e. the number of points minus 1. source"},{"id":3144,"pagetitle":"Objectives","title":"ManoptExamples.get_Bezier_degrees","ref":"/manoptexamples/stable/objectives/#ManoptExamples.get_Bezier_degrees-Tuple{ManifoldsBase.AbstractManifold, AbstractVector{<:ManoptExamples.BezierSegment}}","content":" ManoptExamples.get_Bezier_degrees  ‚Äî  Method get_Bezier_degrees(M::AbstractManifold, B::AbstractVector{<:BezierSegment}) return the degrees of the components of a composite B√©zier curve represented by tuples in  B  containing points on the manifold  M . source"},{"id":3145,"pagetitle":"Objectives","title":"ManoptExamples.get_Bezier_inner_points","ref":"/manoptexamples/stable/objectives/#ManoptExamples.get_Bezier_inner_points-Tuple{ManifoldsBase.AbstractManifold, AbstractVector{<:ManoptExamples.BezierSegment}}","content":" ManoptExamples.get_Bezier_inner_points  ‚Äî  Method get_Bezier_inner_points(M::AbstractManifold, B::AbstractVector{<:BezierSegment} )\nget_Bezier_inner_points(M::AbstractManifold, b::BezierSegment) returns the inner (i.e. despite start and end) points of the segments of the composite B√©zier curve specified by the control points  B . For a single segment  b , its inner points are returned source"},{"id":3146,"pagetitle":"Objectives","title":"ManoptExamples.get_Bezier_junction_tangent_vectors","ref":"/manoptexamples/stable/objectives/#ManoptExamples.get_Bezier_junction_tangent_vectors-Tuple{ManifoldsBase.AbstractManifold, AbstractVector{<:ManoptExamples.BezierSegment}}","content":" ManoptExamples.get_Bezier_junction_tangent_vectors  ‚Äî  Method get_Bezier_junction_tangent_vectors(M::AbstractManifold, B::AbstractVector{<:BezierSegment})\nget_Bezier_junction_tangent_vectors(M::AbstractManifold, b::BezierSegment) returns the tangent vectors at start and end points of the composite B√©zier curve pointing from a junction point to the first and last inner control points for each segment of the composite Bezier curve specified by the control points  B , either a vector of segments of controlpoints. source"},{"id":3147,"pagetitle":"Objectives","title":"ManoptExamples.get_Bezier_junctions","ref":"/manoptexamples/stable/objectives/#ManoptExamples.get_Bezier_junctions","content":" ManoptExamples.get_Bezier_junctions  ‚Äî  Function get_Bezier_junctions(M::AbstractManifold, B::AbstractVector{<:BezierSegment})\nget_Bezier_junctions(M::AbstractManifold, b::BezierSegment) returns the start and end point(s) of the segments of the composite B√©zier curve specified by the control points  B . For just one segment  b , its start and end points are returned. source"},{"id":3148,"pagetitle":"Objectives","title":"ManoptExamples.get_Bezier_points","ref":"/manoptexamples/stable/objectives/#ManoptExamples.get_Bezier_points","content":" ManoptExamples.get_Bezier_points  ‚Äî  Function get_Bezier_points(\n    M::AbstractManifold,\n    B::AbstractVector{<:BezierSegment},\n    reduce::Symbol=:default\n)\nget_Bezier_points(M::AbstractManifold, b::BezierSegment, reduce::Symbol=:default) returns the control points of the segments of the composite B√©zier curve specified by the control points  B , either a vector of segments of controlpoints or a. This method reduces the points depending on the optional  reduce  symbol :default :        no reduction is performed :continuous :     for a continuous function, the junction points are doubled at  $b_{0,i}=b_{n_{i-1},i-1}$ , so only  $b_{0,i}$  is in the vector. :differentiable : for a differentiable function additionally  $\\log_{b_{0,i}}b_{1,i} = -\\log_{b_{n_{i-1},i-1}}b_{n_{i-1}-1,i-1}$  holds. hence  $b_{n_{i-1}-1,i-1}$  is omitted. If only one segment is given, all points of  b ,  b.pts , is returned. source"},{"id":3149,"pagetitle":"Objectives","title":"ManoptExamples.get_Bezier_segments","ref":"/manoptexamples/stable/objectives/#ManoptExamples.get_Bezier_segments-Union{Tuple{P}, Tuple{ManifoldsBase.AbstractManifold, Vector{P}, Any}, Tuple{ManifoldsBase.AbstractManifold, Vector{P}, Any, Symbol}} where P","content":" ManoptExamples.get_Bezier_segments  ‚Äî  Method get_Bezier_segments(M::AbstractManifold, c::AbstractArray{P}, d[, s::Symbol=:default]) returns the array of  BezierSegment s  B  of a composite B√©zier curve reconstructed from an array  c  of points on the manifold  M  and an array of degrees  d . There are a few (reduced) representations that can get extended; see also  get_Bezier_points . For ease of the following, let  $c=(c_1,‚Ä¶,c_k)$  and  $d=(d_1,‚Ä¶,d_m)$ , where  $m$  denotes the number of components the composite B√©zier curve consists of. Then :default :  $k = m + \\sum_{i=1}^m d_i$  since each component requires one point more than its degree. The points are then ordered in tuples, i.e. \\[B = \\bigl[ [c_1,‚Ä¶,c_{d_1+1}], (c_{d_1+2},‚Ä¶,c_{d_1+d_2+2}],‚Ä¶, [c_{k-m+1+d_m},‚Ä¶,c_{k}] \\bigr]\\] :continuous :  $k = 1+ \\sum_{i=1}{m} d_i$ , since for a continuous curve start and end point of successive components are the same, so the very first start point and the end points are stored. \\[B = \\bigl[ [c_1,‚Ä¶,c_{d_1+1}], [c_{d_1+1},‚Ä¶,c_{d_1+d_2+1}],‚Ä¶, [c_{k-1+d_m},‚Ä¶,b_{k}) \\bigr]\\] :differentiable  ‚Äì for a differentiable function additionally to the last explanation, also the second point of any segment was not stored except for the first segment. Hence  $k = 2 - m + \\sum_{i=1}{m} d_i$  and at a junction point  $b_n$  with its given prior point  $c_{n-1}$ , i.e. this is the last inner point of a segment, the first inner point in the next segment the junction is computed as  $b = \\exp_{c_n}(-\\log_{c_n} c_{n-1})$  such that the assumed differentiability holds source"},{"id":3150,"pagetitle":"Objectives","title":"ManoptExamples.grad_L2_acceleration_Bezier","ref":"/manoptexamples/stable/objectives/#ManoptExamples.grad_L2_acceleration_Bezier-Union{Tuple{P}, Tuple{ManifoldsBase.AbstractManifold, AbstractVector{P}, AbstractVector{<:Integer}, AbstractVector, Any, AbstractVector{P}}} where P","content":" ManoptExamples.grad_L2_acceleration_Bezier  ‚Äî  Method grad_L2_acceleration_Bezier(\n    M::AbstractManifold,\n    B::AbstractVector{P},\n    degrees::AbstractVector{<:Integer},\n    T::AbstractVector,\n    Œª,\n    d::AbstractVector{P}\n) where {P} compute the gradient of the discretized acceleration of a composite B√©zier curve on the  Manifold M  with respect to its control points  B  together with a data term that relates the junction points  p_i  to the data  d  with a weight  $Œª$  compared to the acceleration. The curve is evaluated at the points given in  pts  (elementwise in  $[0,N]$ ), where  $N$  is the number of segments of the B√©zier curve. The summands are  grad_distance  for the data term and  grad_acceleration_Bezier  for the acceleration with interpolation constrains. Here the  get_Bezier_junctions  are included in the optimization, i.e. setting  $Œª=0$  yields the unconstrained acceleration minimization. Note that this is ill-posed, since any B√©zier curve identical to a geodesic is a minimizer. Note that the B√©zier-curve is given in reduces form as a point on a  PowerManifold , together with the  degrees  of the segments and assuming a differentiable curve, the segments can internally be reconstructed. See also grad_acceleration_Bezier ,  L2_acceleration_Bezier ,  acceleration_Bezier . source"},{"id":3151,"pagetitle":"Objectives","title":"ManoptExamples.grad_acceleration_Bezier","ref":"/manoptexamples/stable/objectives/#ManoptExamples.grad_acceleration_Bezier-Tuple{ManifoldsBase.AbstractManifold, AbstractVector, AbstractVector{<:Integer}, AbstractVector}","content":" ManoptExamples.grad_acceleration_Bezier  ‚Äî  Method grad_acceleration_Bezier(\n    M::AbstractManifold,\n    B::AbstractVector,\n    degrees::AbstractVector{<:Integer}\n    T::AbstractVector\n) compute the gradient of the discretized acceleration of a (composite) B√©zier curve  $c_B(t)$  on the  Manifold M  with respect to its control points  B  given as a point on the  PowerManifold  assuming C1 conditions and known  degrees . The curve is evaluated at the points given in  T  (elementwise in  $[0,N]$ , where  $N$  is the number of segments of the B√©zier curve). The  get_Bezier_junctions  are fixed for this gradient (interpolation constraint). For the unconstrained gradient, see  grad_L2_acceleration_Bezier  and set  $Œª=0$  therein. This gradient is computed using  adjoint_Jacobi_field s. For details, see  Bergmann, Gousenbourger, Front. Appl. Math. Stat., 2018 . See  de_Casteljau  for more details on the curve. See also acceleration_Bezier ,   grad_L2_acceleration_Bezier ,  L2_acceleration_Bezier . source"},{"id":3152,"pagetitle":"Objectives","title":"Riemannian Mean","ref":"/manoptexamples/stable/objectives/#RiemannianMean","content":" Riemannian Mean See the  Riemannian mean example  to see these in use."},{"id":3153,"pagetitle":"Objectives","title":"ManoptExamples.RiemannianMeanCost","ref":"/manoptexamples/stable/objectives/#ManoptExamples.RiemannianMeanCost","content":" ManoptExamples.RiemannianMeanCost  ‚Äî  Type RiemannianMeanCost{P} A functor representing the Riemannian center of mass (or Riemannian mean) cost function. For a given set of points  $d_1,\\ldots,d_N$  this cost function is defined as \\[f(p) = \\sum_{j=i}^N d_{mathcal M}^2(d_i, p),\\] where  $d_{\\mathcal M}$  is the  distance  on a Riemannian manifold. Constructor RiemannianMeanCost(M::AbstractManifold, data::AbstractVector{<:P}) where {P} Initialize the cost function to a data set  data  of points on a manfiold  M , where each point is of type  P . See also RiemannianMeanGradient!! ,  Riemannian_mean_objective source"},{"id":3154,"pagetitle":"Objectives","title":"ManoptExamples.RiemannianMeanGradient!!","ref":"/manoptexamples/stable/objectives/#ManoptExamples.RiemannianMeanGradient!!","content":" ManoptExamples.RiemannianMeanGradient!!  ‚Äî  Type RiemannianMeanGradient!!{P} where P A functor representing the Riemannian center of mass (or Riemannian mean) cost function. For a given set of points  $d_1,\\ldots,d_N$  this cost function is defined as \\[\\operatorname{grad}f(p) = \\sum_{j=i}^N \\log_p d_i\\] where  $d_{\\mathcal M}$  is the  distance  on a Riemannian manifold and we employ  grad_distance  to compute the single summands. This functor provides both the allocating variant  grad_f(M,p)  as well as the in-place variant  grad_f!(M, X, p)  which computes the gradient in-place of  X . Constructors RiemannianMeanGradient!!(data::AbstractVector{P}, initial_vector::T=nothing) where {P,T} Generate the Riemannian mean gradient based on some data points  data  an intial tangent vector  initial_vector . If you do not provide an initial tangent vector to allocate the intermediate storage of a tangent vector, you can only use the allocating variant. RiemannianMeanGradient!!(\n    M::AbstractManifold,\n    data::AbstractVector{P};\n    initial_vector::T=zero_vector(M, first(data)),\n) where {P,T} Initialize the Riemannian mean gradient, where the internal storage for tangent vectors can be created automatically, since the Riemannian manifold  M  is provideed. See also RiemannianMeanCost ,  Riemannian_mean_objective source"},{"id":3155,"pagetitle":"Objectives","title":"ManoptExamples.Riemannian_mean_objective","ref":"/manoptexamples/stable/objectives/#ManoptExamples.Riemannian_mean_objective-Tuple{AbstractVector}","content":" ManoptExamples.Riemannian_mean_objective  ‚Äî  Method Riemannian_mean_objective(data, initial_vector=nothing, evaluation=AllocatingEvaluation())\nRiemannian_mean_objective(M, data;\ninitial_vector=zero_vector(M, first(data)),\nevaluation=AllocatingEvaluton()\n) Generate the objective for the Riemannian mean task for some given vector of  data  points on the Riemannian manifold  M . See also RiemannianMeanCost ,  RiemannianMeanGradient!! Note The first constructor should only be used if an additional storage of the vector is not feasible, since initialising the  initial_vector  to  nothing  disables the in-place variant. Hence the evaluation is a positional argument, since it only can be changed, if a vector is provided. source"},{"id":3156,"pagetitle":"Objectives","title":"Robust PCA","ref":"/manoptexamples/stable/objectives/#RobustPCA","content":" Robust PCA See the  Robust PCA example  to see these in use."},{"id":3157,"pagetitle":"Objectives","title":"ManoptExamples.RobustPCACost","ref":"/manoptexamples/stable/objectives/#ManoptExamples.RobustPCACost","content":" ManoptExamples.RobustPCACost  ‚Äî  Type RobustPCACost{D,F} A functor representing the Riemannian robust PCA function on the  Grassmann  manifold. For some given (column) data  $D‚àà\\mathbb R^{d\\times n}$  the cost function is defined on some  $\\operatorname{Gr}(d,m)$ ,  $m<n$  as the sum of the distances of the columns  $D_i$  to the subspace spanned by  $p\\in\\operatorname{Gr}(d,m)$  (represented as a point on the Stiefel manifold). The function reads \\[f(U) = \\frac{1}{n}\\sum_{i=1}^n \\lVert pp^{\\mathrm{T}}D_i - D_i\\rVert\\] This cost additionally provides a  Huber regularisation  of the cost, that is for some  $Œµ>0$  one use  $‚Ñì_Œµ(x) = \\sqrt{x^2+Œµ^2} - Œµ$  in \\[f_{Œµ}(p) = \\frac{1}{n}\\sum_{i=1}^n ‚Ñì_Œµ\\bigl(\\lVert pp^{\\mathrm{T}}D_i - D_i\\rVert\\bigr)\\] Note that this is a mutable struct so you can adapt the  $Œµ$  later on. Constructor RobustPCACost(data::AbstractMatrix, Œµ=1.0)\nRobustPCACost(M::Grassmann, data::AbstractMatrix, Œµ=1.0) Initialize the robust PCA cost to some  data $D$ , and some regularization  $Œµ$ . The manifold is optional to comply with all examples, but it is not needed here to construct the cost. source"},{"id":3158,"pagetitle":"Objectives","title":"ManoptExamples.RobustPCAGrad!!","ref":"/manoptexamples/stable/objectives/#ManoptExamples.RobustPCAGrad!!","content":" ManoptExamples.RobustPCAGrad!!  ‚Äî  Type RobustPCAGrad!!{D,F} A functor representing the Riemannian robust PCA gradient on the  Grassmann  manifold. For some given (column) data  $X‚àà\\mathbb R^{p\\times n}$  the gradient of the  RobustPCACost  can be computed by projecting the Euclidean gradient onto the corresponding tangent space. Note that this is a mutable struct so you can adapt the  $Œµ$  later on. Constructor RobustPCAGrad!!(data, Œµ=1.0)\nRobustPCAGrad!!(M::Grassmannian{d,m}, data, Œµ=1.0; evaluation=AllocatingEvaluation()) Initialize the robust PCA cost to some  data $D$ , and some regularization  $Œµ$ . The manifold is optional to comply with all examples, but it is not needed here to construct the cost. Also the  evaluation=  keyword is present only for unification of the interfaces. Indeed, independent of that keyword the functor always works in both variants. source"},{"id":3159,"pagetitle":"Objectives","title":"ManoptExamples.robust_PCA_objective","ref":"/manoptexamples/stable/objectives/#ManoptExamples.robust_PCA_objective","content":" ManoptExamples.robust_PCA_objective  ‚Äî  Function robust_PCA_objective(data::AbstractMatrix, Œµ=1.0; evaluation=AllocatingEvaluation())\nrobust_PCA_objective(M, data::AbstractMatrix, Œµ=1.0; evaluation=AllocatingEvaluton()) Generate the objective for the robust PCA task for some given  data $D$  and Huber regularization parameter  $Œµ$ . See also RobustPCACost ,  RobustPCAGrad!! Note Since the construction is independent of the manifold, that argument is optional and mainly provided to comply with other objectives. Similarly, independent of the  evaluation , indeed the gradient always allows for both the allocating and the in-place variant to be used, though that keyword is used to setup the objective. source"},{"id":3160,"pagetitle":"Objectives","title":"Rosenbrock Function","ref":"/manoptexamples/stable/objectives/#Rosenbrock","content":" Rosenbrock Function See the  Rosenbrock example   and  The Difference of Convex Rosenbrock Example  to see these in use."},{"id":3161,"pagetitle":"Objectives","title":"ManoptExamples.RosenbrockCost","ref":"/manoptexamples/stable/objectives/#ManoptExamples.RosenbrockCost","content":" ManoptExamples.RosenbrockCost  ‚Äî  Type RosenbrockCost Provide the Rosenbrock function in 2D, i.e. for some  $a,b ‚àà ‚Ñù$ \\[f(\\mathcal M, p) = a(p_1^2-p_2)^2 + (p_1-b)^2\\] which means that for the 2D case, the manifold  $\\mathcal M$  is ignored. See also  üìñ Rosenbrock  (with slightly different parameter naming). Constructor f = Rosenbrock(a,b) generates the struct/function of the Rosenbrock cost. source"},{"id":3162,"pagetitle":"Objectives","title":"ManoptExamples.RosenbrockGradient!!","ref":"/manoptexamples/stable/objectives/#ManoptExamples.RosenbrockGradient!!","content":" ManoptExamples.RosenbrockGradient!!  ‚Äî  Type RosenbrockGradient Provide Eclidean GRadient fo the Rosenbrock function in 2D, i.e. for some  $a,b ‚àà ‚Ñù$ \\[\\nabla f(\\mathcal M, p) = \\begin{pmatrix}\n    4a(p_1^2-p_2)p_1 + 2(p_1-b) \\\\\n    -2a(p_1^2-p_2)\n\\end{pmatrix}\\] i.e. also here the manifold is ignored. Constructor RosenbrockGradient(a,b) Functors grad_f!!(M,p)\ngrad_f!!(M, X, p) evaluate the gradient at  $p$  the manifold $\\mathcal M$  is ignored. source"},{"id":3163,"pagetitle":"Objectives","title":"ManoptExamples.RosenbrockMetric","ref":"/manoptexamples/stable/objectives/#ManoptExamples.RosenbrockMetric","content":" ManoptExamples.RosenbrockMetric  ‚Äî  Type RosenbrockMetric <: AbstractMetric A metric related to the Rosenbrock problem, where the metric at a point  $p‚àà\\mathbb R^2$  is given by \\[‚ü®X,Y‚ü©_{\\mathrm{Rb},p} = X^\\mathrm{T}G_pY, \\qquad\nG_p = \\begin{pmatrix}\n  1+4p_{1}^2 & -2p_{1} \\\\\n  -2p_{1} & 1\n\\end{pmatrix},\\] where the  $\\mathrm{Rb}$  stands for Rosenbrock source"},{"id":3164,"pagetitle":"Objectives","title":"Base.exp","ref":"/manoptexamples/stable/objectives/#Base.exp-Tuple{Manifolds.MetricManifold{‚Ñù, <:Manifolds.Euclidean{<:Union{ManifoldsBase.TypeParameter{Tuple{2}}, Tuple{var\"#s1\"} where var\"#s1\"<:Int64}, ‚Ñù}, ManoptExamples.RosenbrockMetric}, Any, Any, Number}","content":" Base.exp  ‚Äî  Method q = exp(::MetricManifold{‚Ñù,Euclidean{Tuple{2},‚Ñù},RosenbrockMetric}, p, X)\nexp!(::MetricManifold{‚Ñù,Euclidean{Tuple{2},‚Ñù},RosenbrockMetric}, q, p, X) Compute the exponential map with respect to the  RosenbrockMetric . \\[    q = \\begin{pmatrix} p_1 + X_1 \\\\ p_2+X_2+X_1^2\\end{pmatrix}\\] source"},{"id":3165,"pagetitle":"Objectives","title":"Base.log","ref":"/manoptexamples/stable/objectives/#Base.log-Tuple{Manifolds.MetricManifold{‚Ñù, <:Manifolds.Euclidean{<:Union{ManifoldsBase.TypeParameter{Tuple{2}}, Tuple{var\"#s8\"} where var\"#s8\"<:Int64}, ‚Ñù}, ManoptExamples.RosenbrockMetric}, Any, Any}","content":" Base.log  ‚Äî  Method X = log(::MetricManifold{‚Ñù,Euclidean{Tuple{2},‚Ñù},RosenbrockMetric}, p, q)\nlog!(::MetricManifold{‚Ñù,Euclidean{Tuple{2},‚Ñù},RosenbrockMetric}, X, p, q) Compute the logarithmic map with respect to the  RosenbrockMetric . The formula reads for any  $j ‚àà \\{1,‚Ä¶,m\\}$ \\[X = \\begin{pmatrix}\n  q_1 - p_1 \\\\\n  q_2 - p_2 + (q_1 - p_1)^2\n\\end{pmatrix}\\] source"},{"id":3166,"pagetitle":"Objectives","title":"Manifolds.inverse_local_metric","ref":"/manoptexamples/stable/objectives/#Manifolds.inverse_local_metric-Tuple{Manifolds.MetricManifold{‚Ñù, <:Manifolds.Euclidean{<:Union{ManifoldsBase.TypeParameter{Tuple{2}}, Tuple{var\"#s1\"} where var\"#s1\"<:Int64}, ‚Ñù}, ManoptExamples.RosenbrockMetric}, Any}","content":" Manifolds.inverse_local_metric  ‚Äî  Method inverse_local_metric(::MetricManifold{‚Ñù,Euclidean{Tuple{2},‚Ñù},RosenbrockMetric}, p) Return the inverse of the local metric matrix of the  RosenbrockMetric  in the canonical unit vector basis of the tangent space  $T_p\\mathbb R^2$  given as \\[G^{-1}_p =\n\\begin{pmatrix}\n    1 & 2p_1\\\\\n    2p_1 & 1+4p_1^2 \\\\\n\\end{pmatrix}.\\] source"},{"id":3167,"pagetitle":"Objectives","title":"Manifolds.local_metric","ref":"/manoptexamples/stable/objectives/#Manifolds.local_metric-Tuple{Manifolds.MetricManifold{‚Ñù, <:Manifolds.Euclidean{<:Union{ManifoldsBase.TypeParameter{Tuple{2}}, Tuple{var\"#s1\"} where var\"#s1\"<:Int64}, ‚Ñù}, ManoptExamples.RosenbrockMetric}, Any}","content":" Manifolds.local_metric  ‚Äî  Method local_metric(::MetricManifold{‚Ñù,Euclidean{Tuple{2},‚Ñù},RosenbrockMetric}, p) Return the local metric matrix of the  RosenbrockMetric  in the canonical unit vector basis of the tangent space  $T_p\\mathbb R^2$  given as \\[G_p = \\begin{pmatrix}\n  1+4p_1^2 & -2p_1 \\\\\n  -2p_1 & 1\n\\end{pmatrix}\\] source"},{"id":3168,"pagetitle":"Objectives","title":"ManifoldsBase.change_representer","ref":"/manoptexamples/stable/objectives/#ManifoldsBase.change_representer-Tuple{Manifolds.MetricManifold{‚Ñù, <:Manifolds.Euclidean{<:Union{ManifoldsBase.TypeParameter{Tuple{2}}, Tuple{var\"#s8\"} where var\"#s8\"<:Int64}, ‚Ñù}, ManoptExamples.RosenbrockMetric}, ManifoldsBase.EuclideanMetric, Any, Any}","content":" ManifoldsBase.change_representer  ‚Äî  Method Y = change_representer(M::MetricManifold{‚Ñù,Euclidean{Tuple{2},‚Ñù},RosenbrockMetric}, ::EuclideanMetric, p, X)\nchange_representer!(M::MetricManifold{‚Ñù,Euclidean{Tuple{2},‚Ñù},RosenbrockMetric}, Y, ::EuclideanMetric, p, X) Given the Euclidan gradient  X  at  p , this function computes the corresponting Riesz representer  Y such that ‚ü®X,Z‚ü© = ‚ü® Y, Z ‚ü©_{\\mathrm{Rb},p} holds for all Z , in other words Y = G(p)^{-1}X `. this function is used in  riemannian_gradient  to convert a Euclidean into a Riemannian gradient. source"},{"id":3169,"pagetitle":"Objectives","title":"ManifoldsBase.inner","ref":"/manoptexamples/stable/objectives/#ManifoldsBase.inner-Tuple{Manifolds.MetricManifold{‚Ñù, <:Manifolds.Euclidean{<:Union{ManifoldsBase.TypeParameter{Tuple{2}}, Tuple{var\"#s1\"} where var\"#s1\"<:Int64}, ‚Ñù}, ManoptExamples.RosenbrockMetric}, Any, Any, Any}","content":" ManifoldsBase.inner  ‚Äî  Method inner(M::MetricManifold{‚Ñù,Euclidean{Tuple{2},‚Ñù},RosenbrockMetric}, p, X, Y) Compute the inner product on  $\\mathbb R^2$  with respect to the  RosenbrockMetric , i.e. for  $X,Y \\in T_p\\mathcal M$  we have \\[‚ü®X,Y‚ü©_{\\mathrm{Rb},p} = X^\\mathrm{T}G_pY, \\qquad\nG_p = \\begin{pmatrix}\n  1+4p_1^2 & -2p_1\\\\\n  -2p_1 & 1\n\\end{pmatrix},\\] source"},{"id":3170,"pagetitle":"Objectives","title":"ManoptExamples.Rosenbrock_objective","ref":"/manoptexamples/stable/objectives/#ManoptExamples.Rosenbrock_objective","content":" ManoptExamples.Rosenbrock_objective  ‚Äî  Function Rosenbrock_objective(M::AbstractManifold=DefaultManifold(), a=100.0, b=1.0, evaluation=AllocatingEvaluation()) Return the gradient objective of the Rosenbrock example. See also  RosenbrockCost ,  RosenbrockGradient!! source"},{"id":3171,"pagetitle":"Objectives","title":"ManoptExamples.minimizer","ref":"/manoptexamples/stable/objectives/#ManoptExamples.minimizer-Tuple{ManoptExamples.RosenbrockCost}","content":" ManoptExamples.minimizer  ‚Äî  Method minimizer(::RosenbrockCost) Return the minimizer of the  RosenbrockCost , which is given by \\[p^* = \\begin{pmatrix} b\\\\b^2 \\end{pmatrix}\\] source"},{"id":3172,"pagetitle":"Objectives","title":"Total Variation","ref":"/manoptexamples/stable/objectives/#Total-Variation","content":" Total Variation See the  Total Variation example  to see these in use."},{"id":3173,"pagetitle":"Objectives","title":"ManoptExamples.Intrinsic_infimal_convolution_TV12","ref":"/manoptexamples/stable/objectives/#ManoptExamples.Intrinsic_infimal_convolution_TV12-Tuple{ManifoldsBase.AbstractManifold, Vararg{Any, 5}}","content":" ManoptExamples.Intrinsic_infimal_convolution_TV12  ‚Äî  Method Intrinsic_infimal_convolution_TV12(M, f, u, v, Œ±, Œ≤) Compute the intrinsic infimal convolution model, where the addition is replaced by a mid point approach and the two functions involved are  second_order_Total_Variation  and  Total_Variation . The model reads \\[E(u,v) =\n  \\frac{1}{2}\\sum_{i ‚àà \\mathcal G}\n    d_{\\mathcal M}\\bigl(g(\\frac{1}{2},v_i,w_i),f_i\\bigr)\n  +\\alpha\\bigl( Œ≤\\mathrm{TV}(v) + (1-Œ≤)\\mathrm{TV}_2(w) \\bigr).\\] for more details see [ BFPS17 ,  BFPS18 ]. See also Total_Variation ,  second_order_Total_Variation source"},{"id":3174,"pagetitle":"Objectives","title":"ManoptExamples.L2_Total_Variation","ref":"/manoptexamples/stable/objectives/#ManoptExamples.L2_Total_Variation-NTuple{4, Any}","content":" ManoptExamples.L2_Total_Variation  ‚Äî  Method L2_Total_Variation(M, p_data, Œ±, p) compute the  $‚Ñì^2$ -TV functional on the  PowerManifold M  for given (fixed) data  p_data  (on  M ), a nonnegative weight  Œ± , and evaluated at  p  (on  M ), i.e. \\[E(p) = d_{\\mathcal M}^2(f,p) + \\alpha \\operatorname{TV}(p)\\] See also Total_Variation source"},{"id":3175,"pagetitle":"Objectives","title":"ManoptExamples.L2_Total_Variation_1_2","ref":"/manoptexamples/stable/objectives/#ManoptExamples.L2_Total_Variation_1_2-Tuple{ManifoldsBase.PowerManifold, Vararg{Any, 4}}","content":" ManoptExamples.L2_Total_Variation_1_2  ‚Äî  Method L2_Total_Variation_1_2(M, f, Œ±, Œ≤, x) compute the  $‚Ñì^2$ -TV-TV2 functional on the  PowerManifold  manifold  M  for given (fixed) data  f  (on  M ), nonnegative weight  Œ± ,  Œ≤ , and evaluated at  x  (on  M ), i.e. \\[E(x) = d_{\\mathcal M}^2(f,x) + \\alpha\\operatorname{TV}(x)\n  + Œ≤\\operatorname{TV}_2(x)\\] See also Total_Variation ,  second_order_Total_Variation source"},{"id":3176,"pagetitle":"Objectives","title":"ManoptExamples.L2_second_order_Total_Variation","ref":"/manoptexamples/stable/objectives/#ManoptExamples.L2_second_order_Total_Variation-Tuple{ManifoldsBase.PowerManifold, Any, Any, Any}","content":" ManoptExamples.L2_second_order_Total_Variation  ‚Äî  Method L2_second_order_Total_Variation(M, f, Œ≤, x) compute the  $‚Ñì^2$ -TV2 functional on the  PowerManifold  manifold  M  for given data  f , nonnegative parameter  Œ≤ , and evaluated at  x , i.e. \\[E(x) = d_{\\mathcal M}^2(f,x) + Œ≤\\operatorname{TV}_2(x)\\] as used in [ BBSW16 ]. See also second_order_Total_Variation source"},{"id":3177,"pagetitle":"Objectives","title":"ManoptExamples.Total_Variation","ref":"/manoptexamples/stable/objectives/#ManoptExamples.Total_Variation","content":" ManoptExamples.Total_Variation  ‚Äî  Function Total_Variation(M,x [,p=2,q=1]) Compute the  $\\operatorname{TV}^p$  functional for data  x on the  PowerManifold  manifold  M , i.e.  $\\mathcal M = \\mathcal N^n$ , where  $n ‚àà \\mathbb N^k$  denotes the dimensions of the data  x . Let  $\\mathcal I_i$  denote the forward neighbors, i.e. with  $\\mathcal G$  as all indices from  $\\mathbf{1} ‚àà \\mathbb N^k$  to  $n$  we have  $\\mathcal I_i = \\{i+e_j, j=1,‚Ä¶,k\\}\\cap \\mathcal G$ . The formula reads \\[E^q(x) = \\sum_{i ‚àà \\mathcal G}\n  \\bigl( \\sum_{j ‚àà  \\mathcal I_i} d^p_{\\mathcal M}(x_i,x_j) \\bigr)^{q/p},\\] see [ WDS14 ] for more details. In long function names, this might be shortened to  TV1  and the  1  might be ommitted if only total variation is present. See also grad_Total_Variation ,  prox_Total_Variation ,  second_order_Total_Variation source"},{"id":3178,"pagetitle":"Objectives","title":"ManoptExamples.adjoint_differential_forward_logs","ref":"/manoptexamples/stable/objectives/#ManoptExamples.adjoint_differential_forward_logs-Union{Tuple{TPR}, Tuple{TSize}, Tuple{TM}, Tuple{ùîΩ}, Tuple{ManifoldsBase.PowerManifold{ùîΩ, TM, TSize, TPR}, Any, Any}} where {ùîΩ, TM, TSize, TPR}","content":" ManoptExamples.adjoint_differential_forward_logs  ‚Äî  Method Y = adjoint_differential_forward_logs(M, p, X)\nadjoint_differential_forward_logs!(M, Y, p, X) Compute the adjoint differential of  forward_logs $F$  occurring, in the power manifold array  p , the differential of the function $F_i(p) = \\sum_{j ‚àà \\mathcal I_i} \\log_{p_i} p_j$ where  $i$  runs over all indices of the  PowerManifold  manifold  M  and  $\\mathcal I_i$  denotes the forward neighbors of  $i$  Let  $n$  be the number dimensions of the  PowerManifold  manifold (i.e.  length(size(x) )). Then the input tangent vector lies on the manifold  $\\mathcal M' = \\mathcal M^n$ . The adjoint differential can be computed in place of  Y . Input M      ‚Äì a  PowerManifold  manifold p      ‚Äì an array of points on a manifold X      ‚Äì a tangent vector to from the n-fold power of  p , where n is the  ndims  of  p Output Y  ‚Äì resulting tangent vector in  $T_p\\mathcal M$  representing the adjoint   differentials of the logs. source"},{"id":3179,"pagetitle":"Objectives","title":"ManoptExamples.differential_forward_logs","ref":"/manoptexamples/stable/objectives/#ManoptExamples.differential_forward_logs-Tuple{ManifoldsBase.PowerManifold, Any, Any}","content":" ManoptExamples.differential_forward_logs  ‚Äî  Method Y = differential_forward_logs(M, p, X)\ndifferential_forward_logs!(M, Y, p, X) compute the differential of  forward_logs $F$  on the  PowerManifold  manifold  M  at  p  and direction  X  , in the power manifold array, the differential of the function \\[F_i(x) = \\sum_{j ‚àà \\mathcal I_i} \\log_{p_i} p_j, \\quad i ‚àà \\mathcal G,\\] where  $\\mathcal G$  is the set of indices of the  PowerManifold  manifold  M  and  $\\mathcal I_i$  denotes the forward neighbors of  $i$ . Input M      ‚Äì a  PowerManifold  manifold p      ‚Äì a point. X      ‚Äì a tangent vector. Output Y  ‚Äì resulting tangent vector in  $T_x\\mathcal N$  representing the differentials of the   logs, where  $\\mathcal N$  is the power manifold with the number of dimensions added   to  size(x) . The computation can also be done in place. source"},{"id":3180,"pagetitle":"Objectives","title":"ManoptExamples.forward_logs","ref":"/manoptexamples/stable/objectives/#ManoptExamples.forward_logs-Union{Tuple{TPR}, Tuple{TSize}, Tuple{TM}, Tuple{ùîΩ}, Tuple{ManifoldsBase.PowerManifold{ùîΩ, TM, TSize, TPR}, Any}} where {ùîΩ, TM, TSize, TPR}","content":" ManoptExamples.forward_logs  ‚Äî  Method Y = forward_logs(M,x)\nforward_logs!(M, Y, x) compute the forward logs  $F$  (generalizing forward differences) occurring, in the power manifold array, the function \\[F_i(x) = \\sum_{j ‚àà \\mathcal I_i} \\log_{x_i} x_j,\\quad i  ‚àà  \\mathcal G,\\] where  $\\mathcal G$  is the set of indices of the  PowerManifold  manifold  M  and  $\\mathcal I_i$  denotes the forward neighbors of  $i$ . This can also be done in place of  Œæ . Input M  ‚Äì a  PowerManifold  manifold x  ‚Äì a point. Output Y  ‚Äì resulting tangent vector in  $T_x\\mathcal M$  representing the logs, where  $\\mathcal N$  is the power manifold with the number of dimensions added to  size(x) . The computation can be done in place of  Y . source"},{"id":3181,"pagetitle":"Objectives","title":"ManoptExamples.grad_Total_Variation","ref":"/manoptexamples/stable/objectives/#ManoptExamples.grad_Total_Variation","content":" ManoptExamples.grad_Total_Variation  ‚Äî  Function X = grad_Total_Variation(M, Œª, x[, p=1])\ngrad_Total_Variation!(M, X, Œª, x[, p=1]) Compute the (sub)gradient  $‚àÇf$  of all forward differences occurring, in the power manifold array, i.e. of the function \\[f(p) = \\sum_{i}\\sum_{j ‚àà \\mathcal I_i} d^p(x_i,x_j)\\] where  $i$  runs over all indices of the  PowerManifold  manifold  M  and  $\\mathcal I_i$  denotes the forward neighbors of  $i$ . Input M  ‚Äì a  PowerManifold  manifold x  ‚Äì a point. Output X ‚Äì resulting tangent vector in  $T_x\\mathcal M$ . The computation can also be done in place. source"},{"id":3182,"pagetitle":"Objectives","title":"ManoptExamples.grad_Total_Variation","ref":"/manoptexamples/stable/objectives/#ManoptExamples.grad_Total_Variation-Union{Tuple{T}, Tuple{ManifoldsBase.AbstractManifold, Tuple{T, T}}, Tuple{ManifoldsBase.AbstractManifold, Tuple{T, T}, Any}} where T","content":" ManoptExamples.grad_Total_Variation  ‚Äî  Method X = grad_Total_Variation(M, (x,y)[, p=1])\ngrad_Total_Variation!(M, X, (x,y)[, p=1]) compute the (sub) gradient of  $\\frac{1}{p}d^p_{\\mathcal M}(x,y)$  with respect to both  $x$  and  $y$  (in place of  X  and  Y ). source"},{"id":3183,"pagetitle":"Objectives","title":"ManoptExamples.grad_intrinsic_infimal_convolution_TV12","ref":"/manoptexamples/stable/objectives/#ManoptExamples.grad_intrinsic_infimal_convolution_TV12-Tuple{ManifoldsBase.AbstractManifold, Vararg{Any, 5}}","content":" ManoptExamples.grad_intrinsic_infimal_convolution_TV12  ‚Äî  Method grad_u, grad_v = grad_intrinsic_infimal_convolution_TV12(M, f, u, v, Œ±, Œ≤) compute (sub)gradient of the intrinsic infimal convolution model using the mid point model of second order differences, see  second_order_Total_Variation , i.e. for some  $f ‚àà \\mathcal M$  on a  PowerManifold  manifold  $\\mathcal M$  this function computes the (sub)gradient of \\[E(u,v) =\n\\frac{1}{2}\\sum_{i ‚àà \\mathcal G} d_{\\mathcal M}(g(\\frac{1}{2},v_i,w_i),f_i)\n+ \\alpha\n\\bigl(\nŒ≤\\mathrm{TV}(v) + (1-Œ≤)\\mathrm{TV}_2(w)\n\\bigr),\\] where both total variations refer to the intrinsic ones,  grad_Total_Variation  and  grad_second_order_Total_Variation , respectively. source"},{"id":3184,"pagetitle":"Objectives","title":"ManoptExamples.grad_second_order_Total_Variation","ref":"/manoptexamples/stable/objectives/#ManoptExamples.grad_second_order_Total_Variation","content":" ManoptExamples.grad_second_order_Total_Variation  ‚Äî  Function grad_second_order_Total_Variation(M::PowerManifold, q[, p=1]) computes the (sub) gradient of  $\\frac{1}{p}d_2^p(q_1,q_2,q_3)$  with respect to all  $q_1,q_2,q_3$  occurring along any array dimension in the point  q , where  M  is the corresponding  PowerManifold . source"},{"id":3185,"pagetitle":"Objectives","title":"ManoptExamples.grad_second_order_Total_Variation","ref":"/manoptexamples/stable/objectives/#ManoptExamples.grad_second_order_Total_Variation","content":" ManoptExamples.grad_second_order_Total_Variation  ‚Äî  Function Y = grad_second_order_Total_Variation(M, q[, p=1])\ngrad_second_order_Total_Variation!(M, Y, q[, p=1]) computes the (sub) gradient of  $\\frac{1}{p}d_2^p(q_1, q_2, q_3)$  with respect to all three components of  $q‚àà\\mathcal M^3$ , where  $d_2$  denotes the second order absolute difference using the mid point model, i.e. let \\[\\mathcal C = \\bigl\\{ c ‚àà \\mathcal M \\ |\\ g(\\tfrac{1}{2};q_1,q_3) \\text{ for some geodesic }g\\bigr\\}\\] denote the mid points between  $q_1$  and  $q_3$  on the manifold  $\\mathcal M$ . Then the absolute second order difference is defined as \\[d_2(q_1,q_2,q_3) = \\min_{c ‚àà \\mathcal C_{q_1,q_3}} d(c, q_2).\\] While the (sub)gradient with respect to  $q_2$  is easy, the other two require the evaluation of an  adjoint_Jacobi_field . The derivation of this gradient can be found in [ BBSW16 ]. source"},{"id":3186,"pagetitle":"Objectives","title":"ManoptExamples.project_collaborative_TV","ref":"/manoptexamples/stable/objectives/#ManoptExamples.project_collaborative_TV","content":" ManoptExamples.project_collaborative_TV  ‚Äî  Function project_collaborative_TV(M, Œª, x, Œû[, p=2,q=1])\nproject_collaborative_TV!(M, Œò, Œª, x, Œû[, p=2,q=1]) compute the projection onto collaborative Norm unit (or Œ±-) ball, i.e. of the function \\[F^q(x) = \\sum_{i‚àà\\mathcal G}\n  \\Bigl( \\sum_{j‚àà\\mathcal I_i}\n    \\sum_{k=1}^d \\lVert X_{i,j}\\rVert_x^p\\Bigr)^\\frac{q}{p},\\] where  $\\mathcal G$  is the set of indices for  $x‚àà\\mathcal M$  and  $\\mathcal I_i$  is the set of its forward neighbors. The computation can also be done in place of  Œò . This is adopted from the paper  Duran, M√∂ller, Sbert, Cremers, SIAM J Imag Sci, 2016 , see their Example 3 for details. source"},{"id":3187,"pagetitle":"Objectives","title":"ManoptExamples.prox_Total_Variation","ref":"/manoptexamples/stable/objectives/#ManoptExamples.prox_Total_Variation","content":" ManoptExamples.prox_Total_Variation  ‚Äî  Function Œæ = prox_Total_Variation(M,Œª,x [,p=1]) compute the proximal maps  $\\operatorname{prox}_{Œª\\varphi}$  of all forward differences occurring in the power manifold array, i.e.  $\\varphi(xi,xj) = d_{\\mathcal M}^p(xi,xj)$  with  xi  and  xj  are array elements of  x  and  j = i+e_k , where  e_k  is the  $k$ th unit vector. The parameter  Œª  is the prox parameter. Input M  ‚Äì a manifold  M Œª  ‚Äì a real value, parameter of the proximal map x  ‚Äì a point. Optional (default is given in brackets) p  ‚Äì (1) exponent of the distance of the TV term Output y  ‚Äì resulting  point containing with all mentioned proximal points evaluated (in a cyclic order). The computation can also be done in place source"},{"id":3188,"pagetitle":"Objectives","title":"ManoptExamples.prox_Total_Variation","ref":"/manoptexamples/stable/objectives/#ManoptExamples.prox_Total_Variation-Union{Tuple{T}, Tuple{ManifoldsBase.AbstractManifold, Number, Tuple{T, T}}, Tuple{ManifoldsBase.AbstractManifold, Number, Tuple{T, T}, Int64}} where T","content":" ManoptExamples.prox_Total_Variation  ‚Äî  Method [y1,y2] = prox_Total_Variation(M, Œª, [x1,x2] [,p=1])\nprox_Total_Variation!(M, [y1,y2] Œª, [x1,x2] [,p=1]) Compute the proximal map  $\\operatorname{prox}_{Œª\\varphi}$  of  $œÜ(x,y) = d_{\\mathcal M}^p(x,y)$  with parameter  Œª . A derivation of this closed form solution is given in see [ WDS14 ]. Input M  ‚Äì a manifold  M Œª  ‚Äì a real value, parameter of the proximal map (x1,x2)  ‚Äì a tuple of two points, Optional (default is given in brackets) p  ‚Äì (1) exponent of the distance of the TV term Output (y1,y2)  ‚Äì resulting tuple of points of the  $\\operatorname{prox}_{ŒªœÜ}($ (x1,x2) $)$ . The result can also be computed in place. source"},{"id":3189,"pagetitle":"Objectives","title":"ManoptExamples.prox_parallel_TV","ref":"/manoptexamples/stable/objectives/#ManoptExamples.prox_parallel_TV","content":" ManoptExamples.prox_parallel_TV  ‚Äî  Function y = prox_parallel_TV(M, Œª, x [,p=1])\nprox_parallel_TV!(M, y, Œª, x [,p=1]) compute the proximal maps  $\\operatorname{prox}_{ŒªœÜ}$  of all forward differences occurring in the power manifold array, i.e.  $œÜ(x_i,x_j) = d_{\\mathcal M}^p(x_i,x_j)$  with  xi  and  xj  are array elements of  x  and  j = i+e_k , where  e_k  is the  $k$ th unit vector. The parameter  Œª  is the prox parameter. Input M      ‚Äì a  PowerManifold  manifold Œª      ‚Äì a real value, parameter of the proximal map x      ‚Äì a point Optional (default is given in brackets) p  ‚Äì ( 1 ) exponent of the distance of the TV term Output y   ‚Äì resulting Array of points with all mentioned proximal points evaluated (in a parallel within the arrays elements). The computation can also be done in place. See also prox_Total_Variation source"},{"id":3190,"pagetitle":"Objectives","title":"ManoptExamples.prox_second_order_Total_Variation","ref":"/manoptexamples/stable/objectives/#ManoptExamples.prox_second_order_Total_Variation-Union{Tuple{T}, Tuple{ManifoldsBase.AbstractManifold, Any, Tuple{T, T, T}}, Tuple{ManifoldsBase.AbstractManifold, Any, Tuple{T, T, T}, Int64}} where T","content":" ManoptExamples.prox_second_order_Total_Variation  ‚Äî  Method (y1,y2,y3) = prox_second_order_Total_Variation(M,Œª,(x1,x2,x3),[p=1], kwargs...)\nprox_second_order_Total_Variation!(M, y, Œª,(x1,x2,x3),[p=1], kwargs...) Compute the proximal map  $\\operatorname{prox}_{Œª\\varphi}$  of  $\\varphi(x_1,x_2,x_3) = d_{\\mathcal M}^p(c(x_1,x_3),x_2)$  with parameter  Œª >0, where  $c(x,z)$  denotes the mid point of a shortest geodesic from  x1  to  x3  that is closest to  x2 . The result can be computed in place of  y . Note that this function does not have a closed form solution but is solbed by a few steps of the  subgradient mehtod  from  manopt.jl  by default. See [ BBSW16 ] for a derivation. Input M           ‚Äì a manifold Œª           ‚Äì a real value, parameter of the proximal map (x1,x2,x3)  ‚Äì a tuple of three points p  ‚Äì ( 1 ) exponent of the distance of the TV term Optional kwargs...  ‚Äì parameters for the internal  subgradient_method      (if  M  is neither  Euclidean  nor  Circle , since for these a closed form     is given) Output (y1,y2,y3)  ‚Äì resulting tuple of points of the proximal map. The computation can also be done in place. source"},{"id":3191,"pagetitle":"Objectives","title":"ManoptExamples.prox_second_order_Total_Variation","ref":"/manoptexamples/stable/objectives/#ManoptExamples.prox_second_order_Total_Variation-Union{Tuple{T}, Tuple{N}, Tuple{ManifoldsBase.PowerManifold{N, T}, Any, Any}, Tuple{ManifoldsBase.PowerManifold{N, T}, Any, Any, Int64}} where {N, T}","content":" ManoptExamples.prox_second_order_Total_Variation  ‚Äî  Method y = prox_second_order_Total_Variation(M, Œª, x[, p=1])\nprox_second_order_Total_Variation!(M, y, Œª, x[, p=1]) compute the proximal maps  $\\operatorname{prox}_{Œª\\varphi}$  of all centered second order differences occurring in the power manifold array, i.e.  $\\varphi(x_k,x_i,x_j) = d_2(x_k,x_i.x_j)$ , where  $k,j$  are backward and forward neighbors (along any dimension in the array of  x ). The parameter  Œª  is the prox parameter. Input M  ‚Äì a manifold  M Œª  ‚Äì a real value, parameter of the proximal map x  ‚Äì a points. Optional (default is given in brackets) p  ‚Äì ( 1 ) exponent of the distance of the TV term Output y  ‚Äì resulting point with all mentioned proximal points evaluated (in a cyclic order). The computation can also be done in place. source"},{"id":3192,"pagetitle":"Objectives","title":"ManoptExamples.second_order_Total_Variation","ref":"/manoptexamples/stable/objectives/#ManoptExamples.second_order_Total_Variation","content":" ManoptExamples.second_order_Total_Variation  ‚Äî  Function second_order_Total_Variation(M,x [,p=1]) compute the  $\\operatorname{TV}_2^p$  functional for data  x  on the  PowerManifold  manifoldmanifold  M , i.e.  $\\mathcal M = \\mathcal N^n$ , where  $n ‚àà \\mathbb N^k$  denotes the dimensions of the data  x . Let  $\\mathcal I_i^{\\pm}$  denote the forward and backward neighbors, respectively, i.e. with  $\\mathcal G$  as all indices from  $\\mathbf{1} ‚àà \\mathbb N^k$  to  $n$  we have  $\\mathcal I^\\pm_i = \\{i\\pm e_j, j=1,‚Ä¶,k\\}\\cap \\mathcal I$ . The formula then reads \\[E(x) = \\sum_{i ‚àà \\mathcal I,\\ j_1 ‚àà  \\mathcal I^+_i,\\ j_2 ‚àà  \\mathcal I^-_i}\nd^p_{\\mathcal M}(c_i(x_{j_1},x_{j_2}), x_i),\\] where  $c_i(‚ãÖ,‚ãÖ)$  denotes the mid point between its two arguments that is nearest to  $x_i$ , see [ BBSW16 ] for a derivation. In long function names, this might be shortened to  TV2 . See also grad_second_order_Total_Variation ,  prox_second_order_Total_Variation source"},{"id":3193,"pagetitle":"Objectives","title":"ManoptExamples.second_order_Total_Variation","ref":"/manoptexamples/stable/objectives/#ManoptExamples.second_order_Total_Variation-Union{Tuple{T}, Tuple{MT}, Tuple{MT, Tuple{T, T, T}}, Tuple{MT, Tuple{T, T, T}, Any}} where {MT<:ManifoldsBase.AbstractManifold, T}","content":" ManoptExamples.second_order_Total_Variation  ‚Äî  Method second_order_Total_Variation(M,(x1,x2,x3) [,p=1]) Compute the  $\\operatorname{TV}_2^p$  functional for the 3-tuple of points  (x1,x2,x3) on the manifold  M . Denote by \\[  \\mathcal C = \\bigl\\{ c ‚àà  \\mathcal M \\ |\\ g(\\tfrac{1}{2};x_1,x_3) \\text{ for some geodesic }g\\bigr\\}\\] the set of mid points between  $x_1$  and  $x_3$ . Then the function reads \\[d_2^p(x_1,x_2,x_3) = \\min_{c ‚àà \\mathcal C} d_{\\mathcal M}(c,x_2),\\] see [ BBSW16 ] for a derivation. In long function names, this might be shortened to  TV2 . See also grad_second_order_Total_Variation ,  prox_second_order_Total_Variation ,  Total_Variation source"},{"id":3194,"pagetitle":"Objectives","title":"Literature","ref":"/manoptexamples/stable/objectives/#Literature","content":" Literature [BBSW16] M.¬†Baƒç√°k, R.¬†Bergmann, G.¬†Steidl and A.¬†Weinmann.  A second order non-smooth variational model for restoring manifold-valued images .  SIAM¬†Journal¬†on¬†Scientific¬†Computing  38 , A567‚ÄìA597  (2016),  arXiv:1506.02409 . [BFPS18] R.¬†Bergmann, J.¬†H.¬†Fitschen, J.¬†Persch and G.¬†Steidl.  Priors with coupled first and second order differences for manifold-valued image processing .  Journal¬†of¬†Mathematical¬†Imaging¬†and¬†Vision  60 , 1459‚Äì1481  (2018),  arXiv:1709.01343 . [BFPS17] R.¬†Bergmann, J.¬†H.¬†Fitschen, J.¬†Persch and G.¬†Steidl.  Infimal convolution coupling of first and second order differences on manifold-valued images . In:  Scale Space and Variational Methods in Computer Vision: 6th International Conference, SSVM 2017, Kolding, Denmark, June 4‚Äì8, 2017, Proceedings , edited by F.¬†Lauze, Y.¬†Dong and A.¬†B.¬†Dahl (Springer International Publishing, 2017); pp.¬†447‚Äì459. [BG18] R.¬†Bergmann and P.-Y.¬†Gousenbourger.  A variational model for data fitting on manifolds by minimizing the acceleration of a B√©zier curve .  Frontiers¬†in¬†Applied¬†Mathematics¬†and¬†Statistics  4  (2018),  arXiv:1807.10090 . [Bou23] N.¬†Boumal.  An Introduction to Optimization on Smooth Manifolds . First¬†Edition ( Cambridge University Press, 2023 ). [Cas59] P.¬†de¬†Casteljau.  Outillage methodes calcul  (Enveloppe Soleau 40.040, Institute National de la Propri√©t√© Industrielle, Paris., 1959). [Cas63] P.¬†de¬†Casteljau.  Courbes et surfaces √† p√¥les  (Microfiche P 4147-1, Institute National de la Propri√©t√© Industrielle, Paris., 1963). [DMSC16] J.¬†Duran, M.¬†Moeller, C.¬†Sbert and D.¬†Cremers.  Collaborative Total Variation: A General Framework for Vectorial TV Models .  SIAM¬†Journal¬†on¬†Imaging¬†Sciences  9 , 116‚Äì151  (2016),  arXiv:1508.01308 . [PN07] T.¬†Popiel and L.¬†Noakes.  B√©zier curves and  $C^2$  interpolation in Riemannian manifolds .  Journal¬†of¬†Approximation¬†Theory  148 , 111‚Äì127  (2007). [WDS14] A.¬†Weinmann, L.¬†Demaret and M.¬†Storath.  Total variation regularization for manifold-valued data .  SIAM¬†Journal¬†on¬†Imaging¬†Sciences  7 , 2226‚Äì2257  (2014)."},{"id":3197,"pagetitle":"References","title":"Literature","ref":"/manoptexamples/stable/references/#Literature","content":" Literature [ASY+19] T.¬†Akiba, S.¬†Sano, T.¬†Yanase, T.¬†Ohta and M.¬†Koyama.  Optuna: A Next-generation Hyperparameter Optimization Framework . In:  Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining  (2019),  arXiv:1907.10902 . [ABBR23] S.¬†D.¬†Axen, M.¬†Baran, R.¬†Bergmann and K.¬†Rzecki.  Manifolds.jl: An Extensible Julia Framework for Data Analysis on Manifolds .  ACM¬†Transactions¬†on¬†Mathematical¬†Software  (2023),  arXiv:2021.08777 . [Bac14] M.¬†Baƒç√°k.  Computing medians and means in Hadamard spaces .  SIAM¬†Journal¬†on¬†Optimization  24 , 1542‚Äì1566  (2014),  arXiv:1210.2145 . [BBSW16] M.¬†Baƒç√°k, R.¬†Bergmann, G.¬†Steidl and A.¬†Weinmann.  A second order non-smooth variational model for restoring manifold-valued images .  SIAM¬†Journal¬†on¬†Scientific¬†Computing  38 , A567‚ÄìA597  (2016),  arXiv:1506.02409 . [BFSS23] R.¬†Bergmann, O.¬†P.¬†Ferreira, E.¬†M.¬†Santos and J.¬†C.¬†Souza.  The difference of convex algorithm on Hadamard manifolds . Preprint (2023),  arXiv:2112.05250 . [BFPS18] R.¬†Bergmann, J.¬†H.¬†Fitschen, J.¬†Persch and G.¬†Steidl.  Priors with coupled first and second order differences for manifold-valued image processing .  Journal¬†of¬†Mathematical¬†Imaging¬†and¬†Vision  60 , 1459‚Äì1481  (2018),  arXiv:1709.01343 . [BFPS17] R.¬†Bergmann, J.¬†H.¬†Fitschen, J.¬†Persch and G.¬†Steidl.  Infimal convolution coupling of first and second order differences on manifold-valued images . In:  Scale Space and Variational Methods in Computer Vision: 6th International Conference, SSVM 2017, Kolding, Denmark, June 4‚Äì8, 2017, Proceedings , edited by F.¬†Lauze, Y.¬†Dong and A.¬†B.¬†Dahl (Springer International Publishing, 2017); pp.¬†447‚Äì459. [BG18] R.¬†Bergmann and P.-Y.¬†Gousenbourger.  A variational model for data fitting on manifolds by minimizing the acceleration of a B√©zier curve .  Frontiers¬†in¬†Applied¬†Mathematics¬†and¬†Statistics  4  (2018),  arXiv:1807.10090 . [BLSW14] R.¬†Bergmann, F.¬†Laus, G.¬†Steidl and A.¬†Weinmann.  Second order differences of cyclic data and applications in variational denoising .  SIAM¬†Journal¬†on¬†Imaging¬†Sciences  7 , 2916‚Äì2953  (2014),  arXiv:1405.5349 . [BPS16] R.¬†Bergmann, J.¬†Persch and G.¬†Steidl.  A parallel Douglas Rachford algorithm for minimizing ROF-like functionals on images with values in symmetric Hadamard manifolds .  SIAM¬†Journal¬†on¬†Imaging¬†Sciences  9 , 901‚Äì937  (2016),  arXiv:1512.02814 . [Bou23] N.¬†Boumal.  An Introduction to Optimization on Smooth Manifolds . First¬†Edition ( Cambridge University Press, 2023 ). [Cas59] P.¬†de¬†Casteljau.  Outillage methodes calcul  (Enveloppe Soleau 40.040, Institute National de la Propri√©t√© Industrielle, Paris., 1959). [Cas63] P.¬†de¬†Casteljau.  Courbes et surfaces √† p√¥les  (Microfiche P 4147-1, Institute National de la Propri√©t√© Industrielle, Paris., 1963). [DMSC16] J.¬†Duran, M.¬†Moeller, C.¬†Sbert and D.¬†Cremers.  Collaborative Total Variation: A General Framework for Vectorial TV Models .  SIAM¬†Journal¬†on¬†Imaging¬†Sciences  9 , 116‚Äì151  (2016),  arXiv:1508.01308 . [LNPS17] F.¬†Laus, M.¬†Nikolova, J.¬†Persch and G.¬†Steidl.  A nonlocal denoising algorithm for manifold-valued images using second order statistics .  SIAM¬†Journal¬†on¬†Imaging¬†Sciences  10 , 416‚Äì448  (2017). [PN07] T.¬†Popiel and L.¬†Noakes.  B√©zier curves and  $C^2$  interpolation in Riemannian manifolds .  Journal¬†of¬†Approximation¬†Theory  148 , 111‚Äì127  (2007). [ROF92] L.¬†I.¬†Rudin, S.¬†Osher and E.¬†Fatemi.  Nonlinear total variation based noise removal algorithms .  Physica¬†D:¬†Nonlinear¬†Phenomena  60 , 259‚Äì268  (1992). [SO15] J.¬†C.¬†Souza and P.¬†R.¬†Oliveira.  A proximal point algorithm for DC fuctions on Hadamard manifolds .  Journal¬†of¬†Global¬†Optimization  63 , 797‚Äì810  (2015). [WS22] M.¬†Weber and S.¬†Sra.  Riemannian Optimization via Frank-Wolfe Methods .  Mathematical¬†Programming  199 , 525‚Äì556  (2022). [WDS14] A.¬†Weinmann, L.¬†Demaret and M.¬†Storath.  Total variation regularization for manifold-valued data .  SIAM¬†Journal¬†on¬†Imaging¬†Sciences  7 , 2226‚Äì2257  (2014)."}]