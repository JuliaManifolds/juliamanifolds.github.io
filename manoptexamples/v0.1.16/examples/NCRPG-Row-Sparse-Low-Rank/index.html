<!DOCTYPE html><HTML lang="en"><head><script charset="utf-8" src="../../../../assets/default/multidoc_injector.js" type="text/javascript"></script><script charset="utf-8" type="text/javascript">window.MULTIDOCUMENTER_ROOT_PATH = '/'</script><script charset="utf-8" src="../../../../assets/default/flexsearch.bundle.js" type="text/javascript"></script><script charset="utf-8" src="../../../../assets/default/flexsearch_integration.js" type="text/javascript"></script><meta charset="UTF-8"/><meta content="width=device-width, initial-scale=1.0" name="viewport"/><title>Row-Sparse Low-Rank Matrix Recovery · ManoptExamples.jl</title><meta content="Row-Sparse Low-Rank Matrix Recovery · ManoptExamples.jl" name="title"/><meta content="Row-Sparse Low-Rank Matrix Recovery · ManoptExamples.jl" property="og:title"/><meta content="Row-Sparse Low-Rank Matrix Recovery · ManoptExamples.jl" property="twitter:title"/><meta content="Documentation for ManoptExamples.jl." name="description"/><meta content="Documentation for ManoptExamples.jl." property="og:description"/><meta content="Documentation for ManoptExamples.jl." property="twitter:description"/><script data-outdated-warner="" src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script data-main="../../assets/documenter.js" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" data-theme-name="catppuccin-mocha" href="../../assets/themes/catppuccin-mocha.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" data-theme-name="catppuccin-macchiato" href="../../assets/themes/catppuccin-macchiato.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" data-theme-name="catppuccin-frappe" href="../../assets/themes/catppuccin-frappe.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" data-theme-name="catppuccin-latte" href="../../assets/themes/catppuccin-latte.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" data-theme-name="documenter-dark" data-theme-primary-dark="" href="../../assets/themes/documenter-dark.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" data-theme-name="documenter-light" data-theme-primary="" href="../../assets/themes/documenter-light.css" rel="stylesheet" type="text/css"/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../../assets/citations.css" rel="stylesheet" type="text/css"/><link href="nothing/manoptexamples/stable/examples/NCRPG-Row-Sparse-Low-Rank/" rel="canonical"/><link href="../../../../assets/default/multidoc.css" rel="stylesheet" type="text/css"/><link href="../../../../assets/default/flexsearch.css" rel="stylesheet" type="text/css"/></head><body><nav id="multi-page-nav"><a class="brand" href="https://juliamanifolds.github.io"><img alt="home" src="../../../../assets/logo-dark.png"/></a><div class="hidden-on-mobile" id="nav-items"><a class="nav-link nav-item" href="../../../../juliamanifolds/">Home</a><a class="nav-link nav-item" href="../../../../manifoldsbase/">ManifoldsBase.jl</a><a class="nav-link nav-item" href="../../../../manifolds/">Manifolds.jl</a><a class="nav-link nav-item" href="../../../../manopt/">Manopt.jl</a><a class="nav-link nav-item" href="../../../../manifolddiffeq/">ManifoldDiffEq.jl</a><a class="nav-link nav-item" href="../../../../manifolddiff/">ManifoldDiff.jl</a><a class="nav-link active nav-item" href="../../../">Manopt Examples</a><div class="search nav-item"><input id="search-input" placeholder="Search everywhere..."/><ul class="suggestions hidden" id="search-result-container"></ul><div class="search-keybinding">/</div></div></div><button id="multidoc-toggler"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg></button></nav><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">ManoptExamples.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../">Overview</a></li><li><input class="collapse-toggle" id="menuitem-2-2" type="checkbox"/><label class="tocitem" for="menuitem-2-2"><span class="docs-label">Difference of Convex</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../Difference-of-Convex-Benchmark/">A Benchmark</a></li><li><a class="tocitem" href="../Difference-of-Convex-Rosenbrock/">Rosenbrock Metric</a></li><li><a class="tocitem" href="../Difference-of-Convex-Frank-Wolfe/">Frank Wolfe comparison</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-3" type="checkbox"/><label class="tocitem" for="menuitem-2-3"><span class="docs-label">Convex Bundle Method</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../RCBM-Median/">Riemannian Median</a></li><li><a class="tocitem" href="../H2-Signal-TV/">Hyperbolic Signal Denoising</a></li><li><a class="tocitem" href="../Spectral-Procrustes/">Spectral Procrustes</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-4" type="checkbox"/><label class="tocitem" for="menuitem-2-4"><span class="docs-label">Projected Gradient Algorithm</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../Constrained-Mean-H2/">Mean on <span>$\mathbb H^2$</span></a></li><li><a class="tocitem" href="../Constrained-Mean-Hn/">Mean on <span>$\mathbb H^n$</span></a></li></ul></li><li><a class="tocitem" href="../HyperparameterOptimization/">Hyperparameter optimziation</a></li><li><a class="tocitem" href="../RayleighQuotient/">The Rayleigh Quotient</a></li><li><a class="tocitem" href="../Riemannian-mean/">Riemannian Mean</a></li><li><input checked="" class="collapse-toggle" id="menuitem-2-8" type="checkbox"/><label class="tocitem" for="menuitem-2-8"><span class="docs-label">Proximal Gradient Methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../NCRPG-Sparse-PCA/">Sparse PCA</a></li><li><a class="tocitem" href="../NCRPG-Grassmann/">Grassmann Experiment</a></li><li class="is-active"><a class="tocitem" href="">Row-Sparse Low-Rank Matrix Recovery</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#The-Problem"><span>The Problem</span></a></li><li><a class="tocitem" href="#Numerical-Experiment"><span>Numerical Experiment</span></a></li><li><a class="tocitem" href="#Technical-details"><span>Technical details</span></a></li><li><a class="tocitem" href="#Literature"><span>Literature</span></a></li></ul></li><li><a class="tocitem" href="../CRPG-Convex-SPD/">Convex Example on SPDs</a></li><li><a class="tocitem" href="../CRPG-Sparse-Approximation/">Sparse Approximation on <span>$\mathbb H^n$</span></a></li><li><a class="tocitem" href="../CRPG-Constrained-Mean-Hn/">Mean on <span>$\mathbb H^n$</span></a></li></ul></li><li><a class="tocitem" href="../Robust-PCA/">Robust PCA</a></li><li><a class="tocitem" href="../Rosenbrock/">Rosenbrock</a></li><li><a class="tocitem" href="../Total-Variation/">Total Variation</a></li></ul></li><li><a class="tocitem" href="../../objectives/">Objectives</a></li><li><a class="tocitem" href="../../data/">Data</a></li><li><a class="tocitem" href="../../contributing/">Contributing to ManoptExamples.jl</a></li><li><a class="tocitem" href="../../changelog/">Changelog</a></li><li><a class="tocitem" href="../../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" href="#" id="documenter-sidebar-button"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li><a class="is-disabled">Proximal Gradient Methods</a></li><li class="is-active"><a href="">Row-Sparse Low-Rank Matrix Recovery</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="">Row-Sparse Low-Rank Matrix Recovery</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaManifolds/ManoptExamples.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaManifolds/ManoptExamples.jl/blob/main/docs/src/examples/NCRPG-Row-Sparse-Low-Rank.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" href="#" id="documenter-settings-button" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" href="javascript:;" id="documenter-article-toggle-button" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Row-sparse-Low-rank-Matrix-Recovery"><a class="docs-heading-anchor" href="#Row-sparse-Low-rank-Matrix-Recovery">Row-sparse Low-rank Matrix Recovery</a><a id="Row-sparse-Low-rank-Matrix-Recovery-1"></a><a class="docs-heading-anchor-permalink" href="#Row-sparse-Low-rank-Matrix-Recovery" title="Permalink"></a></h1><p>Paula John, Hajg Jasa 2025-10-01</p><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>In this example we use the Nonconvex Riemannian Proximal Gradient (NCRPG) method [<a href="../../references/#BergmannJasaJohnPfeffer_2025_1">BJJP25b</a>] and compare it to the Riemannian Alternating Direction Method of Multipliers (RADMM) [<a href="../../references/#JiaxiangShiqianTejes_2022_1">LMS22</a>]. This example reproduces the results from [<a href="../../references/#BergmannJasaJohnPfeffer_2025_1">BJJP25b</a>], Section 6.3. The numbers may vary slightly due to having run this notebook on a different machine.</p><pre><code class="language-julia hljs">using PrettyTables
using BenchmarkTools
using CSV, DataFrames
using ColorSchemes, Plots, LaTeXStrings
using Random, LinearAlgebra, LRUCache, Distributions
using ManifoldDiff, Manifolds, Manopt, ManoptExamples</code></pre><h2 id="The-Problem"><a class="docs-heading-anchor" href="#The-Problem">The Problem</a><a id="The-Problem-1"></a><a class="docs-heading-anchor-permalink" href="#The-Problem" title="Permalink"></a></h2><p>Let <span>$\mathcal M = \mathcal M_r$</span> be the manifold of rank <span>$r$</span> matrices. Let <span>$g \colon \mathcal M \to \mathbb R$</span> be defined by</p><p class="math-container">\[g(X) = \Vert\mathbb A (X) - y\Vert_2^2,\]</p><p>where <span>$\mathbb A \colon \mathbb R^{M \times N} \to \mathbb R^m$</span> is a linear measurement operator.</p><p>Let <span>$h \colon \mathcal M \to \mathbb R$</span> be defined by</p><p class="math-container">\[h(X) = \mu \Vert X \Vert_{1, 2}\]</p><p>be the row sparsity-enforcing term given by the <span>$\ell_{1,2}$</span>-norm, where <span>$\mu \ge 0$</span> is a regularization parameter.</p><p>We define our total objective function as <span>$f = g + h$</span>. The goal is to recover the (low-rank and row-sparse) signal <span>$X$</span> from as few measurements <span>$y$</span> as possible.</p><h2 id="Numerical-Experiment"><a class="docs-heading-anchor" href="#Numerical-Experiment">Numerical Experiment</a><a id="Numerical-Experiment-1"></a><a class="docs-heading-anchor-permalink" href="#Numerical-Experiment" title="Permalink"></a></h2><p>We initialize the experiment parameters, as well as some utility functions.</p><pre><code class="language-julia hljs"># Set random seed for reproducibility
random_seed = 1520
BenchmarkTools.DEFAULT_PARAMETERS.seconds = 180.0

atol = 1e-7
max_iters = 5000
c = 1e-4    # penalty parameter 
M = 500     # amount of rows
N = 100     # amount of columns
s = 10      # amount of non-zero rows
r_m_array = [(1, 300), (2, 500), (3, 700)] # (rank, number of measurements)
step_size = 0.25
init_step_size_bt = 2 * step_size
stop_NCRPG = atol
stop_RADMM = stop_NCRPG * step_size </code></pre><pre><code class="language-julia hljs">function mean_error_zero_rows(Mr, X, zero_rows)
    M, N, r = Manifolds.get_parameter(Mr.size)
    err = 0.0
    for j in zero_rows
        err += norm(X.U[j, :] .* X.S)
    end 
    return err/length(zero_rows)
end</code></pre><p>We define a function to generate the test data for the Sparse PCA problem.</p><pre><code class="language-julia hljs">function generate_data(M, N, r, m, s)
    # Generate rank r matrix with s non-zero rows
    X = rand(M, r) * transpose(Matrix(qr(rand(N, r)).Q[:, 1:r]))
    smpl = sample(1:M, M - s , replace = false)
    X[smpl, :] .= 0.0

    # Normalize
    X = X/norm(X)

    # Generate measurement operator A and signal y
    A = rand(Normal(0, 1/sqrt(m)), m, M * N)
    y = A * vec(X)   
    return X, A, y, smpl
end</code></pre><p>We implement the proximal operators for the <span>$\ell_{1, 2}$</span>-norm on the fixed-rank manifold, following [<a href="../../references/#BergmannJasaJohnPfeffer_2025_1">BJJP25b</a>] and [<a href="../../references/#JiaxiangShiqianTejes_2022_1">LMS22</a>].</p><pre><code class="language-julia hljs"># NCRPG 
function prox_norm12_global(Mr::FixedRankMatrices, prox_param, X::SVDMPoint; c = c) 
    λ = prox_param * c
    M, N, k = Manifolds.get_parameter(Mr.size)
    YU = zeros(M, k)
    for i in 1:M
        normx1_i = norm(X.U[i, :] .* X.S)
        if  normx1_i &gt; λ
            YU[i, :] = ((normx1_i - λ)/normx1_i) * X.U[i, :]
        end
    end
    Z = SVDMPoint(YU * diagm(X.S))
    return SVDMPoint(Z.U, Z.S, Z.Vt * X.Vt)
end
#
#RADMM 
function prox_norm12_global(Mr::FixedRankMatrices, prox_param, X1::Matrix{Float64}; c = c) 
    λ = prox_param * c
    M, N, k = Manifolds.get_parameter(Mr.size)
    Y1 = zeros(M, N)
    for i in 1:M
        normx1_i = norm(X1[i, :])
        if  normx1_i &gt; λ
            Y1[i, :] = ((normx1_i - λ)/normx1_i) * X1[i, :]
        end
    end
    return Y1
end</code></pre><p>Next, we define the objective function, its gradient, and the proximal operator for the <span>$\ell_{1,2}$</span>-norm on the fixed-rank manifold.</p><pre><code class="language-julia hljs"># Objective(s), gradient, and proxes
function norm12(X::SVDMPoint)
    M = size(X.U)[1]
    sum([norm(X.U[i, :].*X.S) for i = 1:M])
end
function f_global(M::FixedRankMatrices, X::SVDMPoint, A, c, y, max_cost = 1e5) 
    X_vec = vec(embed(M, X))
    cost =  0.5 * (norm(A*X_vec - y))^2 + c * norm12(X)
    if cost &gt;= max_cost
        return NaN
    else 
        return cost
    end 
end 
#
g_global(M::FixedRankMatrices, X::SVDMPoint, A, c, y) = 0.5*(norm(A*vec(embed(M, X)) - y))^2 
function grad_g_global(M::FixedRankMatrices, X::SVDMPoint, A, c, y) 
    X_mat = embed(M, X)
    return project(M, X, reshape(A'*(A*vec(X_mat) - y), size(X_mat)))
end 
h_global(M::FixedRankMatrices, X::SVDMPoint, A, c, y) = c * norm12(X)</code></pre><p>We introduce an implementation of the RADMM method for the Row-sparse Low-rank Matrix Recovery problem on the oblique manifold, following [<a href="../../references/#JiaxiangShiqianTejes_2022_1">LMS22</a>].</p><pre><code class="language-julia hljs">"""
\argmin F(X) = 0.5||AX-y||^2 + c *||X||_{1,2}
f(X) = 0.5||AX - y||^2
g(X) = c * ||X||_{1,2}
L_{ρ,γ}(X, Z, Λ) = f(X) + g_γ(Z) + &lt;Λ, X - Z&gt; + ρ/2 * ||X - Z||^2
grad_X L_{ρ,γ}(X, Z, Λ) = project(A'(AX - y) + Λ + ρ(X - Z)) 

"""
function RADMM_blind_deconv(
    A,
    M, # rows
    N, # columns
    rank,
    c,  # penalty parameter 
    y, # signal
    prox_l12;
    η = 1e-1,
    ρ = 0.1,
    γ = 1e-7,
    stop = 1e-8, 
    max_iters  = 100,
    start = 0,
    record = false, 
    ϵ_spars = 1e-5,
    max_cost = 1e5
) 
    flag_succ = false
    Mr = FixedRankMatrices(M, N, rank)
    γρ = γ * ρ
    F(X) = 0.5 * norm(A*vec(X) - y)^2 + c * sum([norm(X[i, :]) for i=1:M])
    grad_augLagr(X::SVDMPoint, X_mat::Matrix, Λ::Matrix, Z::Matrix) = project(Mr, X, reshape(A'*(A*vec(X_mat) - y) + vec(Λ + ρ*(X_mat - Z)), (M, N)))

    if start == 0
        X = rand(Mr)
    else 
        X = start
    end 
    X_mat = embed(Mr, X)
    Z = X_mat
    Λ = zeros(M, N)
    it = -1 
    if !record 
        for i in 1:max_iters 
            descent_dir = -η * grad_augLagr(X, X_mat, Λ, Z)
            X = retract(Mr, X, descent_dir) 
            X_mat = embed(Mr, X)
            Y = prox_l12(Mr, (1 + γρ)/ρ , X_mat + 1/ρ * Λ; c = c)
            Z = (1/γ * Y + Λ + ρ * X_mat)/ (1/γ + ρ)
            Λ = Λ + ρ * (X_mat - Z)
            if (norm(embed(Mr, X, descent_dir)) &lt; stop)
                flag_succ = true 
                it = i 
                break 
            end 
        end
        if it == -1
            it = max_iters 
        end 
        return X, flag_succ, it 
    else 
        Iterates = []
        for i in 1:max_iters 
            descent_dir = -η * grad_augLagr(X, X_mat, Λ, Z)
            X = retract(Mr, X, descent_dir) 
            push!(Iterates, X)
            X_mat = embed(Mr, X)
            Y = prox_l12(Mr, (1 + γρ)/ρ , X_mat + 1/ρ * Λ; c = c)
            Z = (1/γ * Y + Λ + ρ * X_mat)/ (1/γ + ρ)
            Λ = Λ + ρ * (X_mat - Z)
            if (norm(embed(Mr, X, descent_dir)) &lt; stop)
                flag_succ = true 
                it = i 
                break 
            end 
            # if i%100 == 0
            #     println(i, "\t", norm(embed(Mr, X, descent_dir)))
            # end 
        end
        if it == -1 
            it = max_iters 
        end 
        return X, flag_succ, it, Iterates
    end 
end </code></pre><p>We set up some variables to collect the results of the experiments and initialize the dataframes</p><p>And run the experiments</p><pre><code class="language-julia hljs">for (r, m) in r_m_array
    # Set random seed for reproducibility
    Random.seed!(random_seed)
    #
    # Define manifold
    Mr = FixedRankMatrices(M, N, r) #fixed rank manifold
    #
    # Generate rank r matrix with s non-zero rows
    Sol_mat, A, y, zero_rows = generate_data(M, N, r, m, s)
    Sol = SVDMPoint(Sol_mat, r)
    # Local starting point 
    Y = rand(Normal(0, 0.01/sqrt(r)), M, N)
    start = SVDMPoint(Sol_mat + Y, r)
    dist_start_sol = distance(Mr, Sol, start, OrthographicInverseRetraction())
    # Localize objectives
    f(Mr, X) = f_global(Mr, X, A, c, y)
    g(Mr, X) = g_global(Mr, X, A, c, y)
    grad_g(Mr, X) = grad_g_global(Mr, X, A, c, y)
    h(Mr, X) = h_global(Mr, X, A, c, y)
    prox_norm12(Mr, prox_param, X) = prox_norm12_global(Mr, prox_param, X; c = c)
    #
    # Optimization
    # NCRPG
    rec_NCRPG = proximal_gradient_method(Mr, f, g, grad_g, start; 
        prox_nonsmooth=prox_norm12,
        retraction_method=OrthographicRetraction(),
        inverse_retraction_method=OrthographicInverseRetraction(),
        stepsize = ConstantLength(step_size),
        record=[:Iteration, :Iterate],
        return_state=true,
        debug=[ 
            :Iteration,( "|Δp|: %1.9f |"),
            DebugChange(; inverse_retraction_method= OrthographicInverseRetraction()),
            (:Cost, " F(x): %1.11f | "), 
            "\n", 
            :Stop, 
            100
        ],
        stopping_criterion =  StopAfterIteration(max_iters )|StopWhenGradientMappingNormLess(stop_NCRPG)
    )
    bm_NCRPG = @benchmark proximal_gradient_method(``Mr, ``f, ``g, ``grad_g, ``start; 
        prox_nonsmooth=``prox_norm12,
        retraction_method=OrthographicRetraction(),
        inverse_retraction_method=OrthographicInverseRetraction(),
        stepsize = ConstantLength(``step_size),
        stopping_criterion = StopAfterIteration(``max_iters )|StopWhenGradientMappingNormLess(``stop_NCRPG)
    )
    it_NCRPG, res_NCRPG = get_record(rec_NCRPG)[end]
    # NCRPG with backtracking
    rec_NCRPG_bt = proximal_gradient_method(Mr, f, g, grad_g, start; 
        prox_nonsmooth=prox_norm12,
        retraction_method=OrthographicRetraction(),
        inverse_retraction_method=OrthographicInverseRetraction(),
        stepsize = ProximalGradientMethodBacktracking(;             
            strategy=:nonconvex, 
            initial_stepsize=init_step_size_bt
        ),
        record=[:Iteration, :Iterate],
        return_state=true,
        debug=[ 
            :Iteration,( "|Δp|: %1.9f |"),
            DebugChange(; inverse_retraction_method=OrthographicInverseRetraction()),
            (:Cost, " F(x): %1.11f | "), 
            "\n", 
            :Stop, 
            100
        ],
        stopping_criterion = StopAfterIteration(max_iters )|    StopWhenGradientMappingNormLess(stop_NCRPG)
    )
    bm_NCRPG_bt = @benchmark proximal_gradient_method(``Mr, ``f, ``g, ``grad_g, ``start; 
        prox_nonsmooth=``prox_norm12,
        retraction_method=OrthographicRetraction(),
        inverse_retraction_method=OrthographicInverseRetraction(),
        stepsize = ProximalGradientMethodBacktracking(; strategy=:nonconvex, initial_stepsize=``init_step_size_bt),
        stopping_criterion = StopAfterIteration(``max_iters )|  StopWhenGradientMappingNormLess(``stop_NCRPG)
    )
    it_NCRPG_bt, res_NCRPG_bt = get_record(rec_NCRPG_bt)[end]
    # RADMM
    res_RADMM, succ, it_RADMM = RADMM_blind_deconv(A, M, N, r, c, y, prox_norm12_global; 
        max_iters  = max_iters , 
        start = start, 
        η = step_size,  
        stop = stop_RADMM
    )  
    bm_RADMM = @benchmark RADMM_blind_deconv(``A, ``M, ``N, ``r, ``c, ``y, ``prox_norm12_global; 
        max_iters  = max_iters , 
        start = ``start, 
        η = ``step_size,  
        stop = stop_RADMM
    )  
    #
    # Collect results
    # Distances between the results
    dist_NCRPG_RADMM = distance(Mr, res_NCRPG, res_RADMM, OrthographicInverseRetraction())
    dist_NCRPG_bt_RADMM = distance(Mr, res_NCRPG_bt, res_RADMM, OrthographicInverseRetraction())
    dist_NCRPG_NCRPG_bt = distance(Mr, res_NCRPG, res_NCRPG_bt, OrthographicInverseRetraction())
    # Times
    time_RADMM    = median(bm_RADMM   ).time/1e9
    time_NCRPG    = median(bm_NCRPG   ).time/1e9
    time_NCRPG_bt = median(bm_NCRPG_bt).time/1e9
    # Errors
    error_RADMM    = distance(Mr, Sol, res_RADMM,    OrthographicInverseRetraction())
    error_NCRPG    = distance(Mr, Sol, res_NCRPG,    OrthographicInverseRetraction())
    error_NCRPG_bt = distance(Mr, Sol, res_NCRPG_bt, OrthographicInverseRetraction())
    # Mean zero row errors
    mean_zero_row_error_NCRPG    = mean_error_zero_rows(Mr, res_NCRPG, zero_rows    )
    mean_zero_row_error_NCRPG_bt = mean_error_zero_rows(Mr, res_NCRPG_bt, zero_rows )
    mean_zero_row_error_RADMM    = mean_error_zero_rows(Mr, res_RADMM, zero_rows    )
    #
    # Push results to dataframes
    push!(df_RADMM, 
        [
            M, N, m, r, s,
            step_size,
            time_RADMM, 
            error_RADMM,
            it_RADMM,
            mean_zero_row_error_RADMM
        ]
    )
    push!(df_NCRPG, 
        [
            M, N, m, r, s,
            step_size,
            time_NCRPG, 
            error_NCRPG,
            it_NCRPG,
            mean_zero_row_error_NCRPG
        ]
    )
    push!(df_NCRPG_bt, 
        [
            M, N, m, r, s,
            init_step_size_bt,
            time_NCRPG_bt, 
            error_NCRPG_bt,
            it_NCRPG_bt,
            mean_zero_row_error_NCRPG_bt
        ]
    )
    push!(df_distances, 
        [
            M, N, m, r, s,
            dist_NCRPG_NCRPG_bt,
            dist_NCRPG_RADMM,
            dist_NCRPG_bt_RADMM
        ]
    )
end</code></pre><p>We export the results to CSV files</p><pre><code class="language-julia hljs">CSV.write(joinpath(results_folder, "results-fixed-rank-RADMM.csv"), df_RADMM)
CSV.write(joinpath(results_folder, "results-fixed-rank-NCRPG.csv"), df_NCRPG)
CSV.write(joinpath(results_folder, "results-fixed-rank-NCRPG-bt.csv"), df_NCRPG_bt)
CSV.write(joinpath(results_folder, "results-fixed-rank-distances.csv"), df_distances )</code></pre><p>We can take a look at how the algorithms compare to each other in their performance with the following tables. The first table shows the performance RADMM.</p><table><tbody><tr><th style="text-align: right"><strong>M</strong></th><th style="text-align: right"><strong>N</strong></th><th style="text-align: right"><strong>m</strong></th><th style="text-align: right"><strong>r</strong></th><th style="text-align: right"><strong>s</strong></th><th style="text-align: right"><strong>stepsize</strong></th><th style="text-align: right"><strong>time (s)</strong></th><th style="text-align: right"><strong>error</strong></th><th style="text-align: right"><strong>iterations</strong></th><th style="text-align: right"><strong>mean_zero_row_error</strong></th></tr><tr><td style="text-align: right">500.0</td><td style="text-align: right">100.0</td><td style="text-align: right">300.0</td><td style="text-align: right">1.0</td><td style="text-align: right">10.0</td><td style="text-align: right">0.25</td><td style="text-align: right">16.6644</td><td style="text-align: right">0.00052812</td><td style="text-align: right">1431.0</td><td style="text-align: right">5.37441e-9</td></tr><tr><td style="text-align: right">500.0</td><td style="text-align: right">100.0</td><td style="text-align: right">500.0</td><td style="text-align: right">2.0</td><td style="text-align: right">10.0</td><td style="text-align: right">0.25</td><td style="text-align: right">19.1971</td><td style="text-align: right">0.000725431</td><td style="text-align: right">1354.0</td><td style="text-align: right">6.09862e-9</td></tr><tr><td style="text-align: right">500.0</td><td style="text-align: right">100.0</td><td style="text-align: right">700.0</td><td style="text-align: right">3.0</td><td style="text-align: right">10.0</td><td style="text-align: right">0.25</td><td style="text-align: right">32.7179</td><td style="text-align: right">0.000772805</td><td style="text-align: right">1414.0</td><td style="text-align: right">7.4266e-9</td></tr></tbody></table><p>The next table shows the performance of NCRPG with a constant stepsize.</p><table><tbody><tr><th style="text-align: right"><strong>M</strong></th><th style="text-align: right"><strong>N</strong></th><th style="text-align: right"><strong>m</strong></th><th style="text-align: right"><strong>r</strong></th><th style="text-align: right"><strong>s</strong></th><th style="text-align: right"><strong>stepsize</strong></th><th style="text-align: right"><strong>time (s)</strong></th><th style="text-align: right"><strong>error</strong></th><th style="text-align: right"><strong>iterations</strong></th><th style="text-align: right"><strong>mean_zero_row_error</strong></th></tr><tr><td style="text-align: right">500.0</td><td style="text-align: right">100.0</td><td style="text-align: right">300.0</td><td style="text-align: right">1.0</td><td style="text-align: right">10.0</td><td style="text-align: right">0.25</td><td style="text-align: right">10.475</td><td style="text-align: right">0.000528145</td><td style="text-align: right">1049.0</td><td style="text-align: right">0.0</td></tr><tr><td style="text-align: right">500.0</td><td style="text-align: right">100.0</td><td style="text-align: right">500.0</td><td style="text-align: right">2.0</td><td style="text-align: right">10.0</td><td style="text-align: right">0.25</td><td style="text-align: right">20.4298</td><td style="text-align: right">0.000725859</td><td style="text-align: right">1047.0</td><td style="text-align: right">1.15293e-20</td></tr><tr><td style="text-align: right">500.0</td><td style="text-align: right">100.0</td><td style="text-align: right">700.0</td><td style="text-align: right">3.0</td><td style="text-align: right">10.0</td><td style="text-align: right">0.25</td><td style="text-align: right">22.6698</td><td style="text-align: right">0.000775127</td><td style="text-align: right">1120.0</td><td style="text-align: right">4.22854e-20</td></tr></tbody></table><p>The next table shows the performance of NCRPG with a backtracked stepsize. In this case, the column "stepsize" indicates the initial stepsize for the backtracking procedure.</p><table><tbody><tr><th style="text-align: right"><strong>M</strong></th><th style="text-align: right"><strong>N</strong></th><th style="text-align: right"><strong>m</strong></th><th style="text-align: right"><strong>r</strong></th><th style="text-align: right"><strong>s</strong></th><th style="text-align: right"><strong>stepsize</strong></th><th style="text-align: right"><strong>time (s)</strong></th><th style="text-align: right"><strong>error</strong></th><th style="text-align: right"><strong>iterations</strong></th><th style="text-align: right"><strong>mean_zero_row_error</strong></th></tr><tr><td style="text-align: right">500.0</td><td style="text-align: right">100.0</td><td style="text-align: right">300.0</td><td style="text-align: right">1.0</td><td style="text-align: right">10.0</td><td style="text-align: right">0.5</td><td style="text-align: right">16.2641</td><td style="text-align: right">0.000528144</td><td style="text-align: right">562.0</td><td style="text-align: right">0.0</td></tr><tr><td style="text-align: right">500.0</td><td style="text-align: right">100.0</td><td style="text-align: right">500.0</td><td style="text-align: right">2.0</td><td style="text-align: right">10.0</td><td style="text-align: right">0.5</td><td style="text-align: right">31.1954</td><td style="text-align: right">0.000725847</td><td style="text-align: right">604.0</td><td style="text-align: right">1.86904e-20</td></tr><tr><td style="text-align: right">500.0</td><td style="text-align: right">100.0</td><td style="text-align: right">700.0</td><td style="text-align: right">3.0</td><td style="text-align: right">10.0</td><td style="text-align: right">0.5</td><td style="text-align: right">3643.83</td><td style="text-align: right">0.000778708</td><td style="text-align: right">5000.0</td><td style="text-align: right">6.3238e-20</td></tr></tbody></table><p>Second, we look at the distances of the solutions found by each algorithm.</p><table><tbody><tr><th style="text-align: right"><strong>M</strong></th><th style="text-align: right"><strong>N</strong></th><th style="text-align: right"><strong>m</strong></th><th style="text-align: right"><strong>r</strong></th><th style="text-align: right"><strong>s</strong></th><th style="text-align: right"><strong>dist_NCRPG_NCRPG_bt</strong></th><th style="text-align: right"><strong>dist_NCRPG_RADMM</strong></th><th style="text-align: right"><strong>dist_NCRPG_NCRPG_bt</strong></th></tr><tr><td style="text-align: right">500.0</td><td style="text-align: right">100.0</td><td style="text-align: right">300.0</td><td style="text-align: right">1.0</td><td style="text-align: right">10.0</td><td style="text-align: right">1.08617e-8</td><td style="text-align: right">5.59207e-7</td><td style="text-align: right">5.49924e-7</td></tr><tr><td style="text-align: right">500.0</td><td style="text-align: right">100.0</td><td style="text-align: right">500.0</td><td style="text-align: right">2.0</td><td style="text-align: right">10.0</td><td style="text-align: right">2.18404e-8</td><td style="text-align: right">7.53362e-7</td><td style="text-align: right">7.33125e-7</td></tr><tr><td style="text-align: right">500.0</td><td style="text-align: right">100.0</td><td style="text-align: right">700.0</td><td style="text-align: right">3.0</td><td style="text-align: right">10.0</td><td style="text-align: right">1.38488e-5</td><td style="text-align: right">2.39003e-5</td><td style="text-align: right">2.51751e-5</td></tr></tbody></table><h2 id="Technical-details"><a class="docs-heading-anchor" href="#Technical-details">Technical details</a><a id="Technical-details-1"></a><a class="docs-heading-anchor-permalink" href="#Technical-details" title="Permalink"></a></h2><p>This tutorial is cached. It was last run on the following package versions.</p><pre><code class="language-julia hljs">using Pkg
Pkg.status()</code></pre><pre><code class="nohighlight hljs">Status `~/Repositories/Julia/ManoptExamples.jl/examples/Project.toml`
  [6e4b80f9] BenchmarkTools v1.6.0
  [336ed68f] CSV v0.10.15
  [13f3f980] CairoMakie v0.15.6
  [0ca39b1e] Chairmarks v1.3.1
  [35d6a980] ColorSchemes v3.31.0
⌅ [5ae59095] Colors v0.12.11
  [a93c6f00] DataFrames v1.8.0
  [31c24e10] Distributions v0.25.120
  [7073ff75] IJulia v1.30.4
  [682c06a0] JSON v0.21.4
  [8ac3fa9e] LRUCache v1.6.2
  [b964fa9f] LaTeXStrings v1.4.0
  [d3d80556] LineSearches v7.4.0
  [ee78f7c6] Makie v0.24.6
  [af67fdf4] ManifoldDiff v0.4.4
  [1cead3c2] Manifolds v0.10.23
  [3362f125] ManifoldsBase v1.2.0
  [0fc0a36d] Manopt v0.5.23 `../../Manopt.jl`
  [5b8d5e80] ManoptExamples v0.1.15 `..`
  [51fcb6bd] NamedColors v0.2.3
  [91a5bcdd] Plots v1.41.1
  [08abe8d2] PrettyTables v3.0.11
  [6099a3de] PythonCall v0.9.28
  [f468eda6] QuadraticModels v0.9.14
  [1e40b3f8] RipQP v0.7.0
Info Packages marked with ⌅ have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated`</code></pre><p>This tutorial was last rendered October 3, 2025, 15:22:53.</p><h2 id="Literature"><a class="docs-heading-anchor" href="#Literature">Literature</a><a id="Literature-1"></a><a class="docs-heading-anchor-permalink" href="#Literature" title="Permalink"></a></h2><div class="citation noncanonical"><dl><dt>[BJJP25b]</dt><dd><div>R. Bergmann, H. Jasa, P. J. John and M. Pfeffer. <em>The Intrinsic Riemannian Proximal Gradient Method for Nononvex Optimization</em>, preprint (2025), <a href="https://arxiv.org/abs/2506.09775">arXiv:2506.09775</a>.</div></dd><dt>[HW21]</dt><dd><div>W. Huang and K. Wei. <em>Riemannian proximal gradient methods</em>. <a href="https://doi.org/10.1007/s10107-021-01632-3">Mathematical Programming <strong>194</strong>, 371–413</a> (2021).</div></dd></dl></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../NCRPG-Grassmann/">« Grassmann Experiment</a><a class="docs-footer-nextpage" href="../CRPG-Convex-SPD/">Convex Example on SPDs »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label></p><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div><p></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Monday 6 October 2025 09:20">Monday 6 October 2025</span>. Using Julia version 1.11.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></HTML>