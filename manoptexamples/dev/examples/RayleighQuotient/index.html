<!DOCTYPE html><HTML lang="en"><head><script charset="utf-8" src="../../../../assets/default/multidoc_injector.js" type="text/javascript"></script><script charset="utf-8" type="text/javascript">window.MULTIDOCUMENTER_ROOT_PATH = '/'</script><script charset="utf-8" src="../../../../assets/default/flexsearch.bundle.js" type="text/javascript"></script><script charset="utf-8" src="../../../../assets/default/flexsearch_integration.js" type="text/javascript"></script><meta charset="UTF-8"/><meta content="width=device-width, initial-scale=1.0" name="viewport"/><title>The Rayleigh Quotient · ManoptExamples.jl</title><meta content="The Rayleigh Quotient · ManoptExamples.jl" name="title"/><meta content="The Rayleigh Quotient · ManoptExamples.jl" property="og:title"/><meta content="The Rayleigh Quotient · ManoptExamples.jl" property="twitter:title"/><meta content="Documentation for ManoptExamples.jl." name="description"/><meta content="Documentation for ManoptExamples.jl." property="og:description"/><meta content="Documentation for ManoptExamples.jl." property="twitter:description"/><script data-outdated-warner="" src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script data-main="../../assets/documenter.js" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" data-theme-name="documenter-dark" data-theme-primary-dark="" href="../../assets/themes/documenter-dark.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" data-theme-name="documenter-light" data-theme-primary="" href="../../assets/themes/documenter-light.css" rel="stylesheet" type="text/css"/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../../assets/citations.css" rel="stylesheet" type="text/css"/><link href="nothing/manoptexamples/stable/examples/RayleighQuotient/" rel="canonical"/><link href="../../../../assets/default/multidoc.css" rel="stylesheet" type="text/css"/><link href="../../../../assets/default/flexsearch.css" rel="stylesheet" type="text/css"/></head><body><nav id="multi-page-nav"><a class="brand" href="https://juliamanifolds.github.io"><img alt="home" src="../../../../assets/logo-dark.png"/></a><div class="hidden-on-mobile" id="nav-items"><a class="nav-link nav-item" href="../../../../juliamanifolds/">Home</a><a class="nav-link nav-item" href="../../../../manifoldsbase/">ManifoldsBase.jl</a><a class="nav-link nav-item" href="../../../../manifolds/">Manifolds.jl</a><a class="nav-link nav-item" href="../../../../manopt/">Manopt.jl</a><a class="nav-link nav-item" href="../../../../manifolddiffeq/">ManifoldDiffEq.jl</a><a class="nav-link nav-item" href="../../../../manifolddiff/">ManifoldDiff.jl</a><a class="nav-link active nav-item" href="../../../">Manopt Examples</a><div class="search nav-item"><input id="search-input" placeholder="Search..."/><ul class="suggestions hidden" id="search-result-container"></ul><div class="search-keybinding">/</div></div></div><button id="multidoc-toggler"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg></button></nav><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">ManoptExamples.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../">Overview</a></li><li><input class="collapse-toggle" id="menuitem-2-2" type="checkbox"/><label class="tocitem" for="menuitem-2-2"><span class="docs-label">Difference of Convex</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../Difference-of-Convex-Benchmark/">A Benchmark</a></li><li><a class="tocitem" href="../Difference-of-Convex-Rosenbrock/">Rosenbrock Metric</a></li><li><a class="tocitem" href="../Difference-of-Convex-Frank-Wolfe/">Frank Wolfe comparison</a></li></ul></li><li class="is-active"><a class="tocitem" href="">The Rayleigh Quotient</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Summary"><span>Summary</span></a></li><li><a class="tocitem" href="#Literature"><span>Literature</span></a></li></ul></li><li><a class="tocitem" href="../Riemannian-mean/">Riemannian Mean</a></li><li><a class="tocitem" href="../Robust-PCA/">Robust PCA</a></li><li><a class="tocitem" href="../Rosenbrock/">Rosenbrock</a></li><li><a class="tocitem" href="../Total-Variation/">Total Variation</a></li></ul></li><li><a class="tocitem" href="../../objectives/">Objectives</a></li><li><a class="tocitem" href="../../data/">Data</a></li><li><a class="tocitem" href="../../contributing/">Contributing to ManoptExamples.jl</a></li><li><a class="tocitem" href="../../changelog/">Changelog</a></li><li><a class="tocitem" href="../../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" href="#" id="documenter-sidebar-button"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href="">The Rayleigh Quotient</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="">The Rayleigh Quotient</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaManifolds/ManoptExamples.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaManifolds/ManoptExamples.jl/blob/main/docs/src/examples/RayleighQuotient.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" href="#" id="documenter-settings-button" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" href="javascript:;" id="documenter-article-toggle-button" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="The-Rayleigh-Quotient"><a class="docs-heading-anchor" href="#The-Rayleigh-Quotient">The Rayleigh Quotient</a><a id="The-Rayleigh-Quotient-1"></a><a class="docs-heading-anchor-permalink" href="#The-Rayleigh-Quotient" title="Permalink"></a></h1><p>Ronny Bergmann 2024-03-09</p><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>This example reproduces a few conceptual ideas of Optimization on Manifolds that are used throughout [<a href="../../references/#Boumal:2023">Bou23</a>] using the Rayleigh quotient and explores several different ways to use the algorithms from <a href="https://manoptjl.org"><code>Manopt.jl</code></a>.</p><p>For a symmetric matrix <span>$A \in \mathbb R^{n\times n}$</span> we consider the <a href="https://en.wikipedia.org/wiki/Rayleigh_quotient">📖 Rayleigh Quotient</a></p><p class="math-container">\[\operatorname*{arg\,min}_{x \in \mathbb R^n \backslash \{0\}}
\frac{x^{\mathrm{T}}Ax}{\lVert x \rVert^2}.\]</p><p>On the sphere we can omit the denominator and obtain</p><p class="math-container">\[f(p) = p^{\mathrm{T}}Ap,\qquad p ∈ 𝕊^{n-1},\]</p><p>which by itself we can again continue in the embedding as</p><p class="math-container">\[\tilde f(x) = x^{\mathrm{T}}Ax,\qquad x \in \mathbb R^n.\]</p><p>This cost has the nice feature that at the minimizer <span>$p^*\in\mathbb S^{n-1}$</span> the function falue <span>$f(p^*)$</span> is the smalles eigenvalue of <span>$A$</span>.</p><p>For the embedded function <span>$\tilde f$</span> the gradient and Hessian can be computed with classical methods as</p><p class="math-container">\[\begin{align*}
∇\tilde f(x) &amp;= 2Ax, \qquad x ∈ ℝ^n,
\\
∇^2\tilde f(x)[V] &amp;= 2AV, \qquad x, V ∈ ℝ^n.
\end{align*}\]</p><p>Similarly, cf. Examples 3.62 and 5.27 of [<a href="../../references/#Boumal:2023">Bou23</a>], the Riemannian gradient and Hessian on the manifold <span>$\mathcal M = \mathbb S^{n-1}$</span> are given by</p><p class="math-container">\[\begin{align*}
\operatorname{grad} f(p) &amp;= 2Ap - 2(p^{\mathrm{T}}Ap)*p,\qquad p ∈ 𝕊^{n-1},
\\
\operatorname{Hess} f(p)[X] &amp;=  2AX - 2(p^{\mathrm{T}}AX)p - 2(p^{\mathrm{T}}Ap)X,\qquad p ∈ 𝕊^{n-1}, X \in T_p𝕊^{n-1}
\end{align*}\]</p><p>Let’s first generate an example martrx <span>$A$</span>.</p><pre><code class="language-julia hljs">using Pkg;
cd(@__DIR__)
Pkg.activate("."); # use the example environment,</code></pre><pre><code class="language-julia hljs">using LRUCache, BenchmarkTools, LinearAlgebra, Manifolds, ManoptExamples, Manopt, Random
Random.seed!(42)
n = 500
A = Symmetric(randn(n,n))</code></pre><p>And the manifolds</p><pre><code class="language-julia hljs">M = Sphere(n-1)</code></pre><pre><code class="nohighlight hljs">Sphere(499, ℝ)</code></pre><pre><code class="language-julia hljs">E = get_embedding(M)</code></pre><pre><code class="nohighlight hljs">Euclidean(500; field=ℝ)</code></pre><h3 id="Setup-the-corresponding-functions"><a class="docs-heading-anchor" href="#Setup-the-corresponding-functions">Setup the corresponding functions</a><a id="Setup-the-corresponding-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Setup-the-corresponding-functions" title="Permalink"></a></h3><p>Since <a href="../../objectives/#ManoptExamples.RayleighQuotientCost"><code>RayleighQuotientCost</code></a>, <a href="../../objectives/#ManoptExamples.RayleighQuotientGrad!!"><code>RayleighQuotientGrad!!</code></a>, and <a href="../../objectives/#ManoptExamples.RayleighQuotientHess!!"><code>RayleighQuotientHess!!</code></a> are themselves manifold agnostic we only need to initialize them once. Agnostic here means that they would compute <span>$f$</span> is called with <code>M</code> as their first argument and <span>$\tilde f$</span> if called with <code>E</code>.</p><p>We instantiate</p><pre><code class="language-julia hljs">f = ManoptExamples.RayleighQuotientCost(A)
grad_f = ManoptExamples.RayleighQuotientGrad!!(A)
Hess_f = ManoptExamples.RayleighQuotientHess!!(A)</code></pre><p>the suffix <code>!!</code> also indicates that these functions both work as allocating and in-place variants. Given a starting point and some memory</p><pre><code class="language-julia hljs">p0 = [1.0, zeros(n-1)...]
X = zero_vector(M, p0)</code></pre><p>we can both call</p><pre><code class="language-julia hljs">Y = grad_f(M,p0)  # Allocates memory
grad_f(M,X,p0)    # Computes in place of X and returns the result in X.
norm(M, p0, X-Y)</code></pre><pre><code class="nohighlight hljs">0.0</code></pre><p>Now we can use a few different variants of solvers to approaach this and this tutorial will walk you through a few of them.</p><p>First of all let’s construct the actual result – since Rayleigh quotient minimization is not necessarily the best way to compute the smallest Eigenvalue. We can also compute</p><pre><code class="language-julia hljs">λ = min(eigvals(A)...)</code></pre><pre><code class="nohighlight hljs">-44.8386050469405</code></pre><h3 id="A-Solver-based-on-gradient-information"><a class="docs-heading-anchor" href="#A-Solver-based-on-gradient-information">A Solver based on gradient information</a><a id="A-Solver-based-on-gradient-information-1"></a><a class="docs-heading-anchor-permalink" href="#A-Solver-based-on-gradient-information" title="Permalink"></a></h3><p>Let’s first just use first-order information and since we are just starting, maybe we only derived the Euclidean gradient <span>$\nabla \tilde f$</span>. We can “tell” the solver, that the provided function and the gradient are defined as the Euclidean variants in the embedding. internally, <code>Manopt.jl</code> then issues the conversion for Euclidean gradients to the corresponding Riemannian one, cf. e.g. <a href="https://manoptjl.org/stable/tutorials/AutomaticDifferentiation/#EmbeddedGradient">this tutorial section</a> or Section 3.8 or more precisely Example 3.62 in [<a href="../../references/#Boumal:2023">Bou23</a>].</p><p>But instead of diving into all the tecnical details, we can just specify <code>objective_type=:Euclidean</code> to trigger the conversion. We start with a simple <a href="https://manoptjl.org/stable/solvers/gradient_descent/">gradient descent</a></p><pre><code class="language-julia hljs">s = gradient_descent(M, f, grad_f, p0; objective_type=:Euclidean,
    debug = [:Iteration, :Cost, :GradientNorm, 50, "\n"],
    return_state=true,
)
q1 = get_solver_result(s)
s</code></pre><pre><code class="nohighlight hljs">Initial f(x): -0.363357
# 50    f(x): -44.206244|grad f(p)|:2.3878466243532688
# 100   f(x): -44.546883|grad f(p)|:2.2561253654599445
# 150   f(x): -44.765220|grad f(p)|:1.3051578932969594
# 200   f(x): -44.824730|grad f(p)|:0.575815360373987

# Solver state for `Manopt.jl`s Gradient Descent
After 200 iterations

## Parameters
* retraction method: ExponentialRetraction()

## Stepsize
ArmijoLinesearch() with keyword parameters
  * initial_stepsize    = 1.0
  * retraction_method   = ExponentialRetraction()
  * contraction_factor  = 0.95
  * sufficient_decrease = 0.1

## Stopping Criterion
Stop When _one_ of the following are fulfilled:
    Max Iteration 200:  reached
    |grad f| &lt; 1.0e-8: not reached
Overall: reached
This indicates convergence: No

## Debug
    [(:Iteration, "# %-6d"), (:Cost, "f(x): %f"), (:GradientNorm, "|grad f(p)|:%s"), "\n", 50]</code></pre><p>From the final cost we can already see that <code>q1</code> is an eigenvector to the smallest eigenvalue we obtaines above.</p><p>And we can compare this to running with the Riemannian gradient, since the <a href="../../objectives/#ManoptExamples.RayleighQuotientGrad!!"><code>RayleighQuotientGrad!!</code></a> returns this one as well, when just called with the sphere as first Argument, we just have to remove the <code>objective_type</code>.</p><pre><code class="language-julia hljs">q2 = gradient_descent(M, f, grad_f, p0;
    debug = [:Iteration, :Cost, :GradientNorm, 50, "\n"],
)
#Test that both are the same
isapprox(M, q1,q2)</code></pre><pre><code class="nohighlight hljs">Initial f(x): -0.363357
# 50    f(x): -44.206244|grad f(p)|:2.3878466243532728
# 100   f(x): -44.546883|grad f(p)|:2.2561253654599707
# 150   f(x): -44.765220|grad f(p)|:1.305157893296953
# 200   f(x): -44.824730|grad f(p)|:0.5758153603739836

true</code></pre><p>We can also benchmark both</p><pre><code class="language-julia hljs">@benchmark gradient_descent($M, $f, $grad_f, $p0; objective_type=:Euclidean)</code></pre><pre><code class="nohighlight hljs">BenchmarkTools.Trial: 20 samples with 1 evaluation.
 Range (min … max):  250.950 ms … 270.166 ms  ┊ GC (min … max): 8.19% … 7.56%
 Time  (median):     252.998 ms               ┊ GC (median):    8.37%
 Time  (mean ± σ):   255.562 ms ±   5.390 ms  ┊ GC (mean ± σ):  8.34% ± 0.33%

  █▁▁█▁██    ▁  ▁▁▁   ▁▁                      ▁  ▁            ▁  
  ███████▁▁▁▁█▁▁███▁▁▁██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁█▁▁▁▁▁▁▁▁▁▁▁▁█ ▁
  251 ms           Histogram: frequency by time          270 ms &lt;

 Memory estimate: 1.13 GiB, allocs estimate: 3853.</code></pre><pre><code class="language-julia hljs">@benchmark gradient_descent($M, $f, $grad_f, $p0)</code></pre><pre><code class="nohighlight hljs">BenchmarkTools.Trial: 164 samples with 1 evaluation.
 Range (min … max):  29.807 ms … 37.447 ms  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     30.122 ms              ┊ GC (median):    0.00%
 Time  (mean ± σ):   30.602 ms ±  1.015 ms  ┊ GC (mean ± σ):  1.16% ± 1.83%

   ▃█▃                                                         
  ▄████▄▂▃▃▂▁▂▁▂▁▁▃▄▆▅▅▆▃▂▂▂▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂ ▂
  29.8 ms         Histogram: frequency by time        34.8 ms &lt;

 Memory estimate: 12.02 MiB, allocs estimate: 3246.</code></pre><p>We see, that the conversion costs a bit of performance, but if the Euclidean gradient is easier to compute, this might still be ok.</p><h3 id="A-Solver-based-(also)-on-(approximate)-Hessian-information"><a class="docs-heading-anchor" href="#A-Solver-based-(also)-on-(approximate)-Hessian-information">A Solver based (also) on (approximate) Hessian information</a><a id="A-Solver-based-(also)-on-(approximate)-Hessian-information-1"></a><a class="docs-heading-anchor-permalink" href="#A-Solver-based-(also)-on-(approximate)-Hessian-information" title="Permalink"></a></h3><p>To also involve the Hessian, we consider the <a href="https://manoptjl.org/stable/solvers/trust_regions/">trust regions</a> solver with three cases:</p><ol><li>Euclidean, approximating the Hessian</li><li>Euclidean, providing the Hessian</li><li>Riemannian, providing the Hessian but also using in-place evaluations.</li></ol><pre><code class="language-julia hljs">q3 = trust_regions(M, f, grad_f, p0; objective_type=:Euclidean,
    debug = [:Iteration, :Cost, :GradientNorm, 10, "\n"],
);</code></pre><pre><code class="nohighlight hljs">Initial f(x): -0.363357
# 10    f(x): -44.054570|grad f(p)|:9.520440806961885
# 20    f(x): -44.512159|grad f(p)|:3.8960976303377146
# 30    f(x): -44.750745|grad f(p)|:4.0172063476264075
# 40    f(x): -44.921406|grad f(p)|:4.0629541064444235
# 50    f(x): -44.944986|grad f(p)|:1.5625926334092841
# 60    f(x): -44.962671|grad f(p)|:1.4844829786311928
# 70    f(x): -44.981071|grad f(p)|:1.406186078892307
# 80    f(x): -44.998912|grad f(p)|:1.333230383118243
# 90    f(x): -45.016067|grad f(p)|:1.2712292976953228
# 100   f(x): -45.033852|grad f(p)|:1.2245396895601803
# 110   f(x): -45.054112|grad f(p)|:1.1949140426096447
# 120   f(x): -45.077761|grad f(p)|:1.181336063241073
# 130   f(x): -45.104051|grad f(p)|:1.1807084432424522
# 140   f(x): -45.131158|grad f(p)|:1.1891034869646029
# 150   f(x): -45.157245|grad f(p)|:1.2028717827098632
# 160   f(x): -45.181092|grad f(p)|:1.2191967547483598
# 170   f(x): -45.202141|grad f(p)|:1.2361671256155067
# 180   f(x): -45.220310|grad f(p)|:1.252614027690994
# 190   f(x): -45.235779|grad f(p)|:1.2678969023508213
# 200   f(x): -45.248841|grad f(p)|:1.2817199840828324
# 210   f(x): -45.256727|grad f(p)|:1.2916659158016648
# 220   f(x): -45.256727|grad f(p)|:1.2916659158016648
# 230   f(x): -45.256727|grad f(p)|:1.2916659157663253
# 240   f(x): -45.256727|grad f(p)|:1.2916659156249692
# 250   f(x): -45.256727|grad f(p)|:1.291665915483601
# 260   f(x): -45.256727|grad f(p)|:1.2916659153422445
# 270   f(x): -45.256727|grad f(p)|:1.291665915200879
# 280   f(x): -45.256727|grad f(p)|:1.2916659150595229
# 290   f(x): -45.256727|grad f(p)|:1.2916659149181455
# 300   f(x): -45.256727|grad f(p)|:1.291665914776787
# 310   f(x): -45.256727|grad f(p)|:1.2916659146354228
# 320   f(x): -45.256727|grad f(p)|:1.2916659144940739
# 330   f(x): -45.256727|grad f(p)|:1.2916659143526876
# 340   f(x): -45.256727|grad f(p)|:1.2916659142113394
# 350   f(x): -45.256727|grad f(p)|:1.2916659140699758
# 360   f(x): -45.256727|grad f(p)|:1.2916659139286075
# 370   f(x): -45.256727|grad f(p)|:1.2916659137872586
# 380   f(x): -45.256727|grad f(p)|:1.2916659136458828
# 390   f(x): -45.256727|grad f(p)|:1.2916659135045347
# 400   f(x): -45.256727|grad f(p)|:1.2916659133631683
# 410   f(x): -45.256727|grad f(p)|:1.2916659132218014
# 420   f(x): -45.256727|grad f(p)|:1.291665913080452
# 430   f(x): -45.256727|grad f(p)|:1.2916659129390704
# 440   f(x): -45.256727|grad f(p)|:1.2916659127977244
# 450   f(x): -45.256727|grad f(p)|:1.2916659126563357
# 460   f(x): -45.256727|grad f(p)|:1.2916659125149934
# 470   f(x): -45.256727|grad f(p)|:1.291665912373618
# 480   f(x): -45.256727|grad f(p)|:1.2916659122322556
# 490   f(x): -45.256727|grad f(p)|:1.2916659120908875
# 500   f(x): -45.256727|grad f(p)|:1.2916659119495382
# 510   f(x): -45.256727|grad f(p)|:1.2916659118081695
# 520   f(x): -45.256727|grad f(p)|:1.2916659116667941
# 530   f(x): -45.256727|grad f(p)|:1.2916659115254383
# 540   f(x): -45.256727|grad f(p)|:1.291665911384073
# 550   f(x): -45.256727|grad f(p)|:1.291665911242725
# 560   f(x): -45.256727|grad f(p)|:1.2916659111013584
# 570   f(x): -45.256727|grad f(p)|:1.2916659109599946
# 580   f(x): -45.256727|grad f(p)|:1.2916659108186235
# 590   f(x): -45.256727|grad f(p)|:1.2916659106772588
# 600   f(x): -45.256727|grad f(p)|:1.291665910535912
# 610   f(x): -45.256727|grad f(p)|:1.2916659103945327
# 620   f(x): -45.256727|grad f(p)|:1.291665910253165
# 630   f(x): -45.256727|grad f(p)|:1.2916659101118186
# 640   f(x): -45.256727|grad f(p)|:1.2916659099704497
# 650   f(x): -45.256727|grad f(p)|:1.291665909829113
# 660   f(x): -45.256727|grad f(p)|:1.29166590968772
# 670   f(x): -45.256727|grad f(p)|:1.2916659095463716
# 680   f(x): -45.256727|grad f(p)|:1.291665909404996
# 690   f(x): -45.256727|grad f(p)|:1.2916659092636467
# 700   f(x): -45.256727|grad f(p)|:1.2916659091222746
# 710   f(x): -45.256727|grad f(p)|:1.2916659089809122
# 720   f(x): -45.256727|grad f(p)|:1.2916659088395555
# 730   f(x): -45.256727|grad f(p)|:1.2916659086982
# 740   f(x): -45.256727|grad f(p)|:1.2916659085568292
# 750   f(x): -45.256727|grad f(p)|:1.2916659084154538
# 760   f(x): -45.256727|grad f(p)|:1.2916659082740989
# 770   f(x): -45.256727|grad f(p)|:1.2916659081327297
# 780   f(x): -45.256727|grad f(p)|:1.2916659079913815
# 790   f(x): -45.256727|grad f(p)|:1.291665907850015
# 800   f(x): -45.256727|grad f(p)|:1.291665907708641
# 810   f(x): -45.256727|grad f(p)|:1.2916659075672852
# 820   f(x): -45.256727|grad f(p)|:1.2916659074259267
# 830   f(x): -45.256727|grad f(p)|:1.2916659072845595
# 840   f(x): -45.256727|grad f(p)|:1.2916659071431842
# 850   f(x): -45.256727|grad f(p)|:1.2916659070018381
# 860   f(x): -45.256727|grad f(p)|:1.2916659068604721
# 870   f(x): -45.256727|grad f(p)|:1.2916659067191119
# 880   f(x): -45.256727|grad f(p)|:1.2916659065777438
# 890   f(x): -45.256727|grad f(p)|:1.29166590643638
# 900   f(x): -45.256727|grad f(p)|:1.2916659062950224
# 910   f(x): -45.256727|grad f(p)|:1.291665906153663
# 920   f(x): -45.256727|grad f(p)|:1.2916659060122988
# 930   f(x): -45.256727|grad f(p)|:1.2916659058709288
# 940   f(x): -45.256727|grad f(p)|:1.2916659057295612
# 950   f(x): -45.256727|grad f(p)|:1.2916659055882171
# 960   f(x): -45.256727|grad f(p)|:1.2916659054468413
# 970   f(x): -45.256727|grad f(p)|:1.2916659053054909
# 980   f(x): -45.256727|grad f(p)|:1.291665905164106
# 990   f(x): -45.256727|grad f(p)|:1.2916659050227592
# 1000  f(x): -45.256727|grad f(p)|:1.2916659048813917</code></pre><p>To provide the Hessian in the high-level interface we need to prodive it as an anonymous function, since any <code>struct</code> is considered to (eventually) be the also optional starting point. For space reasons, let’s also shorten the debug print to only iterations 7 and 14.</p><pre><code class="language-julia hljs">q4 = trust_regions(M, f, grad_f, (E, p, X) -&gt; Hess_f(E, p, X), p0; objective_type=:Euclidean,
    debug = [:Iteration, :Cost, :GradientNorm, 10, "\n"],
);</code></pre><pre><code class="nohighlight hljs">Initial f(x): -0.363357
# 10    f(x): -44.836478|grad f(p)|:1.681699351968465</code></pre><pre><code class="language-julia hljs">q5 = trust_regions(M, f, grad_f, (M, Y, p, X) -&gt; Hess_f(M, Y, p, X), p0;
    evaluation=InplaceEvaluation(),
    debug = [:Iteration, :Cost, :GradientNorm, 10, "\n"],
);</code></pre><pre><code class="nohighlight hljs">Initial f(x): -0.363357
# 10    f(x): -44.836478|grad f(p)|:1.681699351968463</code></pre><p>Let’s also here compare them in benchmarks. Let’s here compare all variants in their (more performant) in-place versions.</p><pre><code class="language-julia hljs">@benchmark trust_regions($M, $f, $grad_f, $p0;
  objective_type=:Euclidean,
  evaluation=InplaceEvaluation(),
)</code></pre><pre><code class="nohighlight hljs">BenchmarkTools.Trial: 9 samples with 1 evaluation.
 Range (min … max):  602.835 ms … 646.773 ms  ┊ GC (min … max): 8.37% … 8.50%
 Time  (median):     609.301 ms               ┊ GC (median):    8.52%
 Time  (mean ± σ):   616.099 ms ±  15.978 ms  ┊ GC (mean ± σ):  8.48% ± 0.21%

  █ ██  █ █  █        █                             █         █  
  █▁██▁▁█▁█▁▁█▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁█ ▁
  603 ms           Histogram: frequency by time          647 ms &lt;

 Memory estimate: 1.97 GiB, allocs estimate: 62496.</code></pre><pre><code class="language-julia hljs">@benchmark trust_regions($M, $f, $grad_f, $((E, Y, p, X) -&gt; Hess_f(E, Y, p, X)), $p0;
  evaluation=InplaceEvaluation(),
  objective_type=:Euclidean
)</code></pre><pre><code class="nohighlight hljs">BenchmarkTools.Trial: 196 samples with 1 evaluation.
 Range (min … max):  18.351 ms … 34.225 ms  ┊ GC (min … max): 6.69% … 7.02%
 Time  (median):     26.128 ms              ┊ GC (median):    9.13%
 Time  (mean ± σ):   25.502 ms ±  2.580 ms  ┊ GC (mean ± σ):  8.86% ± 2.29%

            ▂                  ▄▇█▅▃▂ ▁                        
  ▇▇▆▄▁▁▄▄▄██▁▆▄▁▄▄▁▄▇▄▄▄▁▄▆▁▄▄████████▁▄▁▁▆▁▁▁▄▁▁▁▄▁▁▁▄▁▁▁▁▄ ▄
  18.4 ms      Histogram: log(frequency) by time      33.1 ms &lt;

 Memory estimate: 43.63 MiB, allocs estimate: 5471.</code></pre><pre><code class="language-julia hljs">@benchmark trust_regions($M, $f, $grad_f, $((M, Y, p, X) -&gt; Hess_f(M, Y, p, X)), $p0;
    evaluation=InplaceEvaluation(),
)</code></pre><pre><code class="nohighlight hljs">BenchmarkTools.Trial: 427 samples with 1 evaluation.
 Range (min … max):  10.974 ms …  17.716 ms  ┊ GC (min … max): 0.00% … 9.23%
 Time  (median):     11.180 ms               ┊ GC (median):    0.00%
 Time  (mean ± σ):   11.719 ms ± 909.483 μs  ┊ GC (mean ± σ):  3.88% ± 5.40%

   ▂▃█▄                                                         
  ▄████▇▇▅▅▃▂▂▃▁▁▂▁▂▁▁▂▂▁▁▁▂▁▁▂▁▁▁▁▁▂▂▁▁▂▁▁▂▁▂▃▃▆▆▆▄▄▄▃▃▃▃▃▃▂▂ ▃
  11 ms           Histogram: frequency by time         13.2 ms &lt;

 Memory estimate: 13.15 MiB, allocs estimate: 5448.</code></pre><p>We see that Hessian approximation is quite costly, and Gradient and Hessian conversion somewhat costly; still, they also might serve as a good starting point, before deciding to delve into computing Riemannian gradients and Hessians.</p><p>Of course all 5 runs obtained solutions close by; one might consider the gradient based runs to not have fully converged.</p><pre><code class="language-julia hljs">[distance(M, q1, q) for q ∈ [q2,q3] ]</code></pre><pre><code class="nohighlight hljs">2-element Vector{Float64}:
 7.359460685640475e-16
 0.048053815279360104</code></pre><pre><code class="language-julia hljs">[distance(M, q3, q) for q ∈ [q4,q5] ]</code></pre><pre><code class="nohighlight hljs">2-element Vector{Float64}:
 0.08270031469111411
 0.08270031469111411</code></pre><p>Which we can also see in the final cost, comparing it to the Eigenvalue</p><pre><code class="language-julia hljs">[f(M, q) - λ for q ∈ [q1, q2, q3, q4, q5] ]</code></pre><pre><code class="nohighlight hljs">5-element Vector{Float64}:
  0.013874911807420176
  0.013874911807405965
 -0.41812208889417946
  3.552713678800501e-14
  3.552713678800501e-14</code></pre><h2 id="Summary"><a class="docs-heading-anchor" href="#Summary">Summary</a><a id="Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Summary" title="Permalink"></a></h2><p>We illustrated several possibilities to call solvers, with both Euclidean gradient and Hessian and Riemannian gradient and Hessian, allocating and in-place function. While the performance is better for the Riemannian case, the Euclidean one is a worthy alternative, when those are easier to compute.</p><h2 id="Literature"><a class="docs-heading-anchor" href="#Literature">Literature</a><a id="Literature-1"></a><a class="docs-heading-anchor-permalink" href="#Literature" title="Permalink"></a></h2><div class="citation noncanonical"><dl><dt>[Bou23]</dt><dd><div>N. Boumal. <a href="https://www.nicolasboumal.net/#book"><em>An Introduction to Optimization on Smooth Manifolds</em></a>. First Edition (<a href="https://doi.org/10.1017/9781009166164">Cambridge University Press, 2023</a>).</div></dd></dl></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../Difference-of-Convex-Frank-Wolfe/">« Frank Wolfe comparison</a><a class="docs-footer-nextpage" href="../Riemannian-mean/">Riemannian Mean »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label></p><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div><p></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Tuesday 12 December 2023 06:37">Tuesday 12 December 2023</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></HTML>